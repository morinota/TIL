<!-- タイトル: Feature Store調べてたらレイクハウスアーキテクチャと繋がったのでIcebergテーブルフォーマットについて調べた! パーティション戦略編! -->


## 1. TL;DR

- Icebergテーブルのクエリ性能を最大化するための重要な要素の一つが、**パーティショニング(partitioning)戦略**。
- Feature Storeのオフラインストアでは、**大量の特徴量レコードに対して高速かつ安価なクエリ**を実現できるかが、モデル品質改善やプロジェクト成功に直結するので重要。
- Icebergは従来のfolder-based (explicit) partitioningとは異なり、**hidden partitioning（メタデータ駆動型）**を採用。クエリ性能の向上や運用しやすさ、パーティション進化の柔軟性などのメリットがある。
- パーティション設計は「**よく使うWhere句とテーブルサイズから逆算**」が基本。時系列なら `day(event_time)` などから始めるのが無難。
- 高カーディナリティカラム（user_idやitem_idなど）はpartitionじゃなくてsort orderを使うべきかも。
  - まずそのままpartition keyにするのは、パーティション数が爆発しやすく現実的ではない。
  - `bucket(id, N)` は分割数を抑える妥協案ではあるが、ハッシュパーティショニングは値の近さを保持しないため、クエリ最適化の効果は限定的。
  - **むしろ高カーディナリティカラムは、partitioningではなくsort order機能の方でクエリ性能を向上させるのが有効なケースが多いのでは...!**:thinking:
- Icebergはパーティション進化が可能なため、最初は粗い粒度で始めて、データ量やクエリパターンに応じて洗練させていく方針が有効なのでは...!:thinking:


## 2. 導入: Icebergテーブルにおけるパーティショニング戦略って重要なの??

本記事は、Icebergテーブルフォーマットのパーティショニングの仕組み、パーティショニング戦略のtipsなどを調査した結果をまとめたものです。

- なぜIcebergテーブルフォーマットを??
  - 要約すると、自分はMLOpsに関心があってFeature Storeの本を読んでたら、オフラインストアの実装にレイクハウスアーキテクチャが採用されることが多いと書いてあったので、その中核技術であるIcebergテーブルフォーマットについて調べている、という感じ。
    - より詳細は、前回の記事([Feature Store調べてたらレイクハウスアーキテクチャと繋がったのでIcebergテーブルフォーマットについて調べた! スキーマ進化編!](https://qiita.com/morinota/items/a670abb84cf5aca480b2))へ!
- なぜIcebergのパーティショニング戦略を??
  - Feature Store (のオフラインストア) がビジネスで価値を発揮するための要件として、**大量or大きな特徴量レコード達に対してなるべく高速 & 安価なクエリ**を実現することが重要。
    - (注意点として、リアルタイムで低レイテンシアクセスできるほど高速、という意味ではないです!その役割はオフラインストアではなくオンラインストアが担うので。ここでは寧ろ、学習用/バッチ推論用に大きなデータセットを作成する際のクエリ性能の話をしてます!)
  - もし学習データセット作成時の**クエリが遅い or 高コストになってしまうと**、データサイエンティストが特徴量の探索やモデルのトレーニングを行う際のフィードバックループが遅くなってしまい、**結果的にモデルの品質向上やプロジェクトの成功に悪影響を与えてしまう可能性も高い**はず。
    - 特にMLプロジェクトの種類によっては、**データサイズの大きい埋め込み表現などのベクトル型の特徴量**を扱うことも多いので、何も気にしてないとクエリ性能が大幅に低下 or コスト爆増の可能性は十分に高いと思われる。
  - そして、**Icebergテーブルのクエリ性能を最大化するための重要な要素の一つに、パーティショニング(partitioning)戦略がある。**

## 3. Icebergのパーティショニングの仕組み (Hidden Partitioning) の話

Icebergのパーティショニングは、**hidden partitioning**と呼ばれるアプローチを採用してる。どうやらこれが結構いい感じらしいです...!:thinking:

### 3.1. そもそもpartitioningってどういう概念だっけという話。
- partitioning = 巨大なデータセットを**小さな複数のデータセットに分割**し、**キー属性に基づいて複数のパーティション(区画, 仕切り)に分配**するプロセス。
  - 全てのレコードは必ずどれか1つのパーティションに属する。
  - 各パーティションは、read / write を独立に実行でき、論理的には小さなデータベースのように振る舞う。
- なぜ分割したいのか??
  - 大規模データでは、テーブル全体スキャンは高コスト(I/Oの量, 時間, クラウド料金)
  - partitioningにより、クエリスコープを限定でき、不要なデータ塊をスキップできる(**partition pruning**と呼ばれる機能)
    - ex. `select ... where month(order_ts) = 10` みたいなクエリがあったときに、10月のパーティションだけを対象とすれば良いので、他の全ての関連しないファイル達をスキップできるようになる
- ちなみに...partitioningの分類: 水平 vs 垂直
  - 水平パーティショニング(Horizontal Partitioning, splitting rows): 
    - データセットを行単位で分割する方法。
  - 垂直パーティショニング(Vertical Partitioning, splitting columns):
    - データセットを列単位で分割する方法。
  - 大規模テーブルの場合は水平パーティショニングが一般的。
- ちなみに...一般的なpartitioning戦略
  - **範囲パーティショニング(Range Partitioning)**: 
    - 連続した値の範囲に基づいて行を分割する方法(ex. year/month/day)。時系列データと相性が良い。
  - **リストパーティショニング(List Partitioning)**: 
    - 明示的な値の集合に基づいて分割(ex. country=US/EU/JP)
  - **ハッシュパーティショニング(Hash Partitioning)**: 
    - ハッシュ関数を使用して行を分割(ex. user_idを16個のbucketに分割するみたいな)。
    - 注意点: **類似値を同じパーティションに配置するような挙動じゃないので、クエリ最適化の観点では効果は薄いらしい。**
  - **複合パーティショニング(Composite Partitioning)**: 
    - 複数戦略を組み合わせる方法(ex. 日付で範囲パーティショニングして、その中でさらにregionでリストパーティショニングするみたいな)。
- Partitioningがもたらすシステム的なメリット達:
  - Reducing query scope (クエリのスコープを限定できる)
  - Parallel processing (異なるパーティションに対して並列に読み書きできる)
  - High throughput (I/Oの効率化により高スループットを実現できる)
  - Scalability (複数マシンに異なるパーティションを分散できる)
  - Maintenance (古いパーティションをアーカイブしたり削除したりするのが簡単)
  - Availability (一部のパーティションが障害を起こしても、他のパーティションは利用可能なままにできる)

### 3.2. 従来 (Iceberg以前) のpartitioningの方法と問題点

- Icebergより前の従来のテーブルフォーマット(Hiveなど)のpartitioningの仕組みは **Folder-based(Explicit) Partitioning**と呼ばれるアプローチを採用。
  - ざっくり「**パーティション = ディレクトリ構造**」という仕組み!
- このFolder-based Partitioningの何がつらいのか??
  - 1. 手動管理つらい:
    - パーティション追加・修復の運用が大変。
  - 2. 柔軟性が低くてつらい:
    - パーティションスキームの変更が困難。既存データを再書き込みする必要があることも多い。
  - 3. クラウドでの大量のlist操作がつらい:
    - S3のようなオブジェクトストレージで、ディレクトリを大量に辿るのがクエリのボトルネックになりやすい。
  - 4. クエリがパーティションを意識する必要があってつらい:
    - クエリを書く人が、どのようにパーティションが切られているかを明確に理解し、適切にwhere句でパーティションキーを参照する必要がある。
      - ex. `select ... where month(order_ts) = 10` みたいなクエリを書けばpruningが効く。しかし、`select ... where order_ts >= '2023-10-01' and order_ts < '2023-11-01'` みたいなクエリを書いてしまうと、pruningが効かずに全てのパーティションをスキャンしてしまう。
  - 5. メタストアが肥大化してつらい:
    - パーティションが増えるほど、Glue catalogのようなメタストアが肥大化し、そこがクエリ性能のボトルネックになりやすい。

### 3.3. Icebergなどのモダンなpartitioningの方法と特徴

- Icebergは、伝統的なfolder-based partitioningから脱却して、**hidden partitioning (i.e. メタデータ駆動型アプローチ)**を採用。
  - 核となる思想は「Decouple partitioning from physical storage layout」。
    - つまりPartitioningを物理的なストレージレイアウトから切り離し、メタデータで管理するアプローチ。
  - パーティション情報はIcebergのメタデータファイル(manifestファイル)に保持される。
    - 具体的には、**各データファイルがどのパーティションに属するかの情報**が、メタデータファイルに保存される。
    - よってクエリ時の動作としては以下。
      - まず Query predicate (クエリのwhere句の条件) を解析。
      - 次に **メタデータファイルを参照して、条件を満たすパーティションに所属するデータファイル一覧を特定する。ここで高価なディレクトリのlist操作は発生しない!**
      - 最後に、特定されたデータファイルだけをスキャンする。
    - ↑はDirectory-based pruningに対してmetadata-driven file pruningと呼ばれるらしい。
- このhidden partitioningの重要な利点たち:
  - 1. パーティションカラムの詳細を意識しなくていい!
    - パーティション情報がテーブルメタデータに入ってるので、エンドユーザがクエリ内で物理的なディレクトリ構造を意識する必要がない。
  - 2. パーティション進化が楽。
    - パーティションスキームの変更が柔軟で、既存データを再書き込みする必要もない。
  - 3. list操作が不要でクエリ性能が向上。
    - S3のようなオブジェクトストレージでディレクトリを大量に辿る必要がないので、クエリ性能が大幅に向上する。

- Icebergのpartitioningの設定の流れ
  - 1. テーブル作成時
    - `PARTITIONED BY`句でパーティションの定義を宣言的(declarative)に指定する。
    - この際 Iceberg が提供する**組み込みの変換関数(transform functions)を使用**して定義する。以下が変換関数の一覧。
      - `identity(col)` - カラムの値をそのままパーティションキーにする。
      - `years(ts), month(ts), day(ts), hour(ts)` - タイムスタンプを年/月/日/時間粒度に変換してパーティションキーにする。
      - `bucket(N, col)` - カラムの値をN個のバケットにハッシュ分割してパーティションキーにする。
      - `truncate(L, col)` - カラムの値を先頭L文字・桁で切り捨ててパーティションキーにする。
  - 2. データ書き込み時
    - Iceberg が partition spec に基づいて変換関数を噛ませて**partition values を自動計算**。
    - データファイルを作成するとともに、各データファイルのpartition valueをメタデータファイルに登録する。
  - 3. データ読み込み(クエリ)時
    - クエリのwhere句の条件を解析。
    - メタデータファイルを参照して、条件を満たすパーティションに所属するデータファイル一覧を特定し、スキャンする。
  - 4. 必要に応じてパーティションスキームを変更する(Partition Evolution)
    - データ量や頻出のクエリパターンが変化してきたら、パーティションスキームを変更することも有効。
    - Icebergはパーティション進化が容易 (既存データを再書き込みする必要なし) なので。

- パーティション進化の挙動
  - 古いデータは古いパーティションスキームのまま、新しいデータは新しいパーティションスキームで書き込まれる。
  - クエリは自動的に両方のスキームを活用
  - データの書き換えは不要（Zero-Copy Evolution）

## 4. Icebergのパーティショニング戦略のtips

「**どのカラムをどう変換して分割すべきか**」を**クエリパターンから逆算**して設計するのが基本!

- 基本的には、「**よく使うWhere句(i.e. filter条件)**」と「**テーブルサイズ**」から決める感じ!
- (1) そもそもpartitionすべきかの判断!
  - 全体で1TB未満くらいのテーブルだったら、無理にpartition切らない方がシンプルで良いことも多いらしい。
    - **過剰に小さくパーティションが切られていると逆にクエリ性能が悪化する事もある**らしい。
      - (たぶんここで悪化するのはクエリ時間。スキャンする量は下がるはずなので、例えばAthenaの場合はコストが下がるはず...!:thinking:)
  - まあ**パーティション進化が容易なので、まずは粗い粒度から始めて、データの増加やクエリパターンの変化がある場合などに必要に応じて洗練させていく**のが良さそう...!!:thinking:
- (2) 時系列イベントテーブルなら...
  - まずは`day(event_time)`や`hour(event_time)`でpartition切るのが無難。
  - 1日にどれくらいデータ入るか見て、日次で多すぎるなら時間単位に、少なすぎるなら月単位を検討する感じ。
- (3) ユーザ/テナント単位のアクセスが多いなら...
  - 日付 + `bucket(user_id, 16)`みたいな、複合partitionを検討。
  - Nは「1partitionあたりの数百MB〜数GB」くらいに落ち着くように試す。
  - ただ個人的に、この `bucket()` という変換関数はあんまり意味ない気がしてる...!!:thinking:
    - **結局ハッシュに基づいて分割するだけなので、あんまりpartitioning pruningでクエリ性能を向上させるという効果は薄い**っぽい。
- (4) カラムのcardinalityを意識する
  - row cardinalityなカラム (ex. countryが数十種類) → `identity(country)`は全然あり。
  - high cardinalityなカラム (ex. user_idが数百万 ~ 数千万以上) → `bucket(16, user_id)`とか`truncate(3, user_id)`みたいに変換をかける。
    - ただ上述した理由で`bucket()`はあまり効果的じゃない気がしてる。**なのでhigh cardinalityなカラム、特にuser_idやitem_idなどの連番っぽいカラムは、partitioningではなくsort order機能の方でクエリ性能を向上させる、のが有効なのかな〜**と思ってる...!:thinking:
  - 基本的には、**低カーディナリティで比較的一様な分布を持つkey**がpartition keyに適してる。
    - 推奨されるkeyの例:
      - 時系列データ: `days(timestamp)`, `hours(timestamp)`
      - カテゴリカルデータ: `region`, `product_category`, `customer_segment`
      - 高カーディナリティ列の場合: `bucket(user_id, N)` (でもこれはハッシュパーティショニングなので個人的に微妙そう...!:thinking:)
    - 避けるべきkeyの例:
      - `user_id`, `transaction_id` などの高カーディナリティ列（バケット化を使わない場合）

## 5. 高カーディナリティなカラムのpartitioningについて思ってる事

- まず前提として、高カーディナリティなカラムをそのままpartition keyにするのは、パーティション数が爆発しやすく現実的ではない。それはそう。
- よって文献などでは`bucket(id, N)`は分割数を抑える妥協案として紹介されてることが多い。
- しかし、`bucket()`は謂わゆる**ハッシュパーティショニング**。これは**類似値を同じパーティションに配置するような挙動じゃない。**
- よって、特にuser_idやitem_idなどの連番っぽい高カーディナリティカラムに対して`bucket()`を使ってpartitioningしても、クエリ性能改善の効果はかなり限定的なのでは...!?と思ってる。
  - 例えば、`bucket(user_id, 16)`で16個のパーティションに分割してるとする。
    - 効果あるケース
      - ある1ユーザのデータを取得したい場合。
      - 16個のうち1個のパーティションだけをスキャンすれば良くなる、恩恵は得られる。
    - 効果ないケース
      - ある16人以上のユーザのデータを取得したい場合。
      - **16人のユーザがどのパーティションに分割されているかはランダム**なので、最悪の場合は16人全員が異なるパーティションに分割されている可能性がある。
      - そうすると、**クエリは結局16個のパーティション全てをスキャンする必要があるため、partition pruningが効かずクエリ性能の向上はほとんど得られない。**
  - 特にFeature Storeのオフラインストアのユースケースでは、**数十万 ~ 数百万ユーザを含む学習用(or バッチ推論用)データセットを作成したいことがほとんど**なので...
    - `bucket(user_id, N)`でNを一定大きめ(100とか1000とか)にしても、結局クエリはN個のパーティション全てをスキャンする必要があるため、クエリ性能の向上はほとんど得られなさそう。
    - 理論的には `bucket(user_id, 全ユーザ数)` とすれば1ユーザごとに完全に分割できるのでpruningの恩恵は得られるが、パーティション数が爆発してデータファイルの読み込みのオーバーヘッドが大きくなりすぎるため、どの道恩恵がなくなってしまうと思われる...!:thinking:
- なので、**むしろ高カーディナリティカラムは、partitioningではなくsort order機能の方でクエリ性能を向上させるのが有効なケースが多いのでは...!**:thinking:
  - という事で、次回はsort order機能周りについて調べてみた事を書こうと思っています:)

## 6. 参考資料

- [What is Hidden Partitioning in Apache Iceberg?](https://www.stackgazer.com/p/what-is-hidden-partitioning-in-apache-iceberg)
- [Iceberg Partitioning and Performance Optimization (Conduktor)](https://conduktor.io/glossary/iceberg-partitioning-and-performance-optimization)
- [Best Practices for Optimizing Apache Iceberg Performance (Starburst)](https://www.starburst.io/blog/best-practices-for-optimizing-apache-iceberg-performance/)
- [Iceberg Partitioning vs. Hive Partitioning](https://olake.io/iceberg/hive-partitioning-vs-iceberg-partitioning/)
