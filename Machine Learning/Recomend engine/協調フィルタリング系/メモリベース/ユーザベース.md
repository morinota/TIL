# ロジック

ユーザベースの協調フィルタリングのロジックは、いわゆるkNN回帰という機械学習手法になる。

kNN(k-Nearest-Neighbor、k近傍法)を簡単に説明すると、推定する対象に最も特徴が似ているk個の観測値を参考にし、値を推定しよう、というもの。
kNNは一般に分類問題に適用されることが多いが、オススメ度のような**連続値を推定する場合、明示的にkNN回帰**と呼ばれる。

# 手順

具体的な手順を見るため、映画のレビューサイトを題材として考える。（ユーザが自分が見た映画作品を評価付けできるサイト）

ここで、あるユーザ（鈴木さん）がまだ評価していない作品に対して協調フィルタリングを使って評価値を推定し、推定された評価の高い上位10作品（Top-Nレコメンド）をレコメンドするとする。

単純化すると、手順は以下のようになる。

1. 鈴木さんと似たような評価をしている（類似度の高い）ユーザを探す
2. 類似度の高い上位k人の評価を参考に、鈴木さんが評価していない映画の評価値を推定する
3. 推定評価値の高い上位10の映画を抽出する

これが典型的なユーザベース協調フィルタリングによるTop-N（ここではN=10）リスト作成手順。
また上記手順の1と2の部分が、kNN回帰による推定に該当する。

# 具体的な例

具体的な評価値を用いて推定してみる。

下記のような評価履歴（ユーザ-アイテムの評価値行列）があったとする。鈴木さんのダークナイト（The Dark Knight ;Batman）に対する評価値はいくつと推定できるだろうか。

| ユーザ   | 作品1 | 作品2 | 作品3 | 作品4 | ダークナイト |
| -------- | ----- | ----- | ----- | ----- | ------------ |
| 鈴木さん | 5     | 3     | 4     | 2     | ?            |
| ユーザ1  | 3     | 1     | 2     | 3     | 3            |
| ユーザ2  | 4     | 3     | 4     | 2     | 5            |
| ユーザ3  | 3     | 3     | 1     | 5     | 4            |
| ユーザ4  | 1     | 5     | 5     | 2     | 1            |

ぱっと見た感じ、鈴木さんの評価はユーザ2と似ている感じがしますが、どうでしょう。
**類似性を定量化するために、なんらかの類似度を算出する必要がある**。
ここでは、以下のユークリッド類似度（距離）を用いて類似度を計算してみます。（一旦、ここでは**類似度を単純に距離の逆数**として、以下のように書きました。普通は分母に1を足すっぽい??）

$$
sim_{euclid}(a, b) = \frac{1}{
    \sqrt{\sum_{y\in items}{(r_{ay} - r_{by})^2}}
    }
$$

| \\       | 鈴木さん  |
| -------- | --------- |
| 鈴木さん | 0.0000000 |
| ユーザ1  | 0.2773501 |
| ユーザ2  | 1.0000000 |
| ユーザ3  | 0.2132007 |
| ユーザ4  | 0.2182179 |

鈴木さん自身との類似度はなぜか0...。Infじゃないのね...

目安までにユークリッド距離に基づいた、鈴木さんと他のユーザ間の距離関数を図示しておく。
(各ユーザの円周上の位置（角度）はランダムなので意味はない)

![](https://cdn-ak.f.st-hatena.com/images/fotolife/b/bp-writer/20170111/20170111161605.png)

類似度が出たので、この中から鈴木さんと類似度の高いユーザを3人(k=3)選んで、ダークナイトに対する評価を推定する。

類似度の高い人の評価をより重視するために、下式のように類似度を重みとして3人の平均評価値（加重平均）をとる。

$$
\hat{r}_{ay} = \frac{
    \sum_{x\in N(a)}{sim(a,x) r_{xy}}
}{
    \sum_{x\in N(a)}{sim(a,x)}
}
$$

ここで

- $r_{xy}$をユーザxのアイテムyへの評価値
- $N(a)$はユーザaの最近傍ユーザ(k-nearest neighbor)の集合とする。

めでたく評価値が推定できました。推定されたダークナイトの評価値は4.0と高めなので、結構オススメのようです。

# 参考

- 後半
  - https://blog.brainpad.co.jp/entry/2017/02/03/153000
