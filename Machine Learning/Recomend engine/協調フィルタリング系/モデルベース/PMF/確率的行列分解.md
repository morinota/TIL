# 参考

- Probabilistic Matrix Factorization を導出して Edward で実装する
  - https://yamaguchiyuto.hatenablog.com/entry/2017/07/13/080000
- 確率的プログラミングライブラリ「Edward」まとめ
  - https://kamonohashiperry.com/archives/1293
- 元論文
  - https://proceedings.neurips.cc/paper/2007/file/d7322ed717dedf1eb4e6e52a37ea7bcd-Paper.pdf

# Probabilitic Matrix Factrization(確率的行列分解)とは??

行列分解は、確率的生成モデルとして解釈する事ができるらしい。
以下のモデルを考える。

## 1

全てのi = 1~Nについて、平均0, 分散$\frac{1}{\lambda}$の正規分布から$u_i$を生成する。(**各$u_i$は独立と解釈してる**...???)

$$
u_i \sim N(\mu=0, \sigma^2=\frac{1}{\lambda})
$$

## 2

全ての$j=1~M$について、平均0、分散$\frac{1}{\lambda}$の正規分布から$v_j$を生成する。

$$
v_j \sim N(\mu=0, \sigma^2=\frac{1}{\lambda})
$$

## 3

$(i, j) \in (i=1~N, j=1~M)$(=すべてのi,j組み合わせ)について、平均$u_i^T v_j$、分散$1$の(一次元)正規分布から$x_{ij}$を生成する。

$$
x_{ij} \sim N(\mu =u_i^T v_j, \sigma^2=1)
$$

## 推定

**与えられたデータ(Rating Matrix)がこのモデルから生成されたと考えて**、ユーザ因子行列$U$とアイテム因子行列$V$をMAP推定してみる。

$X$と$\lambda$が与えられた元での$U$と$V$の事後分布は、以下のように書ける。

$$
p(U, V|X, \lambda) \propto p(U, V, X|\lambda)
= p(X|U, V)p(U|\lambda)p(V|\lambda)
$$

これの対数を取ったものを

# Introduction

- 協調フィルタリングの最も一般的なアプローチの一つは、低次元因子モデルに基づくものである。このようなモデルの背後にある考え方は，ユーザの態度や嗜好は少数の未観測因子によって決定されるというものである．
- 線形因子モデルでは，ユーザーの嗜好は，ユーザー固有の係数を用いて項目因子ベクトルを線形結合することでモデル化される．例えば，N人のユーザとM本の映画について，N×Mの嗜好行列Rは，N×Dのユーザ係数行列U TとD×Mの因子行列Vの積で与えられる[7]．このようなモデルの学習は、与えられた損失関数のもとで、観測されたN×Mのターゲット行列Rの最良のランクD近似を見つけることになる。
- 最近、様々な確率的因子ベースモデルが提案されている[2, 3, 4]。これらのモデルは全て、隠れ因子変数がユーザー評価を表す変数に有向接続するグラフィカルモデルと見なすことができる。このようなモデルの主な欠点は厳密な推論が困難であること[12]であり，このようなモデルにおける隠れた因子に対する事後分布を計算するために，潜在的に遅いか不正確な近似が必要であることを意味している．
- 二乗和距離の最小化に基づく低ランクの近似は、特異値分解(SVD)を用いて求めることができる。SVDは、ターゲット行列Rに対する二乗総和距離を最小化する、与えられたランクの行列ˆ R = U T Vを見つけます。そのような場合、ターゲット行列Rの観測されたエントリに対してのみ、二乗総和距離が計算される。
- 9]が示すように、この一見小さな修正は、標準的なSVDの実装では解けない難しい非凸最適化問題を引き起こすことになります。また，近似行列ˆ R = U T V のランク，すなわち因子の数を制約する代わりに， [10] は U と V のノルムにペナルティを課すことを提案した．しかし，このモデルでの学習は，疎な半正定値計画（SDP）を解く必要があり，このアプローチは数百万の観測値を含むデータセットに対して実行不可能である．

## 既存手法の欠点

- Many of the collaborative filtering algorithms mentioned above have been applied to modelling user ratings on the Netflix Prize dataset that contains 480,189 users, 17,770 movies, and over 100 million observations (user/movie/rating triples).
- However, none of these methods have proved to be particularly successful for two reasons.
  - First, none of the above-mentioned approaches, except for the matrix-factorization-based ones, scale well to large datasets. 第一に，行列因数分解に基づくものを除いて，上記のアプローチはどれも大規模なデータセットにうまく対応できない．
  - Second, most of the existing algorithms have trouble making accurate predictions for users who have very few ratings. 第二に、既存のアルゴリズムのほとんどは、評価が非常に少ないユーザーに対して正確な予測を行うことが困難である。
- A common practice in the collaborative filtering community is to remove all users with fewer than some minimal number of ratings. 協調フィルタリングのコミュニティでは、最小限の評価数以下のユーザーをすべて削除することが一般的である。
- Consequently, the results reported on the standard datasets, such as MovieLens and EachMovie, then seem impressive because the most difficult cases have been removed. その結果、MovieLensやEachMovieなどの標準的なデータセットで報告された結果は、最も困難なケースが取り除かれているため、印象的なものに見えます。
- For example, the Netflix dataset is very imbalanced, with “infrequent” users rating less than 5 movies, while “frequent” users rating over 10,000 movies. 例えば、Netflixのデータセットは非常にバランスが悪く、「頻繁でない」ユーザーは5本以下の映画を評価し、「頻繁な」ユーザーは10,000本以上の映画を評価する。
- However, since the standardized test set includes the complete range of users, the Netflix dataset provides a much more realistic and useful benchmark for collaborative filtering algorithms.しかし、標準化されたテストセットにはあらゆるユーザーが含まれているため、Netflixデータセットは協調フィルタリングアルゴリズムにとって、より現実的で有用なベンチマークを提供することができます。

## 本論文の内容

- The goal of this paper is to present probabilistic algorithms that scale linearly with the number of observations and perform well on very sparse and imbalanced datasets, such as the Netflix dataset. 本論文の目的は、観測数に比例してスケールし、Netflixデータセットのような非常にまばらで不均衡なデータセットで良好に動作する確率的アルゴリズムを提示することである。
- In Section 2 we present the Probabilistic Matrix Factorization (PMF) model that models the user preference matrix as a product of two lower-rank user and movie matrices. セクション2では、ユーザープレファレンス行列を2つの低ランクのユーザ行列と映画行列の積としてモデル化する確率的行列因子分解（PMF）モデルを提示する。
- In Section 3, we extend the PMF model to include adaptive priors over the movie and user feature vectors and show how these priors can be used to control model complexity automatically. セクション3では、映画とユーザーの特徴ベクトルに対する適応的な事前分布を含むようにPMFモデルを拡張し、これらの事前分布を使用してモデルの複雑さを自動的に制御する方法を示す。
- In Section 4 we introduce a constrained version of the PMF model that is based on the assumption that users who rate similar sets of movies have similar preferences.セクション4では、類似の映画群を評価するユーザは類似の嗜好を持つという仮定に基づく、PMFモデルの制約版を導入する。
- In Section 5 we report the experimental results that show that PMF considerably outperforms standard SVD models.セクション5では、PMFが標準的なSVDモデルよりかなり優れていることを示す実験結果を報告する。
- We also show that constrained PMF and PMF with learnable priors improve model performance significantly. また、制約付きPMFと学習可能な事前分布を持つPMFがモデルの性能を著しく向上させることも示す。
- Our results demonstrate that constrained PMF is especially effective at making better predictions for users with few ratings.我々の結果は、制約付きPMFが、評価の少ないユーザに対してより良い予測を行うのに特に効果的であることを示している。

# Probabilistic Matrix Factorization (PMF)

- M本の映画、N人のユーザ、1〜$K^1$の整数値の評価値があるとする。
- $R_{ij}$はユーザiの映画jに対する評価を表し、$U\in \mathbb{R}^{D\times N}$と$V\in \mathbb{R}^{D\times M}$はそれぞれ、ユーザとアイテムの**潜在的特徴行列**である。
- また、列ベクトル$U_i$と$V_j$はそれぞれ、「ユーザ固有の潜在的特徴ベクトル」と「アイテム(映画)固有の潜在的特徴ベクトル」を表す。
- モデルの性能は**テスト集合における二乗平均平方根誤差（RMSE）の計算**によって測定される。
- よって我々はまず、ガウス観測ノイズを用いた確率的線形モデル(probabilistic linear model with Gaussian observation noise)を採用する。

![](/images/2022-06-19-16-23-19.png)

観測された評価に関する条件付き分布を、以下のように定義する。

$$
p(R|U, V, \sigma2) =
\prod_{i=1}^{N} \prod_{j=1}^{M} [N(R_{ij}|U_{i}^T V_{j}, \sigma^2)]^{I_{ij}}
\tag{1}
$$

where

- $N(x|\mu, \sigma^2)$ is the probability density function of the Gaussian distribution with mean μ and variance σ2
- $I_{ij}$はユーザーiが映画jを評価した場合は1に、それ以外は0に等しい指標関数

また、ユーザ特徴ベクトル$U_i$とアイテム特徴ベクトル$V_j$に対して、平均ベクトルを0ベクトルとした「Shperical Gaussian Priors(球形ガウス分布)(=**要は3次元以上の正規分布??**)」を**事前分布**として設定する。

$$
p(U|\sigma_U^2) = \prod_{i=1}^N N(U_i|\mathbf{0}, \sigma_U^2 I),\\
p(V|\sigma_V^2) = \prod_{j=1}^M N(V_j|\mathbf{0}, \sigma_V^2 I)
\tag{2}
$$

(**$\prod$を使ってるって事は、$U_i$間、$V_j$間は独立。$U_i$内の各要素がD次元正規分布に従うって解釈...!**)

ユーザと映画の特徴行列に対する事後分布の対数は次式で与えられる。

まず事後分布の式は式(1)(2)より...

$$
p(U, V|R, \sigma^2, \sigma_V^2, \sigma_U^2)
= \frac{
% まず尤度=(1)
p(R|U, V, \sigma2)
% 次に事前分布=(2)
p(U, V|\sigma_U^2, \sigma_V^2)
}{p(R, \sigma^2, \sigma_V^2, \sigma_U^2)(=Const)} \\
= \frac{
    p(R|U, V, \sigma2)
    % 事前分布の同時確率を積に分解(独立??)
    p(U|\sigma_U^2)
    p(V|\sigma_V^2)
    }{Const}
\\
\because \text{式(1), (2)を代入して...}
\\
= \frac{
    % 尤度関数
    \prod_{i=1}^{N} \prod_{j=1}^{M} [N(R_{ij}|U_{i}^T V_{j}, \sigma^2)]^{I_{ij}}
    % 事前分布
    \cdot \prod_{i=1}^N N(U_i|\mathbf{0}, \sigma_U^2 I)
    \cdot \prod_{j=1}^M N(V_j|\mathbf{0}, \sigma_V^2 I)
}{
    Const
}
\\
= \cdots (また今度展開頑張ってみる??)
$$

### 事後分布の導出時の考え方のアイデア！

上式は以下のように解釈したらわかりやすいかも！同時確率$p((U|\sigma_U^2), (V|\sigma_V^2), R, \sigma^2)$の２通りの分解！

$$
p((U|\sigma_U^2), (V|\sigma_V^2), R, \sigma^2)
= p((U|\sigma_U^2), (V|\sigma_V^2)|R, \sigma^2) \cdot p(R, \sigma^2)
\\
p((U|\sigma_U^2), (V|\sigma_V^2), R, \sigma^2)
= p(R, \sigma^2|(U|\sigma_U^2), (V|\sigma_V^2))
\cdot p((U|\sigma_U^2), (V|\sigma_V^2))
\\
\Leftrightarrow
p((U|\sigma_U^2), (V|\sigma_V^2)|R, \sigma^2) \cdot p(R, \sigma^2)
= p(R, \sigma^2|(U|\sigma_U^2), (V|\sigma_V^2))
\cdot p((U|\sigma_U^2), (V|\sigma_V^2))
\\
\Leftrightarrow
p((U|\sigma_U^2), (V|\sigma_V^2)|R, \sigma^2) =
\frac{
    p(R, \sigma^2|(U|\sigma_U^2), (V|\sigma_V^2))
\cdot p((U|\sigma_U^2), (V|\sigma_V^2))
}{p(R, \sigma^2)}
$$

### 事後分布の対数は...

$$
\ln p(U, V|R,\sigma^2, \sigma_V^2, \sigma_U^2) \\
% 尤度関数部分
= -\frac{1}{2\sigma^2}\sum_{i}^{N} \sum_{j}^{M} I_{ij}(R_{ij} - U_i^TV_j)^2
% 事前分布の部分
- \frac{1}{2\sigma_U^2}\sum_{i=1}^N U_i^T U_i
- \frac{1}{2\sigma_V^2}\sum_{j=1}^M V_j^T V_j
\\
% L2正則化項？？
- \frac{1}{2}(
    (\sum_{i}^{N} \sum_{j}^{M} I_{ij})\ln \sigma^2
    + ND \ln \sigma_U^2 + MD \ln \sigma_V^2
    )
+ Const
$$

ここで、Cはパラメータに依存しない定数である。
**ハイパーパラメータ（すなわち、観測ノイズ分散と事前分散）を固定**したまま、**映画とユーザー特徴上の対数事後分布を最大化**することは、以下の**二次正則化項を持つ二乗誤差和目的関数を最小化することと等価**である。
(やっぱり最後の項はL2正則化項！でもあくまで事後分布の式を対数化したら**結果としてL2正則化項と等価の項が出現してくるってことか！**)

$$
E = -\frac{1}{2\sigma^2}\sum_{i}^{N} \sum_{j}^{M} I_{ij}(R_{ij} - U_i^TV_j)^2 \\
+ \frac{\lambda_U}{2}\sum_{i}^{N}||U_i||_{Fro}^2
+ \frac{\lambda_V}{2}\sum_{j}^{M}||V_j||_{Fro}^2
\tag{4}
$$

ここで

- $\lambda_U = \sigma^2 / \sigma_U^2$
- $\lambda_V = \sigma^2 / \sigma_V^2$
- $||\cdot||_{Fro}$ denotes the Frobenius norm(https://manabitimes.jp/math/1284 参照)
  - ノルムはベクトルや行列の"長さ"の概念の一般化。ベクトル空間に対して「距離」を与える為の数学の道具。

UとVで勾配降下を行うことにより、式4で与えられる目的関数のローカルミニマムを求めることができる。

この実験では，単純な線形ガウスモデルでは**有効な評価値の範囲外まで予測できてしまう**ため，ユーザと映画の特徴ベクトルの内積(==つまり、**"評価行列"の推定値**)をロジスティック関数 g(x) = 1/(1 + exp(-x)) に渡して，予測範囲を限定している
(=>つまり、線形回帰＝＞一般化線形回帰ってこと？？)
g(x)を適用した場合の尤度関数は...

$$
p(R|U, V, \sigma2) =
\prod_{i=1}^{N} \prod_{j=1}^{M} [N(R_{ij}|\mu = g(U_{i}^T V_{j}), \sigma^2)]^{I_{ij}}
\tag{5}
$$

我々は、有効なレーティング値の範囲が我々のモデルが行う予測の範囲と一致するように、関数 $t(x) = (x - 1)/(K - 1) $を用いてレーティング1、...、Kを区間[0、1]にマッピングする。(**要するに、評価値の観測値も同じように0~1の値を取るようにする！って事か！**)

最急降下法を用いて上記の目的関数を最小化することは、**オブザベーションの数に線形な時間を要する**(=O(N)???)。このアルゴリズムをMatlabで簡単に実装すると、学習するモデルが30因子(**D=30**)である場合、Netflixデータセット全体を1時間未満で1回掃引することができるようになる。

# Automatic Complexity Control for PMF Model PMFモデルの自動複雑化制御

## 容量制御の話

- PMFモデルをうまく汎化するためには、容量制御が不可欠である。
  - 十分な数の因子があれば、PMFモデルは任意の行列を任意にうまく近似することができる。
  - PMFモデルの容量を制御する最も簡単な方法は、特徴ベクトルの次元を変更することである。
- しかし、データセットがアンバランスな場合、つまり、オブザベーションの数が異なる行または列で大きく異なる場合、このアプローチは失敗する。
  - なぜなら、任意の1つの特徴次元数は、ある特徴ベクトルには高すぎ、他の特徴ベクトルには低すぎるからである。
  - 上で定義したλUやλVなどの正則化パラメータは、正則化に対してより柔軟なアプローチを提供します。
  - これらの**パラメータの適切な値を見つける最も簡単な方法**は、妥当なパラメータ値のセットを検討し、セット内のパラメータの各設定に対してモデルを訓練し、検証セットで最も良く機能するモデルを選択することであろう。
  - この方法の主な欠点は、単一のモデルを学習する代わりに、多数のモデルを学習する必要があるため、計算コストがかかることである。
- 本論文では、もともと**ニューラルネットワークに適用されていた[6]の方法**を用いて、PMFモデルの正則化パラメータの適切な値を、**モデルの学習に要する時間に大きな影響を与えずに自動的に決定**することができることを示す。

## ではどうやって?

- 上に示したように、L2意味での行列を、そのフロベニウスノルムにペナルティをかけることで正則化された2つの低ランク行列の積で近似する問題は、**低ランク行列の行に球状ガウス事前分布を持つ確率モデルにおけるMAP推定**と見なすことができます。
  - このモデルの複雑さは、ハイパーパラメータ（ノイズ分散σ2と事前分布のパラメータ（上記のσ2 Uとσ2 V））によって制御されます。
  - ハイパーパラメータの事前分布を導入し、[6]で提案されているように、パラメータとハイパーパラメータの両方についてモデルの対数事後分布を最大化することにより、学習データに基づいてモデルの複雑さを自動的に制御することができる。
  - このフレームワークでユーザと映画の特徴ベクトルに対して球形事前分布を用いると、**λUとλVが自動的に選択されるPMFの標準的な形**になる。
- この正則化のアプローチにより、特徴行列のフロベニウスノルムの単純な罰則化よりも洗練された方法を用いることができる。
  - 例えば，対角共分散行列や完全共分散行列，特徴ベクトルに対する調整可能な平均を持つ事前分布を利用することができる．
  - ガウシアン混合分布の事前分布も簡単に扱うことができる。

## 要するに...

要約すると，次の式で与えられるlog posterior(事後分布の対数)を最大化(=MAP推定!)することで，パラメータとハイパーパラメータの点推定値を求めることができる。

$$
\ln p(U,V, \sigma^2, \Theta_U, \Theta_V|R) \\
= \ln p(R|U,V, \sigma^2) + \ln p(U|\Theta_U) + \ln p(V|\Theta_V) \\
+ \ln p(\Theta_U) + \ln p(\Theta_V) + C
\tag{6}
$$

where

- ΘU and ΘV are the hyperparameters for the priors over user and movie feature vectors respectively それぞれユーザーと映画の特徴ベクトルに対する事前分布のハイパーパラメータ。
- C is a constant that does not depend on the parameters or hyperparameters.

When the prior is Gaussian, the optimal hyperparameters can be found in closed form if the movie and user feature vectors are kept fixed. 事前分布がガウス分布の場合、映画とユーザの特徴ベクトルを固定すれば、最適なハイパーパラメータが閉形式で求まる。

Thus to simplify learning we alternate between optimizing the hyperparameters and updating the feature vectors using steepest ascent with the values of hyperparameters fixed. したがって，学習を単純化するために，**ハイパーパラメータの最適化と，ハイパーパラメータの値を固定したまま急勾配で特徴ベクトルを更新することを交互に行う**．

When the prior is a mixture of Gaussians, the hyperparameters can be updated by performing a single step of EM. 事前分布がガウシアンの混合である場合、ハイパーパラメータはEMを1ステップ実行することにより更新することができる。

In all of our experiments we used improper priors for the hyperparameters, but it is easy to extend the closed form updates to handle conjugate priors for the hyperparameters.我々の全ての実験では、ハイパーパラメータに不適切な事前分布(=要するに共役でない事前分布！笑)を用いたが、閉形式の更新を拡張してハイパーパラメータに共役事前分布を扱うことは容易である。

# Constrained PMF 制約条件付きPMF

PMFモデルが適合されると、**評価が非常に少ないユーザは事前平均、つまり平均ユーザに近い特徴ベクトルを持つことになり**、**それらのユーザの予測評価は映画の平均評価に近くな**る。このセクションでは、ユーザー固有の特徴ベクトルを制約する追加的な方法として、**頻度の低いユーザーに強い影響を与える方法**を紹介する。

$W \in \mathbb{R}^{D\times M}$を潜在的な類似性制約行列(latent similarity constraint matrix)とする。この場合、ユーザiの特徴ベクトルを以下のように定義する。

$$
U_i = Y_i + \frac{\sum_{k=1}^M I_{ik}W_k}{\sum_{k=1}^M I_{ik}} \tag{7}
$$

where

- $I$は観測指標行列(Observed indicator matrix)であり、$I_{ij}$はユーザiが映画jを評価した場合に1, そうでない場合に0を取る。
- W:
  - 直感的には、行列Wの第i列は、あるユーザが特定の映画を評価した事が、そのユーザの特徴ベクトル$U_i$の事前平均に与える影響を捉えている。
  - その結果、**同じ(または類似の)映画を見たユーザは、その特徴ベクトルの事前分布が類似する**事になる。
- $Y_i$は、ユーザiの特徴ベクトル$U_i$を得る為に、事前分布の平均に加えられたオフセット項と見ることができる。
  - オフセット項(https://www.datarobot.com/jp/blog/using-offset-term-to-incorporate-business-logic-into-machine-learning-models/)
  - 定数項の事??似てるけど多分違う。定数項は推定されるパラメータだけど、オフセット項はパラメータではなく事前に分析者が設定する値？？
- 制約のないPMFモデルでは、事前平均が0に固定されているため、UiとYiは等しい（図1参照）。

ここで、式(7)を式(5)に代入して、観測された評価行列に対する条件付き分布(＝尤度関数)を次のように定義される。

$$
p(R|Y, V, W, \sigma^2) =
\prod_{i=1}^{N} \prod_{j=1}^{M} [N(R_{ij}|\mu = g(U_{i}^T V_{j}), \sigma^2)]^{I_{ij}} \\
=
\prod_{i=1}^{N} \prod_{j=1}^{M} [N(R_{ij}|\mu = g((Y_i + \frac{\sum_{k=1}^M I_{ik}W_k}{\sum_{k=1}^M I_{ik}})^T V_{j}), \sigma^2)]^{I_{ij}}
\tag{8}
$$

We regularize the latent similarity constraint matrix W by placing a zero-mean spherical Gaussian prior on it:また、潜在的な類似性制約行列Wに対してゼロ平均の球形ガウス**事前分布**を設定し、正則化する

$$
p(W|\sigma_W) = \prod_{k=1}^{M} N(W_k|\mu=0, \Omega=\sigma^2_W I) \tag{9}
$$

PMFモデル(section 2のやつ)と同様に、対数事後分布を最大化することは、以下の、二次正則化項を用いた二乗誤差の総和関数を最小化することと等価である。

$$
E = \frac{1}{2} \sum_{i=1}^{N} \sum_{j=1}^M
I_{ij} \cdot
(R_ij - g([Y_i + \frac{\sum_{k=1}^M I_{ik}W_k}{\sum_{k=1}^M I_{ik}}]^T \cdot V_j))^2
\\
+ \frac{\lambda_Y}{2} \sum_{i=1}^N ||Y_i||^2_{Fro}
+ \frac{\lambda_V}{2} \sum_{j=1}^M ||V_j||^2_{Fro}
+ \frac{\lambda_W}{2} \sum_{k=1}^M ||W_k||^2_{Fro}
\tag{10}
$$

ここで、

- $\lambda_Y = \frac{\sigma^2}{\sigma_Y^2}$
- $\lambda_W = \frac{\sigma^2}{\sigma_W^2}$

そして、Y 、V 、W において**勾配降下**を行い、式 10 で与えられる目的関数を最小化することができる。制約付きPMFモデルの**学習時間は観測値数に対して線形にスケール**するため、高速かつシンプルな実装が可能である。実験結果のセクションで示すように、このモデルは、**特に頻度の低いユーザーに対して、単純な制約なしPMFモデルよりかなり良い性能を発揮する**。

# Experimental Results 実験結果

## Description of the Netflix Data ネットフリックスデータの説明

- Netflixによると、このデータは1998年10月から2005年12月の間に収集され、この期間にNetflixが得たすべての評価の分布を表しています。
  - 学習用データセットは、ランダムに選ばれた480,189人の匿名ユーザーが17,770の映画タイトルに対して行った100,480,507件の評価から構成されています。
  - トレーニングデータの一部として、Netflixは1,408,395のレーティングを含む検証データも提供しています。
- 学習データと検証データに加え、Netflixは2,817,131のユーザーと映画のペアを含むテストセットも提供し、レーティングは伏せられています。
  - このペアは、トレーニングデータセットに含まれるユーザーのサブセットに対する最新のレーティングから選択されたものです。
  - 機械学習の文献にある多くの経験的比較に見られる、テストセットへの意図しないオーバーフィッティングを減らすため、性能は予測された評価をNetflixに提出し、Netflixがテストセットの未知の半分の平均平方根誤差（RMSE）を投稿することで評価されます。
  - ベースラインとして、Netflixは同じデータで学習した独自のシステムのテストスコアを提供し、それは0.9514であった。

To provide additional insight into the performance of different algorithms we created a smaller and much more difficult dataset from the Netflix data by randomly selecting 50,000 users and 1850 movies.
異なるアルゴリズムの性能に関するさらなる洞察を得るために、我々はNetflixのデータから**50,000ユーザと1850映画をランダムに選択**し、**より小さく、より困難なデータセットを作成し**た。
The toy dataset contains 1,082,982 training and 2,462 validation user/movie pairs. Over 50% of the users in the training dataset have less than 10 ratings.
このトイ・データセットには1,082,982のトレーニングデータと2,462の検証用ユーザー/ムービー・ペアが含まれています。トレーニングデータセットの50%以上のユーザは10レーティング以下(rating回数?)である．

## Details of Training 学習の詳細

To speed-up the training, instead of performing batch learning we subdivided the Netflix data into mini-batches of size 100,000 (user/movie/rating triples), and updated the feature vectors after each mini-batch.
学習速度を上げるために、バッチ学習ではなく、Netflixのデータを10万個のミニバッチ（ユーザー／映画／評価のトリプル）に細分化し、ミニバッチごとに特徴ベクトルを更新しています。

After trying various values for the learning rate and momentum and experimenting with various values of D, we chose to use a learning rate of 0.005, and a momentum of 0.9, as this setting of parameters worked well for all values of D we have tried.
学習率と運動量の値をいろいろと試し、Dの値もいろいろと試した結果、学習率0.005、運動量0.9を選択しました。このパラメータ設定は、これまで試したDのすべての値でうまく機能したからです。

## Results for PMF with Adaptive Priors 適応的事前分布によるPMFの結果

- 適応的プライヤーを持つPMFモデルの性能を評価するために、我々は10次元(k=10)の特徴を持つモデルを使用した。
  - この次元は、特徴の次元が比較的低い場合でも、SVDのようなモデルがオーバーフィットする可能性があること、また、このようなモデルを自動的に正則化することによって、何らかの性能向上が得られることを示すために選択されたものである。
- 我々は、SVDモデル、2つの固定プライヤーを持つPMFモデル、適応的プライヤーを持つ2つのPMFモデルを比較した。
  - SVDモデルは、ターゲット行列の観測されたエントリに対する二乗和距離のみを最小化するように学習される。
  - SVDモデルの特徴ベクトルはどのような方法でも正則化されていない。
  - 2つの固定優先PMFモデルは正則化パラメータが異なり、一方（PMF1）はλU = 0.01, λV = 0.001 であり、もう一方（PMF2）はλU = 0.001, λV = 0.0001 であった。
  - 適応的事前分布を持つ最初のPMFモデル（PMFA1）は、ユーザーと映画の特徴ベクトルに対して球形の共分散行列を持つガウス型事前分布を持ち、2番目のモデル（PMFA2）は対角共分散行列を持つものであった。
    - 球形sphericalも対角共分散行列。対角成分の値が等しいのがshperical??
  - どちらの場合も、適応的事前分布は調整可能な平均を持つ。
- 事前パラメータとノイズの共分散は、それぞれ10回と100回の特徴行列の更新ごとに更新された。検証セットにおけるRMSEに基づき、両モデルが比較された。

The results of the comparison are shown on Figure 2 (left panel). 比較した結果を図2（左図）に示す。

なお、球面共分散を用いたPMFモデルの曲線は、対角共分散を用いたモデルの曲線とほぼ同じであるため、示していない。

学習期間中に達成された最も低いRMSEに基づいてモデルを比較すると、SVDモデルは適度に正則化されたPMFモデル（PMF2）とほぼ同じ結果（0.9258対0.9253）ですが、学習の終盤にひどくオーバーフィットしていることがわかります。
PMF1はオーバーフィットしないものの、RMSEが0.9430となり、明らかにアンダーフィットしています。
適応的事前分布を持つモデルは、RMSEが0.9197（対角共分散）、0.9204（球形共分散）となり、競合モデルより明らかに優れていることがわかりました。
これらの結果は、**適応的事前分布による自動正則化が実際にうまく機能することを示唆している**。

さらに、高次元の特徴ベクトルを持つモデルに対する予備的な結果は、特徴ベクトルの次元が大きくなるにつれて、適応的事前分布の使用による性能差が大きくなる可能性があることを示唆している。

対角共分散行列の使用は球形共分散行列に対する大きな改善には至らなかったが、対角共分散は、特徴ベクトルを一度に1次元ずつ学習するPMF学習アルゴリズムの貪欲版の自動正則化に適している可能性がある。

## Results for Constrained PMF 制約付きPMFの結果

- For experiments involving constrained PMF models, we used 30D features (D = 30), since this choice resulted in the best model performance on the validation set.
- 制約付きPMFモデルを含む実験では、30D特徴量（D = 30）を使用し、この選択が検証セットで最良のモデル性能をもたらしたからである。
- Dの値が[20, 60]の範囲であれば、同様の結果を得ることができる。


図3は、トイデータセットに対するSVD、PMF、制約付きPMFの性能結果である。特徴ベクトルの初期化値は3モデルとも同じである。

PMFと制約付きPMFの両モデルにおいて、正則化パラメータはλU = λY = λV = λW = 0.002に設定された。**単純なSVDモデルは大きくオーバーフィットすることが明らか**。
制約付きPMFモデルは、制約なしPMFモデルよりもはるかに性能がよく、収束もかなり速い。

図3（右図）は、ユーザー固有の特徴を制約することで、使用頻度の低いユーザーの予測に与える効果を示している。
トレーニングデータセット中の評価が5つ以下のユーザグループに対するPMFモデルの性能は、各映画の平均評価を常に予測する映画平均アルゴリズムと実質的に同じである。
しかし、**制約付きPMFモデルは、レーティング数が少ないユーザに対してかなり良いパフォーマンスを示す**。
レーティングの数が増加するにつれて、PMFと制約付きPMFの両方が同様の性能を示す。

### 制約付きPMFの面白い側面
制約付きPMFモデルの他の興味深い点は、**ユーザがどの映画を評価したかだけを知っていて、評価の値を知らない場合でも、このモデルは映画平均モデルよりも良い予測をすることができる**ということです。

toyデータセットでは、さらに5万人のユーザーをランダムにサンプリングし、それぞれのユーザーについて、そのユーザーが評価した映画のリストをコンパイルし、実際の評価は破棄した。検証セットでは、単純な映画平均モデルのRMSEが1.0726であったのに対し、制約付きPMFモデルは1.0510を達成しました。

この実験から、ユーザーがどの映画を評価したかだけを知り、実際の評価を知らない場合でも、そのユーザーの嗜好をよりよくモデル化することができることが強く示唆された。


# Summary and Discussion

In this paper we presented Probabilistic Matrix Factorization (PMF) and its two derivatives: PMF with a learnable prior and constrained PMF. 本論文では、確率的行列因子法(PMF)とその派生型である学習可能事前分布を用いたPMFと制約付きPMFを紹介した。PMFは学習可能な事前分布を持つPMFと制約付きPMFである。

We also demonstrated that these models can be efficiently trained and successfully applied to a large dataset containing over 100 million movie ratings. また、これらのモデルが効率的に学習され、1億以上の映画評価を含む大規模データセットにうまく適用できることを示した。

Efficiency in training PMF models comes from finding only point estimates of model parameters and hyperparameters, instead of inferring the full posterior distribution over them. PMFモデルの効率的な学習は、モデルパラメータとハイパーパラメータの事後分布を推定するのではなく、点推定値のみを求めることによって実現される。

If we were to take a fully Bayesian approach, we would put hyperpriors over the hyperparameters and resort to MCMC methods [5] to perform inference. もし、完全にベイズ的なアプローチを取るとしたら、ハイパーパラメータにハイパープリオールをかけ、MCMC法[5]に頼って推論を行うことになります。
****
While this approach is computationally more expensive, preliminary results strongly suggest that a fully Bayesian treatment of the presented PMF models would lead to a significant increase in predictive accuracy.このアプローチは計算コストが高くつくが、予備的な結果は、提示されたPMFモデルの完全なベイズ的取り扱いが、予測精度を大幅に向上させることを強く示唆している。

