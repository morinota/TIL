# 参考

- Probabilistic Matrix Factorization を導出して Edward で実装する
  - https://yamaguchiyuto.hatenablog.com/entry/2017/07/13/080000
- 確率的プログラミングライブラリ「Edward」まとめ
  - https://kamonohashiperry.com/archives/1293
- 元論文
  - https://proceedings.neurips.cc/paper/2007/file/d7322ed717dedf1eb4e6e52a37ea7bcd-Paper.pdf

# Probabilitic Matrix Factrization(確率的行列分解)とは??

行列分解は、確率的生成モデルとして解釈する事ができるらしい。
以下のモデルを考える。

## 1

全てのi = 1~Nについて、平均0, 分散$\frac{1}{\lambda}$の正規分布から$u_i$を生成する。(**各$u_i$は独立と解釈してる**...???)

$$
u_i \sim N(\mu=0, \sigma^2=\frac{1}{\lambda})
$$

## 2

全ての$j=1~M$について、平均0、分散$\frac{1}{\lambda}$の正規分布から$v_j$を生成する。

$$
v_j \sim N(\mu=0, \sigma^2=\frac{1}{\lambda})
$$

## 3

$(i, j) \in (i=1~N, j=1~M)$(=すべてのi,j組み合わせ)について、平均$u_i^T v_j$、分散$1$の(一次元)正規分布から$x_{ij}$を生成する。

$$
x_{ij} \sim N(\mu =u_i^T v_j, \sigma^2=1)
$$

## 推定

**与えられたデータ(Rating Matrix)がこのモデルから生成されたと考えて**、ユーザ因子行列$U$とアイテム因子行列$V$をMAP推定してみる。

$X$と$\lambda$が与えられた元での$U$と$V$の事後分布は、以下のように書ける。

$$
p(U, V|X, \lambda) \propto p(U, V, X|\lambda)
= p(X|U, V)p(U|\lambda)p(V|\lambda)
$$

これの対数を取ったものを

# Introduction

- 協調フィルタリングの最も一般的なアプローチの一つは、低次元因子モデルに基づくものである。このようなモデルの背後にある考え方は，ユーザの態度や嗜好は少数の未観測因子によって決定されるというものである．
- 線形因子モデルでは，ユーザーの嗜好は，ユーザー固有の係数を用いて項目因子ベクトルを線形結合することでモデル化される．例えば，N人のユーザとM本の映画について，N×Mの嗜好行列Rは，N×Dのユーザ係数行列U TとD×Mの因子行列Vの積で与えられる[7]．このようなモデルの学習は、与えられた損失関数のもとで、観測されたN×Mのターゲット行列Rの最良のランクD近似を見つけることになる。
- 最近、様々な確率的因子ベースモデルが提案されている[2, 3, 4]。これらのモデルは全て、隠れ因子変数がユーザー評価を表す変数に有向接続するグラフィカルモデルと見なすことができる。このようなモデルの主な欠点は厳密な推論が困難であること[12]であり，このようなモデルにおける隠れた因子に対する事後分布を計算するために，潜在的に遅いか不正確な近似が必要であることを意味している．
- 二乗和距離の最小化に基づく低ランクの近似は、特異値分解(SVD)を用いて求めることができる。SVDは、ターゲット行列Rに対する二乗総和距離を最小化する、与えられたランクの行列ˆ R = U T Vを見つけます。そのような場合、ターゲット行列Rの観測されたエントリに対してのみ、二乗総和距離が計算される。
- 9]が示すように、この一見小さな修正は、標準的なSVDの実装では解けない難しい非凸最適化問題を引き起こすことになります。また，近似行列ˆ R = U T V のランク，すなわち因子の数を制約する代わりに， [10] は U と V のノルムにペナルティを課すことを提案した．しかし，このモデルでの学習は，疎な半正定値計画（SDP）を解く必要があり，このアプローチは数百万の観測値を含むデータセットに対して実行不可能である．

## 既存手法の欠点

- Many of the collaborative filtering algorithms mentioned above have been applied to modelling user ratings on the Netflix Prize dataset that contains 480,189 users, 17,770 movies, and over 100 million observations (user/movie/rating triples).
- However, none of these methods have proved to be particularly successful for two reasons.
  - First, none of the above-mentioned approaches, except for the matrix-factorization-based ones, scale well to large datasets. 第一に，行列因数分解に基づくものを除いて，上記のアプローチはどれも大規模なデータセットにうまく対応できない．
  - Second, most of the existing algorithms have trouble making accurate predictions for users who have very few ratings. 第二に、既存のアルゴリズムのほとんどは、評価が非常に少ないユーザーに対して正確な予測を行うことが困難である。
- A common practice in the collaborative filtering community is to remove all users with fewer than some minimal number of ratings. 協調フィルタリングのコミュニティでは、最小限の評価数以下のユーザーをすべて削除することが一般的である。
- Consequently, the results reported on the standard datasets, such as MovieLens and EachMovie, then seem impressive because the most difficult cases have been removed. その結果、MovieLensやEachMovieなどの標準的なデータセットで報告された結果は、最も困難なケースが取り除かれているため、印象的なものに見えます。
- For example, the Netflix dataset is very imbalanced, with “infrequent” users rating less than 5 movies, while “frequent” users rating over 10,000 movies. 例えば、Netflixのデータセットは非常にバランスが悪く、「頻繁でない」ユーザーは5本以下の映画を評価し、「頻繁な」ユーザーは10,000本以上の映画を評価する。
- However, since the standardized test set includes the complete range of users, the Netflix dataset provides a much more realistic and useful benchmark for collaborative filtering algorithms.しかし、標準化されたテストセットにはあらゆるユーザーが含まれているため、Netflixデータセットは協調フィルタリングアルゴリズムにとって、より現実的で有用なベンチマークを提供することができます。

## 本論文の内容

- The goal of this paper is to present probabilistic algorithms that scale linearly with the number of observations and perform well on very sparse and imbalanced datasets, such as the Netflix dataset. 本論文の目的は、観測数に比例してスケールし、Netflixデータセットのような非常にまばらで不均衡なデータセットで良好に動作する確率的アルゴリズムを提示することである。
- In Section 2 we present the Probabilistic Matrix Factorization (PMF) model that models the user preference matrix as a product of two lower-rank user and movie matrices. セクション2では、ユーザープレファレンス行列を2つの低ランクのユーザ行列と映画行列の積としてモデル化する確率的行列因子分解（PMF）モデルを提示する。
- In Section 3, we extend the PMF model to include adaptive priors over the movie and user feature vectors and show how these priors can be used to control model complexity automatically. セクション3では、映画とユーザーの特徴ベクトルに対する適応的な事前分布を含むようにPMFモデルを拡張し、これらの事前分布を使用してモデルの複雑さを自動的に制御する方法を示す。
- In Section 4 we introduce a constrained version of the PMF model that is based on the assumption that users who rate similar sets of movies have similar preferences.セクション4では、類似の映画群を評価するユーザは類似の嗜好を持つという仮定に基づく、PMFモデルの制約版を導入する。
- In Section 5 we report the experimental results that show that PMF considerably outperforms standard SVD models.セクション5では、PMFが標準的なSVDモデルよりかなり優れていることを示す実験結果を報告する。
- We also show that constrained PMF and PMF with learnable priors improve model performance significantly. また、制約付きPMFと学習可能な事前分布を持つPMFがモデルの性能を著しく向上させることも示す。
- Our results demonstrate that constrained PMF is especially effective at making better predictions for users with few ratings.我々の結果は、制約付きPMFが、評価の少ないユーザに対してより良い予測を行うのに特に効果的であることを示している。

# Probabilistic Matrix Factorization (PMF)

- M本の映画、N人のユーザ、1〜$K^1$の整数値の評価値があるとする。
- $R_{ij}$はユーザiの映画jに対する評価を表し、$U\in \mathbb{R}^{D\times N}$と$V\in \mathbb{R}^{D\times M}$はそれぞれ、ユーザとアイテムの**潜在的特徴行列**である。
- また、列ベクトル$U_i$と$V_j$はそれぞれ、「ユーザ固有の潜在的特徴ベクトル」と「アイテム(映画)固有の潜在的特徴ベクトル」を表す。
- モデルの性能は**テスト集合における二乗平均平方根誤差（RMSE）の計算**によって測定される。
- よって我々はまず、ガウス観測ノイズを用いた確率的線形モデル(probabilistic linear model with Gaussian observation noise)を採用する。

![](/images/2022-06-19-16-23-19.png)

観測された評価に関する条件付き分布を、以下のように定義する。

$$
p(R|U, V, \sigma2) =
\prod_{i=1}^{N} \prod_{j=1}^{M} [N(R_{ij}|U_{i}^T V_{j}, \sigma^2)]^{I_{ij}}
\tag{1}
$$

where

- $N(x|\mu, \sigma^2)$ is the probability density function of the Gaussian distribution with mean μ and variance σ2
- $I_{ij}$はユーザーiが映画jを評価した場合は1に、それ以外は0に等しい指標関数

また、ユーザ特徴ベクトル$U_i$とアイテム特徴ベクトル$V_j$に対して、平均ベクトルを0ベクトルとした「Shperical Gaussian Priors(球形ガウス分布)(=**要は3次元以上の正規分布??**)」を**事前分布**として設定する。

$$
p(U|\sigma_U^2) = \prod_{i=1}^N N(U_i|\mathbf{0}, \sigma_U^2 I),\\
p(V|\sigma_V^2) = \prod_{j=1}^M N(V_j|\mathbf{0}, \sigma_V^2 I)
\tag{2}
$$

(**$\prod$を使ってるって事は、$U_i$間、$V_j$間は独立。$U_i$内の各要素がD次元正規分布に従うって解釈...!**)

ユーザと映画の特徴行列に対する事後分布の対数は次式で与えられる。

まず事後分布の式は式(1)(2)より...

$$
p(U, V|R, \sigma^2, \sigma_V^2, \sigma_U^2)
= \frac{
% まず尤度=(1)
p(R|U, V, \sigma2)
% 次に事前分布=(2)
p(U, V|\sigma_U^2, \sigma_V^2)
}{p(R, \sigma^2, \sigma_V^2, \sigma_U^2)(=Const)} \\
= \frac{
    p(R|U, V, \sigma2)
    % 事前分布の同時確率を積に分解(独立??)
    p(U|\sigma_U^2)
    p(V|\sigma_V^2)
    }{Const}
\\
\because \text{式(1), (2)を代入して...}
\\
= \frac{
    % 尤度関数
    \prod_{i=1}^{N} \prod_{j=1}^{M} [N(R_{ij}|U_{i}^T V_{j}, \sigma^2)]^{I_{ij}}
    % 事前分布
    \cdot \prod_{i=1}^N N(U_i|\mathbf{0}, \sigma_U^2 I)
    \cdot \prod_{j=1}^M N(V_j|\mathbf{0}, \sigma_V^2 I)
}{
    Const
}
\\
= \cdots (また今度展開頑張ってみる??)
$$

### 事後分布の導出時の考え方のアイデア！

上式は以下のように解釈したらわかりやすいかも！同時確率$p((U|\sigma_U^2), (V|\sigma_V^2), R, \sigma^2)$の２通りの分解！

$$
p((U|\sigma_U^2), (V|\sigma_V^2), R, \sigma^2)
= p((U|\sigma_U^2), (V|\sigma_V^2)|R, \sigma^2) \cdot p(R, \sigma^2)
\\
p((U|\sigma_U^2), (V|\sigma_V^2), R, \sigma^2)
= p(R, \sigma^2|(U|\sigma_U^2), (V|\sigma_V^2))
\cdot p((U|\sigma_U^2), (V|\sigma_V^2))
\\
\Leftrightarrow
p((U|\sigma_U^2), (V|\sigma_V^2)|R, \sigma^2) \cdot p(R, \sigma^2)
= p(R, \sigma^2|(U|\sigma_U^2), (V|\sigma_V^2))
\cdot p((U|\sigma_U^2), (V|\sigma_V^2))
\\
\Leftrightarrow
p((U|\sigma_U^2), (V|\sigma_V^2)|R, \sigma^2) =
\frac{
    p(R, \sigma^2|(U|\sigma_U^2), (V|\sigma_V^2))
\cdot p((U|\sigma_U^2), (V|\sigma_V^2))
}{p(R, \sigma^2)}
$$

### 事後分布の対数は...

$$
\ln p(U, V|R,\sigma^2, \sigma_V^2, \sigma_U^2) \\
% 尤度関数部分
= -\frac{1}{2\sigma^2}\sum_{i}^{N} \sum_{j}^{M} I_{ij}(R_{ij} - U_i^TV_j)^2
% 事前分布の部分
- \frac{1}{2\sigma_U^2}\sum_{i=1}^N U_i^T U_i
- \frac{1}{2\sigma_V^2}\sum_{j=1}^M V_j^T V_j
\\
% L2正則化項？？
- \frac{1}{2}(
    (\sum_{i}^{N} \sum_{j}^{M} I_{ij})\ln \sigma^2
    + ND \ln \sigma_U^2 + MD \ln \sigma_V^2
    )
+ Const
$$

ここで、Cはパラメータに依存しない定数である。
**ハイパーパラメータ（すなわち、観測ノイズ分散と事前分散）を固定**したまま、**映画とユーザー特徴上の対数事後分布を最大化**することは、以下の**二次正則化項を持つ二乗誤差和目的関数を最小化することと等価**である。
(やっぱり最後の項はL2正則化項！でもあくまで事後分布の式を対数化したら**結果としてL2正則化項と等価の項が出現してくるってことか！**)

$$
E = -\frac{1}{2\sigma^2}\sum_{i}^{N} \sum_{j}^{M} I_{ij}(R_{ij} - U_i^TV_j)^2 \\
+ \frac{\lambda_U}{2}\sum_{i}^{N}||U_i||_{Fro}^2
+ \frac{\lambda_V}{2}\sum_{j}^{M}||V_j||_{Fro}^2
\tag{4}
$$

ここで

- $\lambda_U = \sigma^2 / \sigma_U^2$
- $\lambda_V = \sigma^2 / \sigma_V^2$
- $||\cdot||_{Fro}$ denotes the Frobenius norm(https://manabitimes.jp/math/1284 参照)
  - ノルムはベクトルや行列の"長さ"の概念の一般化。ベクトル空間に対して「距離」を与える為の数学の道具。

UとVで勾配降下を行うことにより、式4で与えられる目的関数のローカルミニマムを求めることができる。

この実験では，単純な線形ガウスモデルでは**有効な評価値の範囲外まで予測できてしまう**ため，ユーザと映画の特徴ベクトルの内積(==つまり、**"評価行列"の推定値**)をロジスティック関数 g(x) = 1/(1 + exp(-x)) に渡して，予測範囲を限定している
(=>つまり、線形回帰＝＞一般化線形回帰ってこと？？)

$$
p(R|U, V, \sigma2) =
\prod_{i=1}^{N} \prod_{j=1}^{M} [N(R_{ij}|\mu = g(U_{i}^T V_{j}), \sigma^2)]^{I_{ij}}
$$

我々は、有効なレーティング値の範囲が我々のモデルが行う予測の範囲と一致するように、関数 $t(x) = (x - 1)/(K - 1) $を用いてレーティング1、...、Kを区間[0、1]にマッピングする。(**要するに、評価値の観測値も標準化する！って事か！**)

最急降下法を用いて上記の目的関数を最小化することは、**オブザベーションの数に線形な時間を要する**(=O(N)???)。このアルゴリズムをMatlabで簡単に実装すると、学習するモデルが30因子(**D=30**)である場合、Netflixデータセット全体を1時間未満で1回掃引することができるようになる。
