## 0.1. link

- https://mercari.github.io/ml-system-design-pattern/README_ja.html

# 1. Serving patterns

本番サービスで推論サーバを稼働させ運用するパターン

## 1.1. Web single pattern

Webサーバにモデルを同梱させるパターン.

## 1.2. Synchronous pattern(同期パターン)

- 機械学習の推論を同期的に処理するパターン.
  - "**同期処理**":複数のタスクを実行する際に、順番にタスクが実行される方式.
  - "**非同期処理**": 複数のタスクが並列で実行できる方式.
- クライアントは推論のリクエストに対してレスポンスが得られるまで待機する.

## 1.3. Asynchronous pattern (非同期パターン)

- リクエストと推論の中間に**キューやキャッシュを配置**することで、推論リクエストと推論結果の取得を非同期にする.
- リクエストと推論を切り離すことにより、クライアントのワークフローで推論時間を待つ必要がなくなる. (同期パターンとの対比)

## 1.4. Batch pattern

batch学習的なやつ...!

## 1.5. Preprocess-prediction pattern

前処理と推論で、サーバやコンテナを分割するpattern.(それぞれマイクロサービス化するイメージ??)

## 1.6. Microservice vertical pattern

複数の推論モデルを順列に実行するときのアーキテクチャ.
複数の機械学習モデルを別サーバで並列して配置する.
それぞれに順番に(=同期的に)推論リクエストを送信し

## 1.7. Microservice horizontal pattern

**依存関係のない**複数の推論モデルを平行して実行するのが並列マイクロサービス・パターン.
並列マイクロサービス・パターンでは各推論サーバに平行して推論リクエストを送信することで、複数の推論結果を独立して得る事ができる.

## 1.8. Prediction cache pattern

推論結果をキャッシュ(=メモリに載せておく事?dictみたいな形式で??)に格納することで、同一データの推論をキャッシュ検索することができるようになる.
同一データに対する推論が多く、**入力データの同定をcacheキーで検索できる場合(user_idやitem_idは同定しやすそう...!)**、推論キャッシュ・パターンは有効.
本パターンでは入力データがキャッシュに存在しない場合、推論後に入力データをキー、推論結果を値としてキャッシュに格納する.
以降の推論では、キャッシュを検索と推論を同時に実行し、キャッシュにヒットした場合は推論のレスポンスを待たずに値をクライアントに返却できる.

## 1.9. Data cache pattern

入力データをキャッシュするアーキテクチャ.
入力データがデータベースやストレージにある場合、データをキャッシュしておくことでデータアクセスのオーバーヘッド(=アクセス量超過みたいな意味??)を削減することが可能になる.
キャッシュするデータ量はキャッシュのコストや容量とトレードオフになる.

## 1.10. Prediction circuit break pattern

Webサービスではキャンペーンや不慮の事件等によってアクセスが急激に増加することがある.
クラウドやKubernetesではスケールアウトすることによって増加したアクセスに対応することが可能だが、リソースのスケールアウトよりもアクセス増のほうが急速に発生することが一般的.
推論サーキットブレーカー・パターンはリソース増加(=スケールアウト?)が完了するまでの時間、推論サーバを「全断」させないためのアーキテクチャである.
本パターンでは一定以上の頻度で発生するリクエストを**プロキシ(proxy, "代理", "中継"みたいな意味)で遮断**することによって、推論サーバに送信されるリクエスト数を処理可能な量に制限する.
**サービスが全断する事態を最悪とすれば、一部のリクエストのみを遮断することでサービスを継続する**、という発想.

## 1.11. Multiple stage prediction pattern

マルチ・ステージ推論パターンは推論結果を複数段階に分けてクライアントにレスポンスする場合に有効なアーキテクチャ.
機械学習では一般的に、構造化データを扱うモデルは推論が高速で、画像やテキスト等の非構造化データを扱う場合は遅くなる傾向にある.
サービスの使われ方として、**リクエストに対して素早くレスポンスを返す必要がある一方で、多少遅れてでもより良い結果を返すことでユーザ体験を改善できる**こともある.
インタラクティブな使われ方がされるのであれば、すぐに簡単な推論結果を返して表示した後に、ユーザの使用中により良い推論結果を次の画面（またはスクロールした画面等々）に用意しておく、というライフサイクルが考えられる. 本パターンはそうしたインタラクティブなアプリケーションで効果を発揮するもの.

## Serving template pattern

## Edge prediction pattern: To do

## Antipatterns:

### Online bigsize pattern

### All-in-one pattern
