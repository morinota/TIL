## refs:

https://design.cs.iastate.edu/papers/ESEC-FSE-23a/dlcontract.pdf

## title

Design by Contract for Deep Learning APIs

## abstract

Deep Learning (DL) techniques are increasingly being incorporated in critical software systems today. DL software is buggy too. Recent work in SE has characterized these bugs, studied fix patterns, and proposed detection and localization strategies. In this work, we introduce a preventative measure. We propose design by contract for DL libraries, DL Contract for short, to document the properties of DL libraries and provide developers with a mechanism to identify bugs during development. While DL Contract builds on the traditional design by contract techniques, we need to address unique challenges. In particular, we need to document properties of the training process that are not visible at the functional interface of the DL libraries. To solve these problems, we have introduced mechanisms that allow developers to specify properties of the model architecture, data, and training process. We have designed and implemented DL Contract for Python-based DL libraries and used it to document the properties of Keras, a well-known DL library. We evaluate DL Contract in terms of effectiveness, runtime overhead, and usability. To evaluate the utility of DL Contract, we have developed 15 sample contracts specifically for training problems and structural bugs. We have adopted four well-vetted benchmarks from prior works on DL bug detection and repair. For the effectiveness, DL Contract correctly detects 259 bugs in 272 real-world buggy programs, from well-vetted benchmarks provided in prior work on DL bug detection and repair. We found that the DL Contract overhead is fairly minimal for the used benchmarks. Lastly, to evaluate the usability, we conducted a survey of twenty participants who have used DL Contract to find and fix bugs. The results reveal that DL Contract can be very helpful to DL application developers when debugging their code.

# Introduction

Deep learning is a popular tool for solving complex software development problems such as NLP and vision, but research has shown that deep learning models also have unique bugs [33, 36, 37, 66]. To address this, SE researchers have focused on detecting and localizing these bugs [46, 57, 62]. In this work, we explore an alternative approach to improve the reliability of deep learning software, design by contract (DbC). Traditional DbC [19, 41, 43, 48] provides support for writing preconditions and postconditions at APIs. However, prior work does not provide mechanisms for documenting properties of the model architecture, data, and training process, which are crucial for applying DbC to deep learning APIs. Recent research has proposed techniques for inferring these properties, but DbC aims to provide specification mechanisms for programmers. We propose a DbC methodology for deep learning libraries, called DL Contract. It exposes meta-level properties of the DL training process and model structure as variables, called ML variable, for use in writing contracts. Unlike grey-box contracts [23] that expose part of the program, ML variable provides a higher-level abstraction of the training process and model structure. They are similar to specification-only fields [27] in object-oriented programs [42, 49], but abstract away from the details of the DL model. We have developed DL Contract for Python and a runtime assertion checking framework for DL Contract. We have applied contracts to key API methods of the Keras library and evaluated them using four benchmarks for deep learning bug detection from prior works [52, 57, 62, 65], comprising 272 Keras codes. Our results show that the Keras library with contracts can identify 95% of such bugs during runtime checking. Additionally, we have evaluated the annotation overhead of DL Contract and found it to be zero for users of DL libraries. This means that users do not need to add any contract annotations to their code in order to benefit from our approach. We have also added 15 contracts to the model compilation and training methods of the Keras API and evaluated 257 correct programs, finding 18 false positives due to the randomness effect during training. To evaluate the usability of the contract-enabled Keras library, we conducted a user study with 20 participants with varying levels of expertise in DL application development. Our evaluation also shows that the runtime overhead of checking contracts is fairly minimal. We found that the runtime overhead increases by around 15% compared to the baseline. DL Contract can be disabled during production to result in zero overhead. Our contributions are as follows: • A novel methodology for writing and checking contracts for deep learning libraries by specifying DL APIs with preconditions and postconditions. • A framework [15] that is extensible and generalized to different classes of DL bugs and maps contract violation as a bug, symptoms as the constraint to check, and contract violation messages as suggestions to fix bugs. • The notion of specifying DL-specific contracts by abstracting the DL model architecture, its data properties, and training behavior. • A collection of 15 contracts that prevents prevalent training problems and structural bugs in DL programs. • An annotated version of Keras with the DL Contract as a virtual environment (@Keras) [11]. Developers can use this @Keras environment for debugging without any annotation overhead and minimal runtime overhead (≈15%).

# Motivation

To highlight the difficulty in specifying deep learning APIs and the need for DL Contract, consider a simple Convolutional Neural Network (CNN) code shown in Fig. 1. This code is intended for digit classification when implemented correctly, as outlined in the Keras documentation [10], it achieves 99% training accuracy on the MNIST dataset. In the correct version, images are normalized to the range [0,1] before being processed by a Sequential model with a specific layer architecture. The model is configured using the Compile API and trained using the Fit API, and the evaluate API is used to calculate the loss and accuracy. However, as shown in Fig. 1, the code snippet contains three bugs (on lines 19, 20, and 22) which result in low accuracy and high training time. These bugs are specific to DL programs [62] and may not cause crashes. For example, on line 19, the incorrect activation function, ‘relu’ is used in the last layer of the Dense API [2, 5, 6]. Additionally, on line 20, the incorrect loss function of ‘binary_crossentropy’ is applied in the Compile API [2, 3, 9]. Lastly, on lines 5 and 6, the data is not normalized before being fed into the Fit API [6, 7]. This example also illustrates another challenge for specifying DL APIs. All DL APIs work on a shared DL model, where early APIs construct the model and later APIs, such as fit, compile, and evaluate, make use of it. To write pre/postconditions for DL APIs, having access to only the formal parameters and return values of the APIs is not sufficient. Correct usage depends on the model state at the point of the API call. DL Contract addresses these challenges and can help prevent such bugs by providing a clear specification of the intended behavior of deep learning APIs.

# Deep Learning Contract

In the DL Contract approach, we abstract the data properties, expected output, model architecture, and training behavior of a DNN model and specify the properties of DL APIs connected via a computation graph. We gather and inspect necessary conditions from three sources (details in §4.1). We filter out the obligations from the DL app developer as preconditions and expectations from DL software in as postconditions. Here, we use a novel runtime assertion check in DL computation. In the contract checker modules first parse those contracts and translate them into templates. Those templates are validated to handle the exception if it occurs. If a contract is violated, the user receives a contract violation message Otherwise, the API returns the normal execution output. Thus, our proposed solution generalizes to other bugs and model categories in this way. It would be easy for library developers to specify the contracts for other types of bugs following these procedures of DL Contract. Next, we present the design and usage of DL Contract, including examples and our approach for abstracting DL related properties.

## Writing Deep Learning Contracts

DL Contract uses an annotation-based approach [18, 28] to add contracts to DL APIs, which allows library developers to add contracts without modifying compilers and build tools. This means that software using DL APIs does not need to be modified. DL library developers can add preconditions that must be satisfied before the API is called and postconditions that the API guarantees to be true upon completion. 3.1.1 Syntax. To use contracts in a deep learning library, it is necessary to annotate the API with @contract and @new_contract. This allows library developers to create expressions for checking specified contracts. DL Contract can check types such as tensors and model objects, as well as simple data types like strings, floats, numbers, arrays, and booleans. It utilizes logical operators like AND(,) and OR(|) and allows for arithmetic and comparison expressions. Additionally, DL Contract can be used to check constraints of various model properties during training and abstraction. 3.1.2 Illustrative Example. To create a contract, a library developer annotates a DL API using @contract and @new_contract. Inside @contract, the developer defines types and functions for checking contracts. Using @new_contract, the developer writes functions for performing computations necessary for a contract and for checking preconditions and postconditions. For instance, in Example 3.1, a contract is imposed as a precondition on the Keras training function Fit to ensure that data is within a specified range before training. To prevent this type of bug, a function data_normalization is declared as a contract definition using the @contract annotation (line 8) using the parameter x. Inside the @contract annotation, in the data_normalization function (line 2), the developer further computes to get the range of training data, declared as normalization_interval as a ML variable (line 3). The developer can specify the appropriate range of the ML variable within the contract checker function. The condition is checked on line 4 and if the contract is violated, a suggestion to fix the issue is raised on line 7.

When a buggy DL program makes use of this annotated API, DL Contract will throw the following error. ContractViolated: Data should be normalized before training, train and test data should be divided by value 255.0. Example 3.2 illustrates the use of DL Contract to prevent overfitting bugs [46], in which a model has high training accuracy but low test accuracy. A contract is specified on the validation loss and training loss to check for increasing differences in validation loss and decreasing differences in training loss [57], which is a common cause of overfitting. This expectation is encoded as a postcondition.

To prevent overfitting, a contract can be added to the output of the Fit method in Keras using @contract and a postcondition can be checked using the overfitting function specified with returns (line 16). In this function, the contract writer uses the obtained history object to compute diff*loss and diff_val*- loss (line 6-7) and checks if the difference between validation loss of consecutive epochs tends to increase while the difference between training loss continues to decrease. If this condition is not met, a contract violation message is thrown and when a buggy DL program uses this annotated API, DL Contract will throw an error. ContractViolated: After Epoch: 11, diff_val_loss = 0.34 and diff_loss = -0.12 causes overfitting.

## DL Contract Approach

Next, we present our approach and describe the technical challenges in DL contract checking, such as the need for context-aware ML variable (§3.2.1), assertion techniques (§3.2.2), and support for contracts across multiple APIs in the ML pipeline (§3.2.3). Also, we discuss our technique’s support for post-training contract checking (§3.2.4). 3.2.1 Abstraction of DL specific properties to contracts. To enforce DbC technique for deep learning APIs, a mechanism is needed to capture model abstraction, data properties, and training behavior beyond just the formal parameters and return values of the DL APIs. Standard contracts only enforce constraints on the values of formal parameters and return values of an API method or attributes of an API class. Additionally, machine learning APIs are not isolated, but connected through a computational graph [16]. Therefore, specifying contracts on one API with its formal parameters alone is not sufficient in the DL-specific settings. Fig. 2 describes a scenario in which the developer wants to add a contract to the method dense to ensure that the activation function for the last layer is not relu [8]. Additionally, the developer wants to check the appropriate loss function parameter for the Compile API Fig. 2. The problem with this scenario is that the conventional Design by Contract (DbC) technique cannot specify this contract on a model’s API without causing false alarms in correct codes because it only allows for checking contracts on each API of a model. To solve such problem, we design a way to write DL Contract using functions that allows to compute subset of meta-information with ML variable abstracting model architecture, data properties, training behavior. Fig. 2 shows one way to solve this challenge using DL Contract. In this solution, activation, and loss*func are computed in specified @new_contract contract_checker functions where activation is the parameter of last layer Dense API and loss_func is the parameter of Compile API. This is how DL Contract mechanism enables specifying and checking contract with abstracted model properties which works on any stage of computation graph pipeline. 3.2.2 DL Contract runtime assertion technique. A model is more than what the configuration script defines. Many properties of the model only become tractable during training. As a result, a DL Contract must enable a runtime assertion technique that allows enforcing contracts beyond formal parameters, unlike traditional contract checkers. Furthermore, it must be possible to impose contracts on different pipeline stages of the modeling, i.e., data preprocessing, during model building, and training, etc. To that end, we propose a DL Contract checker with such capabilities by enabling library developers to annotate APIs. Eventually, DL Contract annotations benefit end-users to check their model, data properties, and training behavior at different stages in the DL pipeline. Our method outlined in Algorithm 1 shows the steps involved in parsing and checking contracts in a library. It consists of two steps: registering new contracts defined by the library developer and parsing and validating newly defined contracts applied to the functions defined by the library developer. The framework inspects the library code base to find custom user-defined contracts defined as functions with the @new_contract annotation. The usage of @new_contract on a function invokes the register_new_contract method, which stores a reference to the function in a dictionary. This way of annotating contracts allows writing contracts using abstracted DL properties as discussed in section 3.2.1. For instance, if a library developer writes a contract with any of the properties of 𝑚𝑜𝑑𝑒𝑙 object and checks as a precondition before model compilation or before model training, our technique allows doing that in this way (more details in Example 3.3) which is different than the traditional way of writing contract. The contract_checker method is used to intercept and validate such contracts applied to user-defined functions with the @contract annotation before the function is executed. The method parses the annotation reference, obtains a dictionary of conditions applied to the function’s arguments, and validates the conditions using the visitor design pattern. Consider a contract, @contract(loss=‘str,contract_func’). It validates the loss function and the validation takes place inside a user-defined contract, contract_func. The contract body is stored in argContrDict as <loss,(str,contract_func)>. Then, it obtains the value for the argument loss. The method parse*- template is used to obtain a validation tree for the conditions by composing validation classes (in Algorithm 2). In the example of loss contract, an And class is obtained, with each condition as a subclause. If the first condition, str, is satisfied, a CheckType validation class is returned. If the second condition is a user-defined function, a CheckCallable validation class is returned. The composed validation tree is returned in a template variable. Each validation class implements the method check_contract. To validate the template, check_contract is invoked on the root validation class, which is And. If validation fails for any subclause, And raises an exception. The argument on which a contract is imposed is validated. If preconditions are satisfied, the postconditions are validated. The returned result of the user function is validated as per written contracts. 3.2.3 Contextualized Inter-API Call Contracts. The next challenge is to ensure that DL Contract can be written involving multiple APIs at different stages of the DL pipeline. To solve this problem, DL Contract is designed to write multiple functions using @new_contract annotations that take formal parameters across multiple DL APIs. For example, when the number of the target class is 2 (i.e., binary classification), the activation function of the last layer should not be softmax or relu [3, 5, 9] (which is a type of contract within the same Dense API) and loss function should be ‘binary_cross-entropy’ [2, 3] (which is an inter-argument contract with different APIs, i.e., between last layer and Compile API). Although the best activation function for hidden layers is ReLu [30], if ReLu is used on the last layer, it will set all the negative output to zero, thus leading to an accuracy problem. To prevent such kinds of problems in model architecture, library developers can write DL Contract using the activation and loss function for the binary and multi-class classification according to the experts’ suggestion [2, 3]. Our insight is that such types of contracts can be added to deep learning model-compilation API, i.e., Keras Compile, exposing objects capturing the entire model properties.

Example 3.3 shows last layer activation and loss function contract applied to Keras Compile API, which asserts before Compile API execution. Here, contract_checker1 has been annotated with model object type on line 17 and contract_checker2 has been annotated using loss parameter with string type on line 18. Here, last_layer_output and activation_func are computed on line 3 and line 5 from model object. The loss function has been a formal parameter of Compile API, and contract_checkerfunc2 checks the condition on line 14 and shows a message with suggestions to fix if a contract violation occurs for both Dense and Compile APIs. As those specified contacts are ANDed one after another for one contract (last layer activation and loss function), ‘contract_checkerfunc2’ is only executed if ‘contract_checkerfunc1’ is executed. Since ‘contract_checkerfunc1’ checks whether the number of classes ≥ 3, then ‘checkerfunc2’ would also know if the program runs a multiclass classification. In Example 3.3, on lines 17–18, ‘contract_checkerfunc1’ and ‘contract_checkerfunc2’ have been enforced together. A case of that contract violation is shown below, ContractViolated: For multiclass classification activation_func should be softmax, loss should be categorical crossentropy.

3.2.4 Post-training Contracts. The challenge of capturing DNN training behavior at different stages of the DL pipeline can be addressed with our proposed DL Contract. Library developers can specify desired training behavior for their DL software by adding training-related contracts on properties such as, gradients rate, gradients percentage etc. Training behavior-related properties indicate the expected output from the DL model, so this is a postcondition. The root cause behind a training problem could be client obligation in hidden layers APIs such as activation function, which is a parameter of Dense API (this is a precondition) We might encounter such types of preconditions and postconditions in DL-specific settings, and contracts can be specified using @new_contract and @contract annotations in our proposed approach. To handle such cases, DL Contract advocates specifying contracts as postconditions on DL training APIs, e.g., Keras Fit API, which provides detailed training history. Based on the supplied contract checking function in @new_contract, we compute relevant training properties from the history object such as validation accuracy, loss value, gradient rate etc. Algorithm 1 (lines 8–13) describes how we check and validate postconditions in our framework. Example 3.2 demonstrates this type of postcondition contract.

# Evaluation

# Related Work

Specification of Deep Neural Networks: The closest related ideas in the specification of DNNs include [31, 58, 59]. While [58] provides an overview of the opportunities and challenges of formalizing and reasoning about DNN properties, it does not propose any methodology for writing and checking specifications for deep learning libraries. In contrast, [31] presents a technique for computing input and layer properties from a feed-forward network using input-output characterizations as formal contracts. Additionally, [59] introduces a method for repairing neural network classifiers by inferring the correct specifications. Both [31] and [59] propose inference techniques, while our technique proposes a specification and checking technique that enables the specification of DL libraries and checks those contracts in client code using those libraries, thus preventing bugs and providing fix suggestions. Recently, an empirical study [38] reports categories of required ML contracts, which may help designers of contract languages. Deep Learning Testing, Debugging, and Repairing: Prior work on DL testing, debugging, and repairing includes DeepLocalize [62], MODE [46], AUTOTRAINER [65], DeepDiagnosis[61], DeepFD[25], Ariadne [29], Lagouvardos [40], Nikanjam et al. [52], SHAPETRACER [44], and Tensfa [63]. These approaches focus on detecting and localizing bugs, but DL Contract supports documentation of expected behavior. While DL Contract checker can also double as a bug detection tool, in the long term, developers would also benefit from the documentation and write more correct DL programs. Empirical studies [26, 34, 36, 37, 56, 64, 66] have motivated the need for DL bug repair, but none propose a DbC methodology like DL Contract. Existing DbC Methodology: Existing DbC frameworks for Python, such as PyContracts [32], Pylint [1], and PyTA [45], do not have the capability to check contracts for properties of models and data, or monitor training behavior of DL models. These frameworks do not address the technical challenges of checking contracts beyond API parameters, contracts involving multiple APIs at different stages of the ML pipeline, and contracts on intermediate properties to specify desired training behavior. Additionally, DL Contract’s use of runtime assertions is distinct from checking runtime properties, such as interpreting statecharts [47]. To the best of our knowledge, the concept of applying DbC over the DL computational graph and specifying DL-specific contracts is novel. API Misuse Detection: There have been some API misuse detection techniques such as, [60], which examines the usage of machine learning (ML) cloud APIs in open-source applications. This work finds that many of these applications contain API misuses that degrade their functionality and performance, leading to the development of automated checkers for identifying such misuses. [52] tackles API Misuse (APIM) bugs statically by some rules that occur when practitioners misunderstand the usage of deep learning APIs. Such misusage leads to inconsistencies between the designed DL program and the API’s usage conditions, potentially resulting in reduced effectiveness or runtime exceptions. Existing API misuse detection methods may not be suitable for checking contracts written by library API designers that capture properties of models, data, and training behavior at various program points during runtime. To address this limitation, our approach overcomes technical challenges associated with checking contracts beyond formal API parameters, handling contracts involving multiple APIs at different stages of the ML pipeline, and specifying intermediate properties for desired training behavior.

# Conclusions and future work

In this work, we proposed a novel method for checking contracts for deep learning libraries by specifying DL APIs with preconditions and postconditions. Our approach is extensible and generalizable, allowing for the abstraction of model architecture, data properties, and training behavior. We developed 15 sample DL contracts targeting common bugs and found they effectively prevented structural bugs and training problems. Additionally, our user study showed the usability of DL Contract when applied to the Keras library. We have submitted an API design proposal for its incorporation in future releases of Keras. Possible future work includes static validation, unit testing, and inferring contracts for additional libraries. With ongoing research on decomposing DNN into modules [35, 53, 54], we intend to write contracts for the expected behavior of a DNN module effectively. We want to explore writing contracts to prevent nonfunctional bugs such as fairness bugs [20, 21]. We would also like to extend our approach to prevent additional types of bugs in different stages of the ML pipeline [22]. We can adapt techniques [50, 51] for collecting contracts from mined models with improved performance in terms of accuracy and training time.
