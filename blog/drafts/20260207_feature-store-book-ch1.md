O'Reilly Feature Store Book 第1章: 機械学習システムの構築

## 1. 元記事情報

- **タイトル(原文)**: CHAPTER 1: Building Machine Learning Systems
- **書籍**: O'Reilly Feature Store for Machine Learning
- **種類**: 技術書籍の章
- **元ファイル**: [machine_learning/MLOps/feature_store/oreilly_feature_store_book/chapter_1.md](../machine_learning/MLOps/feature_store/oreilly_feature_store_book/chapter_1.md)

---

## 2. 概要

静的データセットでのモデル学習から、動的データを扱う本格的な機械学習システム構築への移行を解説する章。バッチ、リアルタイム、LLMエージェント型の3種類のMLシステムと、それらを統一的に扱うFTI(Feature-Training-Inference)パイプラインアーキテクチャを紹介する。

## 3. 背景・課題

### 3.1. 一度きりのモデル訓練の限界

多くの企業で、データサイエンティストは毎年同じタスクを実質的にゼロから始めている:

- データソースの再検索とアクセス権限の再取得
- 昨年のJupyterノートブックの更新
- 一度きりの予測を行って終了(PowerPointプレゼンテーション)

この非効率なワークフローでは、モデルが継続的な価値を生み出すことができない。

### 3.2. MLシステム構築の必要性

モデルが繰り返し価値を生成するには、以下を自動化するMLパイプラインの構築が必要:

- データソースからの読み取り
- データの特徴への変換
- モデルの訓練
- 新しいデータでの推論
- 予測結果のダッシュボード更新

**ダッシュボードこそが、モデルがステークホルダーに提供する価値である。**

## 4. 主要なポイント

### 4.1. MLシステムの3つの類型

#### 4.1.1. バッチMLシステム

**例**: SpotifyのDiscovery Weekly

- 週に1回、575M以上のユーザー全員に対して予測を実行
- 予測結果をデータベース(Cassandra)に保存
- ユーザーがログイン時に予測を取得

**特徴**: スケジュール実行、一括処理

#### 4.1.2. リアルタイムMLシステム

**例**: TikTokのレコメンデーションエンジン

- ユーザーの動画視聴行動にほぼリアルタイムで反応
- 最近の視聴行動 + 過去の嗜好 + トレンド情報を統合
- Andrej Karpathy: "It's scary good. It's digital crack."

**特徴**: ユーザーリクエストへの即時応答、動的な予測

TikTokはリアルタイムレコメンデーションを含む最初のオンライン動画プラットフォームであり、これが競争優位性となった。

#### 4.1.3. エージェンティックAIシステム

**例**: Lovable(ウェブアプリケーション構築アシスタント)

- わずか8ヶ月で$100M収益達成(最速記録)
- 自然言語インターフェース
- 高い自律性で目標を達成

**特徴**: LLM + ツール、高度な自律性、インタラクティブ

### 4.2. 機械学習の5つのタイプ

#### 4.2.1. 教師あり学習(Supervised Learning)

- 特徴とラベルを含むデータでモデルを訓練
- 分類問題(Yes/No、マルチクラス)
- 回帰問題(数値予測)
- LLMのファインチューニング

#### 4.2.2. 教師なし学習(Unsupervised Learning)

- ラベルなしの入力特徴から学習
- 例: クレジットカード不正検知

#### 4.2.3. 自己教師あり学習(Self-Supervised Learning)

- ラベルのないデータからラベル付きデータを生成
- **マスキング**が主な方法:
  - NLP: 単語マスキング(BERT)、次文予測
  - 画像: 一部をマスクして元画像を再現

#### 4.2.4. 強化学習(Reinforcement Learning)

- 最適な意思決定を学習(本書では扱わない)

#### 4.2.5. インコンテキスト学習(In-Context Learning)

- LLMに特有の学習方法
- プロンプトにコンテキスト(例)を提供することで新しいタスクを解決
- **エージェントはインコンテキスト学習に基づくが、コンテキストエンジニアリングが必要**
- コンテキストウィンドウが空になるとスキルを忘却(モデルの重みは更新されない)

**ChatGPTの例**: 自己教師あり学習(事前訓練) + 教師あり学習(ファインチューニング) + 強化学習(RLHF) + インコンテキスト学習

### 4.3. データソースの種類

#### 4.3.1. 表形式データ(Tabular Data)

**行指向ストア**:
- リレーショナルデータベース、NoSQLデータベース
- 行の読み書きに最適化
- 例: MySQL、Postgres、Cassandra、MongoDB

**列指向ストア**:
- データウェアハウス、データレイクハウス
- 列の集計処理に最適化
- 例: Snowflake、BigQuery、Databricks

**企業での典型的なパターン**:
- 運用データは行指向ストアに保存
- データパイプラインで列指向ストアに転送
- 分析データは企業のAIシステムにとって最も一般的なデータソース

#### 4.3.2. イベントデータ(Event Data)

- 特定時点での離散的な出来事の記録(クリック、センサー読み取り)
- イベントストリーミングプラットフォーム: Apache Kafka
- 消費者例:
  - 列指向データストア(履歴分析用)
  - ストリーム処理プログラム(リアルタイムMLシステム用)

#### 4.3.3. グラフデータ(Graph Data)

- ノード(エンティティ)とエッジ(関係)
- リンク予測、詐欺検出のMLモデルに有用
- LLMの知識ソースとしても活用

#### 4.3.4. 非構造化データ(Unstructured Data)

- テキスト(PDF、HTML、マークダウン)、画像、動画、音声
- ファイルシステムやオブジェクトストア(Amazon S3)に保存
- 深層学習が大きな進展を遂げた領域

#### 4.3.5. APIスクレイピングデータ

- SaaSシステムからの公開API取得
- ウェブサイトからのスクレイピング
- ローコードツール: Airbyte(Salesforce、HubSpot統合)

**社会のデジタル化によりウェブデータが増加 → AIシステムのデータソースとして有用**

### 4.4. 可変データ(Mutable Data)の重要性

既存のMLコースは**不変データセット(immutable datasets)**のみを扱う傾向:

- 小規模: CSV(数GB)
- 大規模: Parquet(GB〜TB)

しかし、実際のMLシステムは動的に更新されるデータを扱う必要がある。

### 4.5. MLOpsとLLMOps

*(この章では歴史的経緯を紹介しているが、詳細は割愛)*

- MLOps: ML開発・運用のベストプラクティス
- LLMOps: LLM特有の課題に対応(プロンプトエンジニアリング、RAGなど)

### 4.6. FTIパイプラインアーキテクチャ

#### 4.6.1. モジュラリティの重要性

**モジュラー性の利点**:

- モジュールを独立してテストできる → 高品質で信頼性の高いシステム
- チーム間の作業分離が明確
- 機能の再利用が可能
- 共通理解による良好なコミュニケーション

#### 4.6.2. 統一アーキテクチャ: FTI分解

すべてのAIシステムを3つのパイプラインに自然に分解:

**1. Feature Pipeline(特徴パイプライン)**:
- 入力: データ
- 出力: 再利用可能な特徴データ

**2. Training Pipeline(トレーニングパイプライン)**:
- 入力: 特徴データ
- 出力: トレーニング済みモデル

**3. Inference Pipeline(推論パイプライン)**:
- 入力: 特徴データ + モデル
- 出力: 予測 + 予測ログ

**各パイプラインは独立して開発・テスト・運用可能**

#### 4.6.3. 共有データレイヤー

3つのパイプラインを接続する共有データレイヤー:

**Feature Store**:
- リアルタイムデータ: 行指向ストア(オンライン推論用、低レイテンシ)
- 履歴データ: 列指向ストア(モデル訓練、バッチ推論用)
- ベクトル埋め込み: ベクトルインデックス(推論パイプライン、エージェント用)

**Model Registry**:
- トレーニング済みモデルの管理

#### 4.6.4. AIシステムの定義

**AIシステム = Feature Store + Model Registryで接続された独立したFeature/Training/Inference Pipelineのセット**

#### 4.6.5. 実装技術

**バッチコンピュートエンジン**:
- SQL(データウェアハウス)
- Apache Spark
- Pandas、Polars、DuckDB

**ストリーム処理エンジン**:
- Apache Flink
- Spark Structured Streaming
- Feldera

**実装言語**:
- Training Pipeline: Python
- Online Inference Pipeline: Python
- Batch Inference Pipeline: PySpark、Pandas、Polars

### 4.7. Feature Storeを持つAIシステムの分類

#### 4.7.1. リアルタイム(インタラクティブ)MLシステム

- ユーザーリクエストに応じて予測
- リクエストパラメータからオンデマンドで特徴を計算
- Feature Storeから事前計算された特徴を読み取り
- ストリーム処理でフレッシュな特徴を事前計算 → バッチより高速反応

#### 4.7.2. エージェンティックワークフロー

- ユーザーガイド型AIシステム
- LLM + ツール(外部システムへのアクション、データソースからのコンテキスト取得)
- Feature Pipeline、Vector Embedding Pipeline、リアルタイム特徴エンジニアリングがコンテキストデータを作成

#### 4.7.3. バッチMLシステム

- スケジュール実行(時間、日、週、年単位)
- 予測を**Inference Store**(下流データベース)に保存
- 後でML対応アプリケーションが消費

#### 4.7.4. ストリーム処理MLシステム

- ユーザー入力なしでストリーミングデータに対して予測
- machine-to-machine MLシステム
- 例: ネットワーク侵入検知

#### 4.7.5. リアルタイムMLシステム vs エージェンティックワークフロー

どちらも**インタラクティブシステム**(予測リクエストAPI、同時リクエスト処理、モデル使用)

**区別**:

- **リアルタイムMLシステム**: カスタムトレーニングモデル(決定木、深層学習)、内部モデル提供インフラ、シンプルなオンライン推論パイプライン
- **エージェンティックワークフロー**: 複雑なオンライン推論パイプライン(エージェントプログラム)、ツール + 外部API経由のLLM

## 5. 技術的な詳細

### 5.1. Feature Storeの3つのストレージ

従来は「オンラインストア」と「オフラインストア」の2種類と考えられがちだったが、実際には3つ:

1. **行指向ストア(オンラインストア)**: 低レイテンシアクセス用
2. **列指向ストア(オフラインストア)**: モデル訓練とバッチ推論用
3. **ベクトルインデックス**: ベクトル埋め込み保存用

この3つを内包する統合的なFeature Storeの概念が重要。

### 5.2. Inference Storeの概念

バッチMLシステムの予測を保存する下流データベースを**Inference Store**と呼ぶ。この用語は本書で初めて明確に定義されている。

### 5.3. モジュラリティとコンポーザビリティ

モジュラリティは、モジュールが機能するシステムに簡単に構成できる場合にのみ有効:

**良い例**: ウェブアプリケーション(30年後も継続)
- プレゼンテーション層
- ビジネスロジック層
- データベース層

**注意が必要な例**: マイクロサービスアーキテクチャ
- 多すぎるマイクロサービス → 運用複雑性の増加

**FTIアーキテクチャ**:
- 3つのパイプライン(適度な分解)
- Feature Store + Model Registryで接続(明確なインターフェース)
- データ契約を破らない限り、各パイプラインを独立して変更可能

## 6. 学びと考察

### 6.1. 学んだこと

1. **一度きりのモデル訓練の限界**: Kaggle的なワークフローと実運用MLシステムの本質的な違い。「ダッシュボードがステークホルダーへの価値」という視点が重要。

2. **動的データの重要性**: 静的データセット → バッチデータ → リアルタイムデータへの移行が、MLシステム構築の核心。

3. **FTIアーキテクチャの統一性**: バッチ、リアルタイム、エージェントという異なるMLシステムを、Feature/Training/Inference Pipelineという統一的な枠組みで理解できる。

4. **Feature Storeの中心性**: Feature StoreはFTIパイプライン間の「データ契約」を定義する中心的な役割。単なるデータ保存場所ではなく、システムアーキテクチャの要。

5. **インコンテキスト学習の特異性**: LLMの「学んで即忘却」という特性は、従来のML学習パラダイムと根本的に異なる。エージェントにはコンテキストエンジニアリングが必須。

### 6.2. 自分の考察

#### 6.2.1. Feature Storeの3層構造の重要性

「オンライン/オフライン」の2層ではなく、「行指向/列指向/ベクトル」の3層として理解すべき。特にベクトルインデックスをFeature Storeの一部と明確に位置づけることで、RAGエージェントとのアーキテクチャ的な統一性が見えてくる。

これまで「ベクトル検索機能を持つオンラインストアを採用すべきか?」と悩んでいたが、3つを独立した層として扱えばよいことが明確になった。

#### 6.2.2. 「Inference Store」という概念の価値

バッチ推論の予測を保存する下流データベースを明示的に「Inference Store」と命名することで、アーキテクチャのコミュニケーションが明確になる。この用語を積極的に使っていきたい。

#### 6.2.3. TikTokの競争優位性

TikTokがリアルタイムレコメンデーションを「最初に」実装したことが、世界第2位のオンライン動画プラットフォームへの成長の鍵だった。技術的な優位性だけでなく、「最初に実装する」タイミングの重要性を示す好例。

#### 6.2.4. モジュラリティのバランス

ウェブアプリケーションの3層(30年継続)とマイクロサービスの過剰分解(運用複雑性)の対比が興味深い。FTIアーキテクチャの3つのパイプラインは、ちょうど良いモジュラリティのバランスを実現していると感じる。

「分解しすぎず、統合しすぎず」の最適解を見つける重要性。

#### 6.2.5. データソースの民主化

「社会のデジタル化によりウェブデータが増加 → AIシステムのデータソースとして有用」という指摘は重要。自社データだけに閉じる必要はなく、公開API、ウェブスクレイピング、SaaS連携を積極的に活用すべき。

Airbyteのようなローコードツールの活用で、データソース統合の民主化が進んでいる。

#### 6.2.6. エージェントとMLシステムの境界

リアルタイムMLシステムとエージェンティックワークフローの区別が興味深い。どちらも「インタラクティブ」だが、推論パイプラインの複雑性とLLM/ツールの有無で分類される。

今後、両者の境界はさらに曖昧になるかもしれない(カスタムモデル + LLMのハイブリッド型など)。

#### 6.2.7. 財務予測の例の示唆

冒頭の財務予測の例が秀逸。「PowerPointで終わり」から「ダッシュボードで継続的価値」への移行は、多くの企業が直面する課題。

「今年は足場を構築する時間を投資する価値がある」という判断が、長期的な効率化とイノベーションの時間を生み出す。短期的な成果と長期的な投資のバランスの重要性を示している。

## 7. 参考リンク

- [元ファイル](../machine_learning/MLOps/feature_store/oreilly_feature_store_book/chapter_1.md)
- [Apache Kafka](https://kafka.apache.org/)
- [Airbyte](https://airbyte.com/)
- [Apache Flink](https://flink.apache.org/)
- [Feldera](https://www.feldera.com/)
- [Hopsworks](https://www.hopsworks.ai/)

## 8. 次に読むべき章

- **第2章**: FTIパイプラインアーキテクチャの詳細、MVPS(最小限の実行可能な予測サービス)開発プロセス
- **第3章**: 空気質予測MLシステムの実例(APIスクレイピングの実践)
