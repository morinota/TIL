## 0.1. Reference

- https://geographicdata.science/book/notebooks/06_spatial_autocorrelation.html

## 0.2. Spatial Antocorrelationの導入

- 空間的自己相関の概念は、“functional relationship between what happens at one point in space and what happens elsewhere”
  - 「空間の1つのポイントで起こることと，他の場所で起こることの間の機能的関係」
  - ＝＞従って空間的自己相関は、「データ集合の中の観測地(Observation)間の**値の類似性**が、観測地間の**位置の類似性**にどの程度依存しているか」に関係してる。
- 時間的自己相関との関連（ただし別物）：
  - Temporal Autocorrelation「ある時点の変数の値とそれ以前の値を関連付ける」
  - Spatial Autocorrelation「**ある場所での**変数の値と、**他の場所での**同じ変数の値を関連付ける」
  - ＝＞これを理解する為の別の見方として、「ある場所での変数の値に含まれる、**他の場所での同じ変数の値に関する情報の度合い**」

## 0.3. Understanding Spatial Antocorrelation

空間的自己相関の概念をよりよく理解するためには、空間的自己相関がない場合、世界はどのように見えるかを考えることから始めるのが有効。

- 空間的ランダム性：
  - 観測の位置がその値について何の情報も与えない状況
  - 言い換えれば、ある変数が識別可能な空間的パターンに従って分布していない場合、その変数は空間的にランダムである。
- したがって、空間的自己相関は「空間的ランダム性の欠如」と定義することができる。

しかし、この定義ではまだ漠然としすぎている。そこで、より具体的に言うと、空間的自己相関は、**符号**と**スケール**の2つの次元で分類されるのが一般的。

### 0.3.1. Spatial Autocorrelationの符号について

従来の非空間的なケースと同様に、**空間的自己相関は正と負の2つの主要な形態**をとることができる。

- 前者（正のSpatial Autocorrelation）：類似性と地理的な近さが密接に関連する状況である。
  - つまり、**似たような値は近くにあり、異なる値は散らばって遠くにある**傾向がある。
  - これらの値の符号は、空間的自己相関の存在には関係ないことが重要である：高い値の近くに高い値があったり、低い値の近くに低い値があったりすること。
  - この文脈で重要なのは、**近さと統計的類似性の関係が正であること**です。
  - これは多くの社会的文脈でかなり一般的なケースで、実際、いくつかの人間現象は明らかに正の空間自己相関を示します。
    - 例えば、所得や貧困の空間分布を考えてみると、似たような値が近くにあるのが普通です（富裕層は他の富裕層と近く、貧困層も空間に集中している）
- 後者（負のSpatial Autocorrelation）：似たような値が互いに離れている傾向がある状況を反映
  - この場合、統計的な類似性は距離と関連している。
  - これは社会科学ではやや少ないが、まだ存在する。
    - 例えば、空間的な競争のプロセスに従う現象や、一連の施設の立地が最も高い空間的な被覆率を目指すような状況に見られるものである。
    - 異なるブランドのスーパーマーケットや病院の分布は、通常、負の空間依存のパターンに従っている。

### 0.3.2. Spatial Autocorrelationを考慮するスケールについて

また、空間的自己相関を理解するために、空間的自己相関を考慮するスケールを使用することもできる。
一般的に**Global** processes、**Local** processesという言い方をします。

- Global Spatial Autocorrelation：
  - 値の位置が従う全体的な傾向を考えるもの。
  - この分析は、データセットにおけるクラスタリングの度合いについての記述を可能にします。
    - 値は一般的に地理的な分布において特定のパターンに従っているか？
    - 似たような値は、純粋な偶然から予想されるよりも、他の似たような値に近いのだろうか？
    - これらは、グローバルな空間自己相関に関連する質問の一部です。
- Local Spatial Autocorrelation：
  - 地図全体よりもはるかに焦点を絞ったレベルでの、**グローバルなトレンドからの逸脱**に焦点を当てるもの。

# 1. Global Spatial Autocorrelation：

**Global Spatial Autocorrelationの存在、性質、強さについて**データを調査する。

そのために、Explanatory Spatial Data Analysis（ESDA、探索的空間データ解析）と総称される一連の手法を使用する。
非空間的なEDAと同様に、ESDAは上述した目的の為に特別に設計されており、**空間とデータセット内の観測の相対位置**を分析の最前線に置く。

ESDAの手法は幅広く、前章の人口分布図のような単純なアプローチから、統計的推論やデータの地理的配置の明示的な認識を含むより高度で堅牢な手法まで、様々なものがあります。本章の目的は、後者の手法群に足を踏み入れることです。

## 実証的図解 An Empirical Illustration

2016年、イギリスではEU残留か離脱かを決める国民投票、いわゆる「Brexit」投票が行われた。ここでは、選挙管理委員会から提供された、残留派と離脱派の投票率に関する自治体レベルの公式データを使用する。組み合わせるデータセットは2つある。

自己相関を調べる前に必要な最後の要素は、空間重み付け行列です。この例では、8つの最近傍を使用しますが、前の章の重みに関する議論がこの文脈でも適用されますし、他の基準も有効でしょう。また、行の標準化も行います。

- コロプレス図はデータの主な空間的パターンを探るのに適した方法である。
- 一見、正の空間的自己相関があるように見える。
  - EU離脱の投票率が高い自治体は互いに隣接している傾向があり（例えば、東部地域を参照）、離脱の投票率がかなり低い自治体も同様である（北部のスコットランドが良い例である）。
- しかし、人間は非常に優れたパターン検知能力をもっている。
  - =>傾向、パターン、関連性を見出すこの並外れた能力は、**多くの偽陽性を生み出す傾向がある**。

つまり、パターンがあると思い込んでいても、実際には見ているものはほとんどランダムであるというケースです。これは地図の場合に特に顕著で、コレオプレス・マッピングの章で見たように、**幾何学的な形や大きさが、基本的なパターンに対する我々の認識を著しく歪めてしまうことがある**。

- 例えば、上の地図を見れば、空間的な自己相関の存在を推測することができる。
- しかし、我々が見ているものが純粋な偶然から生まれたものかどうかを実際に判断することは、通常、言うほど簡単なことではない。

そして、これこそが、Global Spatial Autocorrelationの指標の目的である。統計学の力を借りて、まず**地図に存在する値の空間分布を要約**し、次に**ランダム性からの逸脱を正式に定量化**します。

しかし、統計を掘り下げる前に、**核となる構成要素である「Spatial Lag」**を理解する必要がある。この概念を理解することで、グローバルな空間自己相関を理解することができるようになります。

## Spatial Lag

Spatial Lag演算子は、空間解析における**空間重み行列($W$)の最も一般的かつ直接的な応用の一つ**。

- 数学的な定義は、$W$と変数ベクトル(＝分析対象の値)の積で表される。
- 概念的には、Spatial Lagは各場所の周囲における変数の挙動を捉えるもので、その点では、変数のローカルスムーザーに似ている（？？）

Spatial Lagは行列表記で次のように表されるWe can formally express it in matrix notation as:

$$
Y_{sl} = W \cdot Y
$$

or, in individual notation(要素毎の表記) as:

$$
y_{sl-i} = \sum_{j} w_{ij} y_j
$$

where

- $w_{ij}$ is the cell in $W$ on the $i$-th row and $j$-th column.
  - thus capturing the **spatial relationship** between observation $i$ and $j$.
- $y_{sl-i}$ thus captures the 各Observationの値と、iとのSpatial Weightの積、の和。
  - non-neighborsの重みは0であるため、iのneighborsの値と重みの積を表す事になる。
  - もしSpatial Weight Matrixがバイナリであれば、**$y_{sl-i}$はiのneighborsの値の合計**となる。

もし行標準化（一般的な変換）であれば，0と1の間で境界ができる．
したがって，**空間ラグは「Local Average」**，**各観測点の近隣の平均値**となる。
この後者の意味は、後述する空間的自己相関の分析を可能にするものである。

Spatial Lagは多くの空間分析手法の重要な要素であり、その為、Pysalでは完全にサポートされています。
任意の変数のSpatial Lagを計算するためには、以下のようにする事ができる。

```
db['Pct_Leave_lag'] = weights.spatial_lag.lag_spatial(
    w, db['Pct_Leave']
)
```

このSpatial Lagの背景を知るために、2つの地方行政区を覗いてみよう。

## Binary case: Join counts(結合回数)

Spatial Lagは、空間的自己相関を定量化するのに重要な役割を果たします。
それを使って、任意の場所での変数の振る舞いを、そのすぐ近くのパターンに関連付け始める事ができます。

最初の一歩は、単純化されたケースであるBinary値について。
(関心を持っている変数が2つの値しか取らないケース)

- この文脈では、**あるオブザベーション(x=1)が同じカテゴリ内(x=1)の他のオブザベーションに囲まれているかどうか**に関心があります。
  - たとえば、我々のデータセットに戻って、「離脱に投票した地方自治体が、同じく離脱に投票した他の人に囲まれている傾向がどの程度あるか」を評価したいのです。
  - 進めるために、まず、地方自治体が離脱に投票した場合は1を、そうでない場合は0を示すバイナリ変数 (Leave)を計算しましょう。

可視化してみると、このマップは正の空間的自己相関の明確なケースを表しているように見えます：
全体的に、与えられた観測が反対のカテゴリの他の観測に囲まれている目に見えるケースはほとんどありません。

この視覚情報から得られた評価を正式に調査するために、"**join count statistic**"と呼ばれるものを使うことができる。

### join count statisticの概念：

- 緑（G、値0）と黄色（Y、値1）の正方形があるチェッカーボードを想像してください。
- この統計のアイデアは、**マップ上の緑-緑（GG）、黄-黄（YY）、または緑-黄/黄-緑（GY）の結合（または隣接ペア）の発生をカウント**すること。
- この文脈では、GGとYYの両方が正のSpatial Autocorrelationを反映し、GYは負のSpatial Autocorrelationを捕らえる。
- この統計量の直感は、**完全な空間的ランダム性の場合**にどれだけのGG、YY、GYが予想されるかの**基準値**を提供し、これを**データセットで観察されたカウントと比較**することである。
  - 予想よりGG/YYが多く、GYが少ないという状況は、正のSpatial Autocorrelationを示唆し、反対に、GG/YYよりGYが多いという状況は、負のSpatial Autocorrelationを指すであろう。

**Spatial Weight Matrixは、ここでは「誰が隣人かそうでないか」を区別するためにのみ使用される**ので、結合数統計量には2値重み(=すなわち0か1)が必要です。したがって、**wを非標準化状態に戻す**ように変換しましょう。

join count statisticsは次のように計算できる：

```python
seed(1234)
jc = esda.join_counts.Join_Counts(db['Leave'], w)
jc
```

```
<esda.join_counts.Join_Counts at 0x7f1e75f2bd30>
```

Pysalではよくあることですが、**計算された統計量の値以外にも多くの情報を保持するオブジェクト（jc）**を作成しています。
例えば、GGの出現回数を確認することができます（属性がbbであることに注意、これは考えられる2つのクラスが黒と白である元の参照に由来しています）。

- `jc.bb`=>返り値は`871.0`。
- 同様にYYの出現回数は`ww`属性で確認することができる。
- また、GY+YGの出現回数は`bw`属性で確認できる。
- 上記3パターンの合計の出現回数は`J`属性で確認できる。

この統計量joint count statisticは、**各クラス（bb, ww, bc）の実際の結合数を空間的ランダム性の場合に期待される結合数と比較する**ことに基づいています。

- GGの期待値：`mean_bb`属性
- GY/YGの期待値：`mean_bw`属性

これらの値がランダムな偶然に由来する可能性が高いかどうかを知るための統計的推論は、**観測値のランダムな空間順列**(=すなわち、Spatial Weight Matrixをランダムに作り直す？？)を使用して、完全な空間ランダム性という帰無仮説の下で合成マップを作成することで行うことができます。

esdaはこのような合成パターン(＝すなわちランダムなSpatial Weight Matrixを使ったJoint countの値？)を999個生成し、これらのパターンから結合カウントの分布を使用して、観測された結合カウント統計の擬似値(=すなわちSpatial Raodomnessの場合に期待される結合数？？)を生成します。

- `jc.p_sim_bb`
- `jc.p_sim_bw`

これらの結果は、正のSpatial Autocorrelationの存在を明確に示しています。なぜなら、同じカテゴリーのペアの結合が予想以上に多く（`p_sim_bb`）、反対の結合が著しく少ない（`p_sim_bw`）からです。**擬似p値の生成**については、次のセクションで詳しく説明します。

## Continuous case(連続値の場合): Moran Plot and Moran’s I

次は関心のある変数が連続値である場合を考える。
この場合によく使われる統計量はMoran's Iで、以下のように定義される。

$$
I = \frac{n}{\sum_{i}\sum_{j} w_{ij}}
\frac{
    \sum_{i}\sum_{j} w_{ij} z_i z_j
}{
    \sum_{i} z_i^2
}
$$

where

- $n$ : 観測地の数
- $z_i$ : location $i$における**標準化された**関心のある変数
- $w_{ij}$ Spatial Weight Matrixの要素

### Moran Plot

その数学の背後にある直感を理解するために、まずグラフィカルな解釈、すなわち**Moran Plot**から始めると便利です。モランプロットは空間データセットを可視化し、Spatial Autocorrelationの性質と強さを調べる方法である。これは基本的に、関心のある変数がそのSpatial Lagに対して表示される伝統的な散布図です。値を平均より上か下かに解釈できるように、興味のある変数は通常、その平均を引くことによって標準化されます。

![](https://geographicdata.science/book/_images/06_spatial_autocorrelation_55_0.png)

- 上図は、ある地方自治体における標準化された「離脱」投票率とそのSpatial Lagとの関係を示したもの。
  - 使用したWは行標準化されているため、各観測の近隣における離脱投票率の平均標準化密度と解釈することが可能である。
- プロットの解釈を助けるために、線形フィットも含まれている。
  - この線は、散布図への最良の線形適合、言い換えれば、2つの変数の間の関係を直線で表す最良の方法を表している。

このプロットは、両変数の間に正の相関関係があることを表している。

- ＝＞これは、正のSpatial Autocorrelationの存在を示している！
  - ＝つまり、類似した値は互いに近くに位置する傾向がある。
  - つまり、全体的な傾向として、高い値は他の高い値に近く、低い値は他の低い値に囲まれていることがわかる。
  - もちろん、高い値が低い値に囲まれたり、逆に低い値が高い値に囲まれたりする特殊な状況もあり得ます。
  - しかし、類似の値がどのようにクラスター化(=集団を形成)されているかという観点から**データの主要なパターンを要約**すると、それらは正の相関関係があり、したがって空間的にクラスター化されていると言うのが最も良い方法であることを意味しているのです。
- この例でいえば、EU離脱の割合が高い自治体は、離脱の割合が高い地域の近くに位置する傾向がある、というように解釈することができます。
  - ＝＞つまり、**離脱票の比率は空間的に正の自己相関がある**と言える。

### Moran Plotを踏まえてMoran's I

モランプロットは、データを探索し、空間的にどの程度値が集まっているかを把握するのに優れたツールである。しかし、**グラフの装置であるため、その洞察をより簡潔に凝縮することが難しい場合**があります。このような場合、**図を要約する統計的尺度**を考え出すのが良い方法である。上で形式的に表現したMoran's Iは、まさにこれを意図している。

つまりMoran's I＝Moran Plotを要約する統計的尺度である！

- 非空間的な設定で平均(mean)が値の分布の重要な要素を要約するのと同じ！！
- 比較を続けると、平均はヒストグラムやカーネル密度プロットを要約する単一の数値と考えることができる。
- 同様に、Moran's IはMoranプロットのエッセンスを多く含んでいる。
  - 実際、この2つの間には密接な関係があり、**Moran's Iの値はMoran Plotの上に重ねた線形フィットの傾き**に対応する。

このデータセットでMoran's Iを計算するには、esdaの特定の関数を直接呼び出します（その前に、もう一度wオブジェクトを標準化したものを並べてみましょう）。

```python
w.transform = 'R'
moran = esda.moran.Moran(db['Pct_Leave'], w)
```

`Moran` メソッドは、実際の統計値よりもはるかに多くの情報を含むオブジェクトを作成します。もし統計量の値を取得したい場合は、`moran.I`属性で取得する。

### Moran's Iの統計的検定

地図に見られるパターンやモランのIがとらえた値が、完全にランダムなプロセスによって生成されたものである可能性はどの程度あるのだろうか。
もし、**同じ変数で、その位置をランダムにシャッフルして考えたら、同じような特徴を持つ地図が得られるのだろうか？**
これらの疑問に対する洞察を得るために、esdaはシミュレーションを行い、**空間的にランダムなプロセスのもとで観察されるようなパターンが得られる可能性**について、確実性の尺度を返します。
これは`p_sim`属性にまとめられている。

- この値は、空間的ランダム性の下でのシミュレーションにおいて、観測値よりも極端な現実化の割合を示す経験的p値(**Empirical p-value**、モンテカルロシミュレーション等で観測的・経験的に得られたP値？statistical p-valueとは別？？)として計算される。
- **マップのモランズIに関連するp値が十分に小さいと、マップがランダムであるという仮説を棄却することができる**。
- 言い換えれば、マップは、値がランダムに場所に割り当てられた場合に期待されるよりも、より多くの空間的パターンを示すと結論づけることができる。

`moran.p_sim`が`0.001`が得られたとする。

これは非常に低い値で、特に、999個の並べ換え（esdaのデフォルト）を使用したシミュレーションの背後にあることを考えると、実際に得られた最小値であり、標準的な用語では、統計的に有意とみなされるでしょう。

- p_simの値の背後にある直感について、もう少し詳しく説明します。
  - **同じ値を持つがランダムに空間に配置された地図**を大量に生成し、それらの地図のそれぞれについてMoranのI統計量を計算すると、その**0.01%(==割合！！)**だけが観測データから得られる値よりも大きな（絶対）値を示し、**残りの99.99%のランダム地図はより小さな（絶対）値のMoranのIを受ける**ことになります。
    - つまり**帰無仮説として、データがSpatial Raodomnessを持つ**と仮定している！
    - ＝＞Spatial Raodomnessを持つデータをランダムにサンプリングしてきた場合、10000回に1回の割合でのみ、Moran's Iの値が、実測値`moran.I`を上回る。
    - ＝＞得られた実測値`moran.I`から、「関心のある変数がSpatial Autocorrelationを持つ」事は統計的に有意であるといえる。
  - **Moran's Iの値はMoran PlotのLinear fitの傾きと解釈できること**をもう一度思い出してみると、この場合、離脱票の割合について観測された特定の空間上の値の配置は、**地図間の投票比率をランダムにシャッフルした場合よりも集中**しており、それゆえ統計的に有意であることが分かる。

最初のステップとして、Global Spatial Autocorrelationの分析は、「**オブザベーションが空間的に正に自己相関しているようである**」ことを教えてくれる。
実際、EUの国民投票の全体的な空間パターンは非常に顕著で、近くの地域は同じように投票する傾向があった。

### Pysal の splot visualizaitonモジュール

Pysalのsplot可視化モジュールのおかげで、Moran Plot（右）と`p_sim`を得るために行う経験的検定のグラフィック（左）を組み合わせた統計量を素早く表示することができます。

```python
plot_moran(moran);
```

![](https://geographicdata.science/book/_images/06_spatial_autocorrelation_64_0.png)

- 左図について
  - 左側のパネルには、999個のランダムなマップを`Pct_Leave`変数(=関心のある変数)の値でシミュレートし(＝Spatial Raodomnessを想定しているから...!)、それらのマップのそれぞれについてMoran's Iを計算して得られた経験分布(**Empirical Distribution**)が灰色で表示されているのがわかります。
  - 青線は、得られたEmirical Distributionのmeanを示しています。
  - 反対に、赤線は、データセットで観測された地形を用いて、この変数について計算されたMoran's Iを示しています。
  - 観測されたパターンの下での値は、Spatial Raodomnessの仮定の下での値より有意に高いことが明らかです。
- 右図について：
  - 左図で得られた洞察は、右のパネルで確認できます。
  - これは、上で作成したMoran Plotと同等のプロットを示しています。

## 他のGlobal Spatial Autocorrelationの評価指標

Moran's IはGlobal Spatial Autocorrelationの統計量として最も広く使われているが、それだけではない。
ここでは、応用的な研究でよく使われる2つの追加的な尺度を紹介する。
これらはすべてSpatial Autocorrelationを考慮しますが、それぞれの**検定の仕様において**、その概念がどのように取り組まれているかが異なります。

### Geary's C

Gearyによって提案されたcontiguity ratio $c$ (連続性比)は次式で与えられる。

$$
C = \frac{n-1}{2 \sum_{i}\sum_{j} w_{ij}}
\frac{
    \sum_{i}\sum_{j} w_{ij} (y_i -y_j)^2
}{
    \sum_{i}(y_i - \bar{y})^2
}
$$

where

- $n$:Observation数
- $w_{ij}$：各要素がBinaryのSpatial Weight Matrixの一要素。
- $y_i$：Observation $i$における、分析対象の変数の値。
- $\bar{y}$：sample mean。

Moran's Iとの比較：

- どちらの指標も、各Observationの**局所的な近隣におけるYの関係を、サンプル全体のそれと比較している**ことがわかる。
- しかし、微妙な違いもある。
  - MoranのIが標準化された値の逆積($z_i z_j$)をとるのに対して、GearyのCは標準化されていない値の差($y_i - y_j$)をとるのである。

計算上、Geary' Cはより負荷が高いが、esdaを使えば簡単に計算することができる。

```python
geary = esda.geary.Geary(db['Pct_Leave'], w)
```

Geary' Cの推定値は`geary.C`属性でアクセスできる。

Geary' Cの統計的検定はMoran's Iと同様の手法で行われる。

### Getis and Ord's G

Geties と Ordらによって提案されたこの統計量は、Spatial Autocorrelationの**距離に基づく統計量のGlobalバージョン**である。

- この統計量は、point dataに対して考えられたもので、それゆえ距離を用います。
- しかし、**2値の空間重み行列が構築できれば**、ポリゴンデータにも適用することができます
- さらに、自然界に由来する正の変数の研究のために設計されている。

Getis and Ord's Gは、次のように定義される：

$$
G(d) = \frac{
    \sum_i \sum_j w_{ij}(d) y_i y_j
}{
    \sum_i \sum_j y_i y_j
}
$$

ここで、

- $w_{ij}(d)$：Observation $i$と$j$の間の関係性に割り当てられたBinaryのSpatial Weightで、**Distance band criterionに従っている**。
  - ＝＞そのため，類似した値（高いか低いか）がどの程度同居する傾向があるかをテストするのによく適している．
  - 言い換えれば、正のSpatial Autocorrelationを表す統計量である。
  - これは通常、ほとんどのGeographic Data Scienceアプリケーションの関心事である。
- しかし、この統計量は、集中する強度の指標として理解できるため、**負のSpatial Autocorrelationのケースを拾い上げることができない**ことに注意することが重要！！

Getis and Ord's Gを計算する為に、Binary distance bandを計算しましょう。すべてのObservationに少なくとも1つの隣接があることを確認するために、`min_threshold_distance`メソッドを使用し、データセットを`Ordnance Survey CRS (EPSG code 27700)` に投影します（メートルで表現されます）。

```python
db_osgb = db.to_crs(epsg=27700)
pts = db_osgb.centroid
xys = pandas.DataFrame({'X': pts.x, 'Y': pts.y})
min_thr = weights.util.min_threshold_distance(xys)
print(min_thr)
```

コンソール出力結果は`180878.91800926204`でした。
よって、すべての自治体が隣接するためには、距離帯は少なくとも約 181 Km である必要があります。
この情報は、Spatial Weight Matrixの生成時に、`DistanceBand` コンストラクタに渡すことができます。

```python
w_db = weights.DistanceBand.from_dataframe(db_osgb, min_thr)
```

では距離ベースのSpatial Weight Matrixが生成できたので、global G statisticを計算します。

```python
gao = esda.getisord.G(db['Pct_Leave'], w_db)
```

G statisticには`gao.G`属性でアクセスできる。
global G statisticの推定の統計的検定は他の指標と同様の方法で行われる。
