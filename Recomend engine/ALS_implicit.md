<!-- タイトル:Implicitデータを用いたALS -->

# 概要

# dataset

この例では、36 万人のユーザーの視聴行動を含む lastfm データセットを使用することにします。
このデータセットには、ユーザ ID、アーティスト ID、アーティスト名、そしてユーザが任意のアーティストを再生した回数が含まれています。
ダウンロードには、ユーザーの年齢、性別、国名などのファイルも含まれていますが、今回は使いません。

# Implicit データに対する行列分解

Implicit データにおいては、「疎行列(評価行列)に含まれるゼロ要素をどのように処理するか」という点が、Explicit データと異なります。
Explicit データの場合、ゼロ要素は単なる未知のフィールド(=「ユーザがまだ接触していないアイテム」)として扱います。
しかし、Implicit データの場合、ゼロ要素は「ユーザがまだ接触していないアイテム」と「ユーザが接触しているが嗜好に合わなかったアイテム」の両方の可能性を含んでいるので、Explicit データと同様に扱う事はできません。そこで、別のアプローチが必要になります！

# Implicit データにおける ALS

今回は Hu, Korenand and Volinsky による Collaborative Filtering for Implicit Feedback Datasets（Facebook と Spotify で使用）で概説されているアプローチをまとめます。
このアプローチでは、あるアイテムに対する嗜好(p)と、その嗜好に対する信頼度(c)をマージします。

- まず、ゼロ要素を低い信頼度 c で負の嗜好、非ゼロ要素を高い信頼度 c とする。
- 信頼度の計算には、再生回数、購入回数、ページ滞在時間、その他のインタラクションの形式を使用する事ができる。

## 嗜好度(Preference) p

Preference は以下のように設定されます。

$$
p_{ui}(r_{ui}) =
    \begin{cases}
        {1 \ (r_{ui} > 0)}\\
        {0 \ (r_{ui} =0)}
    \end{cases}
$$

基本的に Preference は、**評価行列 r のバイナリ表現**になります。

## 信頼度(Confidence) c

信頼度は、$r_{ui}$の大きさを用いて、以下の様に計算されます。

$$
c_{ui} = 1 + \alpha r_{ui}
$$

例えばユーザがアイテムを再生、閲覧、クリックした回数が多い程、信頼度は大きくなります。
また、1 を加えているのは、$\alpha r_{ui}$が 0 であっても、信頼度の最小値が 0 にならないようにする為?
$\alpha$の値は、ユーザとアイテムのインタラクションが一回しかなくても、未知のデータ(ゼロ要素)よりも信頼度が高くなる事を意味しています。(論文中では 40)

## ALS における目的関数

Implicit データにおける行列分解 Matrix Factorization では、上述した Preference と Confidence を用いて少し目的関数が異なります。

$$
\min_{x_u, y_i} \sum_{u, i} c_{ui}(p_{ui} - x_u^T y_i) + \lambda (\sum_u ||x_u||^2 + \sum_i ||y_i||^2)
$$

第二項は正則化項ですね。
第一項に関しては、Explicit データの場合は評価行列の要素$r_{ui}$が直接使われていた所が、Implicit データの場合は Preference（$p_{ui}(r_{ui})$）に置き換わっています。
また、各要素を Confidence で重み付けしているようですね...!
ここで、$\mathbf{X} \in \mathbb{R} ^{k \times m}$はユーザ行列、$\mathbf{Y} \in \mathbb{R} ^{k \times n}$はユーザ行列を意味します。

ALS ではこの目的関数を X と Y を交互に更新して最小化していきます。

## 更新式

ユーザ行列 X とアイテム行列 Y の各列$x_u$と$y_i$の更新式は以下のようになります。（線形回帰の最小二乗法の推定量と似てますね！たぶん目的関数を一回微分して＝０となるパラメータを求めたら、導出できるような気がします...!）

$$
x_u = (Y^T C^u Y + \lambda \mathbf{I})^{-1} Y^T C^u \cdot p(u)\\
y_i = (X^T C^i X + \lambda \mathbf{I})^{-1} X^T C^i \cdot p(i)
$$

ここで、
- Xはユーザ行列。$x_u$はX中のu列目の列ベクトル.
- Yはアイテム行列。$y_i$はY中のi列目の列ベクトル.
- Cは「評価行列の各要素$r_{ui}$から計算された信頼度c_{ui}」を要素とした信頼度行列。ユーザ×アイテムの評価行列の場合は、$C_u$はユーザuの全アイテムの信頼度ベクトル、$C^i$はアイテムiの全ユーザの信頼度ベクトル。
- Pは「「評価行列の各要素$r_{ui}$から計算された(Binary表現に変換された)Preference $p_{ui}$」を要素としたPreference行列。$p(u)$はユーザuの全アイテムのPreferenceベクトル。$p(i)$はアイテムiの全ユーザのPreferenceベクトル。

## 更新式における計算量削減の工夫
更新式中の$Y^T C^u Y$と$X^T C^i X$をそれぞれ、以下の様に分解すると...

$$
X^T C^i X = X^T C^i X + X^T X - X^T X \\ = X^T  X + X^T(C^i -\mathbf{I})X
$$

$$
Y^T C^u Y = Y^T C^u Y + Y^T Y - Y^T Y \\
= Y^T Y + Y^T(C_u - \mathbf{I})Y
$$

これらを更新式に代入すると...
$$
x_u = (Y^T Y + Y^T(C_u - \mathbf{I})Y + \lambda \mathbf{I})^{-1} Y^T C^u \cdot p(u)\\
y_i = (X^T  X + X^T(C^i -\mathbf{I})X + \lambda \mathbf{I})^{-1} X^T C^i \cdot p(i)
$$

ここで、更新式中の$Y^T Y$と$X^T X$は**ユーザインデックスuとアイテムインデックスiに依存しない**為、**事前に計算**する事ができ、**計算量を削減**する事ができます。

上記の2つの更新式を交互に繰り返し計算する事で、$P \approx X ^T \cdot Y = \hat{P} \\$を満たすようなアイテム行列とユーザ行列を推定する事ができます。
(Explicitデータの場合は評価行列を直接近似するような$R \approx X ^T \cdot Y = \hat{R} \\$を推定していましたよね。)

ImplicitデータにおけるALSを用いたMatrix Factorizationでは、**Preference値を用いて評価行列をBinary値に変換**する事と、**目的関数においてConfidence値を用いて各要素の重み付け**をしている点が、Explicitデータの場合と異なるようですね！

この得られた$\hat{P} $において、各ユーザにおけるPreference値の高いアイテムをレコメンドしていく、という理解でいいのか...??
