# link

- https://enakai00.hatenablog.com/entry/2021/07/14/174406

# 不要な記録を更にそぎ落とす(カッコよく言うと刈り込みをする的な何か)

前回、...

> ちなにみ、サブタスク3と言うのは、1≤N≤200 かつ $0≤v1≤1000$ という条件があるもので、重さが巨大になる可能性があります。一方、今回パスしたサブタスク2は、 1≤N≤200 かつ 0≤w1≤1000 という条件があるもので、重さの範囲が 1,000 以下に制限されています。さて・・・単純に記憶するべきデータ量 $2^N$ はどちらも同じなのに、サブタスク2はオッケーで、サブタスク3が通らないのはなぜでしょう？？？？

実際の所、データ量は同じなのに、なんでサブタスク2は時間がかからないんだろう？どこかで妖精さんが勝手にデータを減らしてくれている？？？

実は前回の記事の中に、妖精さんの居場所を示したヒントがあった。

>そう、繰り返しを進めるごとにディクショナリーのキーの数は、（残容量の偶然の一致を除いて）倍々に増えていくので、最終的には、$2^N$ 個ものキーを持った巨大なディクショナリーができあがってしまう...。

ここ！

（残容量の偶然の一致を除いて）

ここ。

サブタスク2は重さの範囲が 1,000 以下に限定されているので、さまざまな重さの組み合わせをした結果、残容量が被る可能性が高くなる。
データ数が最大 200 なので、総容量の値は、論理的に考えて高々 1,000 * 200 = 200,000 通り(?)なので、残容量の値もこれと同じく 200,000 通りに限定される。
一般的な組み合わせの数 $2^200$ よりは圧倒的に小さいことが分かる。

つまり、**サブタスク2は、残容量の値が被りまくることで、結果的にディクショナリーに記録されるデータ量が削減されていた**！

という感じだが、では、このような都合のよい条件がないサブタスク3に対応するにはどうすればよいのだろうか？

ここで、残容量がかぶった場合の処理を思い出してみる。

>結論からいうと、値が大きい方を残すべき。今、解こうとしている問題は、価値をどこまで上げられるか、という問題なのだから、同じ残容量であれば、当然ながら、より高い価値を実現するケースの方が後々で必要になるはず。

つまり、問題のゴールを考えれば、**すべての情報をまじめに記録する必要はなく、「これよりも有利な状況があきらかに存在する」と分かっている組み合わせの情報は捨ててしまっても問題ない**のである！
残容量が被る場合は、ディクショナリーの構成上、どちらかを捨てざるを得ないが、**たとえ残容量が被ってなくても、「これよりも有利な状況があきらかに存在する」と判断できる場合があれば、その情報は積極的に捨てていってよい**のである！

さて・・・それは、どのような状況だろうか？

たとえば、n 個目までの荷物を使った組み合わせで、次の2つの状況が残ったとする。

- 残容量 100 で合計価値 200 ---- (1)
- 残容量 80 で合計価値 180 ---- (2)

これ、(1) の方があきらかに有利だよね？(2) は残容量が少ない上に、合計価値も負けている。

この後、n+1 個目以降の荷物についてさまざまな組み合わせがやってくるが、どう考えても (2) の組み合わせが最終的な答え（合計価値が最大になる組み合わせ）に至ることはない。
n+1 個目以降はまったく同じ組み合わせで、これを (1) と組み合わせた方が最後の合計価値は確実に大きくなる。

つまり、**残容量の降順に情報をソートした場合、合計価値は単調に増加していくべき**であり、**もしも合計価値が減るような部分があれば、その情報はここで捨ててしまっても後の計算には影響しない**のである。

dp[n] を計算するごとにこのような「**刈り込み**」を行なって、**ディクショナリーに記録された情報を積極的に減らせば**、実行時間を改善することができるかも知れない！（このような不要な情報が発生しない様に、意図的に用意されたデータの場合もあるやも知れないが・・・まずは、試してみよう！)

nについてのループの先頭で、以下のような刈り込み処理を追加する。

```python
for n in range(2, N+1):
    # 刈り込み
    dpk = list(dp.keys())
    dpk.sort(reverse=True)
    pre_val = -1
    for available_weight in dpk: # 残り容量が減ると価値は上がるべき
        if dp[available_weight] <= pre_val:
            del dp[available_weight]
        else:
            pre_val = dp[available_weight]
```

この修正を加えたコードを提出した結果は・・・、全問正解！

# まとめ

というわけで、古典的なナップサック問題を例にして、「DP（動的計画法）の心」をひもといてみた。

現実にDPを使用する際は、そうは言っても、「後ろから前を振り返る」的な「とんち問題」の発想で絶妙な遷移処理を組み立てる（思いつく）必要がある。

さまざまな典型問題にあたって、パターンを掴むことも重要だが、単なるパターンとして覚えるのではなく、今回やったように、
- あえて「しらみつぶし」のアルゴリズムを考えてみる
- 1個の場合を考えて、それを踏まえて2個の場合を考えて・・・とデータ数が数個程度の場合を具体的に考察することで、適切な遷移処理のヒントを得る

と言った取り組みに時間をかけるのもよさそう。

# おまけ

今回の問題については、最終的に「刈り込み」でディクショナリーに保存するキーの数を削減することで、ディクショナリーのコピーやキーについてのループにかかる時間を削減することができた。
が、刈り込みに気づくまでは、キーが多いままの状態で、ディクショナリーのコピーなど、（キーが多い場合に）時間のかかる処理をできるだけ減らすための地味なチューニングも試みていた。


