## これは何?

- ECSでMLの特徴量生成ストリーミングパイプラインを実装する場合を考えて、色々調べるメモ.


## ECSについて

- AWS ECS (Elastic Container Service) は、AWS上でコンテナを実行するためのサービス。

### 3つの主要な概念:

- クラスター (cluster):
  - コンテナを実行するための**論理的なグループ**。
    - (あ、じゃあ例えば**A/Bテスト中などで、複数のnews encoderパイプラインを稼働させたい場合は、両パイプラインを異なるサービスで同じクラスターに配置する、みたいなイメージ...??**:thinking:)
  - 複数のAZに跨って構成できる。
  - クラスターはEC2もしくはFargate上で動作する。
- サービス (service)
  - クラスター内でタスクを管理する役割。タスクをスケールさせたり、**指定した数のタスクが常に動作するように維持**する役割。
  - ex.) 特定のルールに基づいて、タスクをスケールイン/アウトする。タスクがクラッシュしたら、新しいタスクを起動する。
  - メモ: **1つのECSサービスには、1つのタスク定義のみが紐づけられる...!:thinking:** 
    - サービスはタスク定義を元に、実際にタスクを実行し管理する...!
    - (同一のタスク定義を使用して複数のサービスを作成することは可能だが、各サービスは独立して管理される)
- タスク (task)
  - ECS上で動作する**コンテナの実行単位**。クラスター内で実行される1つ以上のコンテナの集まり。
  - タスク定義(task definition) で、どのコンテナイメージを使うか、どのリソース(メモリ、CPU)を割り当てるかを指定する。
    - メモ: **cdkではタスクではなくタスク定義を記述して、ECSサービスに紐づける、という理解...!!**:thinking:

### ECRから特定のコンテナイメージをpullしてきて、指定したエントリーポイントを実行させたい。

TypeScriptのcdkで定義する場合、どう実装できそうか。
(調べた感じ、ここはまあ特に問題なく実装できそう...!:thinking:)

- なんとなくどう定義するかのイメージ...!:thinking:
  - まずタスク定義!
    - 1. ECRリポジトリの参照(`ecr.Repository.fromRepositoryArn()`を使って、既存のECRリポジトリを参照)
    - 2. タスク定義の作成(`ecs.FargateTaskDefinition`を使って、タスク定義を作成)
    - 3. タスク定義にコンテナを追加 (`taskDefinition.addContainer()`を使って、コンテナの情報を追加)
      - 3-1. コンテナイメージを指定 (`image`引数に指定)
      - 3-2. エントリーポイントを指定 (`entryPoint`引数に指定)
      - 3-3. 環境変数を指定 (`environment`引数に指定)
      - 3-4. ログをどこに出力するか指定 (`logging`引数に指定)
  - そして、タスク定義をクラスターやサービスに紐付ける!
    - 1. ECSクラスターを定義 (ここではクラスター名, VPC, などを指定)
    - 2. ECSサービスを定義
      - ここでサービスが所属するクラスター, サービスが管理するタスクの定義, 実行するタスク数などを指定する...!!

### パイプラインの種類ごとに計算リソースを独立させたいメモ

- 経緯:
  - 単一クラスター内で全てのstreaming feature pipeliesを含める場合、**A/Bテストしやすさなどを考慮して同一クラスター内の異なるサービス間で計算リソースを独立させたい**!!
    - ex. control variantのnews encoderとtreatment variantのnews encoderの計算リソースは完全に独立していて欲しい。そうでないと「treatmentの処理がcontrolに影響を与えてしまわないか...!」とA/Bテストするのが怖くなってしまう。
- どうやら**EC2のインスタンスタイプの指定は、どうやらサービスごとではなくクラスターごとっぽい??**:thinking:
  - EC2起動タイプの場合、インスタンスタイプをクラスターに紐づける感じになる。その場合、**クラスター内の全てのサービスがそのインスタンスタイプのインスタンスで動作する**っぽい...??
  - サービスごとに異なるインスタンスタイプを使いたい場合は、基本的には複数のクラスターを作成する必要があるみたい。
    - 方法はなくはないらしいが、設定が複雑になってしまうっぽい。
    - (正直、管理するリソースを増やしたくないので、streaming feature pipelinesという単一のクラスターで管理したい...!:thinking:)
  - **おそらくEC2起動タイプの場合、サービス間で計算リソースを完全に独立させることは結構難しそう**...!:thinking:
- 一方で、**Fargate起動タイプの場合は、タスク定義でCPUとメモリの要件を指定するらしい...!** じゃあこっちの方が扱いやすい気がする...!:thinking:
  - Fargate起動タイプの場合、タスク間でリソースの共有は行われない。
  - なので当然、**サービス間でも計算リソースは独立**するはず。こうあるべき...!

### ECSの料金の仕組み

ECSの料金体系は、2つの起動タイプ(EC2/Fargate)によって異なる。

- EC2起動タイプ:
  - ECS自体に追加料金はかからない。
  - 使用するEC2インスタンス、EBSボリューム(=ストレージっぽいやつ??)、データ転送料金などがかかる。
- Fargate起動タイプ:
  - vCPUとメモリの使用量に応じて料金が発生する。
  - コンテナイメージのダウンロード開始からタスクの終了まで、秒単位で計算される(1分の最低料金あり)。
  - 計算式: 合計料金 = (vCPUの使用時間 * 単位時間あたりのvCPU料金) + (メモリの使用時間 * 単位時間あたりのメモリ料金)
  - 単位時間あたりの料金表:
    - 参照:[AWS Fargate の料金](https://aws.amazon.com/jp/fargate/pricing/)
    - Linux/X86の場合:
      - 1時間あたりのvCPU料金: USD 0.05056 /(1hour * 1 vCPU)  (i.e. 7.54円)
      - 1時間あたりのメモリGB料金: USD 0.00553 /(1hour * 1GB) (i.e. 0.83円)
    - Linux/ARMの場合:
  - なので例えばSagemaker TrainingJobの`ml.m5.large`インスタンス相当のリソースをFargateのLinux/X86で使う場合、1時間あたりの料金は以下の通り:
    - vCPU: 0.05056 * 2 = 0.10112 USD (i.e. 15.08円)
    - メモリ: 0.00553 * 8 = 0.04424 USD (i.e. 6.61円)
    - 合計: 21.69円
    - これを24時間365日稼働させると、21.69 * 24 * 365 = 190,004円/per year
      - (あ、全然安いな...!:thinking:)
      - ちなみに1時間あたりの料金ってTrainingJobと比べるとどうなんだろ??:thinking:
        - Sagemaker TrainingJobで`ml.m5.large`インスタンスの料金: USD 0.149/per hour (i.e. 22.26円)
          - 参考: [Amazon SageMaker AI の料金](https://aws.amazon.com/jp/sagemaker-ai/pricing/)
        - あ、ほぼ一致!!ちょっとだけFargateの方が安いくらいなんだ!

### Fargateの制約

- Fargateの計算リソースの制約:
  - メモリ上限: 120GiB
  - vCPU上限: 16個
  - 以前はメモリ上限30GiBとかだったが、2022年9月のアップデートで拡張されたらしい。
    - 参考: [【アップデート】AWS Fargateで最大16個のvCPU,120GiBのメモリが利用可能となりました！](https://dev.classmethod.jp/articles/fargate-vcpu-memory-expansion/)
- AWS BatchのFargateタイプも同様の制限らしい。
  - 参考: [AWS Batch の Fargate タイプで最大16vCPU, 120GiB メモリ指定できるようになりました](https://dev.classmethod.jp/articles/aws-batch-increases-compute-memory-resource-configurations-fargate-type-jobs-4x/)
- Sagemaker TrainingJobなどとの比較
  - GPUが使えない。
  - vCPU数が最大で16なので、場合によっては物足りない。
  - やはりバッチはTrainingJobの方が使いやすそう。
