## refs:

- 反実仮想機械学習

# (準備)繰り返し期待値の法則(law of iterated expectation)を導出してみる。

- 繰り返し期待値の法則(law of iterated expectation)は、**同時分布に関する期待値が、条件付き期待値(conditional expectation)の周辺分布に関する期待値と等しい**、という法則。

$$
E_{p(x,y)}[f(x,y)] = E_{p(x)}[E_{p(y|x)}[f(x,y)]]
$$

左辺から右辺を導出してみる。

$$
E_{p(x,y)}[f(x,y)] = \int_{x} \int_{y} f(x,y) p(x,y) dx dy
\\
= \int_{x} (\int_{y} f(x,y) \frac{p(x,y)}{p(x)} dy) p(x) dx
\\
= \int_{x} (\int_{y} f(x,y) p(y|x) dy) p(x) dx
\\
= \int_{x} E_{p(y|x)}[f(x,y)] p(x) dx
\\
= E_{p(x)}[E_{p(y|x)}[f(x,y)]]
\\
導出完了!!
$$

# 全分散の法則(Law of Total Variance)を導出してみる。

- 全分散の法則(Law of Total Variance)は、**同時分布に関する分散 (=全分散?)が、条件付き分散(conditional variance)に関する期待値と、条件付き期待値(conditional expectation)に関する分散の和に等しい**、という法則。

$$
V_{p(x,y)}[f(x,y)] = V_{p(x)}[E_{p(y|x)}[f(x,y)]] + E_{p(x)}[V_{p(y|x)}[f(x,y)]]
$$

## 左辺を展開していく

左辺から右辺を導出してみる。

$$
V_{p(x,y)}[f(x,y)] = E_{p(x,y)}[(f(x,y) - E_{p(x,y)}[f(x,y)])^2]
\\
\because 2乗の項の中身に、条件付き期待値の+-を追加。
\\
= E_{p(x,y)}[((f(x,y) - E_{p(y|x)}[f(x,y)]) + (E_{p(y|x)}[f(x,y)] - E_{p(x,y)}[f(x,y)]))^2]
\\
\because 2乗の項を展開。
\\
= E_{p(x,y)}[(f(x,y) - E_{p(y|x)}[f(x,y)])^2
\\
+ 2(f(x,y) - E_{p(y|x)}[f(x,y)])(E_{p(y|x)}[f(x,y)] - E_{p(x,y)}[f(x,y)])
\\
+ (E_{p(y|x)}[f(x,y)] - E_{p(x,y)}[f(x,y)])^2]
\\
\because 最も外側の期待値関数に対して、和の期待値を期待値の和に展開する。
\\
= E_{p(x,y)}[(f(x,y) - E_{p(y|x)}[f(x,y)])^2]
\\
+ 2E_{p(x,y)}[(f(x,y) - E_{p(y|x)}[f(x,y)])(E_{p(y|x)}[f(x,y)] - E_{p(x,y)}[f(x,y)])]
\\
+ E_{p(x,y)}[(E_{p(y|x)}[f(x,y)] - E_{p(x,y)}[f(x,y)])^2]
$$

## cross termの部分が0になることを示す。

ここで、第二項、つまり交差項(cross term)の部分について考える。(実はこの項が消えてほしい...!)

$$
2 E_{p(x,y)}[(f(x,y) - E_{p(y|x)}[f(x,y)])(E_{p(y|x)}[f(x,y)] - E_{p(x,y)}[f(x,y)])]
\\
\text{ここで、記号AとBで置き換える}
\\
= 2 E_{p(x,y)}[A B]
$$

繰り返し期待値の法則(law of iterated expectation)を使って、条件付き期待値の周辺分布に関する期待値に変換する。

$$
= 2 E_{p(x)}[E_{p(y|x)}[A B]]
$$

Bの項について。
Bはxの値に依存する関数である。xが決まれば一意に定まる定数項と言える。なぜなら、1項目の$E_{p(y|x)}[f(x,y)]$はxに依存する関数であり、2項目の$E_{p(x,y)}[f(x,y)]$はxにもyにも依存しない定数項であるから。

よって...

$$
= 2 E_{p(x)}[B \cdot E_{p(y|x)}[A]]
$$

ここで、Aの項について。$A = f(x,y) - E_{p(y|x)}[f(x,y)]$ である。Xが与えられた時のAの期待値は0になる。
数式で表すと確かに0になるな...!

$$
E_{p(y|x)}[A] = E_{p(y|x)}[f(x,y) - E_{p(y|x)}[f(x,y)]]
\\
= \int_{y} (f(x,y) - E_{p(y|x)}[f(x,y)]) p(y|x) dy
\\
= \int_{y} f(x,y) p(y|x) dy - E_{p(y|x)}[f(x,y)] \int_{y} p(y|x) dy
\\
= E_{p(x,y)}[f(x,y)] - E_{p(y|x)}[f(x,y)] \cdot 1
\\
= 0
$$

従って、cross termは消える!

$$
2 E_{p(x,y)}[A B] = 2 E_{p(x)}[B \cdot E_{p(y|x)}[A]]
\\
= 2 E_{p(x)}[B \cdot 0] = 2 E_{p(x)}[0] = 0
$$

## cross termを消した後の式を整理する。

第二項を消した後の式を再掲すると以下。

$$
V_{p(x,y)}[f(x,y)] = E_{p(x,y)}[(f(x,y) - E_{p(y|x)}[f(x,y)])^2]
\\
+ 0
\\
+ E_{p(x,y)}[(E_{p(y|x)}[f(x,y)] - E_{p(x,y)}[f(x,y)])^2]
$$

ここからは簡単なはず...!

### 第一項について

繰り返し期待値の法則(law of iterated expectation)を使って、同時分布 $p(x,y)$ に関する期待値を、、条件付き期待値(conditional expectation)の周辺分布に関する期待値に変換すると...!!

$$
= E_{p(x)}[E_{p(y|x)}[(f(x,y) - E_{p(y|x)}[f(x,y)])^2]]
\\
+ 第二項(一旦放置)
$$

あとは、期待値と分散の定義を使って整理すると...!

$$
= E_{p(x)}[V_{p(y|x)}[f(x,y)]]
\\
+ 第二項(一旦放置)
$$

最終的な全分散の法則の右辺第二項と一致するようになった...!!
(後は第二項が、最終的な右辺第一項 $V_{p(x)}[E_{p(y|x)}[f(x,y)]]$ に一致することを示せばよい...!)

### 第二項について

第二項 $E_{p(x,y)}[(E_{p(y|x)}[f(x,y)] - E_{p(x,y)}[f(x,y)])^2]$ が、最終的な右辺第一項 $V_{p(x)}[E_{p(y|x)}[f(x,y)]]$ に一致することを示す。

帰納的に考えると、第二項は以下のように展開できる。

$$
目的の右辺第一項 = V_{p(x)}[E_{p(y|x)}[f(x,y)]]
\\
\because 分散の定義式より
\\
= E_{p(x)}[(E_{p(y|x)}[f(x,y)] - E_{p(x)}[E_{p(y|x)}[f(x,y)]])^2]
\\
\because 繰り返し期待値の法則より
\\
= E_{p(x)}[(E_{p(y|x)}[f(x,y)] - E_{p(x,y)}[f(x,y)])^2]
$$

ここで、

- $E_{p(x)}[\cdot]$ は、xに関する周辺分布$p(x)$に関する期待値。
- $E_{p(y|x)}[\cdot]$ は、xが与えられた時のyの条件付き分布 $p(y|x)$ に関する期待値。(xの値に依存する関数?)
- $E_{p(x,y)}[\cdot]$ は、同時分布$p(x,y)$に関する期待値。つまり、全てのxとyの組み合わせに関する期待値。

あれ? 一致させたかった第二項 $E_{p(x,y)}[(E_{p(y|x)}[f(x,y)] - E_{p(x,y)}[f(x,y)])^2]$ と比べると、**一番外側の期待値関数が $E_{p(x)}[\cdot]$ と $E_{p(x,y)}[\cdot]$ で違うじゃん**...!??

- ここで大事なのは、この式の意味するところ...! 実は両者は同じ意味を持っている...!!
  - **なぜなら、この平方根の期待値は、全xとyのペアに対して一貫して計算されるから...!!**

よって、以下が成立できる。

$$
f_{p(x)}[(E_{p(y|x)}[f(x,y)] - E_{p(x,y)}[f(x,y)])^2] = E_{p(x,y)}[(E_{p(y|x)}[f(x,y)] - E_{p(x,y)}[f(x,y)])^2]
$$

よって第二項が、全分散の法則の右辺第一項 $V_{p(x)}[E_{p(y|x)}[f(x,y)]]$ に一致することが示された...!!

以上より、全分散の法則(Law of Total Variance)が導出された...!!
