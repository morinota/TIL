# chapter 2 機械学習実践の為の基礎技術

published date: hogehoge September 2022,
authors: Wondo Rhee, Sung Min Cho, Bongwon Suh
url(paper): https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf
(勉強会発表者: morinota)

---

## どんなもの?

- 「正確な予測を導く」問題と「高性能な意思決定を導く」問題に対して、chapter 1で導入したフレームワークを適用してハンズオン的に進めながら、実際に施策を導く際にたどるべき思考回路をなぞる.

## 先行研究と比べて何がすごい？

論文でないので飛ばします.

## 技術や手法の肝は？

### 「正確な予測を導く」問題

#### データの観測構造をモデル化

データの観測構造をモデル化すると、会員登録の有無に依って観測データと予測対照群の間に性質の違いが生じる事が分かった.

#### 解きたい問題を特定する

MLモデルを学習する際に(観測データから計算可能か否かは一旦おいておいて)最適化したい目的関数を定義する事を、"解きたい問題の特定"と呼んでいた。

$$
J(f_{\phi}) = E_{X}[l(Y, f_{\phi}(X)) |O=0]
$$

ここで目的関数 $J(f_{\phi})$ は、「あるパラメータ$\phi$によって定義される予測モデル$f_{\phi}$が、非会員ユーザの属性情報$Y$をどれだけの誤差で予測できているのか?」を定量化したものである。
注目すべきは、期待値が$O=0$による条件付きになっている点。このように条件付きの期待予測損失を目的関数として定義する事で、非会員ユーザが予測対象である、という我々のモチベーションを表現している。
またこの時点では、理想的な目的関数といて、観測データ$D$とは切り離して定義している点にも注目。

$$
J(f_{\phi}) = E_{X}[l(Y, f_{\phi}(X)) |O=0]
\\
= \int l(Y, f_{\phi}(X)) f_{X|O}(x|o=0) dx
\\
\because \text{条件付き期待値ってこのように定義されるのか...} E[X|Y=y] = \int_{X} f_{X|Y}(x|y) dx
\\
= \int l(Y, f_{\phi}(X)) \frac{f_{X,O}(x, o)}{f_{O}(o)} dx
\\
\because \text{同時確率と条件付き確率の関係式より... } P(X,Y) = P(X|Y)P(Y) (離散確率分布の場合)
-> \int_{X} f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_{Y}(y)}
\\
= \int l(Y, f_{\phi}(X)) \frac{f_{X}(x) \cdot P(O=0|x)}{P(O=0)} dx
\\
\because \text{分子の同時確率を、同様の関係式に基づいて分割}
\\
\approx  \int l(Y, f_{\phi}(X))f_{X}(x) (1 - \theta(x)) dx
\\
\because \text{特徴量Xを持つユーザが会員になる確率を以下のように定義} \theta(X) = P(O=1|X)
\\
\text{Oはbinaryの確率変数なので...}  P(O=0|x) = 1 - \theta(X)
\\
\text{P(O=0)はXやYに依らない定数なので無視できる}
\\
=E_{X}[(1 - \theta(X)) \cdot  l(Y, f_{\phi}(X))]
$$

これにより真の目的関数 $J(f_{\phi})$ が、$(1 - \theta(x))$で重み付けられた損失関数でも表せる事がわかった。

予測モデルの学習は、ここで定義した予測誤差を最小化するモデルパラメータ$\phi$を得る問題として定式化される。

$$
\phi^* = \argmin_{\phi} J(f_{\phi})
$$

#### 観測データのみから解きたい問題を近似する

我々が手元で観測できるデータは母集団からサンプリングされた有限個のデータなので、$J(f_{\phi})$を直接最適化する問題を解いて $f_{\phi}$ を学習する事は現実的に不可能。

今回扱っているセグメント拡張の問題において目的変数が観測されるのは、既に会員登録しているユーザのみ。
この状況で得られる学習データは以下のように表す事ができる。

$$
D = {(X_i, Y_i) | O_i = 1}_{i=1}^{N}
$$

手元で観測できる学習データを確認したところで、それを用いて解くべき問題を近似する方法を導出する。
この解くべき問題を近似する段階で多くの人は、データの観測構造に気を払う事なく、ナイーブな経験損失に飛びついてしまいがち。ここでナイーブな経験尊師tとは、観測されているデータに対する予測誤差の単純平均を意味する。

$$
\hat{J}_{naive}(f_{\phi}; D) = \frac{1}{N} \sum_{i:O_i =1}^{N} l(Y_i, f_{\phi}(X_i))
\\
= \frac{1}{N} \sum_{i=1}^{N} O_i \cdot l(Y_i, f_{\phi}(X_i))
$$

ナイーブ推定量が実際のところどのような目的関数を近似するものなのかを確かめる為に、その期待値を導出してみる。
ある適当な予測モデル$f_{\phi}$が与えられた時、次のように計算される。

$$
E_{X,O}[\hat{J}_{naive}(f_{\phi}; D)]
\\
= E_{X,O}[\frac{1}{N} \sum_{i=1}^{N} O_i \cdot l(Y_i, f_{\phi}(X_i))]
\\
= \frac{1}{N} \sum_{i=1}^{N} E_{X}[E_{O}[O_i|X_i] \cdot l(Y_i, f_{\phi}(X_i))]
\\
\because \text{ここの導出がまだ理解してない...}
\\
= \frac{1}{N} \sum_{i=1}^{N} E_{X}[\theta(X_i) \cdot l(Y_i, f_{\phi}(X_i))]
\\
\because \theta(X) = E[O|X]
\\
= E_{X}[\theta(X) \cdot l(Y, f_{\phi}(X))]
$$

(メモ: 同時確率(X,O)の期待値の式変形について)

$$
E_{x,o}[o A] = \int \int o A f(x,o) dxdo = \int \int o A f(x) f(o|x) dxdo
\\
= E_{x}[\int o A f(o|x) do] = E_{x}[A E_{o|x}[o]]
= E_{x}[A E_{o}[o|x]]
\\
\because E_{o|x}[o] = E_{o}[o|x] \text{ 条件付き期待値の表記法の問題?}
$$

このナイーブな経験損失 の期待値を見ると、損失関数 $l(Y, f_{\phi}(X))$ が $\theta(X_i)$ で重みづけられてしまっている事が分かる。
すなわち、**会員になりやすい(属性情報が観測されやすい)データを必要以上に重視してしまう**設計になっている。
この場合、本来重視したかったはずの非会員ユーザに対する予測精度は寧ろ軽視されてしまう。

同様の問題はセグメント拡張に限らず、多くの問題設定で生じ得る。

- ex)メール配信に関連する施策。
  - メール配信を受けてタップする確率をユーザ毎に予測したいタスクでは、メールをタップした人についての目的変数しか得る事ができない。
  - この場合、ナイーブ推定量が定義するように、目的変数が観測されたユーザのデータのみに絞って、目的変数を計算するかもしれない。メールをタップしやすい人たちと、メールをタップしにくい人達の間には、メール配信の時間帯やメールのタイトル等に応じた傾向の違いが見込まれるにもかかわらず...!
  - すなわち、メール配信に関連する施策でも、観測データと予測対象の間に存在する乖離に気を払わなければ、**本来解きたい問題とはかけ離れた問題についての精度を追求してしまう可能性がある**。

近似方法を導く為に、真の目的関数とナイーブな経験損失の期待値を比較し、その違いを洗い出す。

$$
J(f_{\phi}) = E_{X}[(1 -\theta(X)) \cdot l(Y, f_{\phi}(X))]
\\
E_{X,O}[\hat{J}_{naive}(f_{\phi};D)] = E_{X}[\theta(X) \cdot l(Y, f_{\phi}(X))]
\\
\therefore J(f_{\phi}) = \frac{(1 -\theta(X))}{\theta(X)} E_{X,O}[\hat{J}_{naive}(f_{\phi};D)]
\\
\text{厳密には違うけど...乖離を定量化するイメージ}
$$

期待値を計算した後に真の目的関数が現れるよう、乖離の大きさを考慮した推定量を新たに設計する。

$$
\hat{J}_{IW}(f_{\phi};D)
= \frac{1}{N} \sum_{i:O_i = 1} \frac{(1 -\theta(X))}{\theta(X)} l(Y, f_{\phi}(X))
= \frac{1}{N} \sum_{i=1}^{N}O_i \cdot \frac{(1 -\theta(X))}{\theta(X)} l(Y, f_{\phi}(X))
$$

ここでは重みを学習におけるユーザiの重要度と捉え、**重要度重み付け損失(Importance Weight)**とでも呼ぶべき推定量を定義した。
属性情報が得られる会員データのみを用いている点では、ナイーブな経験損失と同様。
しかし、先程特定した乖離の大きさを考慮すべく、予め損失関数に重み付けしている点が異なる。

なお、重要度重み付け損失の計算に必要なそれぞれのデータが観測される確率$\theta(X)$は、事前にデータから推定しておく必要がある。
これは、次の誤差最小化問題を解く事で推定できる。

$$
\hat{\psi} = \argmin_{\psi} \frac{1}{N} \sum_{i=1}^{N} l(O_i, g_{\psi}(X_i))
$$

ここで $g_{\psi}$は、binary変数$O_i$を予測する為のパラメータ$\psi$で定義される予測モデルである。
$\theta(X)$は、特徴量$X$を持つユーザが$O_i=1$となる確率と定義していたので、O_iを目的変数とみなした予測誤差最小化問題を解けば良い。
この予測モデルの学習には、観測されたトレーニングデータを用いる点に注目。
なお、会員かどうかの情報$O_i$は全ユーザについて観測されているはずなので、上記の$g_{\psi}$は 真の目的関数と観測データで計算可能な目的関数の乖離を気にせず解くことができる。



### 「高性能な意思決定を導く」問題

## どうやって有効だと検証した?

論文でないので飛ばします.

## 議論はある？

## 次に読むべき論文は？

## お気持ち実装
