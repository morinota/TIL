# 方策勾配ベースのランク学習にて、公平性や格差の制約を追加するためのアプローチ「Fair-PG-Rank」の論文を読んだ!

## ざっくりどんな論文??

- 「報酬最大化 + 公平性制約」の両方を考慮してランク学習(LTR)するための手法を提案した論文。
- 

## 本論文のモチベーションは??



## 公平性や格差を考慮したランキング方策の学習

- 本論文の主な目標:
  - ユーザの効用（utility）を最大化するだけの従来のランク学習(LTR)じゃなく、
- 例:
  - 男性5人と女性5人の求職者がいて、男性の関連性確率は0.89、女性の関連性確率は0.88だった場合、メリット最大化だけ考えると男性が上位に表示されて**露出の不公平が生じる**。
  - なので、**メリットに基づいた露出配分**を制約として組み込みたい!
- 満たしたい目標3つ:
  - 1つ目: 露出はメリットに比例すること!
  - 2つ目: そのルール(比例の仕方)を明示的に指定可能であること!
  - 3つ目: でもユーザ効用も犠牲にしないように最適化すること!

### ERM(経験リスク最小化)によるランキング方策学習の定式化

基本設定:
- クエリ分布 $Q$ からサンプリングされるクエリ $q$ がある。
- 各クエリ $q$ には、候補ドキュメント集合 $d^q$ があり、各ドキュメント $d_{i} \in d_q$ にはクエリ $q$ への関連性スコア $rel^q_{i}$がある。
- 各ドキュメントは、特徴量ベクトル $x^{q}_{i} = \Psi(q, d^{i}_{q})$ で表現される。

学習対象:
- 学習したいのは、確率的なランキング方策 $\pi$ (ドキュメントのランキング順列 $r$ の確率分布)。
- 目的は、以下の $\pi^{*}$ を見つけること。


$$
\pi^{*} = \arg\max_{\pi} \mathbb{E}_{q \sim Q} [U(\pi|q)]
$$

- 日本語にすると、「確率分布 $p(q) = Q$ に対する効用 $U(\pi|q)$ の期待値を、最大化するようなランキング方策 $\pi$ を見つけたい!」ってこと。
- ここで、効用(Utility)は以下で表される。
  - $U(\pi|q) = \mathbb{E}_{r \sim \pi(r|q)} [\Delta(r, rel^q)]$
  - 日本語にすると、「あるクエリqに対して、確率分布 $\pi(r|q)$ のランキング方策を稼働させた場合の、なんらかの指標 $\Delta$ の期待値」ってこと。
  - (あ、$U(\pi|q)$ ってqの関数なのか...!:thinking:)
- $Delta$ は例えばnDCGとか...!! 任意のランキングのユーザ体験に関わるmetricで良さそう??:thinking:

### 公平性制約の導入

- 上述の効用(Utility) $U(\pi|q)$ の他に、本手法では $D(\pi|q)$ という「不公平さを表す指標」を定義して、以下のような制約付きの最適化問題を解くようにする。
  - (あ、効用Uだけじゃなくて、この不公平指標Dもqの関数なのか...!:thinking:)

$$
\pi^{*} = \arg\max_{\pi} \mathbb{E}_{q \sim Q} [U(\pi|q)] 
\quad \text{s.t.} \quad D(\pi|q) \leq \epsilon
$$

- ラグランジュ乗数 $\lambda$ を導入して、以下のようにトレードオフを考慮した1つの式にまとめられる:

$$
\pi^{*}_{\lambda} = \arg\max_{\pi} \mathbb{E}_{q \sim Q} [U(\pi|q) - \lambda D(\pi|q)]
$$

### 不公平指標 D の定義について

格差測定Dを定式化するために、まず位置バイアスと露出を定義する必要がある。

- Position Bias (位置バイアス) $v_{j}$
  - ランキング内のある位置 $j$ の位置バイアス $v_{j}$ は、「ランキングにアクセスするユーザのうち、位置 $j$ のアイテムを調べる割合」として定義される。
    - (これってこの論文オリジナルの定義??:thinking:)
- Exposure (露出) $Exposure(d_{i}|\pi)$
  - 特定のクエリ $q$ とあるランキング方策 $\pi(r|q)$ におけるドキュメント $d_{i}$ の露出は、「ドキュメントが受ける注意(attention)の期待値」として定義される。
    - (露出は、qと $\pi$ の関数なのか...!:thinking:)
  - 数式で表すと以下。
    - 日本語でいうと「あるクエリ $q$ に対するランキング方策 $\pi$ によるドキュメント $d_i$ の露出は、ドキュメント $d_i$ の表示位置 $r(d_i)$ における位置バイアス $v_{r(d_i)}$ の、ランキングの確率分布に関する期待値」って感じ...!
    - ここで、$r(d_i)$ は、あるランキング $r$ におけるドキュメント $d_i$ の位置を表す。

$$
Exposure(d_{i}|\pi) = v_{\pi}(d_i) = \mathbb{E}_{r \sim \pi(r|q)} [v_{r(d_i)}]
$$

### メリットに基づく露出の割り当て制約について

- 基本的なアイデア:
  - メリットが高いドキュメントは、低いドキュメントと比べてより多くの露出を受けるべきである。

### 個々のドキュメント粒度の公平性(Individual Fairness)

### グループ粒度の公平性(Group Fairness)

## 公平なランク学習のための方策学習アルゴリズム「Fair-PG-Rank」について


