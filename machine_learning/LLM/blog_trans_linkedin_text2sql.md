https://www.linkedin.com/blog/engineering/ai/practical-text-to-sql-for-data-analytics

# Practical text-to-SQL for data analytics å®Ÿç”¨çš„ãªãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰SQLã¸ã®å¤‰æ›ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿åˆ†æ
December 9, 2024 2024å¹´12æœˆ9æ—¥
Co-authors:Co-authored byAlbert Chen,Co-authored byManas Bundele,Co-authored byGaurav Ahlawat,Co-authored byPatrick Stetz,Co-authored byZhitao (James) W.,Co-authored byQiang Fei,Co-authored byDonghoon (Don) Jung,Co-authored byAudrey Chu,Co-authored byBharadwaj Jayaraman,Co-authored byAyushi  Panth,Co-authored byYatin Arora,Co-authored bySourav Jain,Co-authored byRenjith Varma,Co-authored byAlex Ilin,Co-authored byIuliia Melnychuk ğŸ‡ºğŸ‡¦,Co-authored byChelsea C.,Co-authored byJoyan Sil, andCo-authored byXiaofeng Wang
å…±è‘—è€…ï¼šã‚¢ãƒ«ãƒãƒ¼ãƒˆãƒ»ãƒã‚§ãƒ³ã€ãƒãƒŠã‚¹ãƒ»ãƒãƒ³ãƒ‡ãƒ¬ã€ã‚¬ã‚¦ãƒ©ãƒ–ãƒ»ã‚¢ãƒ¼ãƒ©ãƒ¯ãƒƒãƒˆã€ãƒ‘ãƒˆãƒªãƒƒã‚¯ãƒ»ã‚¹ãƒ†ãƒƒãƒ„ã€ã‚¸ãƒ¼ã‚¿ã‚ªï¼ˆã‚¸ã‚§ãƒ¼ãƒ ã‚ºï¼‰W.ã€ãƒã‚¢ãƒ³ãƒ»ãƒ•ã‚§ã‚¤ã€ãƒ‰ãƒ³ãƒ•ãƒ¼ãƒ³ï¼ˆãƒ‰ãƒ³ï¼‰ãƒ»ã‚¸ãƒ§ãƒ³ã€ã‚ªãƒ¼ãƒ‰ãƒªãƒ¼ãƒ»ãƒãƒ¥ãƒ¼ã€ãƒãƒ©ãƒ‰ãƒ¯ã‚¸ãƒ»ã‚¸ãƒ£ãƒ¤ãƒ©ãƒãƒ³ã€ã‚¢ãƒ¦ã‚·ãƒ»ãƒ‘ãƒ³ã€ãƒ¤ãƒ†ã‚£ãƒ³ãƒ»ã‚¢ãƒ­ãƒ¼ãƒ©ã€ã‚½ã‚¦ãƒ©ãƒ–ãƒ»ã‚¸ã‚§ã‚¤ãƒ³ã€ãƒ¬ãƒ³ã‚¸ã‚¹ãƒ»ãƒ´ã‚¡ãƒ«ãƒã€ã‚¢ãƒ¬ãƒƒã‚¯ã‚¹ãƒ»ã‚¤ãƒªãƒ³ã€ãƒ¦ãƒªã‚¢ãƒ»ãƒ¡ãƒ«ãƒ‹ãƒãƒ¥ã‚¯ ğŸ‡ºğŸ‡¦ã€ãƒã‚§ãƒ«ã‚·ãƒ¼ãƒ»C.ã€ã‚¸ãƒ§ãƒ¤ãƒ³ãƒ»ã‚·ãƒ«ã€ãã—ã¦ã‚·ãƒ£ã‚ªãƒ•ã‚§ãƒ³ãƒ»ãƒ¯ãƒ³

In most tech companies, data experts spend a significant amount of their time helping colleagues find data they need â€“ time that could be spent on complex analysis and strategic initiatives. 
ã»ã¨ã‚“ã©ã®ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ä¼æ¥­ã§ã¯ã€**ãƒ‡ãƒ¼ã‚¿å°‚é–€å®¶ã¯åŒåƒšãŒå¿…è¦ã¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã¤ã‘ã‚‹æ‰‹åŠ©ã‘ã«å¤šãã®æ™‚é–“ã‚’è²»ã‚„ã—ã¦ã„ã¾ã™**ã€‚ã“ã®æ™‚é–“ã¯ã€è¤‡é›‘ãªåˆ†æã‚„æˆ¦ç•¥çš„ãªå–ã‚Šçµ„ã¿ã«ä½¿ã†ã“ã¨ãŒã§ãã‚‹ã¯ãšã§ã™ã€‚
This bottleneck not only frustrates data teams but also creates delays for business partners waiting for crucial insights. 
**ã“ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¯ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ãƒ ã‚’è‹›ç«‹ãŸã›ã‚‹ã ã‘ã§ãªãã€é‡è¦ãªæ´å¯Ÿã‚’å¾…ã£ã¦ã„ã‚‹ãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã«é…å»¶ã‚’å¼•ãèµ·ã“ã—ã¾ã™**ã€‚

Generative AI presents an opportunity to improve this workflow. 
ç”ŸæˆAIã¯ã€ã“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ”¹å–„ã™ã‚‹æ©Ÿä¼šã‚’æä¾›ã—ã¾ã™ã€‚
As part of our data democratization efforts at LinkedIn, we've developed SQL Bot, an AI-powered assistant integrated within our DARWIN data science platform. 
LinkedInã§ã®ãƒ‡ãƒ¼ã‚¿æ°‘ä¸»åŒ–ã®å–ã‚Šçµ„ã¿ã®ä¸€ç’°ã¨ã—ã¦ã€ç§ãŸã¡ã¯DARWINãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«çµ±åˆã•ã‚ŒãŸAIé§†å‹•ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã‚ã‚‹SQL Botã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚
This internal tool transforms natural language questions into SQL: it finds the right tables, writes queries, fixes errors, and enables employees across functions to independently access the data insights they need under the appropriate permissions. 
ã“ã®å†…éƒ¨ãƒ„ãƒ¼ãƒ«ã¯ã€è‡ªç„¶è¨€èªã®è³ªå•ã‚’SQLã«å¤‰æ›ã—ã¾ã™ï¼šé©åˆ‡ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¦‹ã¤ã‘ã€ã‚¯ã‚¨ãƒªã‚’ä½œæˆã—ã€ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã€é©åˆ‡ãªæ¨©é™ã®ä¸‹ã§å„æ©Ÿèƒ½ã®å¾“æ¥­å“¡ãŒå¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã®æ´å¯Ÿã«ç‹¬ç«‹ã—ã¦ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚
Behind the scenes, SQL Bot is a multi-agent system built on top of LangChain and LangGraph. 
SQL Botã¯ã€LangChainã¨LangGraphã®ä¸Šã«æ§‹ç¯‰ã•ã‚ŒãŸãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚

![fig]()

While creating a proof of concept for a Text-to-SQL tool is straightforward, the challenge lies in navigating complex enterprise data warehouses to identify authoritative data sources that accurately answer user questions. 
ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰SQLã¸ã®ãƒ„ãƒ¼ãƒ«ã®æ¦‚å¿µå®Ÿè¨¼ã‚’ä½œæˆã™ã‚‹ã“ã¨ã¯ç°¡å˜ã§ã™ãŒã€**èª²é¡Œã¯è¤‡é›‘ãªä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹ã‚’ãƒŠãƒ“ã‚²ãƒ¼ãƒˆã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«æ­£ç¢ºã«ç­”ãˆã‚‹æ¨©å¨ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ç‰¹å®šã™ã‚‹ã“ã¨**ã«ã‚ã‚Šã¾ã™ã€‚
In this post, we share key strategies that enabled us to deploy a practical text-to-SQL solution, now utilized by hundreds of employees across LinkedInâ€™s diverse business verticals.
ã“ã®æŠ•ç¨¿ã§ã¯ã€ç§ãŸã¡ãŒ**å®Ÿç”¨çš„ãªtext-to-sqlã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å±•é–‹ã™ã‚‹ãŸã‚ã«æ¡ç”¨ã—ãŸé‡è¦ãªæˆ¦ç•¥**ã‚’å…±æœ‰ã—ã¾ã™ã€‚ã“ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€LinkedInã®å¤šæ§˜ãªãƒ“ã‚¸ãƒã‚¹åˆ†é‡ã§æ•°ç™¾äººã®å¾“æ¥­å“¡ã«ã‚ˆã£ã¦åˆ©ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚

<!-- ã“ã“ã¾ã§èª­ã‚“ã ! -->

## Strategy #1: Quality table metadata and personalized retrieval æˆ¦ç•¥ #1: é«˜å“è³ªãªãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸæ¤œç´¢

Text-to-SQL is often framed as a Retrieval-Augmented Generation (RAG) application, where context such as table schemas, example queries, and other domain knowledge are retrieved and passed to a Large Language Model (LLM) to answer the question.
Text-to-SQLã¯ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒã€ä¾‹ã®ã‚¯ã‚¨ãƒªã€ãã®ä»–ã®ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ãªã©ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒå–å¾—ã•ã‚Œã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã«æ¸¡ã•ã‚Œã¦è³ªå•ã«ç­”ãˆã‚‹Retrieval-Augmented Generationï¼ˆRAGï¼‰ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦ã—ã°ã—ã°ä½ç½®ã¥ã‘ã‚‰ã‚Œã¾ã™ã€‚

We use Embedding-Based Retrieval (EBR) to retrieve context semantically relevant to the userâ€™s question. 
ç§ãŸã¡ã¯ã€ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«æ„å‘³çš„ã«é–¢é€£ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ãŸã‚ã«ã€Embedding-Based Retrieval (EBR)ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚(ä»¥é™ã€ã“ã®ãƒ–ãƒ­ã‚°ã§ã¯ã€åŸ‹ã‚è¾¼ã¿ãƒ™ãƒ¼ã‚¹ã®æ¤œç´¢ã‚’EBRã¨å‘¼ã‚“ã§ã‚‹...!:thinking:)
One challenge in retrieving tables and fields is the frequent absence or incompleteness of descriptions. 
**ãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å–å¾—ã™ã‚‹éš›ã®ä¸€ã¤ã®èª²é¡Œã¯ã€èª¬æ˜ã®é »ç¹ãªæ¬ å¦‚ã‚„ä¸å®Œå…¨ã•**ã§ã™ã€‚
To address this, we initiated a dataset certification effort to collect comprehensive descriptions for hundreds of important tables. 
ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€ç§ãŸã¡ã¯**æ•°ç™¾ã®é‡è¦ãªãƒ†ãƒ¼ãƒ–ãƒ«ã®åŒ…æ‹¬çš„ãªèª¬æ˜ã‚’åé›†ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèªè¨¼**ã®å–ã‚Šçµ„ã¿ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚
Domain experts identified key tables within their areas and provided mandatory table descriptions and optional field descriptions. 
ãƒ‰ãƒ¡ã‚¤ãƒ³ã®å°‚é–€å®¶ã¯ã€**è‡ªåˆ†ã®åˆ†é‡å†…ã®é‡è¦ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç‰¹å®šã—ã€å¿…é ˆã®ãƒ†ãƒ¼ãƒ–ãƒ«èª¬æ˜ã¨ä»»æ„ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰èª¬æ˜ã‚’æä¾›**ã—ã¾ã—ãŸã€‚
These descriptions were augmented with AI-generated annotations based on existing documentation and Slack discussions, further enhancing our ability to retrieve the right tables and use them properly in queries. 
ã“ã‚Œã‚‰ã®èª¬æ˜ã¯ã€æ—¢å­˜ã®æ–‡æ›¸ã‚„Slackã®è­°è«–ã«åŸºã¥ã„ã¦AIç”Ÿæˆã®æ³¨é‡ˆã§è£œå®Œã•ã‚Œã€æ­£ã—ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å–å¾—ã—ã€ã‚¯ã‚¨ãƒªã§é©åˆ‡ã«ä½¿ç”¨ã™ã‚‹èƒ½åŠ›ãŒã•ã‚‰ã«å‘ä¸Šã—ã¾ã—ãŸã€‚

Another challenge is the sheer volume of tablesâ€”at LinkedIn, itâ€™s in the millionsâ€”and the implicit context embedded in user questions. 
ã‚‚ã†ä¸€ã¤ã®èª²é¡Œã¯ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ•°ãŒè†¨å¤§ã§ã‚ã‚‹ã“ã¨ã§ã™ã€‚LinkedInã§ã¯ã€æ•°ç™¾ä¸‡ã«åŠã³ã¾ã™ã€‚ãã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«åŸ‹ã‚è¾¼ã¾ã‚ŒãŸæš—é»™ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚
We can quickly narrow down the volume of tables to a few thousand by looking at access popularity. 
**ã‚¢ã‚¯ã‚»ã‚¹ã®äººæ°—ã‚’è¦‹ã‚‹ã“ã¨ã§ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ•°ã‚’æ•°åƒã«ç°¡å˜ã«çµã‚Šè¾¼ã‚€ã“ã¨ãŒã§ãã‚‹**ã€‚
However, addressing the implicit context is more subtle. 
ã—ã‹ã—ã€æš—é»™ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾å‡¦ã™ã‚‹ã“ã¨ã¯ã‚ˆã‚Šå¾®å¦™ã§ã™ã€‚
For instance, the question "What was the average CTR yesterday?" should be answered differently depending on whether the employee is interested in email notifications, ads or search quality. 
**ä¾‹ãˆã°ã€ã€Œæ˜¨æ—¥ã®å¹³å‡CTRã¯ä½•ã§ã—ãŸã‹ï¼Ÿã€ã¨ã„ã†è³ªå•ã¯ã€å¾“æ¥­å“¡ãŒãƒ¡ãƒ¼ãƒ«é€šçŸ¥ã€åºƒå‘Šã€ã¾ãŸã¯æ¤œç´¢å“è³ªã«èˆˆå‘³ãŒã‚ã‚‹ã‹ã©ã†ã‹ã«ã‚ˆã£ã¦ç•°ãªã‚‹ç­”ãˆãŒå¿…è¦**ã§ã™ã€‚
To address this, we infer the default datasets for a user based on the organizational chart. 
ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€ç§ãŸã¡ã¯**çµ„ç¹”å›³ã«åŸºã¥ã„ã¦ãƒ¦ãƒ¼ã‚¶ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ¨æ¸¬**ã—ã¾ã™ã€‚
We also apply Independent Component Analysis (ICA) across user-dataset access history to develop components (sets of datasets) that correspond to different business use cases. 
ã¾ãŸã€ãƒ¦ãƒ¼ã‚¶ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¢ã‚¯ã‚»ã‚¹å±¥æ­´ã«å¯¾ã—ã¦ç‹¬ç«‹æˆåˆ†åˆ†æï¼ˆICAï¼‰ã‚’é©ç”¨ã—ã€ç•°ãªã‚‹ãƒ“ã‚¸ãƒã‚¹ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«å¯¾å¿œã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚»ãƒƒãƒˆï¼‰ã‚’é–‹ç™ºã—ã¾ã™ã€‚
Results are personalized by using the top components relevant to each user. 
çµæœã¯ã€å„ãƒ¦ãƒ¼ã‚¶ã«é–¢é€£ã™ã‚‹ãƒˆãƒƒãƒ—ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§**ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚º**ã•ã‚Œã¾ã™ã€‚
Users are able to change the default filter values if needed. 
ãƒ¦ãƒ¼ã‚¶ã¯å¿…è¦ã«å¿œã˜ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ•ã‚£ãƒ«ã‚¿å€¤ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

In practice, tables and fields are deprecated or added over time. 
å®Ÿéš›ã«ã¯ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯æ™‚é–“ã¨ã¨ã‚‚ã«å»ƒæ­¢ã•ã‚ŒãŸã‚Šè¿½åŠ ã•ã‚ŒãŸã‚Šã—ã¾ã™ã€‚
It is typical for a table to be used for a few years before it is replaced with another table with improved performance, schema, and/or logic. 
ãƒ†ãƒ¼ãƒ–ãƒ«ã¯ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ã‚¹ã‚­ãƒ¼ãƒã€ã¾ãŸã¯ãƒ­ã‚¸ãƒƒã‚¯ãŒæ”¹å–„ã•ã‚ŒãŸåˆ¥ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«ç½®ãæ›ãˆã‚‰ã‚Œã‚‹ã¾ã§æ•°å¹´é–“ä½¿ç”¨ã•ã‚Œã‚‹ã®ãŒä¸€èˆ¬çš„ã§ã™ã€‚
Thus, the source of truth to answer a question can change. 
ã—ãŸãŒã£ã¦ã€è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®çœŸå®Ÿã®æºã¯å¤‰ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
To automate the process of picking up new tables, we automatically ingest popular queried tables into our vector store. 
æ–°ã—ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å–å¾—ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãŸã‚ã«ã€**äººæ°—ã®ã‚ã‚‹ã‚¯ã‚¨ãƒªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è‡ªå‹•çš„ã«ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã«å–ã‚Šè¾¼ã¿**ã¾ã™ã€‚
DataHub, our metadata search and discovery tool, allows users to mark datasets and fields as deprecated â€“ we use this signal to automatically offboard datasets and fields. 
ç§ãŸã¡ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ãŠã‚ˆã³ç™ºè¦‹ãƒ„ãƒ¼ãƒ«ã§ã‚ã‚‹DataHubã¯ã€**ãƒ¦ãƒ¼ã‚¶ãŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å»ƒæ­¢ã¨ã—ã¦ãƒãƒ¼ã‚¯ã™ã‚‹**ã“ã¨ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚ç§ãŸã¡ã¯**ã“ã®ä¿¡å·ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è‡ªå‹•çš„ã«ã‚ªãƒ•ãƒœãƒ¼ãƒ‰(é€€è·)**ã—ã¾ã™ã€‚

<!-- ã“ã“ã¾ã§èª­ã‚“ã ! -->

## Strategy #2: Knowledge graph and LLMs for ranking, writing, self-correction
## æˆ¦ç•¥ #2: çŸ¥è­˜ã‚°ãƒ©ãƒ•ã¨LLMsã«ã‚ˆã‚‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€åŸ·ç­†ã€è‡ªå·±ä¿®æ­£

The output of the first strategy is a candidate list of tables, selected by filtering and EBR. 
æœ€åˆã®æˆ¦ç•¥ã®å‡ºåŠ›ã¯ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨EBRã«ã‚ˆã£ã¦é¸æŠã•ã‚ŒãŸã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®å€™è£œãƒªã‚¹ãƒˆã§ã™ã€‚
In this section, we outline a few approaches that have helped us generate accurate queries. 
ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€æ­£ç¢ºãªã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã™ã‚‹ã®ã«å½¹ç«‹ã£ãŸã„ãã¤ã‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¦‚èª¬ã—ã¾ã™ã€‚

![fig]()
Figure 2: Knowledge graph. Users, table clusters, tables, and fields are nodes. The nodes have attributes derived from DataHub, query logs, crowdsourced domain knowledge, etc.
å›³2: çŸ¥è­˜ã‚°ãƒ©ãƒ•ã€‚ãƒ¦ãƒ¼ã‚¶ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¯ãƒ©ã‚¹ã‚¿ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒãƒãƒ¼ãƒ‰ã§ã™ã€‚ãƒãƒ¼ãƒ‰ã«ã¯ã€DataHubã€ã‚¯ã‚¨ãƒªãƒ­ã‚°ã€ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°ã•ã‚ŒãŸãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­†ãªã©ã‹ã‚‰æ´¾ç”Ÿã—ãŸå±æ€§ãŒã‚ã‚Šã¾ã™ã€‚

First, we need a deep semantic understanding of concepts and datasets to generate accurate queries. 
ã¾ãšã€æ­£ç¢ºãªã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã¯ã€æ¦‚å¿µã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹æ·±ã„semantic understanding(æ„å‘³ç†è§£)ãŒå¿…è¦ã§ã™ã€‚
In addition to leveraging tables and fields, we organize additional information into a knowledge graph: 
**ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ´»ç”¨ã™ã‚‹ã ã‘ã§ãªãã€è¿½åŠ æƒ…å ±ã‚’çŸ¥è­˜ã‚°ãƒ©ãƒ•ã«æ•´ç†**ã—ã¾ã™ã€‚

1. We use DataHub to look up table schemas, field descriptions, the top K values for categorical dimension fields, partition keys, and a classification of fields into metrics, dimensions, and attributes. 
ç§ãŸã¡ã¯DataHubã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®èª¬æ˜ã€ã‚«ãƒ†ã‚´ãƒªæ¬¡å…ƒãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ä¸Šä½Kå€¤ã€ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚­ãƒ¼ã€ãŠã‚ˆã³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®åˆ†é¡(metricsã€dimensionsã€attributes)ã‚’èª¿ã¹ã¾ã™ã€‚

2. We collect domain knowledge from users in SQL Botâ€™s UI. SQL Botã®UIã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ã®ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’åé›†ã—ã¾ã™ã€‚

3. We use successful queries from query logs to derive aggregate information, such as table/field popularity and common table joins. 
ã‚¯ã‚¨ãƒªãƒ­ã‚°ã‹ã‚‰æˆåŠŸã—ãŸã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨ã—ã¦ã€**ãƒ†ãƒ¼ãƒ–ãƒ«/ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®äººæ°—**ã‚„**ä¸€èˆ¬çš„ãªãƒ†ãƒ¼ãƒ–ãƒ«çµåˆ**ãªã©ã®é›†ç´„æƒ…å ±ã‚’å°å‡ºã—ã¾ã™ã€‚

4. We incorporate example queries from internal wikis and from notebooks in DARWIN. 
**å†…éƒ¨ã‚¦ã‚£ã‚­ã‚„DARWINã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‹ã‚‰ã®ä¾‹ã‚¯ã‚¨ãƒª**ã‚’å–ã‚Šå…¥ã‚Œã¾ã™ã€‚
Because the quality of code in DARWIN can vary, we only include notebooks certified by users and those that meet a set of heuristics for recency and reliability â€“ for instance, we prefer recently created notebooks titled by users that have a high number of executions. 
**DARWINã®ã‚³ãƒ¼ãƒ‰ã®å“è³ªã¯ã•ã¾ã–ã¾ãªã®ã§ã€ãƒ¦ãƒ¼ã‚¶ã«ã‚ˆã£ã¦èªè¨¼ã•ã‚ŒãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¨ã€æœ€è¿‘æ€§ã¨ä¿¡é ¼æ€§ã®ãŸã‚ã®ä¸€é€£ã®ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯(i.e. ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ã®åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯!:thinking:)ã‚’æº€ãŸã™ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ã¿ã‚’å«ã‚ã¾ã™**ã€‚
ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã®ä¾‹: é«˜ã„å®Ÿè¡Œå›æ•°ã‚’æŒã¤ãƒ¦ãƒ¼ã‚¶ã«ã‚ˆã£ã¦ã€æœ€è¿‘ä½œæˆã•ã‚ŒãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯æœ‰åŠ¹ã¨ã™ã‚‹ã€‚

<!-- ã“ã“ã¾ã§èª­ã‚“ã ! -->

Then, we use LLMs to filter and sort the results from EBR using the knowledge graph. 
æ¬¡ã«ã€çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’ä½¿ç”¨ã—ã¦ã€EBRã‹ã‚‰ã®çµæœã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãŠã‚ˆã³ã‚½ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã«LLMsã‚’ä½¿ç”¨ã—ã¾ã™ã€‚(**EBRã—ãŸçµæœã«å¯¾ã—ã¦ã€çŸ¥è­˜ã‚°ãƒ©ãƒ•*LLMã§éš›ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°&ã‚½ãƒ¼ãƒˆã™ã‚‹ã£ã¦ã“ã¨ã½ã„...?**:thinking:)
After retrieving the top 20 tables via EBR, we employ a LLM re-ranker to select the top 7 tables for query writing. 
**EBRã‚’ä»‹ã—ã¦ä¸Šä½20ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å–å¾—ã—ãŸå¾Œã€ã‚¯ã‚¨ãƒªä½œæˆã®ãŸã‚ã«ä¸Šä½7ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠã™ã‚‹ãŸã‚ã«LLMå†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½¿ç”¨**ã—ã¾ã™ã€‚
The inputs to table selection include table descriptions, example queries, domain knowledge, and explanations of internal jargon detected in the userâ€™s question. 
**ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠã®å…¥åŠ›ã«ã¯ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®èª¬æ˜ã€ä¾‹ã‚¯ã‚¨ãƒªã€ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã€ãŠã‚ˆã³ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã§æ¤œå‡ºã•ã‚ŒãŸå†…éƒ¨ç”¨èªã®èª¬æ˜ãŒå«ã¾ã‚Œã¾ã™**ã€‚
We use another LLM re-ranker to select fields from the selected tables. 
**é¸æŠã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’é¸æŠã™ã‚‹ãŸã‚ã«ã€åˆ¥ã®LLMå†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½¿ç”¨**ã—ã¾ã™ã€‚
The input to field selection includes the information used for table selection, plus the full table schemas with field descriptions, top K values, and other field attributes. 
ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰é¸æŠã®å…¥åŠ›ã«ã¯ã€**ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠã«ä½¿ç”¨ã•ã‚Œã‚‹æƒ…å ±ã«åŠ ãˆã¦ã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®èª¬æ˜ã€ä¸Šä½Kå€¤ã€ãŠã‚ˆã³ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å±æ€§ã‚’å«ã‚€å®Œå…¨ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒ**ãŒå«ã¾ã‚Œã¾ã™ã€‚
Fields are ordered by access frequency over a recent time window. 
ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ã€æœ€è¿‘ã®æ™‚é–“ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã®**ã‚¢ã‚¯ã‚»ã‚¹é »åº¦ã«ã‚ˆã£ã¦é †åºä»˜ã‘**ã•ã‚Œã¾ã™ã€‚

After that, our query writing process is iterative, so that SQL Bot generates a plan and solves each step of the plan incrementally to build to the final query. 
ãã®å¾Œã€ç§ãŸã¡ã®**ã‚¯ã‚¨ãƒªä½œæˆãƒ—ãƒ­ã‚»ã‚¹ã¯iterative**ã§ã‚ã‚Šã€SQL Botã¯è¨ˆç”»ã‚’ç”Ÿæˆã—ã€æœ€çµ‚ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã«è¨ˆç”»ã®**å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ®µéšçš„ã«è§£æ±º**ã—ã¾ã™ã€‚(ã‚„ã£ã±ã‚Šåˆ†æ¥­ã•ã›ã‚‹ã®ãŒæœ‰åŠ¹ãªã®ã‹...!:thinking:)
Solutions to previous tasks are stored in our chatbotâ€™s internal state to be provided to the next step. 
ä»¥å‰ã®ã‚¿ã‚¹ã‚¯ã®è§£æ±ºç­–ã¯ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«æä¾›ã•ã‚Œã‚‹ãŸã‚ã«ã€ç§ãŸã¡ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®å†…éƒ¨çŠ¶æ…‹ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚(=ã“ã‚Œã¯LangGraphã®ãƒãƒ¼ãƒ‰é–“ã®é€šä¿¡ã®è©±ã£ã½ã„...!:thinking:)
While this method is effective for complex questions, we found it can result in overly complicated queries for simple questions, so we instruct the query planner to minimize the number of steps it creates. 
ã“ã®æ–¹æ³•ã¯è¤‡é›‘ãªè³ªå•ã«ã¯åŠ¹æœçš„ã§ã™ãŒã€å˜ç´”ãªè³ªå•ã«å¯¾ã—ã¦éåº¦ã«è¤‡é›‘ãªã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã«ä½œæˆã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ã®æ•°ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹ã‚ˆã†æŒ‡ç¤ºã—ã¾ã™ã€‚
This condenses queries for simple questions while maintaining performance on complex questions. 
ã“ã‚Œã«ã‚ˆã‚Šã€å˜ç´”ãªè³ªå•ã®ã‚¯ã‚¨ãƒªãŒç°¡æ½”ã«ãªã‚Šã€è¤‡é›‘ãªè³ªå•ã«å¯¾ã™ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒç¶­æŒã•ã‚Œã¾ã™ã€‚

Finally, we run a set of validators on the output followed by a self-correction agent to fix errors. 
æœ€å¾Œã«ã€**å‡ºåŠ›ã«å¯¾ã—ã¦ä¸€é€£ã®ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼ã‚’å®Ÿè¡Œ**ã—ã€ãã®å¾Œã«ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã™ã‚‹ãŸã‚ã®è‡ªå·±ä¿®æ­£ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
Validators work best when they access new information not available to the query writer. 
**ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼ã¯ã€ã‚¯ã‚¨ãƒªä½œæˆè€…ãŒåˆ©ç”¨ã§ããªã„æ–°ã—ã„æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹éš›ã«æœ€ã‚‚åŠ¹æœçš„**ã§ã™ã€‚
We verify the existence of tables and fields, and execute the EXPLAIN statement on the query to detect syntax and other errors. 
ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ã‚’ç¢ºèªã—ã€**ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦EXPLAINæ–‡ã‚’å®Ÿè¡Œ**ã—ã¦æ§‹æ–‡ã‚„ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡ºã—ã¾ã™ã€‚
These errors are fed into a self-correction agent, which is equipped with tools to retrieve additional tables or fields if needed before updating the query. 
ã“ã‚Œã‚‰ã®ã‚¨ãƒ©ãƒ¼ã¯è‡ªå·±ä¿®æ­£ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«é€ã‚‰ã‚Œã€å¿…è¦ã«å¿œã˜ã¦ã‚¯ã‚¨ãƒªã‚’æ›´æ–°ã™ã‚‹å‰ã«è¿½åŠ ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ãŒè£…å‚™ã•ã‚Œã¦ã„ã¾ã™ã€‚

![](https://www.linkedin.com/blog/engineering/ai/practical-text-to-sql-for-data-analytics)
Figure 3: Modeling architecture. The userâ€™s question is classified and delegated to the appropriate flow. Open-ended follow-up chats are handled by an agent.
å›³3: ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€‚ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã¯åˆ†é¡ã•ã‚Œã€é©åˆ‡ãªãƒ•ãƒ­ãƒ¼ã«å§”ä»»ã•ã‚Œã¾ã™ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ã®ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ãƒãƒ£ãƒƒãƒˆã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã£ã¦å‡¦ç†ã•ã‚Œã¾ã™ã€‚

<!-- ã“ã“ã¾ã§èª­ã‚“ã ! -->

## Strategy #3: User experience with rich chat elements
## æˆ¦ç•¥ #3: ãƒªãƒƒãƒãƒãƒ£ãƒƒãƒˆè¦ç´ ã‚’ç”¨ã„ãŸãƒ¦ãƒ¼ã‚¶ä½“é¨“

User experience is central to gaining adoption. 
ãƒ¦ãƒ¼ã‚¶ä½“é¨“ã¯ã€æ¡ç”¨ã‚’å¾—ã‚‹ãŸã‚ã®ä¸­å¿ƒçš„ãªè¦ç´ ã§ã™ã€‚
Users prioritize ease of use and fast responses. 
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯**ä½¿ã„ã‚„ã™ã•ã¨è¿…é€Ÿãªå¿œç­”**ã‚’é‡è¦–ã—ã¾ã™ã€‚

We integrated SQL Bot directly into DARWIN, allowing users to access it within the same browser window as they write and execute their queries. 
ç§ãŸã¡ã¯**SQL Botã‚’DARWINã«ç›´æ¥çµ±åˆã—ã€ãƒ¦ãƒ¼ã‚¶ãŒã‚¯ã‚¨ãƒªã‚’ä½œæˆã—ã¦å®Ÿè¡Œã™ã‚‹éš›ã«åŒã˜ãƒ–ãƒ©ã‚¦ã‚¶ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å†…ã§ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹**ã‚ˆã†ã«ã—ã¾ã—ãŸã€‚
This integration increased adoption by 5-10x compared to our prototype chatbot application launched as a standalone app. 
ã“ã®çµ±åˆã«ã‚ˆã‚Šã€**ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ã‚¢ãƒ—ãƒªã¨ã—ã¦ç«‹ã¡ä¸Šã’ãŸãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨æ¯”è¼ƒã—ã¦ã€æ¡ç”¨ãŒ5ã€œ10å€å¢—åŠ **ã—ã¾ã—ãŸã€‚
To aid discovery, DARWIN has entry points for SQL Bot in the sidebar, as well as a â€œFix with AIâ€ button that appears whenever a query execution fails. 
ç™ºè¦‹ã‚’åŠ©ã‘ã‚‹ãŸã‚ã«ã€DARWINã«ã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«SQL Botã¸ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚Šã€ã‚¯ã‚¨ãƒªã®å®Ÿè¡ŒãŒå¤±æ•—ã™ã‚‹ãŸã³ã«ã€ŒAIã§ä¿®æ­£ã€ãƒœã‚¿ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
Chat history is saved so users can continue previous conversations. 
ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã¯ä¿å­˜ã•ã‚Œã‚‹ãŸã‚ã€ãƒ¦ãƒ¼ã‚¶ã¯ä»¥å‰ã®ä¼šè©±ã‚’ç¶šã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
They can also submit in-product feedback or add custom instructions to personalize the botâ€™s behavior. 
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯è£½å“å†…ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡ã—ãŸã‚Šã€ãƒœãƒƒãƒˆã®å‹•ä½œã‚’ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã™ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ æŒ‡ç¤ºã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

Our initial prototype answered every question with a SQL query, but users actually wanted to find tables, ask questions about the datasets, see reference queries, or ask general questions about query syntax. 
ç§ãŸã¡ã®åˆæœŸãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã¯ã™ã¹ã¦ã®è³ªå•ã«SQLã‚¯ã‚¨ãƒªã§å›ç­”ã—ã¾ã—ãŸãŒã€**ãƒ¦ãƒ¼ã‚¶ã¯å®Ÿéš›ã«ã¯ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¦‹ã¤ã‘ãŸã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é–¢ã™ã‚‹è³ªå•ã‚’ã—ãŸã‚Šã€å‚è€ƒã‚¯ã‚¨ãƒªã‚’è¦‹ãŸã‚Šã€ã‚¯ã‚¨ãƒªæ§‹æ–‡ã«é–¢ã™ã‚‹ä¸€èˆ¬çš„ãªè³ªå•ã‚’ã—ãŸã„**ã¨è€ƒãˆã¦ã„ã¾ã—ãŸã€‚
We now use intent classification to classify the question and decide how to respond. 
ç¾åœ¨ã€ç§ãŸã¡ã¯æ„å›³åˆ†é¡ã‚’ä½¿ç”¨ã—ã¦è³ªå•ã‚’åˆ†é¡ã—ã€ã©ã®ã‚ˆã†ã«å¿œç­”ã™ã‚‹ã‹ã‚’æ±ºå®šã—ã¦ã„ã¾ã™ã€‚

Itâ€™s essential for a chatbot to be conversational so that users can ask follow-up questions. 
**ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãŒä¼šè©±å½¢å¼ã§ã‚ã‚‹ã“ã¨ã¯é‡è¦ã§ã‚ã‚Šã€ãƒ¦ãƒ¼ã‚¶ãŒãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã®è³ªå•ã‚’ã™ã‚‹ã“ã¨ãŒã§ãã‚‹**ã‚ˆã†ã«ã—ã¾ã™ã€‚(ãªã‚‹ã»ã©ã€ãƒ¦ãƒ¼ã‚¶ãŒè£œè¶³æƒ…å ±ã‚’æ›¸ãè¶³ã—ã¦å‡ºåŠ›ã‚’èª¿æ•´ã§ãã‚‹ã¨ã„ã†ç‚¹ã§ã€ä¼šè©±å½¢å¼ã§ã‚ã‚‹ã“ã¨ãŒé‡è¦ãªã®ã‹...!:thinking:)
We provide â€œquick repliesâ€ such as â€œupdate query,â€ â€œupdate table selections,â€ and â€œexplain these tablesâ€ to guide users on the types of follow-ups they could try. 
ç§ãŸã¡ã¯â€œ**quick replies**â€ã¨ã—ã¦ã€Œã‚¯ã‚¨ãƒªã‚’æ›´æ–°ã€ã€ã€Œãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠã‚’æ›´æ–°ã€ã€ã€Œã“ã‚Œã‚‰ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’èª¬æ˜ã€ãªã©ã‚’æä¾›ã—ã€ãƒ¦ãƒ¼ã‚¶ãŒè©¦ã™ã“ã¨ãŒã§ãã‚‹ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã®ç¨®é¡ã‚’æ¡ˆå†…ã—ã¾ã™ã€‚(UIã®å·¥å¤«!)
Additionally, users have the option to enable a guided experience, where SQL Bot walks them through each step of the query writing processâ€”finding tables, and solving each step in the query.
ã•ã‚‰ã«ã€ãƒ¦ãƒ¼ã‚¶ã¯ã‚¬ã‚¤ãƒ‰ä»˜ãä½“é¨“ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã€SQL BotãŒã‚¯ã‚¨ãƒªä½œæˆãƒ—ãƒ­ã‚»ã‚¹ã®å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ¡ˆå†…ã—ã¾ã™â€”ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¦‹ã¤ã‘ã€ã‚¯ã‚¨ãƒªã®å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’è§£æ±ºã—ã¾ã™ã€‚
The user can interact at each step to provide feedback on the table or queries. 
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã§ãã¾ã™ã€‚
This helps users understand the query and gives them more control over the query-writing process. 
ã“ã‚Œã«ã‚ˆã‚Šã€**ãƒ¦ãƒ¼ã‚¶ã¯ã‚¯ã‚¨ãƒªã‚’ç†è§£ã—ã€ã‚¯ã‚¨ãƒªä½œæˆãƒ—ãƒ­ã‚»ã‚¹ã«å¯¾ã™ã‚‹ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã‚’å¼·åŒ–ã§ãã¾ã™**ã€‚(Langgraphã ã¨ã“ã®è¾ºã‚Šã®å®Ÿè£…ã‚‚ã‚„ã‚Šã‚„ã™ã„ã®ã‹ãª...!:thinking:)

To help users understand the botâ€™s output, we have incorporated rich display elements for tables and queries. 
ãƒ¦ãƒ¼ã‚¶ãŒãƒœãƒƒãƒˆã®å‡ºåŠ›ã‚’ç†è§£ã§ãã‚‹ã‚ˆã†ã«ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã‚¯ã‚¨ãƒªã®ãŸã‚ã®ãƒªãƒƒãƒè¡¨ç¤ºè¦ç´ ã‚’çµ„ã¿è¾¼ã¿ã¾ã—ãŸã€‚
The table element shows the retrieved tables, their descriptions, tags indicating whether the dataset is â€œcertifiedâ€ or â€œpopularâ€, average monthly access frequency, commonly joined tables, and a link to DataHub for more information. 
ãƒ†ãƒ¼ãƒ–ãƒ«è¦ç´ ã¯ã€å–å¾—ã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã€ãã®èª¬æ˜ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã€Œèªå®šã€ã¾ãŸã¯ã€Œäººæ°—ã€ã§ã‚ã‚‹ã‹ã‚’ç¤ºã™ã‚¿ã‚°ã€å¹³å‡æœˆé–“ã‚¢ã‚¯ã‚»ã‚¹é »åº¦ã€ä¸€èˆ¬çš„ã«çµåˆã•ã‚Œã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã€ãŠã‚ˆã³è©³ç´°æƒ…å ±ã®ãŸã‚ã®DataHubã¸ã®ãƒªãƒ³ã‚¯ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
In the guided experience, users may use these checkboxes to select the tables they want the bot to use. 
ã‚¬ã‚¤ãƒ‰ä»˜ãä½“é¨“ã§ã¯ã€ãƒ¦ãƒ¼ã‚¶ã¯ã“ã‚Œã‚‰ã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã€ãƒœãƒƒãƒˆã«ä½¿ç”¨ã—ã¦ã»ã—ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠã§ãã¾ã™ã€‚
The query element displays the formatted query, explanation, and validation checks on whether the tables exist, fields exist, and the syntax is correct. 
ã‚¯ã‚¨ãƒªè¦ç´ ã¯ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸã‚¯ã‚¨ãƒªã€èª¬æ˜ã€ãŠã‚ˆã³ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå­˜åœ¨ã™ã‚‹ã‹ã€æ§‹æ–‡ãŒæ­£ã—ã„ã‹ã®æ¤œè¨¼ãƒã‚§ãƒƒã‚¯ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
This helps users understand the output and identify any issues that need fixing. 
ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å‡ºåŠ›ã‚’ç†è§£ã—ã€ä¿®æ­£ãŒå¿…è¦ãªå•é¡Œã‚’ç‰¹å®šã§ãã¾ã™ã€‚
They can ask the bot to make updates. 
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ãƒœãƒƒãƒˆã«æ›´æ–°ã‚’ä¾é ¼ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

![]()
Figure 5: Query output includes validation checks, explanation, and tables.
å›³5: ã‚¯ã‚¨ãƒªå‡ºåŠ›ã«ã¯ã€æ¤œè¨¼ãƒã‚§ãƒƒã‚¯ã€èª¬æ˜ã€ãŠã‚ˆã³ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå«ã¾ã‚Œã¾ã™ã€‚

Each dataset at LinkedIn has its own access control list which permits dataset read access to only specific users or groups. 
LinkedInã®å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯ã€ç‰¹å®šã®ãƒ¦ãƒ¼ã‚¶ã¾ãŸã¯ã‚°ãƒ«ãƒ¼ãƒ—ã«ã®ã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿å–ã‚Šã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ã™ã‚‹ç‹¬è‡ªã®ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ãƒªã‚¹ãƒˆãŒã‚ã‚Šã¾ã™ã€‚(ã†ã‚“ã†ã‚“...!:thinking:)
To prevent issues where a user runs a query and is denied access, we check if the user is a member of a group with the appropriate access and if so, we automatically provide the code necessary to leverage the group's credentials. 
ãƒ¦ãƒ¼ã‚¶ãŒã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¦ã‚¢ã‚¯ã‚»ã‚¹ã‚’æ‹’å¦ã•ã‚Œã‚‹å•é¡Œã‚’é˜²ããŸã‚ã«ã€ãƒ¦ãƒ¼ã‚¶ãŒé©åˆ‡ãªã‚¢ã‚¯ã‚»ã‚¹æ¨©ã‚’æŒã¤ã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ¡ãƒ³ãƒãƒ¼ã§ã‚ã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã€ãã†ã§ã‚ã‚Œã°ã€ã‚°ãƒ«ãƒ¼ãƒ—ã®è³‡æ ¼æƒ…å ±ã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã«å¿…è¦ãªã‚³ãƒ¼ãƒ‰ã‚’è‡ªå‹•çš„ã«æä¾›ã—ã¾ã™ã€‚
This reduces frustration for the user, especially for those new to SQL at LinkedIn. 
ã“ã‚Œã«ã‚ˆã‚Šã€ç‰¹ã«LinkedInã§SQLã«ä¸æ…£ã‚Œãªãƒ¦ãƒ¼ã‚¶ã®ãƒ•ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒè»½æ¸›ã•ã‚Œã¾ã™ã€‚

<!-- ã“ã“ã¾ã§èª­ã‚“ã ! -->

## Strategy #4: Options for user customization æˆ¦ç•¥ #4: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³

We want users to have the ability to improve SQL Botâ€™s performance without making requests to the platform team. 
ç§ãŸã¡ã¯ã€**ãƒ¦ãƒ¼ã‚¶ãŒãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãƒãƒ¼ãƒ ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã›ãšã«SQL Botã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹èƒ½åŠ›ã‚’æŒã¤ã“ã¨**ã‚’æœ›ã‚“ã§ã„ã¾ã™ã€‚(è©•ä¾¡ã«åŸºã¥ãæ”¹å–„ã ...!:thinking:)
To this end, we provide three levers that allow users to customize the experience for their product area: 
ã“ã®ç›®çš„ã®ãŸã‚ã«ã€ç§ãŸã¡ã¯ãƒ¦ãƒ¼ã‚¶ãŒè‡ªåˆ†ã®è£½å“é ˜åŸŸã«å¯¾ã™ã‚‹ä½“é¨“ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã‚‹3ã¤ã®æ‰‹æ®µã‚’æä¾›ã—ã¾ã™ã€‚

1. **Dataset customization**: Users can define the datasets for a product area by providing email group(s) or by explicitly specifying the users and datasets to use. 
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º: ãƒ¦ãƒ¼ã‚¶ã¯ã€ãƒ¡ãƒ¼ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æä¾›ã™ã‚‹ã‹ã€ä½¿ç”¨ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ˜ç¤ºçš„ã«æŒ‡å®šã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€è£½å“é ˜åŸŸã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å®šç¾©ã§ãã¾ã™ã€‚ 
The product areaâ€™s datasets are those commonly used by the group of users in that area, with the option to include or exclude additional datasets as specified. 
è£½å“é ˜åŸŸã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ãã®é ˜åŸŸã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ—ã«ã‚ˆã£ã¦ä¸€èˆ¬çš„ã«ä½¿ç”¨ã•ã‚Œã‚‹ã‚‚ã®ã§ã‚ã‚Šã€æŒ‡å®šã•ã‚ŒãŸè¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å«ã‚ã‚‹ã‹é™¤å¤–ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã™ã€‚ 
Users can select product areas to use through the UI. 
ãƒ¦ãƒ¼ã‚¶ã¯UIã‚’é€šã˜ã¦ä½¿ç”¨ã™ã‚‹è£½å“é ˜åŸŸã‚’é¸æŠã§ãã¾ã™ã€‚

2. **Custom instructions**: Users can provide custom textual instructions to SQL Bot directly in DARWIN. 
ã‚«ã‚¹ã‚¿ãƒ æŒ‡ç¤º: ãƒ¦ãƒ¼ã‚¶ã¯ã€DARWINå†…ã§SQL Botã«ç›´æ¥ã‚«ã‚¹ã‚¿ãƒ ãƒ†ã‚­ã‚¹ãƒˆæŒ‡ç¤ºã‚’æä¾›ã§ãã¾ã™ã€‚ 
The instructions can either enrich the overall domain knowledge of SQL Bot or provide guidelines for SQL Bot to behave in a specific manner to match user preferences. 
ã“ã‚Œã‚‰ã®æŒ‡ç¤ºã¯ã€SQL Botã®å…¨ä½“çš„ãªãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’è±Šã‹ã«ã™ã‚‹ã‹ã€ãƒ¦ãƒ¼ã‚¶ã®å¥½ã¿ã«åˆã‚ã›ã¦ç‰¹å®šã®æ–¹æ³•ã§å‹•ä½œã™ã‚‹ãŸã‚ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚ 
The user-supplied instructions are used when selecting tables and fields, and when writing and fixing queries. 
**ãƒ¦ãƒ¼ã‚¶ãŒæä¾›ã—ãŸæŒ‡ç¤ºã¯ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’é¸æŠã™ã‚‹éš›ã€ã¾ãŸã‚¯ã‚¨ãƒªã‚’æ›¸ãéš›ã‚„ä¿®æ­£ã™ã‚‹éš›ã«ä½¿ç”¨**ã•ã‚Œã¾ã™ã€‚

3. Example queries: Users can create example queries to be indexed into our vector store. 
ä¾‹ç¤ºã‚¯ã‚¨ãƒª: **ãƒ¦ãƒ¼ã‚¶ã¯ã€ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã•ã‚Œã‚‹ä¾‹ç¤ºã‚¯ã‚¨ãƒªã‚’ä½œæˆã§ãã¾ã™**ã€‚(ã“ã‚Œã¯ã„ã„ã­!:thinking:)
These can be added directly in DARWIN by creating a notebook and tagging it as â€œcertified.â€ 
ã“ã‚Œã‚‰ã¯ã€ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆã—ã€ã€Œcertifiedã€ã¨ã‚¿ã‚°ä»˜ã‘ã™ã‚‹ã“ã¨ã§ã€DARWINã«ç›´æ¥è¿½åŠ ã§ãã¾ã™ã€‚(Snowflakeã§ã‚‚notebookã‚’ä½œã‚‹æ„Ÿã˜ã ã‹ã‚‰ã€ã“ã®è¾ºã‚Šã®å®Ÿè£…ã‚‚ã‚„ã‚Šã‚„ã™ã„ã‹ã‚‚...!:thinking:)

<!-- ã“ã“ã¾ã§èª­ã‚“ã ! -->

## Strategy #5: Ongoing Benchmarking æˆ¦ç•¥ #5: ç¶™ç¶šçš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°

There are many hyperparameters for the bot, such as what text to embed, what context to pass to each LLM, how to represent the context and meta prompts, how to manage agent memory, how many items to retrieve, how many times to run self-correction, and which steps to include in the model architecture. 
**ãƒœãƒƒãƒˆã«ã¯å¤šãã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚Š**ã€ã©ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åŸ‹ã‚è¾¼ã‚€ã‹ã€å„LLMã«ã©ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¸¡ã™ã‹ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ¡ã‚¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã©ã®ã‚ˆã†ã«è¡¨ç¾ã™ã‚‹ã‹ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¡ãƒ¢ãƒªã‚’ã©ã®ã‚ˆã†ã«ç®¡ç†ã™ã‚‹ã‹ã€å–å¾—ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã®æ•°ã€è‡ªå·±ä¿®æ­£ã‚’å®Ÿè¡Œã™ã‚‹å›æ•°ã€ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«å«ã‚ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ãªã©ãŒã‚ã‚Šã¾ã™ã€‚ 
Therefore, it is crucial to develop a benchmark set to assess both quality and performance.
ã—ãŸãŒã£ã¦ã€**å“è³ªã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ä¸¡æ–¹ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚»ãƒƒãƒˆã‚’é–‹ç™ºã™ã‚‹ã“ã¨ãŒé‡è¦**ã§ã™ã€‚

A benchmark should preferably be tailored to the specific application, as text-to-SQL requirements can vary widely depending on factors like the target user, number of datasets, the clarity of table and column names, the complexity of the desired queries, the SQL dialect, target response time, and the degree of specialized domain knowledge required. 
ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã€ç‰¹å®šã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«åˆã‚ã›ã¦èª¿æ•´ã•ã‚Œã‚‹ã¹ãã§ã‚ã‚Šã€text-to-SQLã®è¦ä»¶ã¯ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¦ãƒ¼ã‚¶ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ•°ã€ãƒ†ãƒ¼ãƒ–ãƒ«ãŠã‚ˆã³ã‚«ãƒ©ãƒ åã®æ˜ç¢ºã•ã€æœ›ã¾ã—ã„ã‚¯ã‚¨ãƒªã®è¤‡é›‘ã•ã€SQLãƒ€ã‚¤ã‚¢ãƒ¬ã‚¯ãƒˆã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¿œç­”æ™‚é–“ã€å¿…è¦ãªå°‚é–€çš„ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã®ç¨‹åº¦ãªã©ã®è¦å› ã«ã‚ˆã£ã¦å¤§ããç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ 
We collaborated with domain experts across 10 product areas to define a set of over 130 benchmark questions. 
ç§ãŸã¡ã¯ã€**10ã®è£½å“åˆ†é‡ã«ã‚ãŸã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³å°‚é–€å®¶ã¨å”åŠ›ã—ã¦ã€130ä»¥ä¸Šã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è³ªå•ã®ã‚»ãƒƒãƒˆã‚’å®šç¾©ã—ã¾ã—ãŸ**ã€‚ 
Each question includes a well-formulated question and ground truth answers.
å„è³ªå•ã«ã¯ã€**é©åˆ‡ã«æ§‹æˆã•ã‚ŒãŸè³ªå•ã¨çœŸå®Ÿã®å›ç­”**ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

Our evaluation metrics include recall of tables and fields compared to the ground truth, table/field hallucination rate, syntax correctness, and response latency. 
**ç§ãŸã¡ã®è©•ä¾¡æŒ‡æ¨™ã«ã¯ã€çœŸå®Ÿã¨æ¯”è¼ƒã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ãŠã‚ˆã³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å†ç¾ç‡ã€ãƒ†ãƒ¼ãƒ–ãƒ«/ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®hallucinationç‡ã€æ§‹æ–‡ã®æ­£ç¢ºæ€§ã€å¿œç­”ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒå«ã¾ã‚Œã¾ã™**ã€‚
These are easy to compute and we focused on these during the first phase of development while we worked on finding the right tables/fields and avoiding obvious query issues.
ã“ã‚Œã‚‰ã¯è¨ˆç®—ãŒå®¹æ˜“ã§ã‚ã‚Šã€ç§ãŸã¡ã¯æœ€åˆã®é–‹ç™ºæ®µéšã§ã€é©åˆ‡ãªãƒ†ãƒ¼ãƒ–ãƒ«/ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¦‹ã¤ã‘ã€æ˜ã‚‰ã‹ãªã‚¯ã‚¨ãƒªã®å•é¡Œã‚’é¿ã‘ã‚‹ã“ã¨ã«æ³¨åŠ›ã—ã¾ã—ãŸã€‚

For example, this chart shows the increase in table recall from adding re-rankers, descriptions, and example queries:
ä¾‹ãˆã°ã€ã“ã®ãƒãƒ£ãƒ¼ãƒˆã¯ã€å†ãƒ©ãƒ³ã‚«ãƒ¼ã€èª¬æ˜ã€ãŠã‚ˆã³ä¾‹ã®ã‚¯ã‚¨ãƒªã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã«ã‚ˆã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã®å†ç¾ç‡ã®å¢—åŠ ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚

![]()
Figure 6: Re-rankers, descriptions, and example queries help SQL Bot identify the correct tables.
å›³6: å†ãƒ©ãƒ³ã‚«ãƒ¼ã€èª¬æ˜ã€ãŠã‚ˆã³ä¾‹ã®ã‚¯ã‚¨ãƒªã¯ã€SQL BotãŒæ­£ã—ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç‰¹å®šã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚

<!-- ã“ã“ã¾ã§èª­ã‚“ã ! -->

However, those metrics are not sufficient to assess query accuracy. 
ã—ã‹ã—ã€**ã“ã‚Œã‚‰ã®æŒ‡æ¨™ã ã‘ã§ã¯ã‚¯ã‚¨ãƒªã®æ­£ç¢ºæ€§ã‚’è©•ä¾¡ã™ã‚‹ã«ã¯ä¸ååˆ†**ã§ã™ã€‚ 
For that, we use a combination of human evaluation and LLM-as-a-judge to evaluate responses given the question, the table schemas, and the ground truths. 
ãã®ãŸã‚ã«ã€ç§ãŸã¡ã¯**äººé–“ã®è©•ä¾¡ã¨LLM-as-a-judgeã®çµ„ã¿åˆã‚ã›ã‚’ä½¿ç”¨**ã—ã¦ã€è³ªå•ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒã€ãŠã‚ˆã³çœŸå®Ÿã«åŸºã¥ã„ã¦å¿œç­”ã‚’è©•ä¾¡ã—ã¾ã™ã€‚ 
The rubric includes overall score and dimensions on correctness in terms of tables, columns, joins, filters, aggregations, etc. as well as the quality of the answer in terms of efficiency and complexity. 
è©•ä¾¡åŸºæº–ã«ã¯ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã€åˆ—ã€çµåˆã€ãƒ•ã‚£ãƒ«ã‚¿ã€é›†è¨ˆãªã©ã®è¦³ç‚¹ã§ã®æ­£ç¢ºæ€§ã«åŠ ãˆã¦ã€åŠ¹ç‡æ€§ã¨è¤‡é›‘ã•ã®è¦³ç‚¹ã§ã®å›ç­”ã®å“è³ªã«é–¢ã™ã‚‹ç·åˆã‚¹ã‚³ã‚¢ã¨æ¬¡å…ƒãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
This approach was more practical for us than running SQL queries and comparing outputs because it does not require data access, allows us to assess how close the query is to being correct, and gives deeper insights on how the model can be improved.
ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€SQLã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¦å‡ºåŠ›ã‚’æ¯”è¼ƒã™ã‚‹ã‚ˆã‚Šã‚‚å®Ÿç”¨çš„ã§ã—ãŸã€‚ãªãœãªã‚‰ã€ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ã‚’å¿…è¦ã¨ã›ãšã€ã‚¯ã‚¨ãƒªãŒã©ã‚Œã ã‘æ­£ç¢ºã§ã‚ã‚‹ã‹ã‚’è©•ä¾¡ã§ãã€ãƒ¢ãƒ‡ãƒ«ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®ã‚ˆã‚Šæ·±ã„æ´å¯Ÿã‚’æä¾›ã™ã‚‹ã‹ã‚‰ã§ã™ã€‚
(ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚ˆãã‚ã‹ã£ã¦ãªã„...!:thinking:)

We discovered early on that there can be multiple ways to answer a question. 
ç§ãŸã¡ã¯æ—©ã„æ®µéšã§ã€**è³ªå•ã«å¯¾ã™ã‚‹å›ç­”æ–¹æ³•ãŒè¤‡æ•°å­˜åœ¨ã™ã‚‹å¯èƒ½æ€§**ãŒã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚ 
About ~60% of our benchmark questions now have multiple answers. 
ç¾åœ¨ã€ç§ãŸã¡ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è³ªå•ã®ç´„60%ã«ã¯è¤‡æ•°ã®å›ç­”ãŒã‚ã‚Šã¾ã™ã€‚ 
Without these additional answers, we underreported recall by 10-15%. 
ã“ã‚Œã‚‰ã®è¿½åŠ ã®å›ç­”ãŒãªã‘ã‚Œã°ã€ç§ãŸã¡ã¯å†ç¾ç‡ã‚’10-15%éå°å ±å‘Šã—ã¦ã„ã¾ã—ãŸã€‚ 
We use expert human review every 3 months to add accepted answers to our benchmark. 
ç§ãŸã¡ã¯ã€**3ã‹æœˆã”ã¨ã«å°‚é–€å®¶ã«ã‚ˆã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã„ã€å—ã‘å…¥ã‚Œã‚‰ã‚ŒãŸå›ç­”ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«è¿½åŠ **ã—ã¾ã™ã€‚ 
LLM-as-a-judge facilitates this process: weâ€™ve found that it returns a score within 1 point of the human score 75% of the time, and larger disagreements often indicate that thereâ€™s a correct answer not in our SOT. 
LLM-as-a-judgeã¯ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®¹æ˜“ã«ã™ã‚‹ã€‚ç§ãŸã¡ã¯ã€LLMãŒäººé–“ã®ã‚¹ã‚³ã‚¢ã‹ã‚‰1ãƒã‚¤ãƒ³ãƒˆä»¥å†…ã®ã‚¹ã‚³ã‚¢ã‚’75%ã®ç¢ºç‡ã§è¿”ã™ã“ã¨ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚ã¾ãŸã€å¤§ããªä¸ä¸€è‡´ã¯ã€ç§ãŸã¡ã®SOTã«ãªã„æ­£ã—ã„å›ç­”ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã“ã¨ãŒã‚ˆãã‚ã‚Šã¾ã™ã€‚ 
We ask experts to review these cases and update our benchmark if needed.
ç§ãŸã¡ã¯å°‚é–€å®¶ã«ã“ã‚Œã‚‰ã®ã‚±ãƒ¼ã‚¹ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ã‚‚ã‚‰ã„ã€å¿…è¦ã«å¿œã˜ã¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ›´æ–°ã—ã¦ã‚‚ã‚‰ã„ã¾ã™ã€‚

<!-- ã“ã“ã¾ã§èª­ã‚“ã ! -->

## Conclusion çµè«–

We have been building SQL Bot for over 1 year across a virtual team that has domain expertise in our priority product areas. 
ç§ãŸã¡ã¯ã€å„ªå…ˆè£½å“åˆ†é‡ã«ãŠã‘ã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³å°‚é–€çŸ¥è­˜ã‚’æŒã¤ãƒãƒ¼ãƒãƒ£ãƒ«ãƒãƒ¼ãƒ ã§ã€**1å¹´ä»¥ä¸Šã«ã‚ãŸã‚ŠSQL Botã‚’æ§‹ç¯‰**ã—ã¦ãã¾ã—ãŸã€‚ 
Our early pilots gathered a lot of interest from users, and weâ€™ve seen sustained adoption in the months following integration into DARWIN. 
åˆæœŸã®ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆã§ã¯å¤šãã®ãƒ¦ãƒ¼ã‚¶ã®é–¢å¿ƒã‚’é›†ã‚ã€DARWINã¸ã®çµ±åˆå¾Œã®æ•°ãƒ¶æœˆé–“ã§æŒç¶šçš„ãªæ¡ç”¨ãŒè¦‹ã‚‰ã‚Œã¾ã—ãŸã€‚ 
In a recent survey, ~95% rated SQL Botâ€™s query accuracy â€œPassesâ€ or above, and ~40% rated the query accuracy â€œVery Goodâ€ or â€œExcellentâ€. 
æœ€è¿‘ã®èª¿æŸ»ã§ã¯ã€ç´„95%ãŒSQL Botã®ã‚¯ã‚¨ãƒªç²¾åº¦ã‚’ã€Œåˆæ ¼ã€ä»¥ä¸Šã¨è©•ä¾¡ã—ã€ç´„40%ãŒã€Œéå¸¸ã«è‰¯ã„ã€ã¾ãŸã¯ã€Œå„ªç§€ã€ã¨è©•ä¾¡ã—ã¾ã—ãŸã€‚ 

Looking ahead, there are opportunities to improve the user experience, for example through faster response time, in-line query revisions, exposing the context that SQL Bot used to answer the question, and learning from user interactions over time. 
ä»Šå¾Œã¯ã€ãƒ¦ãƒ¼ã‚¶ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ã‚’æ”¹å–„ã™ã‚‹æ©Ÿä¼šãŒã‚ã‚Šã€ä¾‹ãˆã°ã€å¿œç­”æ™‚é–“ã®çŸ­ç¸®ã€ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚¯ã‚¨ãƒªä¿®æ­£ã€SQL BotãŒè³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ä½¿ç”¨ã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æç¤ºã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ã®å­¦ç¿’ãªã©ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚ 
Additionally, improving semantic accuracy could be facilitated by identifying champions to lead self-serve context curation efforts within their respective areas. 
ã•ã‚‰ã«ã€æ„å‘³çš„ç²¾åº¦ã®å‘ä¸Šã¯ã€ãã‚Œãã‚Œã®åˆ†é‡ã§ã‚»ãƒ«ãƒ•ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ´»å‹•ã‚’ãƒªãƒ¼ãƒ‰ã™ã‚‹ãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³ã‚’ç‰¹å®šã™ã‚‹ã“ã¨ã§ä¿ƒé€²ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ 

One takeaway is that the â€œFix with AIâ€ feature was easy to develop but has very high usageâ€”accounting for 80% of our sessionsâ€”frequently saving users time in debugging their queries. 
ä¸€ã¤ã®æ•™è¨“ã¯ã€**â€œFix with AIâ€ æ©Ÿèƒ½ã¯é–‹ç™ºãŒå®¹æ˜“ã§ã‚ã£ãŸãŒã€éå¸¸ã«é«˜ã„ä½¿ç”¨ç‡ã‚’èª‡ã‚Šã€ç§ãŸã¡ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®80%ã‚’å ã‚ã€ãƒ¦ãƒ¼ã‚¶ãŒã‚¯ã‚¨ãƒªã®ãƒ‡ãƒãƒƒã‚°ã«ã‹ã‹ã‚‹æ™‚é–“ã‚’é »ç¹ã«ç¯€ç´„ã—ã¦ã„ã‚‹**ã¨ã„ã†ã“ã¨ã§ã™ã€‚
Identifying high-ROI pain points like this is a good place to start the text-to-SQL journey. 
ã“ã®ã‚ˆã†ãª**é«˜ROIã®pain pointsã‚’ç‰¹å®š**ã™ã‚‹ã“ã¨ã¯ã€text-to-SQLã®æ—…ã‚’å§‹ã‚ã‚‹è‰¯ã„å‡ºç™ºç‚¹ã§ã™ã€‚(ä¿ºã‚‚ROIã®é«˜ã„pain pointç‰¹å®šã—ã¦ã‡ã€œ! æ¨è–¦ã ã¨ã€ã¾ãšã¯1ã¤ã®è¡Œå‹•ã‚’æ¨è–¦ã™ã‚‹æ„æ€æ±ºå®šæœ€é©åŒ–å•é¡Œã‹ãª...!:thinking:)

<!-- ã“ã“ã¾ã§èª­ã‚“ã ! -->

## Acknowledgements è¬è¾

Thanks to all contributors to the project across Engineering / Product, including Michael Cheng, Clarisse Rahbar, Sparsh Agarwal, Manohar Mohan Rao, Paul Lee, Vishal Chandawarkar. 
ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°/ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆå…¨ä½“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«è²¢çŒ®ã—ãŸã™ã¹ã¦ã®æ–¹ã€…ã€ç‰¹ã«Michael Chengã€Clarisse Rahbarã€Sparsh Agarwalã€Manohar Mohan Raoã€Paul Leeã€Vishal Chandawarkarã«æ„Ÿè¬ã—ã¾ã™ã€‚

Thanks to Trino experts for brainstorming ideas, writing a query plan parser, and reviewing this blog post: Erik Krogen, Slim Bouguerra. 
ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ãƒ–ãƒ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒŸãƒ³ã‚°ã—ã€ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½œæˆã—ã€ã“ã®ãƒ–ãƒ­ã‚°æŠ•ç¨¿ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã‚ŒãŸTrinoã®å°‚é–€å®¶ã€Erik Krogenã€Slim Bouguerraã«æ„Ÿè¬ã—ã¾ã™ã€‚

Thanks to Data Science experts for curating the benchmark dataset and evaluating query accuracy: Kavi Tan, Andrew Jabara, Noora Wu, Ruoyun Guo, Steve Na, Ashish Tripathy, Michael Kosk, Lingjun Chen, Cole Silva, Feiran Ji, Janet Luo, Franklin Marsh, Mengyao Yang, Tao Lin, Huanqi Zhu, Paul Matsiras, Andrew Kirk. 
ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã€ã‚¯ã‚¨ãƒªã®ç²¾åº¦ã‚’è©•ä¾¡ã—ã¦ãã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®å°‚é–€å®¶ã€Kavi Tanã€Andrew Jabaraã€Noora Wuã€Ruoyun Guoã€Steve Naã€Ashish Tripathyã€Michael Koskã€Lingjun Chenã€Cole Silvaã€Feiran Jiã€Janet Luoã€Franklin Marshã€Mengyao Yangã€Tao Linã€Huanqi Zhuã€Paul Matsirasã€Andrew Kirkã«æ„Ÿè¬ã—ã¾ã™ã€‚

Thanks to Engineering partners for providing APIs for knowledge graph construction: Shailesh Jannu, Na Zhang, Leo Sun, Alex Bachuk, Steve Calvert. 
ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•æ§‹ç¯‰ã®ãŸã‚ã®APIã‚’æä¾›ã—ã¦ãã‚ŒãŸã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã€Shailesh Jannuã€Na Zhangã€Leo Sunã€Alex Bachukã€Steve Calvertã«æ„Ÿè¬ã—ã¾ã™ã€‚

Thanks to Leadership for supporting this project: Ya Xu, Zheng Li, Jia Ding, Kuo-Ning Huang, Harikumar Velayutham, Shishir Sathe, Justin Dyer. 
ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æ”¯æ´ã—ã¦ãã‚ŒãŸãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—ã€Ya Xuã€Zheng Liã€Jia Dingã€Kuo-Ning Huangã€Harikumar Velayuthamã€Shishir Satheã€Justin Dyerã«æ„Ÿè¬ã—ã¾ã™ã€‚

Topics: Generative AI, Artificial intelligence, Data Management, Data Science 
ãƒˆãƒ”ãƒƒã‚¯: ã‚¸ã‚§ãƒãƒ¬ãƒ¼ãƒ†ã‚£ãƒ–AIã€äººå·¥çŸ¥èƒ½ã€ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹
