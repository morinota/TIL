## これは何?

- Text2SQLサービスの実現のために、個人的に情報収集した内容を雑多にまとめたものです。

## まず生成AIアプリケーションを設計する上での定石みたいなものを調べてみる

### これは何?

- Text2SQLの前に、まずLLMを使ったアプリケーションをどう設計すると良さそうか、の情報を調べたかった。
- 「機械学習システムデザイン」原著者であるChip Huyenさんのブログ「Building A Generative AI Platform」を読んで、内容まとめや感想をメモしておく。
- <https://huyenchip.com/2024/07/25/genai-platform.html>

### まずは最も単純なアーキテクチャから始まる

- 著者の方曰く、各社がどのように生成AIアプリケーションを導入しているかを調査した結果、そのプラットフォームには**多くの共通点**があるっぽい。
  - 記事内では、**生成AIプラットフォームの一般的なコンポーネント**、それらがどう機能するか、それらがどう実装されるか、についてまとめている。

![全体的なアーキテクチャ](https://prod-files-secure.s3.us-west-2.amazonaws.com/6623ab3b-143f-49a2-82e8-9548c88947bc/93440e6b-f6d8-4509-8e67-8479935c71d7/image.png)

- **まずは最も単純なアーキテクチャから始め、徐々にさらに多くのコンポーネントを追加していく**。
  - ここで、「最も単純なアーキテクチャ」とは下図のような構成を意味する。
    - 具体的には、アプリケーションがクエリを受け取り、それをモデルAPIに送信する。モデルAPIはレスポンスを生成し、それがユーザに返される。
    - ちなみにモデルAPIは、サードパーティAPI(ex. OpenAI, Google, AWS, etc.)でも、内製でホストされたAPIでもOK。

![生成AIプラットフォームの最も単純なアーキテクチャ](https://prod-files-secure.s3.us-west-2.amazonaws.com/6623ab3b-143f-49a2-82e8-9548c88947bc/c7ee4653-af60-452c-bb55-4b2320f2f3b9/image.png)

この「最も単純なアーキテクチャ」に、必要に応じてコンポーネントを追加していく。もし追加コンポーネントがなくてもシステムが上手く動作する場合は、省略すればいいよね...! (省略可能か否かの判断は、開発プロセスの各段階で必要)。

追加されうるコンポーネント達は以下の6つ:

1. Context Construction: モデルが外部情報にアクセス可能にするためのコンポーネント
2. Guardrails: システムとユーザを守るためのコンポーネント
3. 複数のモデルを扱うためのRouterとGateway
4. レイテンシーとコストを削減するためのCache
5. 生成AIシステムの能力を最大限に引き出すための、complex logicやwrite actionの追加  
6. Observability(監視とデバッグのためのシステムの可視化)とOrchestration(全てのコンポーネントの連携)

### 追加コンポーネント1つ目: Context Construction

- システムへの最初の拡張は、**各クエリのために必要な情報を補完できるメカニズム**を導入すること。
  - このように関連情報を集めることを**Context construction(コンテキスト構築?)**と呼ぶ。
- Context constructionはどういうモチベーションで必要なの??
  - 1. まず前提: **LLMの回答の信頼性を向上させたい!!**
    - 多くの場合、**クエリ(i.e. 質問)に対して適切に回答するためには文脈(context)が必要**である。LLMの内部知識だけで対応するにはどうしても限界がある。
  - 2. LLMの内部知識の依存度を下げたい...!!
    - **LLMの内部知識は、学習データと学習方法に大きく依存し、信頼性が低い**。
      - contextが多いほど、LLMが内部知識に頼る必要が少なくなる。
      - (なるほど! 内部知識をあんまり信頼できないから、基本的にはcontextを追加したいモチベーションがあるのか...!:thinking:)
  - 3. LLMの回答が時代遅れになるのを防ぎたい...!!
    - context constructionにより、LLMは新しい情報を継続的に取り込んで意思決定を行い、時代遅れになるのを防ぐことができる。
    - ex.
      - 先週までのデータで訓練されたモデルは、**新しい情報がコンテキストに含まれていない限り、今週に関する質問に答えることができない**...!
      - 最新の情報でモデルのcontextを更新することで、モデルは最新の状態を維持し、カットオフ日を超えるクエリにも応答できるようになる:thinking_face:
    - つまり、従来のMLOpsにおける「継続的訓練(Continual Training)」に近いような役割を果たすと言っても良さそう??

#### 具体的なContext Constructionの手法: RAG

- **Context construction の最も有名な手法として、RAG(Retrieval-Augmented Generation)**がある。
  - RAGは2つのコンポーネントから構成される: 
    - retriever(外部ソースから関連情報を取得する)
    - generator(ex.言語モデル)
- retrieverは、別にRAG固有のコンポーネントではないよね、という話:
  - 検索エンジン、推薦システムなど、他のアプリケーションでも結構使われてる。
    - 2-stages推薦でも、retrieveとrankの2つのステージがある!
  - **なので、従来の検索システム向けに開発された多くの検索アルゴリズムは、RAGにも適用できる!**
- retrieve対象のDocumentとchunkingの話:
  - retrieveにおける外部ソースには通常、メモ・契約書・ニュース記事などの非構造化データ(テキストデータ)が含まれる = これらを総称して **Document** と呼ぶ。
  - 各Documentのtoken数によっては、**1つのDocument全体をcontextとして渡すのが難しい場合**もある。
    - (原因は、LLM APIに渡せる最大コンテキスト長の制約や、アプリケーションのレイテンシー要件など...!)
  - なのでこの場合、**RAGでは通常、各Documentを適切なサイズのchunkに分割する**。
    - 適切なchunkサイズは、LLMの最大コンテキスト長とアプリケーションのレイテンシー要件などを考慮して決定する。
    - (なるほど...! 例えばニュース記事を一つのdocumentとみなす場合、本文全体をLLMに渡すのがアプリケーションの要件的に無理かもしれない。その場合、単一のdocumentを小さなセクションに分割(chunking)する...!!!:thinking:)
    - ちなみにchunkingと最適なchunkサイズについてより詳しく知りたい場合は、Pinecone、Langchain、Llamaindex、Greg Kamradtのチュートリアルを参照、とのこと。
- 主要な2種類のretrieveアプローチの話:
  - アプローチ1: **Term-based retrieval(単語ベースの検索)**
    - ex. 「transformer」というクエリが与えられた場合、このキーワードを含むすべての文書を関連情報としてfetchする。
    - より洗練されたアルゴリズムには、BM25（TF-IDFの活用）とElasticsearch（転置インデックスの活用）がある
    - 単語ベースの検索は、通常テキストデータに用いられるが、タイトル、タグ、キャプション、コメントなどの**テキストメタデータを持つ画像や動画にも有効**。
  - アプローチ2: **Embedding-based retrieval(埋め込みベースの検索、ベクトル検索)**
    - 各Documentのchunkを任意の埋め込みモデルを使用して埋め込みベクトルに変換しておく。(ex. BERT、sentence-transformers、OpenAIやGoogleが提供する独自の埋め込みモデル, etc.)
    - クエリが与えられると、クエリ埋め込みに最も近いデータk個が、任意のベクトル検索アルゴリズム(=ほぼほぼ何らかの近似近傍探索アルゴリズム!)によって関連情報としてfetchされる。
    - **埋め込みベースの検索は、非テキストのDocument(ex. 画像、ビデオ、オーディオ、コード)でも適用できる**。
      - 例えば、コードをDocumentとして扱う場合、多くのケースでは、**SQLテーブルやデータフレームを自然言語に要約してから、これらの要約を使用してretrieve用の埋め込みを生成**する。
      - (うんうん、実際にいくつかのText2SQLの事例でもこの方法を採用してた...!:thinking:)
      - (ちなみに、この方法を使えば、**term-based retrievalでも同様に非テキストデータを扱えるよね...??** これは別にembedding-based retrieval固有の方法ではない気がする...!:thinking:)
  - 両アプローチの比較:
    - **term-based retrievalは、embedding-based retrievalよりもはるかに高速で安価**。
      - (そうなのか...!まあDocumentの件数にもよるだろうけど、そりゃANNしなきゃってモチベーションもあるわけだ:thinking:)
      - BM25とElasticsearchは、業界で広く使用されており、より複雑な検索システムの**強力なベースライン**として機能する。
    - 埋め込みベースの検索は、計算コストが高いが、時間の経過とともに大幅に改善され、単語ベースの検索を上回ることができる。
      - (どうなんだろ、レイテンシーも重要だし...!**元々はRAGってembedding-based retrieval一択なのかなと思ってたけど、アプリケーション要件によってはterm-based retrievalの方が良いケースも結構あるのかも...!**:thinking:)
- まあ本番の検索システムは通常、いくつかのアプローチを組み合わせるハイブリッド検索だよねという話:
  - term-based retrievalとembedding-based retrievalを組み合わせる → ハイブリッド検索
  - よくあるパターン1つ目が、**sequentialパターン** (要するに2-stages推薦みたいな感じか...!:thinking:)
    - - 第一段階として、term-basedシステムなどの安価で精度の低いretrieverが候補を取得
    - 第二段階として、embedding-basedシステムなどのより正確でコストの高いretrieverが候補から最適なものを見つける
      - 第2段階はrerankingとも呼ばれる。(まさに、2-stages推薦と同じじゃん!:thinking:)
  - よくあるパターン2つ目が、**ensembleパターン**
    - 複数のretrieverを使って候補を同時に取得し、それらの異なるランキングを組み合わせて最終的なランキングを生成する。
    - (よくKaggleで目にするような、スコアを平均するようなensembleアプローチではなく、複数のランキングを混ぜ合わせるのでinterleaving的な感じか...!:thinking:)
    
- Context constructionにおいて、Documentの正確なランキングは重要かの話:
  - 検索や推薦と比較するとそれほど重要ではないかもしれないが、Documentの順序は一定重要っぽい。
  - なぜならそれが、**generatorモデルがcontextをどれだけうまく処理できるかに影響を与えるから**
  - generatorモデルは、**contextの最初と最後の文書をよりよく理解する可能性**がある。
  - しかし、対象Documentが含まれてさえいれば、その順序の影響は、検索ランキングと比較したら小さいらしい。
    
#### RAGの性能向上に関連するテクニック: Query Rewriting

- hogehoge

### 追加コンポーネント2つ目: Guardrails



### 追加コンポーネント3つ目: RouterとGateway

### 追加コンポーネント4つ目: Cache

### 追加コンポーネント5つ目: Complex LogicやWrite Action

### 追加コンポーネント6つ目: ObservabilityとOrchestration
