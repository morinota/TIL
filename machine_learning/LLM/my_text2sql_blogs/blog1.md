## これは何?

- Text2SQLサービスの実現のために、個人的に情報収集した内容を雑多にまとめたものです。

## まず生成AIアプリケーションを設計する上での定石みたいなものを調べてみる

### これは何?

- Text2SQLの前に、まずLLMを使ったアプリケーションをどう設計すると良さそうか、の情報を調べたかった。
- 「機械学習システムデザイン」原著者であるChip Huyenさんのブログ「Building A Generative AI Platform」を読んで、内容まとめや感想をメモしておく。
- <https://huyenchip.com/2024/07/25/genai-platform.html>

### まずは最も単純なアーキテクチャから始まる

- 著者の方曰く、各社がどのように生成AIアプリケーションを導入しているかを調査した結果、そのプラットフォームには**多くの共通点**があるっぽい。
  - 記事内では、**生成AIプラットフォームの一般的なコンポーネント**、それらがどう機能するか、それらがどう実装されるか、についてまとめている。

![全体的なアーキテクチャ](https://prod-files-secure.s3.us-west-2.amazonaws.com/6623ab3b-143f-49a2-82e8-9548c88947bc/93440e6b-f6d8-4509-8e67-8479935c71d7/image.png)

- **まずは最も単純なアーキテクチャから始め、徐々にさらに多くのコンポーネントを追加していく**。
  - ここで、「最も単純なアーキテクチャ」とは下図のような構成を意味する。
    - 具体的には、アプリケーションがクエリを受け取り、それをモデルAPIに送信する。モデルAPIはレスポンスを生成し、それがユーザに返される。
    - ちなみにモデルAPIは、サードパーティAPI(ex. OpenAI, Google, AWS, etc.)でも、内製でホストされたAPIでもOK。

![生成AIプラットフォームの最も単純なアーキテクチャ](https://prod-files-secure.s3.us-west-2.amazonaws.com/6623ab3b-143f-49a2-82e8-9548c88947bc/c7ee4653-af60-452c-bb55-4b2320f2f3b9/image.png)

この「最も単純なアーキテクチャ」に、必要に応じてコンポーネントを追加していく。もし追加コンポーネントがなくてもシステムが上手く動作する場合は、省略すればいいよね...! (省略可能か否かの判断は、開発プロセスの各段階で必要)。

追加されうるコンポーネント達は以下の6つ:

1. Context Construction: モデルが外部情報にアクセス可能にするためのコンポーネント
2. Guardrails: システムとユーザを守るためのコンポーネント
3. 複数のモデルを扱うためのRouterとGateway
4. レイテンシーとコストを削減するためのCache
5. 生成AIシステムの能力を最大限に引き出すための、complex logicやwrite actionの追加  
6. Observability(監視とデバッグのためのシステムの可視化)とOrchestration(全てのコンポーネントの連携)

### 追加コンポーネント1つ目: Context Construction

- システムへの最初の拡張は、**各クエリのために必要な情報を補完できるメカニズム**を導入すること。
  - このように関連情報を集めることを**Context construction(コンテキスト構築?)**と呼ぶ。
- Context constructionはどういうモチベーションで必要なの??
  - 1. まず前提: **LLMの回答の信頼性を向上させたい!!**
    - 多くの場合、**クエリ(i.e. 質問)に対して適切に回答するためには文脈(context)が必要**である。LLMの内部知識だけで対応するにはどうしても限界がある。
  - 2. LLMの内部知識の依存度を下げたい...!!
    - **LLMの内部知識は、学習データと学習方法に大きく依存し、信頼性が低い**。
      - contextが多いほど、LLMが内部知識に頼る必要が少なくなる。
      - (なるほど! 内部知識をあんまり信頼できないから、基本的にはcontextを追加したいモチベーションがあるのか...!:thinking:)
  - 3. LLMの回答が時代遅れになるのを防ぎたい...!!
    - context constructionにより、LLMは新しい情報を継続的に取り込んで意思決定を行い、時代遅れになるのを防ぐことができる。
    - ex.
      - 先週までのデータで訓練されたモデルは、**新しい情報がコンテキストに含まれていない限り、今週に関する質問に答えることができない**...!
      - 最新の情報でモデルのcontextを更新することで、モデルは最新の状態を維持し、カットオフ日を超えるクエリにも応答できるようになる:thinking_face:
    - つまり、従来のMLOpsにおける「継続的訓練(Continual Training)」に近いような役割を果たすと言っても良さそう??

#### 具体的なContext Constructionの手法: RAG

- **Context construction の最も有名な手法として、RAG(Retrieval-Augmented Generation)**がある。
  - RAGは2つのコンポーネントから構成される: 
    - retriever(外部ソースから関連情報を取得する)
    - generator(ex.言語モデル)
- retrieverは、RAG固有のコンポーネントではない。
  - 検索エンジン、推薦システムなど、他のアプリケーションでも結構使われてる。
    - 2-stages推薦でも、retrieveとrankの2つのステージがある!
  - **なので、従来の検索システム向けに開発された多くの検索アルゴリズムは、RAGにも適用できる!**
    - (dual-encodingなど?:thinking:)

#### RAGの性能向上に関連するテクニック: Query Rewriting

- hogehoge

### 追加コンポーネント2つ目: Guardrails



### 追加コンポーネント3つ目: RouterとGateway

### 追加コンポーネント4つ目: Cache

### 追加コンポーネント5つ目: Complex LogicやWrite Action

### 追加コンポーネント6つ目: ObservabilityとOrchestration
