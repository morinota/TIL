## これは何?

- 「機械学習システムデザイン」原著者であるChip Huyenさんのブログ「Building A Generative AI Platform」を読んで、内容まとめや感想をまとめる。
  - この本の他にも、確か別のブログが結構バズってた
  - <https://www.oreilly.co.jp/books/9784814400409/>
- <https://huyenchip.com/2024/07/25/genai-platform.html>

# Building A Generative AI Platform

- 各社がどのように生成AIアプリケーションを導入しているかを調査した結果、そのプラットフォームには**多くの共通点**があることに気づいた。
  - 記事内では、**生成AIプラットフォームの一般的なコンポーネント**、それらがどう機能するか、それらがどう実装されるか、についてまとめている。
  - 全体的なアーキテクチャは以下

        ![全体的なアーキテクチャ](https://prod-files-secure.s3.us-west-2.amazonaws.com/6623ab3b-143f-49a2-82e8-9548c88947bc/93440e6b-f6d8-4509-8e67-8479935c71d7/image.png)

        全体的なアーキテクチャ

- この記事では、最も単純なアーキテクチャから始め、徐々にさらに多くのコンポーネントを追加していく
  - 「最も単純なアーキテクチャ」 = アプリケーションはクエリを受け取り、それをモデルAPIに送信する。モデルAPIはレスポンスを生成し、それがユーザに返される。
    - ここで「モデルAPI」は、サードパーティAPI(ex. OpenAI, Google, AWS, etc.)でも、内製でホストされたAPIでもOK。

![生成AIプラットフォームの最も単純なアーキテクチャ](https://prod-files-secure.s3.us-west-2.amazonaws.com/6623ab3b-143f-49a2-82e8-9548c88947bc/c7ee4653-af60-452c-bb55-4b2320f2f3b9/image.png)

- この「最も単純なアーキテクチャ」に、必要に応じてコンポーネントを追加していく。
- また、コンポーネントがなくてもシステムが上手く動作する場合は、省略もできる。
  - 省略可能か否かの評価は、開発プロセスの各段階で必要。
- 追加していくコンポーネント達は以下の5つ
    1. Context Construction: モデルが外部情報にアクセス可能にするためのコンポーネント
    2. Guardrails: システムとユーザを守るためのコンポーネント
    3. 複数のモデルを扱うためのRouterとGateway
    4. レイテンシーとコストを削減するためのCache
    5. 生成AIシステムの能力を最大限に引き出すための、complex logicやwrite actionの追加
  - また、Observability(監視とデバッグのためのシステムの可視化)とOrchestration(全てのコンポーネントの連携)も、プラットフォームの重要なコンポーネント。

## Step 1. Enhance Context コンテキストの強化

- プラットフォームへの最初の拡張では、「各クエリに必要な情報を補完するメカニズム」を追加する。
  - 関連情報を集めることを「**Context construction(コンテキスト構築?)**」と呼ぶ。

### Context constructionの必要性

- 多くのクエリは、答えるために文脈(context)が必要。モデルが内部知識だけで対応するには限界がある。
- コンテキストに関連する情報が多ければ多いほど、モデルが内部知識に頼る必要が少なくなる。
  - モデルの内部知識は、学習データと学習方法に大きく依存し、信頼性が低い。
  - なるほど、信頼性の観点から、基本的にはcontextを追加したいモチベーションがあるのか...!🤔
- 既存研究によると、**contextで関連情報にアクセスできると、モデルがより詳細な回答を生成するのに役立ち、ハルシネーションを減らすことができる**（Lewis et al., 2020）
  - ex. 「Acmeのfancy-printer-A300は100ppsを印刷しますか？」というクエリが与えられた場合、そのfancy-printer-A300（プリンタ）の詳細仕様が提供されれば、モデルはより正確な回答ができる。
- 基盤モデルにおけるContext constructionの役割は、従来のMLモデルにおける特徴量エンジニアリングと同じ!
  - **役割 = モデルに入力を処理するために必要な情報を提供すること**
- context学習は、Contiuous Learningの一種。
  - (Context constructionって、in-context learningって言えるの??:thinking_face:)
  - これにより、**モデルは新しい情報を継続的に取り込んで意思決定を行い、時代遅れになるのを防ぐことができる**。
  - ex.)
    - 先週までのデータで訓練されたモデルは、**新しい情報がコンテキストに含まれていない限り、今週に関する質問に答えることができない**...!
    - 最新の情報でモデルのcontextを更新することで、モデルは最新の状態を維持し、カットオフ日を超えるクエリにも応答できるようになる:thinking_face:

### RAG

- Context construction の最も有名な手法として、RAG(Retrieval-Augmented Generation)がある。
  - RAGは2つのコンポーネントから構成される: generator(ex.言語モデル)とretriever(外部ソースから関連情報を取得する)
  - retrieverは、RAG固有のコンポーネントではない。
    - 検索エンジン、推薦システムなど、他のアプリケーションでも使われる。
      - 2-stages推薦でも、retrieveとrankの2つのステージがある!
    - **なので、従来の検索システム向けに開発された多くの検索アルゴリズムは、RAGにも適用できる!**
      - (dual-encodingなど?:thinking:)
- 外部ソースには通常、メモ、契約、ニュース更新などの非構造化データが含まれている。
  - それらを総称して **document(文書)** と呼ぶ!
  - 文書は10トークンにも100万トークンにもなる
  - 直感的には1つのdocument全体を取得すると、contextが非常に長くなり得る!
    - なのでRAGでは通常、documentsを管理可能なチャンクに分割する。これは、モデルの最大コンテキスト長とアプリケーションのレイテンシ要件から決定できる。
      - (ex. **ニュース記事を一つのdocumentとみなす場合、本文全体をgeneratorに渡すのがアプリケーションの要件的に無理かもしれない。その場合、単一のdocumentを小さなセクションに分割(chunking)する...!!!**:thinking:)
      - chunkingと最適なchunkサイズについて詳しく知りたい場合は、Pinecone、Langchain、Llamaindex、Greg Kamradtのチュートリアルを参照。

- 外部メモリソースからのデータがロードされ、chunk化されたら、**2つの主要なアプローチを使用してretrieval**が行われる
  - Term-based retrieval(単語ベースの検索)
    - ex. 「transformer」というクエリが与えられた場合、このキーワードを含むすべての文書を関連情報としてfetchする。
    - より洗練されたアルゴリズムには、BM25（TF-IDFを活用）とElasticsearch（逆インデックスを活用）がある
    - 単語ベース検索は、通常テキストデータに用いられるが、タイトル、タグ、キャプション、コメントなどの**テキストメタデータを持つ画像や動画にも有効**。

  - Embedding-based retrieval(埋め込みベースの検索, ベクトル検索とも呼ばれる)
    - データのchunkを任意の埋め込みモデルを使用して埋め込みベクトルに変換しておく。(ex. BERT、sentence-transformers、OpenAIやGoogleが提供する独自の埋め込みモデル, etc.)
    - クエリが与えられると、ベクトル検索アルゴリズム(=たぶん近傍探索?)によって決定されたクエリ埋め込みに最も近いデータk個が関連情報としてfetchされる。
      - ベクトル検索は通常、近似最近傍（ANN, Approximate Nearest Neighbors）アルゴリズムを使用して高速化される。
      - (特にリアルタイム推論のLLMアプリケーションで、context constructionのための手段としてRAGでembedding-based retrievalを使う場合、ANNを使う必要があるの...!:thinking:)
    - 埋め込みベースの検索は、テキスト文書だけでなく、画像、ビデオ、オーディオ、コードでも機能する
      - 例えば文書としてコードを採用する場合、多くのチームは**SQLテーブルやデータフレームを要約してから、これらの要約を使用して検索用の埋め込みを生成**しようとする
      - (データを直接embeddingに変換するのではなく、要約してからembeddingに変換するアプローチ。text-to-SQLアプリケーションでも採用してるアプローチじゃん...!:thinking:)
  - 両アプローチの比較
    - 単語ベースの検索は、埋め込みベースの検索よりもはるかに高速で安価。
      - (そうなのか...!まあ文書の件数にもよるだろうけど、そりゃANNアルゴリズム使わなきゃってモチベーションもあるわけだ:thinking:)
      - BM25とElasticsearchは、業界で広く使用されており、より複雑な検索システムの**強力なベースラインとして機能**する。
    - 埋め込みベースの検索は、計算コストが高いが、時間の経過とともに大幅に改善され、単語ベースの検索を上回ることができる。(どうなんだろ...!レイテンシーも重要だし:thinking:)

- ハイブリッド検索
  - プロダクション検索システムは通常、いくつかのアプローチを組み合わせる。
  - 単語ベースの検索と埋め込みベースの検索を組み合わせることを**ハイブリッド検索**と呼ぶ。
  - よくあるパターンが"sequential"(要するにtwo-stages推薦みたいな感じ...!:thinking:)
    - 第一段階として、term-basedシステムなどの安価で精度の低いretrieverが候補を取得
    - 第二段階として、embedding-basedシステムなどのより正確でコストの高いretrieverが候補から最適なものを見つける
      - 第2段階はrerankingとも呼ばれる。(まさに、2-stages推薦と同じじゃん!:thinking:)
  - もう一つのよくあるパターンは ensemble
    - 複数のリトリーバーを使って候補を同時に取得し、それらの異なるランキングを組み合わせて最終的なランキングを生成する。
    - (よくKaggleで目にするような、スコアを平均するようなアンサンブル学習ではなく、interleaving的なアプローチの意味だった...!:thinking:)

- context Constructionにおいて、文書の正確な順位は重要??
  - 検索や推薦と比較するとそれほど重要ではないかもしれないが、文書の順序は依然として重要
    - -> なぜならそれが、**generatorモデルがcontextをどれだけうまく処理できるかに影響を与えるから**
    - generatorモデルは、**contextの最初と最後の文書をよりよく理解する可能性**がある。
    - しかし、対象documentが含まれてさえいれば、その順序の影響は、検索ランキングと比較したら小さいらしい。

### 表形式データにおけるRAG

(構造化データから関連情報をretrieveして、contextとしてgeneratorに渡すケース! 事例としては少なさそう??:thinking:)
(例えばA/Bテストでの観測結果をもとに、A/Bテストレポートを書いて! みたいなタスクだったら、構造化データをretrieveさせる必要があるだろうか...??:thinking:)

- 外部データソースは、データフレームやSQLテーブル(の中身!)のように構造化データである可能性もある。
  - SQLテーブルからのデータ検索は、**非構造化documentからのデータ検索とは大きく異なる**。
  - クエリ(=生成AIアプリケーションのクエリの意味!)が与えられると、システムは次のように動作する
    - hoge
