## これは何?

- 「機械学習システムデザイン」原著者であるChip Huyenさんのブログ「Building A Generative AI Platform」を読んで、内容まとめや感想をまとめる。
  - この本の他にも、確か別のブログが結構バズってた
  - <https://www.oreilly.co.jp/books/9784814400409/>
- <https://huyenchip.com/2024/07/25/genai-platform.html>

# Building A Generative AI Platform

- 各社がどのように生成AIアプリケーションを導入しているかを調査した結果、そのプラットフォームには**多くの共通点**があることに気づいた。
  - 記事内では、**生成AIプラットフォームの一般的なコンポーネント**、それらがどう機能するか、それらがどう実装されるか、についてまとめている。
  - 全体的なアーキテクチャは以下

        ![全体的なアーキテクチャ](https://prod-files-secure.s3.us-west-2.amazonaws.com/6623ab3b-143f-49a2-82e8-9548c88947bc/93440e6b-f6d8-4509-8e67-8479935c71d7/image.png)

        全体的なアーキテクチャ

- この記事では、最も単純なアーキテクチャから始め、徐々にさらに多くのコンポーネントを追加していく
  - 「最も単純なアーキテクチャ」 = アプリケーションはクエリを受け取り、それをモデルAPIに送信する。モデルAPIはレスポンスを生成し、それがユーザに返される。
    - ここで「モデルAPI」は、サードパーティAPI(ex. OpenAI, Google, AWS, etc.)でも、内製でホストされたAPIでもOK。

![生成AIプラットフォームの最も単純なアーキテクチャ](https://prod-files-secure.s3.us-west-2.amazonaws.com/6623ab3b-143f-49a2-82e8-9548c88947bc/c7ee4653-af60-452c-bb55-4b2320f2f3b9/image.png)

- この「最も単純なアーキテクチャ」に、必要に応じてコンポーネントを追加していく。
- また、コンポーネントがなくてもシステムが上手く動作する場合は、省略もできる。
  - 省略可能か否かの評価は、開発プロセスの各段階で必要。
- 追加していくコンポーネント達は以下の5つ
    1. Context Construction: モデルが外部情報にアクセス可能にするためのコンポーネント
    2. Guardrails: システムとユーザを守るためのコンポーネント
    3. 複数のモデルを扱うためのRouterとGateway
    4. レイテンシーとコストを削減するためのCache
    5. 生成AIシステムの能力を最大限に引き出すための、complex logicやwrite actionの追加
  - また、Observability(監視とデバッグのためのシステムの可視化)とOrchestration(全てのコンポーネントの連携)も、プラットフォームの重要なコンポーネント。

## Step 1. Enhance Context コンテキストの強化

- プラットフォームへの最初の拡張では、「各クエリに必要な情報を補完するメカニズム」を追加する。
  - 関連情報を集めることを「**Context construction(コンテキスト構築?)**」と呼ぶ。

### Context constructionの必要性

- 多くのクエリは、答えるために文脈(context)が必要。モデルが内部知識だけで対応するには限界がある。
- コンテキストに関連する情報が多ければ多いほど、モデルが内部知識に頼る必要が少なくなる。
  - モデルの内部知識は、学習データと学習方法に大きく依存し、信頼性が低い。
  - なるほど、信頼性の観点から、基本的にはcontextを追加したいモチベーションがあるのか...!🤔
- 既存研究によると、**contextで関連情報にアクセスできると、モデルがより詳細な回答を生成するのに役立ち、ハルシネーションを減らすことができる**（Lewis et al., 2020）
  - ex. 「Acmeのfancy-printer-A300は100ppsを印刷しますか？」というクエリが与えられた場合、そのfancy-printer-A300（プリンタ）の詳細仕様が提供されれば、モデルはより正確な回答ができる。
- 基盤モデルにおけるContext constructionの役割は、従来のMLモデルにおける特徴量エンジニアリングと同じ!
  - **役割 = モデルに入力を処理するために必要な情報を提供すること**
- context学習は、Contiuous Learningの一種。
  - (Context constructionって、in-context learningって言えるの??:thinking_face:)
  - これにより、**モデルは新しい情報を継続的に取り込んで意思決定を行い、時代遅れになるのを防ぐことができる**。
  - ex.)
    - 先週までのデータで訓練されたモデルは、**新しい情報がコンテキストに含まれていない限り、今週に関する質問に答えることができない**...!
    - 最新の情報でモデルのcontextを更新することで、モデルは最新の状態を維持し、カットオフ日を超えるクエリにも応答できるようになる:thinking_face:

### RAG

- Context construction の最も有名な手法として、RAG(Retrieval-Augmented Generation)がある。
  - RAGは2つのコンポーネントから構成される: generator(ex.言語モデル)とretriever(外部ソースから関連情報を取得する)
  - retrieverは、RAG固有のコンポーネントではない。
    - 検索エンジン、推薦システムなど、他のアプリケーションでも使われる。
      - 2-stages推薦でも、retrieveとrankの2つのステージがある!
    - **なので、従来の検索システム向けに開発された多くの検索アルゴリズムは、RAGにも適用できる!**
      - (dual-encodingなど?:thinking:)
- 外部ソースには通常、メモ、契約、ニュース更新などの非構造化データが含まれている。
  - それらを総称して **document(文書)** と呼ぶ!
  - 文書は10トークンにも100万トークンにもなる
  - 直感的には1つのdocument全体を取得すると、contextが非常に長くなり得る!
    - なのでRAGでは通常、documentsを管理可能なチャンクに分割する。これは、モデルの最大コンテキスト長とアプリケーションのレイテンシ要件から決定できる。
      - (ex. **ニュース記事を一つのdocumentとみなす場合、本文全体をgeneratorに渡すのがアプリケーションの要件的に無理かもしれない。その場合、単一のdocumentを小さなセクションに分割(chunking)する...!!!**:thinking:)
      - chunkingと最適なchunkサイズについて詳しく知りたい場合は、Pinecone、Langchain、Llamaindex、Greg Kamradtのチュートリアルを参照。

- 外部メモリソースからのデータがロードされ、chunk化されたら、**2つの主要なアプローチを使用してretrieval**が行われる
  - Term-based retrieval(単語ベースの検索)
    - ex. 「transformer」というクエリが与えられた場合、このキーワードを含むすべての文書を関連情報としてfetchする。
    - より洗練されたアルゴリズムには、BM25（TF-IDFを活用）とElasticsearch（逆インデックスを活用）がある
    - 単語ベース検索は、通常テキストデータに用いられるが、タイトル、タグ、キャプション、コメントなどの**テキストメタデータを持つ画像や動画にも有効**。

  - Embedding-based retrieval(埋め込みベースの検索, ベクトル検索とも呼ばれる)
    - データのchunkを任意の埋め込みモデルを使用して埋め込みベクトルに変換しておく。(ex. BERT、sentence-transformers、OpenAIやGoogleが提供する独自の埋め込みモデル, etc.)
    - クエリが与えられると、ベクトル検索アルゴリズム(=たぶん近傍探索?)によって決定されたクエリ埋め込みに最も近いデータk個が関連情報としてfetchされる。
      - ベクトル検索は通常、近似最近傍（ANN, Approximate Nearest Neighbors）アルゴリズムを使用して高速化される。
      - (特にリアルタイム推論のLLMアプリケーションで、context constructionのための手段としてRAGでembedding-based retrievalを使う場合、ANNを使う必要があるの...!:thinking:)
    - 埋め込みベースの検索は、テキスト文書だけでなく、画像、ビデオ、オーディオ、コードでも機能する
      - 例えば文書としてコードを採用する場合、多くのチームは**SQLテーブルやデータフレームを要約してから、これらの要約を使用して検索用の埋め込みを生成**しようとする
      - (データを直接embeddingに変換するのではなく、要約してからembeddingに変換するアプローチ。text-to-SQLアプリケーションでも採用してるアプローチじゃん...!:thinking:)
  - 両アプローチの比較
    - 単語ベースの検索は、埋め込みベースの検索よりもはるかに高速で安価。
      - (そうなのか...!まあ文書の件数にもよるだろうけど、そりゃANNアルゴリズム使わなきゃってモチベーションもあるわけだ:thinking:)
      - BM25とElasticsearchは、業界で広く使用されており、より複雑な検索システムの**強力なベースラインとして機能**する。
    - 埋め込みベースの検索は、計算コストが高いが、時間の経過とともに大幅に改善され、単語ベースの検索を上回ることができる。(どうなんだろ...!レイテンシーも重要だし:thinking:)

- ハイブリッド検索
  - プロダクション検索システムは通常、いくつかのアプローチを組み合わせる。
  - 単語ベースの検索と埋め込みベースの検索を組み合わせることを**ハイブリッド検索**と呼ぶ。
  - よくあるパターンが"sequential"(要するにtwo-stages推薦みたいな感じ...!:thinking:)
    - 第一段階として、term-basedシステムなどの安価で精度の低いretrieverが候補を取得
    - 第二段階として、embedding-basedシステムなどのより正確でコストの高いretrieverが候補から最適なものを見つける
      - 第2段階はrerankingとも呼ばれる。(まさに、2-stages推薦と同じじゃん!:thinking:)
  - もう一つのよくあるパターンは ensemble
    - 複数のリトリーバーを使って候補を同時に取得し、それらの異なるランキングを組み合わせて最終的なランキングを生成する。
    - (よくKaggleで目にするような、スコアを平均するようなアンサンブル学習ではなく、interleaving的なアプローチの意味だった...!:thinking:)

- context Constructionにおいて、文書の正確な順位は重要??
  - 検索や推薦と比較するとそれほど重要ではないかもしれないが、文書の順序は依然として重要
    - -> なぜならそれが、**generatorモデルがcontextをどれだけうまく処理できるかに影響を与えるから**
    - generatorモデルは、**contextの最初と最後の文書をよりよく理解する可能性**がある。
    - しかし、対象documentが含まれてさえいれば、その順序の影響は、検索ランキングと比較したら小さいらしい。

### 表形式データにおけるRAG

(構造化データから関連情報をretrieveして、contextとしてgeneratorに渡すケース! 事例としては少なさそう??:thinking:)
(例えばA/Bテストでの観測結果をもとに、A/Bテストレポートを書いて! みたいなタスクだったら、構造化データをretrieveさせる必要があるだろうか...??:thinking:)

- 外部データソースは、データフレームやSQLテーブル(の中身!)のように構造化データである可能性もある。
- 例えば、SQLテーブルからのデータ検索は、**非構造化documentからのデータ検索とは大きく異なる**。
  - クエリ(=生成AIアプリケーションのクエリの意味!)が与えられると、システムは次のように動作する
    - 1. Text-to-SQL: ユーザクエリとテーブルスキーマに基づいて、必要なSQLクエリを決定する
      - (まずここが結構難しくて、一筋縄ではいかないはず...!:thinking:)
    - 2. SQLの実行
    - 3. 生成: SQLの結果と元のユーザクエリに基づいてレスポンスを生成する

![](https://huyenchip.com/assets/pics/genai-platform/4-rag-with-tabular-data.png)

### Agenticな(i.e. エージェントらしい)RAG

context constructionのための外部データソースやretrieveアプローチを、モデル自身が選択するケースの話:thinking:

- contextを取得する外部データソースとして、インターネットも有効
  - GoogleやBingのAPIのようなウェブ検索ツールは、各クエリに関連する情報を収集するための豊富で最新のリソースにアクセスできる。
  - ex. 「今年のオスカーは誰が受賞しましたか？」というクエリが与えられた場合、システムは最新のオスカーに関する情報を検索し、この情報をcontextとして使用してユーザに最終的な応答を生成する

- term-based retrieval、embedding-based retrieval、SQL実行、ウェブ検索は、いずれも**生成モデルがcontext constructionを行うために取ることができるアクション**である
  - よってそれぞれのアクション(=retrieve方法)は、モデルが呼び出せる関数とみなせる。
  - つまり、Agenticな(エージェントらしい)RAGアプローチ。

- ちなみに、AIのAgentic、Agentらしさの定義
  - 「LangGraph」のドキュメントによると...”**LLMがアプリケーションの制御フローを決定すること**”

AgenticなRAGの場合のアーキテクチャは以下

![](https://huyenchip.com/assets/pics/genai-platform/5-agentic-rag.png)

- (余談) Read-only actions と write actions
  - AgenticなLLMシステムにおいて、モデルが呼び出す関数は、**read-only actions**と**write actions**に分類できる。
    - read-only actions: 外部データソースから情報をretrieveするが、状態を変更しないアクション
      - (基本的にcontext constructionのための手段としてRAGを使う場合は、read-only actionsのイメージ:thinking:)
    - write actions: データベースに書き込む、メールを送信するなど、状態を変更するアクション
  - LLMにwrite actionsの権限を与えると、モデルはより多くのタスクを実行できるが、より多くのリスクも伴う。

### Query rewriting

- 多くの場合、正しい情報を取得する可能性を高めるために、ユーザのクエリを書き換える必要がある。
  - (関連情報をより良い感じにretrieveするために、クエリをrewriteするケース:thinking:)

query rewritingが必要になるユーザクエリの例

```shell
ユーザ: ジョン・ドウが最後に何かを買ったのはいつですか？
AI： ジョンが最後にFruity Fedoraの帽子を買ったのは2週間前の2030年1月3日です。
ユーザ: エミリー・ドウはどうですか？
```

- 最後の質問「エミリー・ドウはどうですか？」は曖昧。
  - **このクエリをそのまま使って文書をretrieveすると、無関係な情報が得られる可能性が高い**。
    - (確かに、対話式のアプリケーションだと特に問題になりそう:thinking:)
- ユーザが実際に尋ねていることを反映させるために、このクエリを書き換える必要がある。
  - 書き換えられた新しいクエリは、単独で意味をなすようになってるはず...!
  - この例では、最後の質問は、「エミリー・ドウが最後に私たちから何かを買ったのはいつですか？」に書き換えるべき...!
- query rewritingは通常、他のAIモデルを使って行われる。「**次の会話が与えられたら、ユーザが実際に尋ねていることを反映させるために、最後のユーザ入力を書き換えてください**」のようなプロンプトを使用する。

- query rewritingは、場合によっては複雑な処理が必要になる
  - identity resolutionや、他の知識を組み込む必要がある時など。
    - identity resolution: ユーザが入力したクエリや質問が特定の「人物、物、場所」などを指している場合、その指し示している「アイデンティティ（特定対象）」を正確に特定する必要がある。
    - ex.
      - 会話内の言及: 「彼の妻についてもっと知りたい」というクエリが与えられた場合、モデルは「彼」が誰を指しているのかを特定した後で、DBにクエリを送信して「彼」の妻について調べる必要がある。
      - この情報がない場合、**query rewriting用モデルは、名前をhallucinateする代わりに、このクエリが解決できないことを認めて、誤った回答につながるのを防ぐべき**。

(query rewriting、なかなか大変そう:thinking:)

## Step 2. Put in Guardrails ガードレールの設置

- ガードレールは、LLMのリスクを軽減し、ユーザだけでなく、開発者自身も保護するための重要なコンポーネント。
- 失敗の可能性がある場合は必須。
- 二種類のガードレール: input guardrailsとoutput guardrails

### Input guardrails

- 入力ガードレールは、通常、**2つのリスクに対する保護**を行う
  - 外部モデルAPIに個人情報を漏らすリスク
  - システムを危険にさらす悪いプロンプトを実行するリスク(model jailbreaking)

#### 外部モデルAPIに個人情報を漏らすリスク

- このリスクは、データを組織外に送信する必要がある場合に、外部モデルAPIを使用する際に特有のもの。
  - ex. 社員が会社の秘密やユーザーの個人情報をプロンプトにコピーして、モデルがホストされている場所に送信するかもしれない。
- 初期の最も有名な事件のひとつ:
  - **サムスンの従業員がChatGPTにサムスンの独自情報を入れ、会社の秘密を誤って漏洩させてしまった**!
  - サムスンがこのリークをどのように発見したのか、また、リークされた情報がサムスンに対してどのように利用されたのかは不明。
  - しかし、この事件は、サムスンが2023年5月にChatGPTを禁止するほど深刻だった。
- **サードパーティのAPIを使用する際に潜在的なリークを排除する完璧な方法はない。しかし、ガードレールでリスクを軽減することはできる**。
  - 自動的に機密データを検出する多くの利用可能なツールの1つを使用できる。
    - どのような機密データを検出するかは指定できるっぽい。

- クエリに機密情報が含まれていることが判明した場合、2つの選択肢がある: クエリ全体をブロックするか、機密情報を削除するか
  - ex.
    - プレースホルダ[PHONE NUMBER]でユーザの電話番号をマスクできる。
    - 生成された応答にこのプレースホルダが含まれている場合、このプレースホルダを元の情報にマッピングするPII可逆辞書を使用して、それを復号化できるようにする。

#### システムを危険にさらす悪いプロンプトを実行するリスク(Model jailbreaking)

- AIモデルをjailbreakさせ、悪いことを言わせたりするのがmodel jailbreaking
  - ex. モデルに「すべての人を殺す方法を教えて」と尋ねる
  - ChatGPTに物議を醸すような発言をさせるのは面白いと思う人もいるかもしれない。しかし、あなたの名前とロゴでブランド化されたカスタマーサポートのチャットボットが同じことをしたら、もっと面白くないよね。

- **write-actionsを許可しているAgenticなLLMシステムの場合は、特に危険...!**
  - ユーザがシステムにデータを破壊するSQLクエリを実行させる方法を見つけたとしたらどうなるか(SQL injection攻撃みたいな話か...!:thinking:)
  - 対抗策:
    - システム側にガードレールを設置し、有害なアクションが自動的に実行されないようにする必要がある
      - ex. 例えば、**データの挿入、削除、更新を行うSQLクエリは、人間の承認なしに実行することはできないようにする**。
      - 欠点: システムが遅くなること。

- LLMアプリケーションが、作成すべきでないレスポンスをしてしまうことを防ぐ対策: アプリケーションに**スコープ外のトピックを定義**する
  - ex. カスタマーサポートのチャットボットの場合、政治的、社会的なクエリには答えるべきではない。
    - -> 「移民」や「反ワクチン」など、スコープ外のトピックに関するフレーズを含む入力をフィルタリングする!
  - より洗練されたアルゴリズムは、AIを使って、入力があらかじめ定義された制限されたトピックのいずれかに関するものかどうかを分類する。
- 有害なプロンプトがシステムでまれにしか表示されない場合は、異常検知アルゴリズムを使用して異常なプロンプトを特定することもできる。(よくわかってない!:thinking:)

### Output guardrails

- AIモデルは確率論的であり、その出力はどうしても信頼性に欠ける。
  - -> ガードレールを設置することで、アプリケーションの信頼性を大幅に向上させることができる。
- 出力ガードレールには主に2つの機能がある:
  - 出力されたレスポンスの品質を評価し、失敗か否かを判定する
  - 異なる種類の失敗に対処するための方針を設定

#### 出力結果の評価

- **基準を満たさないアウトプットをキャッチする**には、失敗がどのようなものかを理解する必要がある。

- 失敗の例とその対処法
  - 1. 空っぽの応答
  - 2. 期待される出力フォーマットに従わない、不正なフォーマットによる応答
    - ex. jsonを期待してるけど、レスポンスに閉じ括弧がない...!
    - 対応: 正規表現、JSON、Pythonコードバリデータなど、特定のフォーマット用のvalidatorを使用する
  - 3. 人種差別や性差別などの有害な応答
    - 対応: 有害性の検出ツールを使用する
  - 4. hallucinateされた、事実に矛盾する応答
    - hallucinationの検出と軽減は、活発な研究分野
    - 軽減策: RAGなどのcontext constructionを使用
    - 検出策: Search Engine Factuality Evaluator, SelfCheckGPT, etc.
  - 5. 機密情報を含む応答
    - 対応策: 機密データでモデルをトレーニングしないこと。最初からcontextとして機密データをretrieveすることを許可しないこと
  - 6. 自社や競合他社を誤って表現するなど、ブランドリスクのある応答
    - ex. Xによって訓練されたモデルであるGrokが、GrokがOpenAIによって訓練されたと示唆する応答を生成し、インターネットがXがOpenAIのデータを盗んだと疑うようになった。
    - 対応策: キーワード監視。
      - もし自社ブランドや競合他社に関するレスポンスを特定したら、これらの出力をブロックしたり、人間のレビュアーに渡したり、他のモデルを使用してこれらの出力の感情を検出して、正しい感情のみが返されるようにする(なるほど...!:thinking:)
  - 7. 一般的に品質が悪い応答
    - ex. モデルにエッセイを書くように頼んだら、そのエッセイがひどかった。モデルに低カロリーのケーキのレシピを頼んだら、出来上がったレシピに砂糖が過剰に含まれていた。
    - 対応策: モデルの回答の質を評価するために、AIジャッジを使用する(これは現在、かなり一般的になってるらしい!:thinking:)
      - AIジャッジに使用するモデルは、汎用モデル（ChatGPT、Claudeなど）、もしくは、具体的なスコアを出力する学習済みモデル。(前者の方が開発も運用もコストが低そう:thinking:)

#### 異なる種類の失敗に対処するための方針を設定

- リトライポリシーの採用!!
  - 失敗時の対応として、**多くの失敗は、基本的なリトライロジックを使用して軽減できる**
    - というのも、AIモデルは確率的なものである。つまり、もう一度クエリを試せば、違う回答が返ってくるかもしれない。
    - ex.
      - レスポンスが空であれば、空でないレスポンスが返ってくるまでX回再試行する。
      - レスポンスが不正なフォーマットであれば、モデルが正しくフォーマットされたレスポンスを生成するまで再試行する。
- リトライポリシーのデメリット: **余分なレイテンシーとコスト**を発生させる
  - 失敗を検出した後に再試行すると、ユーザが経験する待ち時間は2倍になる
    - -> **待ち時間を減らすために、並列に呼び出すのは有効なアイデア**(なるほど...!:thinking:)
    - ex. それぞれのクエリに対して、最初のクエリが失敗するのを待ってから再試行するのではなく、このクエリをモデルに同時に2回送信し、2つのレスポンスを返してもらい、より良い方を選ぶ。
    - **冗長なAPIコールの数は増えるが、レイテンシーは管理可能な範囲に抑えられる**!

- 失敗時に人間に頼るポリシーの採用!!
  - トリッキーなクエリを処理するために人間に頼ることもよくあること。
    - ex. クエリに特定のキーワードが含まれている場合、クエリを人間のオペレーターに転送する
  - 事例によっては、専門的なモデル（社内で訓練された可能性もある）を使って、会話を人間に転送するタイミングを決定する
    - ex. **感情分析モデルがユーザが怒っていると検出したときに、会話を人間のオペレーターに転送する**

### ガードレールのトレードオフ

- 信頼性とレイテンシーのトレードオフ
  - ガードレール（安全性確保の仕組み）の重要性を認識しつつも、レイテンシー（応答速度）を重視するチームもある。
    - 一部のチームは、レイテンシー増加の懸念からガードレールを実装しないことを選択。
    - しかし、こうしたチームは少数であり、多くのチームは「レイテンシーの増加よりもリスクの増大がコスト高」と考えている。
  - stream completionモードでの出力ガードレール
    - 出力ガードレールは、stream completionモードではうまく機能しない可能性がある。
    - **通常、全体のレスポンスをユーザーに表示する前に生成するが、stream completionではトークンが生成されると同時にユーザーにストリーミングされ、待機時間が短縮される**。
    - 欠点として、部分的な応答の評価が難しいため、不適切な応答がガードレールでブロックされる前にユーザーに送られる可能性がある。
- セルフホストとサードパーティAPIのトレードオフ
  - モデルをセルフホストすることで、データを外部（サードパーティ）に送信せずに済み、入力ガードレールの必要性が減少する。
  - 一方で、サードパーティサービスのガードレールに頼らず、必要なガードレールを自ら実装しなければならない。

### 入力/出力ガードレールの設置場所

生成AIプラットフォームのアーキテクチャ内で、ガードレールは、独立したコンポーネント、もしくは後述するモデルゲートウェイの一部として実装される。

## Step 3. RouterとGatewayの設置

アプリケーションが複雑化し、より多くのモデルを扱うようになると、**複数のモデルを扱うのに役立つ2種類のツール**が登場した -> RouterとGateway

### Router

- アプリケーションは、異なる種類のユーザクエリに対応するために、複数のモデルを使用することがよくある。(必ずしも1つのモデルで全てのクエリに対応する必要もない...!:thinking:)
- **異なるユーザクエリに対して異なるソリューションを持つことには、いくつかの利点**がある
  - 第一に、特化型のモデルを使用できる。
    - 特化型のモデルは、汎用モデルよりも性能が向上し得る。
  - 第二に、コスト削減に役立つ
    - すべてのクエリを高価なモデルにルーティングする代わりに、より安価なモデルに簡単なクエリをルーティングすることができる

- ルーターは通常、**ユーザが何をしようとしているかを予測するintent classifier(意図分類器)**で構成される
  - 予測された意図に基づいて、クエリは適切なソリューションにルーティングされる。
  - ex. カスタマーサポートのチャットボットの場合
    - 「パスワードをリセットしたい」ユーザをパスワードリセットのページに誘導する。
    - 「請求ミスを訂正したい」ユーザを人間のオペレーターにルーティングする。
    - 「技術的な問題のトラブルシューティングをしたい」トラブルシューティング用に細かく調整されたモデルにルーティングする。
- また、**intent classifierはシステムがスコープ外の会話を避けるのにも役立つ**。
  - クエリが不適切と判断された場合、チャットボットはAPIコールを無駄にすることなく、予め用意された定型文の1つを使って丁寧に拒否することができる(ex. 「申し訳ありませんが、その情報は提供できません。プロダクトに関する質問があればお知らせください」)

- システムが複数のアクションにアクセスできる場合、**ルーターはnext action predictorを含めることができ**、システムが次にどのアクションを取るかを決定するのに役立つ。(まあmodel routing自体が、アクションの選択だもんなぁ...:thinking:)
  - **クエリがあいまいな場合は、説明を求めることも有効なアクションの1つ** (なるほど確かに...!:thinking:)
  - ex. ユーザクエリ「freeeze!」を受け取った場合、システムは「アカウントを凍結したいのですか?それとも天気について話しているのですか?」や「申し訳ありません。詳しく説明していただけますか？」と尋ねることができる。

- intent classifierやnext action predictorは、汎用モデル、または特化した分類モデルを利用できる。
  - **特化した分類モデルは、通常、汎用モデルよりもはるかに小さく高速であり**、システムが多数のモデルを使用しても、大幅な追加のレイテンシーやコストをかけることなく使用できる。
(これが特化モデルの利点か:thinking:)

### Gateway

- モデル・ゲートウェイは、**組織が異なるモデルに対して統一された安全な方法でインターフェースを持つことを可能にする**中間層である。
  - 最も基本的な機能 = 「開発者が異なるモデルに同じ方法でアクセスできるようにすること」
    - (大事だ...!:thinking:)
    - self-hostされたモデルか、OpenAIやGoogleなどの商用APIの背後にあるモデルかの違いはない。
    - -> コードの保守が容易になる!
      - モデルAPIが変更された場合、そのモデルAPIを使用するすべてのアプリケーションを更新する必要がある代わりに、モデルゲートウェイだけを更新すればよい!

![]()

- 最も単純な形では、モデルゲートウェイは統一されたwrapper!
  - コード例

```python
import google.generativeai as genai
import openai

def openai_model(input_data, model_name, max_tokens):
    openai.api_key = os.environ["OPENAI_API_KEY"]
    response = openai.Completion.create(
        engine=model_name,
        prompt=input_data,
        max_tokens=max_tokens
    )
    return {"response": response.choices[0].text.strip()}

def gemini_model(input_data, model_name, max_tokens):
    genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
    model = genai.GenerativeModel(model_name=model_name)
    response = model.generate_content(input_data, max_tokens=max_tokens)
    return {"response": response["choices"][0]["message"]["content"]}

@app.route('/model', methods=['POST'])
def model_gateway():
    data = request.get_json()
    model_type = data.get("model_type")
    model_name = data.get("model_name")
    input_data = data.get("input_data")
    max_tokens = data.get("max_tokens")

    if model_type == "openai":
        result = openai_model(input_data, model_name, max_tokens)
    elif model_type == "gemini":
        result = gemini_model(input_data, model_name, max_tokens)
    return jsonify(result)
```

- モデルゲートウェイの他の機能:
  - 1. アクセス制御とコスト管理:
    - OpenAI APIにアクセスしたい人全員にあなたの組織のトークンを渡すのではなく、**モデルゲートウェイにアクセス権を与えることで、中央集権化された制御されたアクセスポイント**を作成する
    - またどのユーザやアプリケーションがどのモデルにアクセスできるかを指定する**細かいアクセス制御**を実装することができる
    - 更に、APIコールの使用状況を監視し、制限することで、乱用を防ぎ、コストを効果的に管理することができる。
    - (うんうん、**モデル利用状況の管理の観点から、モデルサービスとの窓口は1箇所 = 中央集権化されている方が都合がいい**んだよね:thinking:)
  - 2. fallback policyの実装:
    - モデルゲートウェイは、レート制限やAPIの失敗（残念ながら一般的）を克服するためのフォールバックポリシーの実装のために利用できる。
      - (あ、推論モデルに不具合があった場合になんとか対応するためのフォールバック戦略か...!:thinking:)
    - プライマリAPIが利用できない場合、ゲートウェイはリクエストを代替モデルにルーティングしたり、短い待ち時間後に再試行したり、他の様々な戦略で失敗対応できる
      - -> **アプリケーションが中断することなくスムーズに動作することが保証**できる(大事...!:thinking:)
  - 3. ルーティング、ロードバランシング、ロギング、アナリティクスなどの他の様々な機能を実装するのに適した場所
    - (推薦統一インタフェースでも...!:thinking:)
    - ゲートウェイ・サービスの中には、キャッシュやガードレールを提供するものもある

ゲートウェイとルーターが追加され、我々のプラットフォームはよりエキサイティングになった!

![]()

## Step 4. キャッシュによるレイテンシーの削減
