# 強化学習ベースの推薦方策にて、LLMで擬似feedbackを生成するユーザシミュレータの論文を読んだ!

## これは何?

- 論文タイトルは「LLM-Powered User Simulator for Recommender System」。推薦システムのためのLLMを活用したユーザシミュレーターを提案する論文。

## この論文のモチベーション

- ユーザfeedbackのシミュレーターが求められてる話:
  - 強化学習（RL）ベースの推薦システムは、ユーザーの嗜好や長期的なエンゲージメントを捉える能力の高さから注目されてる。
  - でもRLベースの推薦システムが価値を発揮するためには、agentがenvironmentと対話してより良い意思決定を学習するような、**interactiveな学習が必要**。(i.e. つまりオンライン学習か...!:thiking:)
  - しかしオンライン学習のための実データの取得は、コストや時間やプライバシーの制約がある。
  - なので、ユーザfeedbackのシミュレーションができるとかなり嬉しい!
- 既存のユーザシミュレーターの課題:
  - 主に2つの課題がある。
  - 課題1: ユーザ嗜好の明示的なモデリングの欠如
    - ユーザの嗜好やfeedbackをより正確にシミュレートできるか??
  - 課題2: シミュレートされたfeedbackの忠実度を評価する方法の欠如
    - どのようにシミュレートされたfeedbackの忠実度を評価するか??
- LLMのシミュレーターとしての活用可能性:
  - LLMは幅広い分野で常識と推論能力において顕著な有効性を示してる。
  - なので、推薦システムのユーザシミュレーターとしても有望。でも課題もある:
    - 課題1: LLMを呼び出す際の計算コストと時間コストが大きいこと。
    - 課題2: LLMのハルシネーションのりすく
- 本論文の貢献:
  - 貢献1: 推薦アイテムに対するユーザエンゲージメントを支配する本質的なロジックを特定し、**ユーザfeedbackを明示的に推論する論理モデル**の提案。
  - 貢献2: ルールベースの論理モデル * データ駆動型の統計モデルからなるアンサンブルモデルを構築。これにより誤った推論の可能性を減らす。
  - 貢献3: 5つのベンチマークデータセットを用いて、提案手法の有効性を実証。

## 方法論について

- 前提知識: ユーザシミュレータについて
  - 目的: 推薦アイテム $i_{c}$ に対するユーザのエンゲージメント $y_c$ を推定すること。
  - 定式化すると $P(y_c | i_{c}, h)$ となる。
    - ここで $h$ はあるユーザの過去の行動履歴。(ユーザのcontext...!:thinking:)
    - $y_c$ はユーザのエンゲージメント(評価、購入、badボタンなど)
- 方法論の全体像:
  - LLMによるアイテムの分析 → ユーザの過去の行動との比較 → 推論
- LLMによるアイテムの分析について
  - その1: **客観的アイテム説明の生成(Objective Item Description Collection)**
    - アイテムが「何であるか」を識別するために、アイテムの事実に基づく説明文を生成する。
    - アプローチ:
      - 入力: アイテムの名前、カテゴリ、属性などの基本的な詳細を含むプロンプトテンプレート $T_{obj}$
      - LLMに入力
      - 出力: 
        - そのアイテムのカテゴリ説明 (アイテムのジャンルを表すキーワードリスト) $D_{cate}^{obj}$
        - そのアイテムを好きになる客観的理由(肯定的な側面を表すキーワードリスト) $D_{pos}^{obj}$
        - そのアイテムを嫌いになる客観的理由(否定的な側面を表すキーワードリスト) $D_{neg}^{obj}$
  - その2: **主観的アイテム説明の生成(Subjective Item Description Collection)**
    - ユーザがアイテムをどのように見るかを理解するために、世論が意思決定プロセスに大きく影響する可能性を考慮して、**そのアイテムに対するコメントを調査して好き嫌いの感情を示すキーワードを見つける。**
    - アプローチ:
      - 入力: アイテムの説明文。ユーザのフィードバック(コメントなど)を含むプロンプトテンプレート $T_{sub}$ 
      - LLMに入力
      - 出力:
        - そのアイテムを好きになる主観的理由(肯定的な側面を表すキーワードリスト) $D_{pos}^{sub}$
        - そのアイテムを嫌いになる主観的理由(否定的な側面を表すキーワードリスト) $D_{neg}^{sub}$
  - 客観的アイテム説明と主観的アイテム説明の統合
    - 客観的および主観的な観点から、好き嫌いを表すキーワードリストが得られたら、それらを統合して包括的なアイテム説明を得る。
    - アプローチ
      - $D_{pos} = D_{pos}^{obj} \cup D_{pos}^{sub}$
      - $D_{neg} = D_{neg}^{obj} \cup D_{neg}^{sub}$
      - その後、キーワードリストをフィルタリングする手順を適用する。
        - 一般的すぎるもの、稀すぎるものを除外。
    - 最終的に以下の3つのテキスト説明文を得る。
      - アイテムのカテゴリ説明 $D_{cate}$
      - アイテムを好きになる理由を示すキーワード集合 $D_{pos}$
      - アイテムを嫌いになる理由を示すキーワード集合 $D_{neg}$
- ユーザの過去の行動と比較して、論理モデル(Logical Model)を構築。
  - 明示的なユーザーインタラクションロジックに従って、推奨された候補アイテムに対するユーザーエンゲージメントをシミュレートする論理モデルを設計。
  - 2種類の論理モデルを提案してる:
    - その1: キーワードマッチングモデル(Keywords Matching Model) $f_{mat}$
      - ユーザの過去の行動履歴 $h$ が与えられたとき、テキストキーワードの直接的なマッチングを使用して、ユーザのエンゲージメント $y_c$ を予測する。
      - アプローチ:
        - 推薦アイテム $i_c$ と同じカテゴリに属する過去のinteractionアイテム集合を抽出。
        - 歴史的に好きなアイテム集合 $I_{pos}$ と嫌いなアイテム集合 $I_{neg}$ を抽出。
        - 推薦候補アイテム $i_c$ へのユーザエンゲージメント $y_c$ を予測するキーワードマッチングモデル $f_{mat}(I_{pos}, I_{neg}, i_{c})$ を実行。
          - $I_{pos}$ 内のアイテムの$D_{pos}$ キーワードと、 $i_c$ の $D_{pos}$ キーワードで、一致するキーワード数 $\alpha_{pos}$ を計算。
          - 同様に、$I_{neg}$ 内のアイテムの $D_{neg}$ キーワードと、 $i_c$ の $D_{neg}$ キーワードで、一致するキーワード数 $\alpha_{neg}$ を計算。
          - $\alpha_{pos} > \alpha_{neg}$ の場合は1、$\alpha_{pos} < \alpha_{neg}$ の場合は0、$\alpha_{pos} = \alpha_{neg}$ の場合はランダムに1または0を返す。
    - その2: 類似度計算モデル(Similarity Calculation Model) $f_{sim}$
      - 
