## refs

- [新卒1年目が挑む！！十数万リクエストに耐える Contextual Bandit を用いたレコメンドシステムの構築 ~ バックエンド編 ~](https://developers.cyberagent.co.jp/blog/archives/57070/)

# どんな話だった??

1. 概要:
  1. Abemaさんでcontexual banditを用いたレコメンドシステムを導入した話 (元はユーザセグメント毎のcontext-free banditを利用してた)
  2. 使い所は、モジュール内のアイテムの並び替え
     1. モジュール = 横カルーセルみたいなイメージ!
     2. アイテム = 各モジュール内に表示されるコンテンツ的なやつ!
2. なんでcontextual banditを採用したの??
   1. hoge
3. どんなシステム設計にしてる??
   1. モデル学習
      1. 毎時のバッチ学習。Vertex AI Pipelinesで実行管理される。
         1. 文面的に、おそらくモジュールごとにバンディットインスタンスを分けてるっぽい...??:thinking:
      2. 報酬データに基づいてcontextual banditのモデルパラメータが更新され、レコメンド用のBigQueryテーブルに書き込まれる。
      3. バッチ学習が完了したら、完了した旨をPub/Subに通知。
   2. モデルパラメータの管理
      1. 前段のPub/Subの通知をトリガーに処理が起動。
      2. BigQueryに保存されたモデルパラメータを推論時に高速に参照できるように、Redis Clusterに転送する。
      3. Redis Clusterを採用した理由。
         1. 高いパフォーマンス: 大量のリクエストに対して低レイテンシを処理できるように、インメモリキャッシュによる高速なデータアクセスが不可欠。
   3. ユーザリクエストを受けての推論
      1. 大量のリクエストに耐えるためにRedis Clusterを採用したが、**更にパフォーマンスを上げるために、サーバー内にもインメモリキャッシュを設置した多段キャッシュ構成**を採用。
         1. ちなみに、インメモリキャッシュのライブラリは、他アルゴリズムと比較してパフォーマンスが高いS3-FIFO アルゴリズム(??)が使用されているかつ TTL(Time To Live) を設定できる maypok86/otter (go用のライブラリらしい!)を採用。
            1. ちなみに「S3-FIFO アルゴリズム」って??
               1. 「キャッシュの中からどれを追い出すか？」を考える“キャッシュイビクション（キャッシュ消去）”のためのアルゴリズムの一つらしい。
               2. S3はSimple, Scalable, Segmented。
               3. FIFOはFirst In First Out。
      2. 流れ:
         1. ユーザリクエストを受け取る。たぶんこの時にユーザの属性情報(=コンテキスト)も一緒に受け取る。
         2. 推論に使いたいモデルパラメータを、まずはサーバー内のインメモリキャッシュから取得しようとする。
         3. サーバー内のインメモリキャッシュにない場合は、Redis Clusterに問い合わせて取得する。
         4. 取得したパラメータを元に推論 (各アイテムの期待報酬の推定値を計算) 
         5. 推論結果を元にアイテムを並び替える。
         6. アイテム集合をモジュール一覧として返す。
