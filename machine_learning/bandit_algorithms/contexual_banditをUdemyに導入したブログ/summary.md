<!-- 仮タイトル: Udemyのユニット推薦にバンディットアルゴリズムを導入するブログを読んだ! -->

## これは何??

- Udemyさんのユニット推薦にMAB(multi-armed bandit)アルゴリズムを導入するテックブログを読んだメモです!

## 導入

- 探索-活用のバランスをとるアプローチが様々なアプリケーションで成功を収めてるため、MAB(multi-armed bandit)アルゴリズムの人気が高まってる。
  - 特に成功してるアプリケーションの一つが、推薦。
- ゼロからMABシステムを本番システムに導入するのって エンジニアリング・運用・データサイエンス全部の観点から大変。
- 今回のテックブログでその実体験をシェアしてる。
  - part1: 理論とデータサイエンス的な話
  - part2: ソフトウェアエンジニアリング的な話

## MABとは?? なぜ推薦にMABを使うのか??

### 問題設定

- MABは、不確実性の元での意思決定問題を解くために使用される **explore-exploitアルゴリズム**の一種。
- explore-exploitアルゴリズムってどんなもの??
  - 例: カジノのスロットマシン。



### 定義

- 標準的なMAB問題の設定は、以下のように定義できる:
  - バンディットは、不確実性の下で意思決定を行うために使用される探索-活用アルゴリズムの一種。これは簡略化された強化学習アルゴリズムとみなせる。
  - $k$ 本のアーム（選択肢）のセット $A = \{a_1, a_2, \ldots, a_k\}$ が与えられた時、目標は、これらのアームをプレイする事で得られる累積報酬を最大化するために、最良のアームを決定すること。
  - アーム $a_i$ が時刻 $t$ にプレイされると、そのアームの報酬確率分布からサンプリングされた報酬 $r_{t}$ が得られる。プレイされていないアームに対しては他の報酬は観察されない。このアーム-報酬ペア $(a_i, r_t)$ を**観察(observation)**と呼んで記録する。

### 推薦にMABを使うこと

- hoge

## MAB導入のデータサイエンス的な話

### ランキング問題をMAB問題として解くこと

- hoge

#### 検討したアプローチ1: Per-Position Framework

- hoge

#### 検討したアプローチ2: Slate Bandit Framework

- hoge

### MAB活用におけるDS的な課題

#### 課題1: 収束の達成とその測定

#### 課題2: 方策のオフライン評価

## MAB導入のソフトウェアエンジニアリング的な話

### システムアーキテクチャの全体像

### MAB導入におけるエンジニアリング的な課題

#### 課題1: リアルタイムシステムを開発することの学習コスト

#### 課題2: リアルタイムシステムの運用の大変さ

## 今後の発展の方向性

### 報酬の強化(報酬関数の定義の見直し、拡張みたいな話!)

### Contextual Bandit
