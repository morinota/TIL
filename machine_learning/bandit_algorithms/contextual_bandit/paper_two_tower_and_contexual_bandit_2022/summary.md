# Two-Stage Neural Contextual Bandits for Personalised News Recommendation

## ニュース推薦の問題設定

- ユーザにパーソナライズされたニュースを逐次的に推薦するニュース推薦システムを考え、全ユーザの累積報酬を最大化することを目指す。
  - 推薦システムはユーザとのインタラクション履歴から学習し、特定のユーザに対して、候補ニュースセットから選択された複数のニュースを表示する。
  - ニュースドメインの特徴
    - 候補ニュースセットの数が膨大で、かつ時間と共に動的に変化する点。
    - 多くのコールドユーザ（すなわち、履歴を持たないユーザ）が存在し、またユーザの興味は時間とともに変化する可能性がある。
- 上述のような推薦戦略を設計する方法は、contexual banditの分野で研究されている**sequential decision-making problem(逐次的な意思決定問題)として定式化**できる
  - ニュース推薦システムはエージェントとみなされる。
  - ニュースアイテムはアーム(選択肢)。
  - ユーザ及び/またはアイテムの埋め込み表現がコンテキストを形成する。
  - 具体的には...
    - 各試行 $t = 1, \ldots, N$ において、ユーザ $u_t$ と候補アームセット $A_t$ が与えられた場合、すべての $i \in A_t$ に対してアイテム埋め込み $x_i \in \mathbb{R}^{d_1}$ を生成し、ユーザ埋め込み $z_{u_t} \in \mathbb{R}^{d_2}$ をコンテキストとして使用する。
      - 以下では、曖昧さがない場合は $u_t$ の下付き文字tを省略する。
    - エージェントは、コンテキストが与えられた場合に、方策(policy) $\pi$ に従って $m \geq 1$ 個のニュースアイテムリスト $S_{rec}$ を推薦する。
    - その後、エージェントはフィードバック $\{y_{t,1}, \ldots, y_{t,m}\}$ を受け取る。
      - ここで、$y_{t,i} \in \{0, 1\}$ はイテレーション $t$ で推薦した アイテム $i$ に対して得られた報酬を示す。
  - 目標は、期待される累積後悔(cumulative regret)（定義1）を最小化するポリシーを設計することであり、これは期待される累積報酬を最大化することと同等**。

## UCB(upper confidence bound, 上限信頼区間)アルゴリズム

- UCBアルゴリズムとは??
  - 探索と活用のトレードオフをうまくバランスするために提案された、古典的なバンディットアルゴリズムの一種。
  - sublinear regret boundを持つことが証明されてるらしい。
    - (「sublinear regret boundを持つ」= ざっくり、ポリシーが長期的にはほぼ最適なポリシーに近づくことを保証する重要な性質らしい...!:thinking:)
- アイデア
  - もっとも高いUCB取得スコア(UCB acquisition score)を持つアームを選択すること。
    - UCB取得スコア = アームの期待報酬の推定値 + その信頼区間の幅

ある試行tにおける、ユーザ-アイテムペア $(u, i)$ に対するUCB取得スコアは以下のように計算される。

$$
\alpha_{UCB}(u, i) := \hat{y}_{u,i} + \beta \sigma_{u,i},
$$

ここで、

- $\hat{y}_{u,i}$: ユーザ $u$ に対してアイテム $i$ を推薦した場合の(即時)報酬の期待値の推定値
- $\sigma_{u,i}$ は、報酬期待値の推定値の信頼区間の幅
- $\beta$ は、活用と探索のバランスを調整するハイパーパラメータ

## LinUCBアルゴリズム

- LinUCBとは?
  - UCBアルゴリズム + 線形モデルを組み合わせたcontextual banditアルゴリズムの一種。
-

## Generalized LinUCBアルゴリズム

- 論文タイトル「Parametric Bandits: The Generalized Linear Case」
- **contextual bandit * UCBアルゴリズムの、GLM(一般化線形モデル)版**って感じのやつ!
  - i.e. つまり、報酬が従う確率分布が正規分布以外の場合(ex. 報酬がbinaryだったり、カウントデータだったり...!)にも、LinUCBのようなアルゴリズムを適用できるように拡張(一般化)したやつ!
- GLB(Generalized Linear Bandit、一般化線形バンディット)
  - LinUCBなどの線形バンディットだと「報酬 = 文脈ベクトルとパラメータの掛け算」だけど、このモデルだと「報酬 = 文脈ベクトルとパラメータの掛け算の結果を、逆リンク関数で変換したもの」としてモデル化する。ここがポイント。
    - ex.)
      - 報酬がbinaryの場合: 逆リンク関数を $\frac{\exp(x)}{1 + \exp(x)}$ として、報酬をモデル化する。
      - 報酬がカウントデータの場合: 逆リンク関数を $\exp(x)$ として、報酬をモデル化する。
- GLM-UCBアルゴリズムの話
  - 流れ!
    - 推定: 過去の観測データからパラメータ $\hat{\theta}$ を計算する。
    - 探索ボーナス(exploration bonus): 見積もりが足りないアームには追加で「ボーナス」をつけて探索を優先する
    - 選択: **「報酬の期待値の推定値 + 探索ボーナス」が一番高いアームを選ぶ**!
  - 特徴
    - 報酬の構造をモデル化するので、無駄に全部のアームを探索しなくて良くなる。
    - 理論的には、GLM-UCBの累積後悔は、「特徴量ベクトルの次元 $d$ 」には依存するけど、「アームの数$K$」には依存しないらしい。

### 探索ボーナス(Exploration Bonus)の算出方法

以下の式で計算される

$$
\beta_{t}[a] = \rho(t) ||m_a||_{M_{t-1}}
$$

ここで

- $\beta_{t}[a]$: アーム $a$ に対する探索ボーナス (タイムステップtによってデータの溜まり度合いが変わり、変化していくはず)
- $\rho(t)$: タイムステップ $t$ に基づく、探索ボーナスのスケーリング係数
- $||m_a||_{M_{t-1}}$: アーム $a$ の特徴量ベクトル $m_a$ に基づいた、「**重み付きノルム**」
  
重みつきノルムは、以下のように計算される:

$$
||m_a||_{M_{t-1}} = \sqrt{m_a^T M_{t-1}^{-1} m_a}
$$

ここで、

- $m_a$: アーム $a$ の特徴量ベクトル (特徴量の次元数 $d$)
- $M_{t-1}$: タイムステップ $t-1$ までに得られた特徴量ベクトルの「設計行列」(design matrix)。($d \times d$ の行列)
- $M_{t-1}^{-1}$: 設計行列の逆行列

設計行列は以下のように計算される。
タイムステップ $t-1$ までに収集されたデータを要約する行列。**設計行列は、これまでのタイムステップで選ばれた全てのアームの特徴量ベクトルの外積和を取る**ことで計算される。

$$
M_{t-1} = \sum_{l=1}^{t-1} m_{A_k} m_{A_k}^T
$$

ここで、

- $m_{A_k}$: タイムステップ $k$ で選択されたアーム $A_k$ の特徴量ベクトル(次元数 $d$)
- $m_{A_k}^T$: $m_{A_k}$ の転置行列 (列ベクトルを転置してるので、行ベクトルになる)
- $m_{A_k} m_{A_k}^T$: ベクトル $m_{A_k}$ の外積 ($d \times d$ の行列になる)
  - (内積だと掛け算の順番が逆...!:thinking_face:)
  - 対称行列であることに注意!
  - 行列の要素は、特徴量ベクトルの成分の積で構成される。

これを踏まえて「重みつきノルム」$||m_a||_{M_{t-1}} = \sqrt{m_a^T M_{t-1}^{-1} m_a}$ のざっくりとした意味合いは...

- 設計行列の逆行列 $M_{t-1}^{-1}$ を使って、**特徴量ベクトル $m_a$ が設計行列上でどれだけ「重要」か**をはかる
- 大まかなイメージ:
  - $m_a$ が設計行列 $M_{t-1}$ によってよくカバーされている(i.e. 情報が十分に集まっている)なら、ノルム $||m_a||_{M_{t-1}}$ は小さくなる
  - 逆に、情報が少ないアームの $m_a$ は、この値が大きくなり、探索ボーナスが増えるという仕組み。

## Two-Stage Neural Contextual Bandits

- 本論文の提案手法
  - GLM-UCBアルゴリズムをベースに、ニューラルネットワークを組み合わせた、Two-Stage Neural Contextual Banditsアルゴリズムを提案。
  - 具体的には、2種類のアルゴリズムを提案:
    - （**どちらも、パラメータがすべてのユーザおよび（または）ニュースアイテムのペアによって共有されるshared bandits modelsである点に注意**）
    - S-N-GALM-UCB(Shared Neural Generalized Additive Linear Model UCB)
      - 一般化加法線形モデル。
    - S-N-GBLM-UCB(Shared Neural Generalized Bilinear UCB)
      - 一般化バイリニアモデル。

### 一般化加法線形モデルについて

特徴: アイテム関連のパラメータとユーザ関連のパラメータを別々にモデル化する。

この場合、あるタイムステップにおいて、ユーザ-アイテムペア $(u, i)$ に対する報酬の期待値は以下のようにモデル化される。

$$
E[y_{u,i}|x_i, z_u] = \rho(\gamma x_i^T \theta_x^{*} + \tilde{\gamma} \theta_z^{*T} z_u)
$$

ここで

- $x_i$: アイテム $i$ の特徴量ベクトル
- $z_u$: ユーザ $u$ の特徴量ベクトル
- $\theta_x^{*}$: アイテム関連のパラメータ
- $\theta_z^{*}$: ユーザ関連のパラメータ
- $\gamma$: ハイパーパラメータ。アイテム関連のパラメータの重要度を調整する。
  - $\tilde{\gamma}$ = 1 - $\gamma$になる。
- $\rho$: 逆リンク関数。報酬が従う確率分布によって決める。（ex. シグモイド関数とか）

また、この場合の探索ボーナスは以下のように計算される。

$$
\beta * (\gamma||x_i||_{M_{i, t-1}^{-1}} + \tilde{\gamma}||z_u||_{M_{u, t-1}^{-1}})
$$

ここで、

- $\beta$: スケーリング係数というハイパーパラメータ。探索ボーナスをどれだけ効かせるかを調整する。
- $||x_i||_{M_{i, t-1}}$: アイテム $i$ の特徴量ベクトル $x_i$ の重みつきノルム
- $||z_u||_{M_{u, t-1}}$: ユーザ $u$ の特徴量ベクトル $z_u$ の重みつきノルム
- $M_{i, t-1}$: アイテム $i$ に関する設計行列。
  - (なお論文中では、設計行列に正則化項として、単位行列 $I_{d}$ を加えてる)
- $M_{u, t-1}$: ユーザ $u$ に関する設計行列。
  - (なお論文中では、設計行列に正則化項として、単位行列 $I_{d}$ を加えてる)

このように、ユーザとアイテムの不確実性を別々に扱う点が加法モデルの特徴。

#### (疑問) 設計行列の作り方が、GLM-UCBと異なる気がする...?? -> いや、多分一緒だった! 数式の表記の仕方が異なるだけで...!!:thinking_face:

- GLM-UCBの場合の設計行列の定義式は、$M_{t-1} = \sum_{l=1}^{t-1} m_{A_k} m_{A_k}^T$ で sum を取っていた。
- 一方、今回の論文の場合は、行列積の表記をとってる $M_{i, t-1} = D_{i, t-1}^T D_{i, t-1}$ としてる。
  - $D_{i, t-1} \in \mathbb{R}^{t \times d}$ であり、行列の各行に、ユーザ $u$ に対してタイムステップ $t$ までに選ばれたアイテム特徴量ベクトル $x_i$ が含まれる。
  - ユーザ用の設計行列の場合も同様に、$D_{u, t-1} \in \mathbb{R}^{t \times d}$ であり、行列の各行に、アイテム $i$ に対してタイムステップ $t$ までに選ばれたユーザ特徴量ベクトル $z_u$ が含まれる。
- **あれ？？っていうか、アイテム特徴量の設計行列はユーザごとに作られてるし、ユーザ特徴量の設計行列もアイテムごとに作られてるっぽい...?? 管理大変すぎない??** 計算量も多くなりそうだし...!!:thinking_face:

### 一般化バイリニアモデルについて

この場合の報酬の期待値は以下のようにモデル化される。

$$
E[y_{u,i}|x_i, z_u] = \rho(x_i^T \theta_x^{*} z_u)
$$

この場合の探索ボーナスは以下のように計算される。

$$
\beta * || vec(x_i z_u^T) ||_{M_{t-1}^{-1}}
$$

ここで、

- $vec(x_i z_u^T)$: アイテム特徴量ベクトル $x_i$ とユーザ特徴量ベクトル $z_u$ の外積として得られた行列を、一次元ベクトルに変換したもの。
  - ベクトルの長さは d_i * d_u になるはず。長くない??:thinking_face:
- $M_{t-1}$: 設計行列。
  - $M_{t-1} = \sum_{l=1}^{t-1} vec(x_i z_u^T) vec(x_i z_u^T)^T$ で計算される。
  - $vec(x_i z_u^T)$ を特徴量ベクトルと見做した場合の設計行列の定義式...!:thinking_face:
- 信頼区間を計算することは、潜在的に大きな設計行列の逆行列を計算する必要があるため、計算コストが高くなる可能性がある。
  - これめっちゃ弱点じゃない?? **計算量がかなり多くなりそうで実用的じゃなくない??**:thinking_face:

なんかこの弱点を踏まえると、無理にcontextual banditとtwo-tower NNを組み合わせるメリットがあんまりない気がしてきた。結局two-towerで作ったアイテム表現とユーザ表現を、contextual banditのための特徴量として使う、くらいのアプローチの方がシンプルで実用的なのかも...??:thinking_face:
