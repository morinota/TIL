---
marp: true
theme: default
paginate: true
---

# あれ、この問題設定って意思決定最適化タスクか? → 「バンディットアルゴリズム」は

---

## これは何？

- **Multi-Armed Bandit（MAB）**の基礎概念の解説
- UdemyでのMAB導入事例をベースとした説明
- 推薦システムでなぜMABが有効なのかを理解する

---

## MABの問題設定：カジノのスロットマシン

![bg right:40% 80%](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QtG3PRxhrP-BkB6bO6aVgw.png)

- カジノに複数のスロットマシンがある
- 各マシンは異なる報酬確率分布を持つ
- **目標**：限られた試行回数で累積報酬を最大化
- **問題**：どのマシンが最も良いか事前に分からない

---

## 探索-活用のジレンマ

### 探索（Exploration）
- 各アームの報酬分布を学習
- 新しい情報を得られる
- **短期的には最適でない選択**

### 活用（Exploitation）  
- 現在の知識で最良のアームを選択
- **短期的に最も良いと思われる選択**

### ジレンマ
両方をバランス良く行う必要がある！

---

## MABの定式化

- **$k$ 本のアーム**：$A = \{a_1, a_2, \ldots, a_k\}$
- **目標**：累積報酬の最大化
- **観測**：アーム $a_i$ を時刻 $t$ にプレイ → 報酬 $r_t$ を獲得
- **戦略**：時刻 $t-1$ までの観測履歴から、時刻 $t$ の最適なアーム選択

**重要**：プレイしていないアームの報酬は観測できない

---

## なぜ推薦システムでMABが有効？

### 推薦問題 → MAB問題への対応

- **候補アイテム集合** → **アームの集合**
- **アイテムの表示** → **アームをプレイする**
- **ユーザフィードバック** → **報酬の観測**
  （クリック、いいね、購入など）

---

## MABが推薦に適している3つの理由

### 1. **機会コスト**の存在
- より良いアイテムを推薦できた可能性
- MABは累積regret（後悔）を最小化

### 2. **フィードバックループバイアス**の解消
- 人気アイテムばかり推薦される悪循環を断ち切る
- 探索により新しいアイテムにも機会を与える

### 3. **コールドスタート問題**への対処
- 新しいアイテムも自然に探索対象となる
- 全候補に公平な機会を提供

---

## Single-Play vs Multi-Play MAB

### Single-Play MAB
- 一度に1つのアームを選択
- 例：バナー最適化、サムネイル最適化

### Multi-Play MAB（ランキング問題）
- **複数のアームを同時に選択**
- 例：推薦ランキング、複数アイテム表示
- **複数のポジションを考慮する必要**

---

## Udemyでの応用：推薦ユニットランキング

### 問題設定
1. **各推薦ユニット**（横カルーセル）= **アーム**
2. **固定時間の表示**（15分）= **アームをプレイ**
3. **クリック・登録**の組み合わせ = **報酬**

### 目標
ユーザのホームページでの推薦ユニットの最適な順序決定

---

## ランキング問題のフレームワーク選択

### Per-Position Framework
- 各ポジション専用のMABインスタンス
- **利点**：詳細な最適化
- **欠点**：複雑性、データ分散

### Slate Bandit Framework ✅
- 単一MABで上位k位置を同時最適化
- **利点**：シンプル、データ効率
- **欠点**：粒度の低下

**Udemy選択**: Slate Bandit Framework（k=3）

---

## MAB戦略の例

### 代表的なアルゴリズム
- **ε-greedy**：固定確率で探索
- **UCB (Upper Confidence Bound)**：信頼区間ベース
- **Thompson Sampling** ✅：ベイズ的アプローチ

**Udemyでの選択**: Thompson Sampling

---

## 収束の重要性

### 収束とは？
- 最適なアームへの集約
- 探索の減少、活用の増加

### 収束に影響する要因
1. **アーム数**：多いほど時間がかかる
2. **報酬差**：小さいほど区別困難  
3. **フィードバック量**：多いほど早い
4. **戦略選択**：アルゴリズムによる違い

---

## まとめ

### MABの特徴
- **探索-活用のバランス**で最適化
- **リアルタイム学習**による継続的改善
- **推薦システムとの相性が抜群**

### 推薦での価値
- フィードバックループバイアス解消
- コールドスタート問題対応  
- 機会コスト最小化

**MABは推薦システム最適化の強力なツール！**
