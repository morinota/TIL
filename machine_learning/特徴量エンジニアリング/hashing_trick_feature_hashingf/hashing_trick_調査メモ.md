## これは何??

- 特徴量エンジニアリングの一種であるHashing Trick(Feature Hashing)について調べたメモ。

## refs:

- 日本語記事: [ロジスティック回帰に対するFeature Hashingの影響](https://qiita.com/tyoshitake/items/0b18f02a85db45b455cf)
  - **one-hotエンコーディングした137次元の特徴量ベクトルを、Hashing Trickで40~130次元に圧縮しても精度低下は(0.835 - (0.82~0.83)) = 0.005程度に抑えられる**、という実験結果。同記事では、「次元を1/3程度に圧縮しても精度がそこまで落ちないなら、計算コスト次第では有効な手段になり得る」と明言しており、カテゴリ数が数百~数千になると有効性が更に高まるとコメントしてる。
- Booking.com データサイエンス組織のテックブログ: [Don’t be tricked by the Hashing Trick](https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087)
- [機械学習処理におけるカテゴリ変数の扱い方(Feature hashingについて)](https://developers.microad.co.jp/entry/2018/12/07/184133#Feature-hashing%E3%81%A8%E3%81%AF)

## Hashing Trick(Feature Hashing)とは? 最初にざっくりメモ:

- **巨大なカテゴリ特徴量を、さくっと低次元ベクトルに押し込むための手法**。
  - 目的が共通する手法として、one-hotエンコーディング, multi-hotエンコーディング, entity embeddingなどがある。
- 特徴量をハッシュ関数に通して、その値をベクトルのインデックスとして使う。

## Hashing Trickの仕組み

例えば、以下のようなカテゴリ特徴量があったとする。

```
特徴量名 | 職種 | 趣味
社員A | 営業 | 釣り
社員B | デザイナー | サッカー
社員C | エンジニア | 盆栽
```

one-hotエンコーディングを使うと、以下のように変換される。

```
# 右から順に、"職種__営業", "職種__デザイナー", "職種__エンジニア", "趣味__釣り", "趣味__サッカー", "趣味__盆栽"の順番
社員A = [1, 0, 0, 1, 0, 0] 
社員B = [0, 1, 0, 0, 1, 0]
社員C = [0, 0, 1, 0, 0, 1]
```

Feature Hashingの場合は、ハッシュ関数を用いてカテゴリ変数データを指定した次元のベクトルに圧縮する。
例えば、社員Aのデータを `{"職種": "営業", "趣味": "釣り"}`と表現する。

1. まず圧縮後のベクトルの次元数を指定する。ここでは4次元ベクトルに圧縮するとする。
2. 次に、各カテゴリ特徴量をハッシュ関数に通して、バケットのインデックスを決定する。
   - 例えば、ハッシュ関数 `h(x) = (hash(x) mod 4)` を使うとする。
   - "職種__営業"をハッシュ関数に通すと、`h("職種__営業") = 2` となる。
   - "趣味__釣り"をハッシュ関数に通すと、`h("趣味__釣り") = 0` となる。
3. もう一つハッシュ関数を用意して、符号(+1/-1)を決定する。(衝突時のバイアスを減らすため)
   - 例えば、`g(x) = if (hash(x) mod 2 == 0) then +1 else -1` とする。
   - "職種__営業"を符号ハッシュ関数に通すと、`g("職種__営業") = +1` となる。
   - "趣味__釣り"を符号ハッシュ関数に通すと、`g("趣味__釣り") = -1` となる。
4. 最後に、圧縮後のベクトルを生成する。
   - "職種__営業"はインデックス2に+1 × 符号(+1) = 1を指定。
   - "趣味__釣り"はインデックス0に+1 × 符号(-1) = -1を指定。
   - したがって、社員Aの圧縮後ベクトルは `[-1, 0, 1, 0]` となる。

## feature hashingのバリエーション

- 符号ハッシュを使うか否かで、以下の2種類に分類できる。
  - Shi et al.(2009)の方法:
    - 値をunsignd sumする。**つまり符号ハッシュを使わず、単純にインデックスに1を足し合わせる。**
  - Weinberger et al.(2009)の方法:
    - 符号ハッシュも使って、値をsigned sumする。(+1/-1を掛けて足し合わせる)
    - **こっちがデファクトスタンダードらしい。`sklearn.FeatureHasher`もこちらの方法を採用してるみたい。**

- また、**複数のカテゴリ特徴量を扱う際のハッシュ空間の構成方法**によって、以下の2種類に分類できる。
  - **global hashing space**: 
    - 全ての特徴量で、同一のハッシュ空間を利用する方法。指定するパラメータがhashing spaceの次元数1つだけで済むため、**実装がシンプル**。
  - **per-field hashing space**: 
    - 各特徴量ごとにhashing spaceを構成する方法。
    - 特徴量ごとに異なるハッシュ空間を利用するため、国やドメインといった異なる特徴量のhash衝突は明確に避けられる。
