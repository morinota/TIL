# はじめに

多くの推薦システムでは、人気のアイテムは頻繁に推薦され、人気のないニッチなアイテムはほとんどor全く推薦されないという、Popularity Bias(人気度バイアス)に悩まされています.

こうしたニッチなアイテム(論文中では"Long tail"にあるアイテム)は一部のユーザにとっては好ましいアイテムである一方で、推薦されづらい事からユーザに発見されづらい為、推薦システムにおいて重要な問題です.

いわゆるSerendipity(= like + didn't expect)的な観点から見ると、まさに推薦システムの力でユーザに届けてあげたいですよね.

この論文では、推薦システムの出力に後処理ステップを追加する事で、許容できる範囲の推薦精度を維持しながらも推薦におけるニッチなアイテムの表現力を高めるアプローチを提案しています.

このアプローチの良い所は、"後処理"的なアプローチである事から推薦結果を生み出すアルゴリズムの種類に依らずに適用可能なところみたいです...!

## Popularity Biasとは

一般的に協調フィルタリングによる推薦システムでは、少数のユーザグループにしか人気がないかもしれない"Long tail"なアイテムと比べて、人気のあるアイテム(i.e. より多くのfeed backを得ているアイテム)を高くスコアリングしやすいです.

もちろん人気のあるアイテムは良い推薦であることが多いのですが、すでに有名である可能性も高いです.
なので、人気のあるアイテムだけを推薦することは、**新しいアイテムの発見を促進せず、ニッチな嗜好を持つユーザーの興味を無視する**ことになります.

また、ユーザに対して人気アイテムだけを推薦していると、ニッチなアイテムの情報がユーザに届く機会が減り、アイテムの製作者にとって不公平になる可能性もあります.

## short head, long tail, distant tail

![Figure 1: The long-tail of item popularity. ](https://d3i71xaburhd42.cloudfront.net/6d77d7467f993780d02f3d8ea563959643d48f89/1-Figure1-1.png)

図1は、推薦システムにおけるlong tail現象を説明する為の図で、y軸はアイテム毎の評価数(feedback数, reaction数)、x軸は各アイテムのランク(まあ評価数の降順でソートしてるイメージかな?)を示しています.

左から一本目の縦線は、人気順で上位20%のアイテムを分けており、左側(図1の分布三分割における左パート)のアイテム達は、右側の80% tailのアイテムよりも合計で多くの評価(feedback, reaction)を受けています.
こういった人気アイテムを"**short head**"なアイテムと呼び、多くのユーザの注目を集める非常に人気の高いアイテムです.

左から2本目の縦線は、分布のtailを2つに分けています.
縦線の左側(図1の分布三分割における中央パート)を "**long tail**"と呼びます. これらのlong tailなアイテム達は、多くのアルゴリズムが推薦リストに含めないにも関わらず、協調的な推薦が可能なアイテム達です

一方で、左から2本目の縦線の右側(図1の分布三分割における右パート)のアイテム達を"**distant tail**"なアイテムと呼びます.
distant tailなアイテム達は、受け取る評価(reaction, feedback)数が非常に少なく、ユーザ間の比較が困難なアイテム達です.
もちろん質が低くユーザに好まれないアイテムもありますが、まだ追加されたばかり**新規アイテムもdistant tailに含まれ**ます.
このようなcold-startなアイテムに対応する為には、コンテンツベースやハイブリッド型の推薦アルゴリズムを採用する必要があります.

本論文では、協調フィルタリング推薦に関する研究である為、long tailアイテム達に注目しています.

## 関連研究

long-tailの領域からserendipity(=like + didn't expect)を満たすアイテムを推薦する事は、一般に推薦システムの重要な役割であると考えられています.

[Erik Brynjolfsson, Yu Jeffrey Hu, and Michael D Smith. 2006. From niches to riches: Anatomy of the long tail. Sloan Management Review (2006)]()では、Amazonの書籍売上の30-40%は、通常実店舗で見つけられないようなアイテムで湿られている事を示しました.

long-tailなアイテム達は、ユーザの嗜好をより深く理解する為にも重要です.
というのも、ユーザの嗜好の特徴を探索する場合、一般的により多くのlong-tailアイテム達を提示する必要があります. (人気で偏ったアイテムばかりをユーザ達に見せていては、各ユーザの多様な嗜好の特徴を十分に得られないですもんね...)

最後に、long-tailアイテムを推薦する事は、社会的な市場の機会公平性にとっても重要です.
Popularity Biasに苦しむ市場は、より無名なアイテムを発見する機会に欠け、定義上、少数の大きなブランドや有名なアーティスト達に支配される事になります.
このような市場は同質性が高く、革新性や創造性を発揮する機会が少なくなります. ユーザ目線でも、**ユーザが多様な情報・商品・コンテンツ、ひいては多様な意見や視点と出会う機会**が少なくなりますよね...!

人気アイテム分布のlong-tailという考え方と、それが推薦システムの品質に与える影響については、いくつかの研究者によって検討されてきており、主に評価行列の因子分解の学習プロセスにおいてlong-tailを考慮するアプローチをとっているっぽい?(正則化する方法が一般的っぽい!)

一方で本論文のアプローチでは、推薦結果に対して後処理を行うので、任意のアルゴリズムの出力に適用可能.

また、本論文のアプローチでは、「人気(short-head)アイテムだけに興味を持つユーザ(i.e. いわゆる"ミーハー"みたいな存在...??)が存在する可能性」を考慮し、long-tail promotionのパーソナライズも検討しています.

そして最後にrecommendation diversityの観点から、本論文のアプローチは「アイテムの絶対的な特性ではなく相対的な人気度合いに依存して多様化を試みる」という点で、過去の多様化アプローチと異なっている、との事.

# 手法

## xQuADでPopularity Biasを制御する

出力結果の多様化は主に情報検索の文脈で研究されており、特にウェブ検索エンジンでは、**クエリのアスペクト**を完全にカバーする文書のランキングを一緒に見つけるという類似の目標があるそう.
ここでいう"クエリのアスペクト"とは、複数の意味を持つ単語やフレーズに対して、それぞれの意味を指し示すものです. (~~検索クエリを指定した背景の思考みたいな...??~~, 違いました).
例えば、検索クエリに「アップル」という単語が含まれている場合、「アップル」は果物「りんご」としての意味だけでなく、「Apple」という企業や、「iPad」などの製品の意味も持ちます.

**xQuAD(EXplicit Query Aspect Diversification)**という手法は、検索クエリに対して、それぞれの意味を持つアスペクトを抽出し、それぞれのアスペクトに対して検索を実行することで、検索結果の多様性を向上させる事を試みています.
与えられた文書が、カバーされていないアスペクトをどの程度満たしているかを推定することにより、アイテムが反復的に選択される.

(この時点ではなんのこっちゃよくわかりません...)

この手法を応用することで、**long-tailアイテムに対するユーザーの関心の違いを認識**することを目指します.
推薦リストにおいて、人気度の異なるアイテムの多様性を**一律に高めること**は、一部のユーザにとってうまく機能しない可能性があります.
本論文では、人気度の低いグループに属するアイテム（すなわち、**long-tailアイテム）にパーソナライズド・ボーナスを追加**する変形を提案しています.
パーソナライズされた係数は、各ユーザのlong-tailアイテムに対する過去の興味に基づいて決定されます.

## xQuADモデルの構築

推薦アルゴリズムにおけるPopularity Biasを制御するために、xQuADモデルを構築します.
何らかのベース推薦アルゴリズムによって、あるユーザー$u$に対してランク付けされた推薦リスト$R$が既に生成されていると仮定します.
修正されたxQuADモデルのタスクは、**正確でありながら人気の偏りを管理する新しい再順位付けリスト** $S$（$|S| < |R|$）を生成することです.

新しい推薦リストは、以下の基準に従って繰り返し構築されます.

$$
score = P(v|u) + \lambda P(v, S'|u) \tag{1}
$$

ここで、

- 第一項 $P(v|u)$:
  - ベース推薦アルゴリズムによって予測された値.
  - ユーザ$u \in U$が、$V$内のアイテム$v $に興味を持つ尤度.
    - (尤もらしさの尺度. スコアの大きさのスケールは各推薦手法に依存するだろうが、同じ推薦手法によるスコア間では、大きい程、uのvに対する嗜好度は高い.)
    - 尤度: P(v)の確率分布のパラメータがuの時の、確率P(v)の値??
  - RやSとは独立.
  - 一般に、この値が高い順の上位n件が推薦リスト$R$に追加されているはず.
- 第二項 $P(v, S'|u)$:
  - ユーザー$u$が、現在の$S$にないアイテム$v$に興味を持つ尤度.
  - $S'$は$S$の排反を意味する.
  - つまり**uがvを好む & 且つvがSに含まれていない事の同時確率**みたいなイメージ??
- 直感的には、第1項はランキング精度を、第2項は2つの異なるカテゴリのアイテム（すなわち、short-tailとlong-tail）間の多様性を促進します.
- $\lambda$:
  - 一般にPopularity Biasをどの程度強く制御するかをコントロールするパラメータ.
  - 大きく指定する程、long-tail多様性を考慮した推薦結果になる.

式1のもとで**最も高いスコアを得たアイテムが出力リストSに追加**され、Sが所望の長さになるまでこの処理が繰り返されます.

short-headとlong-tailの両方のアイテムを含む、より多様な推薦を実現するために、long-tail($Gamma$)とshort-head($Gamma'$)の両方のアイテムカテゴリに対する周辺尤度$P(v, S′|u)$(式1の第二項)を以下のように計算します.

$$
P(v, S'|u) = \sum_{d \in {\Gamma, \Gamma'}} P(v, S'|d) P(d|u)
\tag{2}
$$

(ここで、$d$: $\Gamma$ or $\Gamma'$...??, $v \in d$という条件でのP(v,S'))

[18]のアプローチに従い、残り(?)のアイテムは$S$の現在の内容から独立しており、short-headとlong-tailのカテゴリが与えられているアイテムは互いに独立していると仮定します.(i.e. $\Gamma$と$\Gamma'$は重複していない!!)
これらの仮定の下で、式.2の$P(v, S′|d)$を次のように計算することができます.

$$
P(v, S'|d) = P(v|d) P(S'|d) \\
(\text{vとS'が独立なので、同時確率を確率の積に分解できる.})
\\
= P(v|d) \Pi_{i \in S} (1 - P(i|d, S))
\tag{3}
\\
(\text{??})
$$

式(3)に式(2)を代入, 更にそれを式(1)により以下の式が得られます.

$$
score = (1 - \lambda)P(v|u)+\lambda \sum_{c \in {\Gamma, \Gamma'}} P(c|u) P(v|c) \Pi_{i \in S} (1 - P(i|c, S)) \\
\tag{4}
$$

ここで$P(v|d)$は、$v \in d$の場合は1, そうでない場合は0.

$P(i|d, S)$の算出方法に関しては、2つの異なるアルゴリズムを作成する事で、2つの異なる方法で算出可能です.
最初の方法は$P(v|d)$と同じ様な関数で、**リストSのアイテムiが既にカテゴリdをカバーしているとき1**に等しく、それ以外は0となる指標関数(indicator function)を使用する方法です.
この方法は**バイナリxQuAD**と呼ばれ、オリジナルのxQuADはこの方法で導入されています.

本論文で紹介するもう一つの方法は、リスト$S$中のアイテム達がカテゴリ$d$(long-tail or short-head)を**カバーしている比率**を求める方法です.

尤度 $P(d|u)$ は、**異なるアイテム・カテゴリに対するユーザーの嗜好を表す尺度**です.
言い換えれば、各ユーザーが、long-tailアイテム達 vs short-headアイテム達のどちらにより興味があるかを定量化するものです.
我々はこの尤度を、ユーザープロファイルの中でカテゴリ$d$に属するアイテムの比率で計算します.

次に$S$に追加するアイテムを選択するために、式4に従って$R$と$S$の各アイテムについて再ランク付けスコアを計算します.
あるアイテム$v′ \in d$に対して、$S$が$d$をカバーしていない場合、推定ユーザー嗜好度$P(v′|u)$に正の項が追加されることになります.
(S内のアイテムが全てshort-headのアイテム達のケース -> Sがlong-headをカバーしていない状況 -> long-head内のアイテムv'のスコアをかさ増しする!みたいな！)
(基本的には、$S$にlong-tailとshort-head両方のアイテム達が含まれやすくなるって事??)
したがって、選択される確率が大きくなり、精度と人気度バイアスのバランスをとることができます.

バイナリxQuADの場合は、繰り返し掛け算の項 $\Pi_{i\in S}(1 - P(i|c,S))$ の値は、$S$に含まれる現在のアイテムがまだカテゴリ$d$を全くカバーしていない場合(i.e. S内のアイテムs達が全て $s \in d'$のケース)のみ、1になります.

したがって、バイナリxQuADは、**最も良いlong-tailアイテムを一つ含む**ことによってベースリストの最小限の再順位を最適化するが、それ以上の多様性は求めません.
(ん??一つしか含まれないの...??)

# 実験

## 使用データ、short-headとlong-tailの分割.

論文では，提案アルゴリズムを2つの公開データセットでテストしています.

- Movielens 1Mデータセット:
  - 6,040人のMovieLensユーザによる約3,900本の映画に対する1,000,209件の匿名の評価.
  - 各ユーザは最低20の評価値を持っている
- Epinionsデータセット:ユーザがアイテムをレビューできる消費者意見サイトから収集されたもの.
  - 1つのアイテムしか評価していないユーザが多数存在する.

[2]のデータ削減手順(???)に従って、**長いプロフィールを持つユーザはlong-tailのアイテムを持つ可能性が非常に高い**(??)ため、20未満の評価を持つユーザをEpinionデータセットから削除しました.
(これはReference[2]を読まないとわからなそう.)

short headアイテムが評価の80%に、long-tailアイテムが評価の残りの20%に対応するように、両データセットのアイテムをlong-tail($\Gamma$)とshort-head($\Gamma'$)に分割しています.
MovieLensでは、短頭項目は506件以上の評価を持つアイテム.
Epinionsでは、ショートヘッドのアイテムは73件以上の評価を持つアイテム.

## 4つの推薦手法で比較する

実験では以下の4種類の推薦手法を用いて、全ユーザそれぞれに対して4種類の推薦アイテムリストを作成しています.

- RankALS: ベースラインとなる推薦アルゴリズム.
- LT-Reg(regularized long-tail diversification algorithm):
- Binary xQuAD: 本論文で提案されたアプローチの1つ.
- Smooth xQuAD: 本論文で提案されたアプローチの1つ.

## 評価方法

Popularity Biasを緩和するアルゴリズムの有効性を評価するために、4つの異なるmetricsを使用しています.

### Average Recommendation Popularity (ARP): 平均レコメンデーション人気度（ARP）

この[22]の指標は、各推薦リスト内のアイテムの**平均人気度**を計算します.
推薦リスト内の任意のアイテムについて、人気度の代理指標として、それらのアイテムの**平均評価数**を測定します:

$$
ARP = \frac{1}{|U_t|} \sum_{u \in U_t} \frac{\sum_{i \in L_u} \phi(i)}{|L_u|}
\tag{5}
$$

ここで、$\phi(i)$はトレーニングセットでアイテムiが評価された回数である。
$L_u$ はユーザ u の推薦アイテムリスト、$|U_t|$ はテストセットにおける全ユーザ数である。全ユーザの推薦アイテムリストで平均を取っている.

### Average Percentage of Long Tail Items (APLT): 平均ロングテールアイテム比率（APLT）.

[2]で使用されているように、この指標は推奨リストにおけるlong-tailアイテムの平均的な割合を測定し、次のように定義されています。

$$
APLT = \frac{1}{|U_t|}\sum_{u \in U_t} \frac{|{i,i \in (L_u \cap \Gamma)}|}{|L_u|}
\tag{6}
$$

この指標は、全ユーザーの推薦リストにおいて、long-tail集合に属するアイテムの平均的な割合を示しています。

### Average Coverage of Long Tail items (ACLT): ロングテールアイテムの平均カバー率（ACLT）

long-tailアイテム達が**推薦全体の中でどの程度露出するか**を評価する別の指標です. (意味合いとしてはAPLTも同じ??)

APLT の問題点の一つは、全ユーザが同じLong-tailアイテムセットを推薦されたとしても、それが高くなる可能性があることです。(ex. 1種類のlong-tailアイテムを全ユーザに推薦しても、複数のlong-tailアイテムを1ユーザ一つずつ推薦したとしても値が等しくなってしまう.)

それに対して、ACLT は推薦システムがlong-tailアイテム達の何割をカバーしたかを測定します.

$$
ACLT = \frac{1}{|U_t|} \sum_{u \in U_t} \sum_{i \in L_u} \mathbb{1}(i \in \Gamma)
\tag{7}
$$

ここで、$mathbb{1}(i \in \Gamma)$ は指標関数(indicator function)であり、$i \in \Gamma$にあるとき 1 になり、その他のケースでは0になります.

この関数は[4]のAggregate Diversity metricと関連しているが、アイテムカタログのロングテール部分のみを見るものです.(Reference[4]を読んでいないので、なんのこっちゃ状態.)

前述のlong-tail多様性指標に加えて、多様性と精度のトレードオフを検証するために、ランキング・アルゴリズムの精度も評価しました.
具体的には,ランキング精度の標準的なNDCG（Normalized Discounted cumulative Gain）指標を使用しています.

## 結果

図 2 は，Epinions データセットに対して，様々な λ の値を使用した結果を示している（LT-Reg アルゴリズムは，パラメータ λ を使用して，ロングテール正則化項の重みを制御していることに注意).

![Figure 2: Results for the Epinions dataset ](https://d3i71xaburhd42.cloudfront.net/6d77d7467f993780d02f3d8ea563959643d48f89/4-Figure2-1.png)

すべての結果は、訓練とテストのそれぞれで%80 -%20 の分割を使用しており、5回のクロスバリデーションからの平均値です.

予想通り、すべてのアルゴリズムで多様性スコアが向上しているが、ランキングの精度は若干低下しています.
しかし、アルゴリズム間の差は明らか.

露出度指標（ACLT）プロットは、2つの再ランキングアルゴリズム、特にSmoothバージョンは、正則化手法よりもlong-tail在庫全体のアイテムを露出させるのに非常に良い仕事をしていることを示しています.

ランキング精度を見ると、予想通り、ランク付けされたリストに対して**最小限の調整を行うバイナリ版の方がわずかに優れている**ことがわかります.

LT-Regはリスト単位のAPLTでもカタログ単位のACLTでも、long-tailアイテムを促進する効果はそれほど高くはない.

同じ結果を別の角度から見たのが図3です.

![Figure 3: Comparison of popularity bias control for different algorithms at different levels of NDCG loss (Epinions) ](https://d3i71xaburhd42.cloudfront.net/6d77d7467f993780d02f3d8ea563959643d48f89/4-Figure3-1.png)

ここでは、NDCG損失に対するロングテールの多様性メトリクスを見て、図2に見られるパターンを明確にしています.

BinaryとSmoothアルゴリズムは**多様性と精度のトレードオフ**の点でかなり似ていることがわかりますが、LT-Regはランキング精度の損失が大きくなると明らかに低く、平坦な改善曲線を描くことがわかります.(精度が下がっても、多様性も向上しない.)

RPメトリックは唯一、特にNDCGロスの値が低い場合に、3つの"long-tail多様性を考慮したのアルゴリズム"のmetricがかなり類似しています.

### Movie lens データ

MovieLensデータセットでは、図4に見られるように、アルゴリズム間で相対的な性能の違いが見られます.

![Figure 4: Results for the MovieLens dataset](https://d3i71xaburhd42.cloudfront.net/6d77d7467f993780d02f3d8ea563959643d48f89/5-Figure4-1.png)

Smooth re-ranking法は、long-tail多様性においてより明確な利益を示し、LT-RegはARP@10においてはより効果的です.

この発見は、図5の相対的な結果でも確認されました.
また、他のmetricsでは差があるにもかかわらず、ARPではアルゴリズムが非常に似た値を示していることがわかります.

![Figure 5: Comparison of popularity bias control for different algorithms at different levels of NDCG loss (MovieLens)](https://d3i71xaburhd42.cloudfront.net/6d77d7467f993780d02f3d8ea563959643d48f89/5-Figure5-1.png)

### ２つのデータセットを比較して...

2つのデータセットを比較すると、long-tailの多様化は、**より疎なEpinionsのデータセットではより困難**であることがわかります.

**10%のNDCG(精度)損失**で、Epinionsの場合はlong-tailアイテム達の約15%を露出させることが可能です.
一方、MovieLensの場合は0.2%の損失で同等以上の利益がもたらされます.

LT-Regはあまり効果がありません.

**SparserデータセットではBinaryとSmoothの性能はほぼ同じ**ですが、MovieLensでは違いが現れ、Smoothアルゴリズムは特にACLTの観点からより強い改善を示しています.

この効果は、より疎なデータでは、推薦リストに昇格させる単一のlong-tailアイテムを見つけることがより困難であり、そうすることでより大きな精度の損失がかかるという事実による可能性が高い.
MovieLensでは、このような**質の高いアイテム(=long-tail域にあるが、質の高いアイテムの事?)**が頻繁に登場し、Smooth目的では、このようなアイテムを複数推薦リストに昇格させることが重要視されています.

もう一つの結論は、ARP尺度を単独で使用した場合、long-tailの多様性を測る尺度としては不十分であるということです.
ARPには、long-tailとshort-headのアイテムを区別する**閾値を実験者が設定する必要がない**という利点があります。
しかし、ここで見るように、**アルゴリズムは非常に似たARPパフォーマンスを持ちながら**、long-tailカタログをカバーする能力と、long-tailアイテムをユーザに紹介する能力において、全く異なる場合があります.
したがって、これらの指標をすべて一緒に見ることが重要です.

# 結論と今後の課題

B to Cの組織や情報提供者にとって、long-tail商品を適切にカバーすることは重要です.

short-head アイテムは多くのユーザーに知られている可能性が高いため、この**人気帯以外のアイテムを推薦できるかどうかが、レコメンデーションシステムがユーザーに新しい商品や体験を紹介できるかどうかを左右**する.

2つのデータセットにおいて，モデルベース手法と比較して，再ランキング手法が精度の損失を小さく抑えながらlong-tail アイテムの多様性をブーストすることを示すことができた.

また，[22]の平均推薦人気度（ARP）指標は，**それ自体ではlong-tail促進を評価するための良い指標ではない**ことを示しました．
なぜなら，アルゴリズムはARPのパフォーマンスが似ていても，人気の偏りに関する他の指標では全く異なるパフォーマンスを持っているかもしれないからです．
そのため，アルゴリズムの有効性を正しく把握するためには，APLT や ACLT などの他の評価指標と併用することが望ましいと言えます．

将来的に、このモデルをmultistakeholder recommendation に使用することが考えられる.(例えば、job matchingとか?相互推薦??)

# 参考

- 今回の論文 [Managing Popularity Bias in Recommender Systems with Personalized Re-ranking](https://arxiv.org/pdf/1901.07555.pdf?)
- regularized long-tail diversification algorithmに関する論文 [Controlling Popularity Bias in Learning to Rank Recommendation](https://dl.acm.org/doi/10.1145/3109859.3109912)
-
