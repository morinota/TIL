# Bayesian Personalized Ranking from Implicit Feedback

published date: hogehoge September 2022,
authors: Wondo Rhee, Sung Min Cho, Bongwon Suh
url(paper): https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf
(勉強会発表者: morinota)

---

## どんなもの?

- KDD'23に採択されたAmazonの論文

## 先行研究と比べて何がすごい？

Sequential推薦システムって?

- Sequential推薦システムは、**過去のuser-itemのinteractionを時間的に順序付けられたsequenceとして**モデル化し、ユーザが潜在的に興味を持っているアイテムを推薦する。
  - Sequential推薦の利点は、ユーザの短期的嗜好と長期的嗜好の両方を捉える事ができること。

Sequential推薦の既存手法の多くは、**ID-basedな手法でありtransferable(移行可能)でない**点。

- Sequential推薦の既存研究では、マルコフ連鎖モデル[9, 25] -> RNN/CNNモデル[11, 17, 28, 34] -> self-attention型モデル[14, 19, 27]の順で、様々な手法が提案されてる。
- **基本的にはID-basedな手法**であり、成果物としてitem embedding tableを作成する。(もちろんいくつかの手法では、itemのcontextを特徴量としてID embeddingに組み込んでいる。)
- ID-basedな手法は、コールドスタートアイテムの理解や、**モデルを学習した後に異なる推薦シナリオに適用するcross-domain推薦(??)**の実施に難がある。
  - アイテム固有のIDは、コールドスタートアイテムや新しいデータセットのトレーニングデータからモデルが移行可能な知識を学習することを妨げる。
  - 結果として、アイテムIDはコールドスタートアイテムに対する逐次レコメンダーの性能を制限し、**継続的に追加される新しいアイテムに対して逐次レコメンダーを再トレーニングしなければならない**。

transferableな推薦システムは、cold-start itemや、cross domain推薦においても利益をもたらす。

- 最近の研究[7, 12]では、知識の**効果的なcross-domain dransfer**を行うために、異なるドメインで共通の知識を得るために**自然言語テキスト(ex. タイトル、アイテムの説明文)の一般性を活用**し、有効な性能を出している。
  - 基本的な考え方: BERT [6]のような事前に訓練された言語モデルを採用してテキスト表現を取得し、テキスト表現からアイテム表現への変換を学習すること

しかし、**言語からitemへの変換を学習するアプローチには、いくつかの限界がある**:

- (1) 事前学習済みの言語モデルは、通常、一般的な言語corpus(ex. Wikipedia)で学習され、推薦タスク用のテキスト情報とは異なる言語domainの自然言語タスクに適している。
  - (ex. 推薦タスク用のテキスト情報=本論文の手法のケースでは、item's attributeの連結)
  - よって、**事前学習済み言語モデルによるアイテムのテキスト表現は、通常、推薦タスクにおいて最適ではない**。
- (2) 事前学習済みの言語モデルから得られるテキスト表現は、**粗い粒度(文レベル)のテキスト特徴を提供するだけ**で、推薦のための細かい粒度(単語レベル)のユーザの好み(ex. 服の推薦のために最近のインタラクションで同じ色を見つける)を学習することができない。
- (3)事前学習済みの言語モデル(ex. 言語理解タスク)と変換モデル(ex. 推薦タスク)はindependent training。
  - **joint trainingできたほうが推薦タスクの為の言語理解モデルとして性能良くなるよね**...!!

本論文の提案手法 Recformer は、言語理解タスクと推薦タスクのアプローチを、ID-freeのsequential推薦タスクに統一する事を目指す。
基本的な考え方は、**言語理解と逐次推薦のjoint training**を通じて、言語モデルの汎用性を利用しtransferableな推薦システムを作る事。

## 技術や手法の肝は？

## どうやって有効だと検証した?

- オンライン実験ではなく、オフラインデータセットを用いた評価のみだった。

## 議論はある？

## 次に読むべき論文は？

## お気持ち実装
