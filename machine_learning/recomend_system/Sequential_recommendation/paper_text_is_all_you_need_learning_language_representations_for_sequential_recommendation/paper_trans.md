## 0.1. link ãƒªãƒ³ã‚¯

https://arxiv.org/abs/2305.13731
https://arxiv.org/abs/2305.13731

## 0.2. title ã‚¿ã‚¤ãƒˆãƒ«

Text Is All You Need: Learning Language Representations for Sequential Recommendation
ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Œã°ã„ã„ï¼š
é€æ¬¡æ¨è–¦ã®ãŸã‚ã®è¨€èªè¡¨ç¾ã‚’å­¦ã¶

## 0.3. abstract æŠ„éŒ²

Sequential recommendation aims to model dynamic user behavior from historical interactions.
é€æ¬¡ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€éå»ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªãƒ¦ãƒ¼ã‚¶è¡Œå‹•ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚
Existing methods rely on either explicit item IDs or general textual features for sequence modeling to understand user preferences.
æ—¢å­˜ã®æ–¹æ³•ã¯ã€ãƒ¦ãƒ¼ã‚¶ã®å—œå¥½ã‚’ç†è§£ã™ã‚‹ãŸã‚ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«ã€æ˜ç¤ºçš„ãªã‚¢ã‚¤ãƒ†ãƒ IDã‹ä¸€èˆ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã®ã©ã¡ã‚‰ã‹ã«ä¾å­˜ã—ã¦ã„ã‚‹ã€‚
While promising, these approaches still struggle to model cold-start items or transfer knowledge to new datasets.
æœ‰æœ›ã§ã¯ã‚ã‚‹ãŒã€ã“ã‚Œã‚‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ¢ãƒ‡ãƒ«åŒ–ã‚„ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®çŸ¥è­˜ã®ç§»è¡Œ(?onlineæ›´æ–°çš„ãªè©±ã ã‚ã†ã‹??)ã«ã¯ã¾ã è‹¦åŠ´ã—ã¦ã„ã‚‹ã€‚
In this paper, we propose to model user preferences and item features as language representations that can be generalized to new items and datasets.
æœ¬è«–æ–‡ã§ã¯ã€**ãƒ¦ãƒ¼ã‚¶ã®å—œå¥½ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ç‰¹å¾´é‡ã‚’ã€æ–°ã—ã„ã‚¢ã‚¤ãƒ†ãƒ ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«æ±åŒ–å¯èƒ½ãªè¨€èªè¡¨ç¾ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ã“ã¨**ã‚’ææ¡ˆã™ã‚‹ã€‚
To this end, we present a novel framework, named Recformer, which effectively learns language representations for sequential recommendation.
ã“ã®ç›®çš„ã®ãŸã‚ã«ã€æˆ‘ã€…ã¯ã€**é€æ¬¡æ¨è–¦ã®ãŸã‚ã®è¨€èªè¡¨ç¾ã‚’åŠ¹æœçš„ã«å­¦ç¿’ã™ã‚‹ã€Recformer**ã¨åä»˜ã‘ã‚‰ã‚ŒãŸæ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æç¤ºã™ã‚‹ã€‚
Specifically, we propose to formulate an item as a "sentence" (word sequence) by flattening item key-value attributes described by text so that an item sequence for a user becomes a sequence of sentences.
å…·ä½“çš„ã«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã§è¨˜è¿°ã•ã‚ŒãŸã‚¢ã‚¤ãƒ†ãƒ ã®key-valueå±æ€§ã‚’å¹³å¦åŒ–ã™ã‚‹ã“ã¨ã§ã€**å„ãƒ¦ãƒ¼ã‚¶ã®ã‚¢ã‚¤ãƒ†ãƒ sequence(=interaction history)ãŒ sequenceã®sequenceã«ãªã‚‹ã‚ˆã†ã«**ã€ã‚¢ã‚¤ãƒ†ãƒ ã‚’"æ–‡"(å˜èªsequence)ã¨ã—ã¦å®šå¼åŒ–ã™ã‚‹ã“ã¨ã‚’ææ¡ˆã™ã‚‹ã€‚(ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã®æ–‡è„ˆã ã¨æ™®é€šãªè€ƒãˆæ–¹ãªæ°—ãŒã™ã‚‹ã‘ã©ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒãŸãªã„ã‚¢ã‚¤ãƒ†ãƒ ã®æ¨è–¦å•é¡Œã«ã‚‚é©ç”¨ã§ãã‚‹ã£ã¦è©±ã ã‚ã†ã‹??:thinking:)
For recommendation, Recformer is trained to understand the "sentence" sequence and retrieve the next "sentence".
æ¨è–¦ã®ãŸã‚ã«ã€Recformerã¯"sentence"ã®ä¸¦ã³ã‚’ç†è§£ã—ã€æ¬¡ã®"sentence"ã‚’æ¤œç´¢ã™ã‚‹ã‚ˆã†ã«è¨“ç·´ã•ã‚Œã¦ã„ã‚‹ã€‚(next-item-predictionãªã‚‰ã¬next-sentence-predictionã£ã¦ã“ã¨??)
To encode item sequences, we design a bi-directional Transformer similar to the model Longformer but with different embedding layers for sequential recommendation.
ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã«ã€æˆ‘ã€…ã¯ã€ãƒ¢ãƒ‡ãƒ«Longformerã¨åŒæ§˜ã®bi-directionalãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’è¨­è¨ˆã™ã‚‹ãŒã€ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«æ¨è–¦ã®ãŸã‚ã«ç•°ãªã‚‹ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’æŒã¤ã€‚
For effective representation learning, we propose novel pretraining and finetuning methods which combine language understanding and recommendation tasks.
åŠ¹æœçš„ãªè¡¨ç¾å­¦ç¿’ã®ãŸã‚ã«ã€è¨€èªç†è§£ã¨æ¨è–¦ã‚¿ã‚¹ã‚¯ã‚’çµ„ã¿åˆã‚ã›ãŸæ–°ã—ã„äº‹å‰å­¦ç¿’ã¨å¾®èª¿æ•´æ–¹æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚
Therefore, Recformer can effectively recommend the next item based on language representations.
ã—ãŸãŒã£ã¦ã€Recformerã¯ã€è¨€èªè¡¨ç¾ã«åŸºã¥ã„ã¦æ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’åŠ¹æœçš„ã«æ¨è–¦ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
Extensive experiments conducted on six datasets demonstrate the effectiveness of Recformer for sequential recommendation, especially in low-resource and cold-start settings.
6ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦è¡Œã‚ã‚ŒãŸåºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€Recformerã®é€æ¬¡æ¨è–¦ã®æœ‰åŠ¹æ€§ãŒã€ç‰¹ã«ä½ãƒªã‚½ãƒ¼ã‚¹ã‹ã¤ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆãªç’°å¢ƒã«ãŠã„ã¦å®Ÿè¨¼ã•ã‚ŒãŸã€‚

# 1. Introduction ã¯ã˜ã‚ã«

Sequential recommender systems model historical user interactions as temporally-ordered sequences to recommend potential items that users are interested in.
ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«ãƒ»ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ãƒ»ã‚·ã‚¹ãƒ†ãƒ ã¯ã€éå»ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ã‚„ã‚Šã¨ã‚Šã‚’æ™‚é–“çš„ã«é †åºä»˜ã‘ã‚‰ã‚ŒãŸã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€ãƒ¦ãƒ¼ã‚¶ãŒèˆˆå‘³ã‚’æŒã£ã¦ã„ã‚‹æ½œåœ¨çš„ãªã‚¢ã‚¤ãƒ†ãƒ ã‚’æ¨è–¦ã™ã‚‹ã€‚
Sequential recommenders [11, 14, 25, 27] can capture both short-term and long-term preferences of users and hence are widely used in different recommendation scenarios.
**é€æ¬¡ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼[11, 14, 25, 27]ã¯ã€ãƒ¦ãƒ¼ã‚¶ã®çŸ­æœŸçš„å—œå¥½ã¨é•·æœŸçš„å—œå¥½ã®ä¸¡æ–¹ã‚’æ‰ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ãŸã‚ã€æ§˜ã€…ãªãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒŠãƒªã‚ªã§åºƒãä½¿ã‚ã‚Œã¦ã„ã‚‹**ã€‚

Various methods have been proposed to improve the performance of sequential recommendation, including Markov Chains [9, 25], RNN/CNN models [11, 17, 28, 34] and self-attentive models [14, 19, 27].
é€æ¬¡æ¨è–¦ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€ãƒãƒ«ã‚³ãƒ•é€£é–[9, 25]ã€RNN/CNNãƒ¢ãƒ‡ãƒ«[11, 17, 28, 34]ã€self-attentionå‹ãƒ¢ãƒ‡ãƒ«[14, 19, 27]ãªã©ã€æ§˜ã€…ãªæ‰‹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚
Traditional sequential recommendation models convert items into IDs and create item embedding tables for encoding.
å¾“æ¥ã®é€æ¬¡æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ã‚’IDã«å¤‰æ›ã—ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãŸã‚ã«itemåŸ‹ã‚è¾¼ã¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã™ã‚‹ã€‚(ID-basedãªæ‰‹æ³•)
Item embeddings are learned from sequences of user interactions.
ã‚¢ã‚¤ãƒ†ãƒ åŸ‹ã‚è¾¼ã¿ã¯ã€ãƒ¦ãƒ¼ã‚¶ã¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‹ã‚‰å­¦ç¿’ã•ã‚Œã‚‹ã€‚
To enrich item features, some approaches [4, 20, 37, 38] incorporate item contexts such as item textual information or categorical features into ID embeddings.
**ã‚¢ã‚¤ãƒ†ãƒ ã®ç‰¹å¾´é‡ã‚’è±Šã‹ã«ã™ã‚‹ãŸã‚ã«ã€ã„ãã¤ã‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ[4, 20, 37, 38]ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚„ã‚«ãƒ†ã‚´ãƒªçš„ç‰¹å¾´ãªã©ã®ã‚¢ã‚¤ãƒ†ãƒ ã®contextã‚’IDåŸ‹ã‚è¾¼ã¿ã«çµ„ã¿è¾¼ã‚“ã§ã„ã‚‹**ã€‚(ã ã‚ˆãª...!)
While ID-based methods are promising, they struggle to understand cold-start items or conduct cross-domain recommendations where models are trained and then applied to different recommendation scenarios.
IDãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã¯æœ‰æœ›ã§ã¯ã‚ã‚‹ãŒã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã®ç†è§£ã‚„ã€**ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ãŸå¾Œã«ç•°ãªã‚‹æ¨è–¦ã‚·ãƒŠãƒªã‚ªã«é©ç”¨ã™ã‚‹cross-domainæ¨è–¦(??)**ã®å®Ÿæ–½ã«è‹¦æˆ¦ã—ã¦ã„ã‚‹ã€‚
Item-specific IDs prevent models from learning transferable knowledge from training data for cold-start items and new datasets.
**ã‚¢ã‚¤ãƒ†ãƒ å›ºæœ‰ã®IDã¯ã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã‚„æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ãŒç§»è¡Œå¯èƒ½ãªçŸ¥è­˜ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã‚’å¦¨ã’ã‚‹**ã€‚(OPEã®MIPSæ¨å®šé‡ã®ã€actionã‚’ä½¿ã‚ãšã«action feature embeddingã‚’ä½¿ã†ã€ã¿ãŸã„ãª??)
As a result, item IDs limit the performance of sequential recommenders on cold-start items and we have to re-train a sequential recommender for continually added new items.
ãã®çµæœã€ã‚¢ã‚¤ãƒ†ãƒ IDã¯ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã«å¯¾ã™ã‚‹é€æ¬¡ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã®æ€§èƒ½ã‚’åˆ¶é™ã—ã€**ç¶™ç¶šçš„ã«è¿½åŠ ã•ã‚Œã‚‹æ–°ã—ã„ã‚¢ã‚¤ãƒ†ãƒ ã«å¯¾ã—ã¦é€æ¬¡ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚’å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„**ã€‚
Therefore, transferable recommenders can benefit both cold-start items and new-domain datasets.
ã—ãŸãŒã£ã¦ã€**è»¢é€å¯èƒ½(transferable)ãªãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼**ã¯ã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã®ã‚¢ã‚¤ãƒ†ãƒ ã¨æ–°ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ(=cross domainæ¨è–¦ã®è©±?)ã®ä¸¡æ–¹ã«åˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ãŒã§ãã‚‹ã€‚

To develop transferable recommender systems, previous studies usually assume shared information such as overlapping users/items [13, 26, 39] and common features [29] is available and then reduce the gap between source and target domains by learning either semantic mappings [39] or transferable components [16].
**è»¢é€å¯èƒ½(transferable)ãªæ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹ç™ºã™ã‚‹ãŸã‚ã«**ã€å…ˆè¡Œç ”ç©¶ã§ã¯é€šå¸¸ã€é‡è¤‡ã™ã‚‹ãƒ¦ãƒ¼ã‚¶/ã‚¢ã‚¤ãƒ†ãƒ [13, 26, 39]ã‚„å…±é€šã®ç‰¹å¾´é‡[29]ãªã©ã®å…±æœ‰æƒ…å ±ãŒåˆ©ç”¨å¯èƒ½ã§ã‚ã‚‹ã¨ä»®å®šã—ã€æ„å‘³çš„ãƒãƒƒãƒ”ãƒ³ã‚°[39]ã¾ãŸã¯è»¢é€å¯èƒ½ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ[16]ã®ã„ãšã‚Œã‹ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€ã‚½ãƒ¼ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‰ãƒ¡ã‚¤ãƒ³é–“ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’æ¸›ã‚‰ã™ã€‚
Such assumptions are rarely true in real applications because items in different domains (e.g., Laptops and T-shirts) usually contain different features for recommendation.
ã“ã®ã‚ˆã†ãªä»®å®šã¯ã€å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã»ã¨ã‚“ã©å½“ã¦ã¯ã¾ã‚‰ãªã„ã€‚
ãªãœãªã‚‰ã€**ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆä¾‹ãˆã°ã€ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã¨Tã‚·ãƒ£ãƒ„ï¼‰ã®ã‚¢ã‚¤ãƒ†ãƒ ã¯ã€é€šå¸¸ã€æ¨è–¦ã®ãŸã‚ã®ç•°ãªã‚‹ç‰¹å¾´é‡ã‚’å«ã‚“ã§ã„ã‚‹**ã‹ã‚‰ã§ã‚ã‚‹ã€‚(i.e. ãƒãƒ¼ãƒˆPCã®æ¨è–¦ã§æœ‰åŠ¹ãªç‰¹å¾´é‡ã¨ã€Tã‚·ãƒ£ãƒ„ã®æ¨è–¦ã§æœ‰åŠ¹ãªç‰¹å¾´é‡ã¯ç•°ãªã‚‹ã€ã£ã¦æ„å‘³??:thinking:)
Therefore, to have effective cross-domain transfer, recent works [7, 12] leverage the generality of natural language texts (e.g., titles, descriptions of items) for common knowledge in different domains.
ã—ãŸãŒã£ã¦ã€åŠ¹æœçš„ãªã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³è»¢é€ã‚’è¡Œã†ãŸã‚ã«ã€æœ€è¿‘ã®ç ”ç©¶[7, 12]ã§ã¯ã€**ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã§å…±é€šã®çŸ¥è­˜ã‚’å¾—ã‚‹ãŸã‚ã«ã€è‡ªç„¶è¨€èªãƒ†ã‚­ã‚¹ãƒˆ(ä¾‹ï¼šã‚¿ã‚¤ãƒˆãƒ«ã€ã‚¢ã‚¤ãƒ†ãƒ ã®èª¬æ˜)ã®ä¸€èˆ¬æ€§ã‚’æ´»ç”¨**ã—ã¦ã„ã‚‹ã€‚
The basic idea is to employ pre-trained language models such as BERT [6] to obtain text representations and then learn the transformation from text representations to item representations.
åŸºæœ¬çš„ãªè€ƒãˆæ–¹ã¯ã€**BERT [6]ã®ã‚ˆã†ãªäº‹å‰ã«è¨“ç·´ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ¡ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¾ã‚’å–å¾—ã—ã€ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¾ã‹ã‚‰ã‚¢ã‚¤ãƒ†ãƒ è¡¨ç¾ã¸ã®å¤‰æ›ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨**ã§ã‚ã‚‹ã€‚
The knowledge of the transformation can be transferred across different domains and shows promising performance.
å¤‰æ›ã®çŸ¥è­˜ã¯ã€ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã¾ãŸãŒã£ã¦è»¢é€ã™ã‚‹ã“ã¨ãŒã§ãã€æœ‰æœ›ãªæ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
However, such frameworks of learning transformation from language to items have several limitations:
ã—ã‹ã—ã€è¨€èªã‹ã‚‰é …ç›®ã¸ã®å¤‰æ›ã‚’å­¦ç¿’ã™ã‚‹ã“ã®ã‚ˆã†ãªæ çµ„ã¿ã«ã¯ã€ã„ãã¤ã‹ã®é™ç•ŒãŒã‚ã‚‹ï¼š
(1) Pre-trained language models are usually trained on a general language corpus (e.g., Wikipedia) serving natural language tasks that have a different language domain from item texts (e.g., concatenation of item attributes), hence text representations from pretrained language models for items are usually sub-optimal.
(1)äº‹å‰ã«å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€é€šå¸¸ã€ä¸€èˆ¬çš„ãªè¨€èªã‚³ãƒ¼ãƒ‘ã‚¹ï¼ˆä¾‹ãˆã°ã€Wikipediaï¼‰ã§å­¦ç¿’ã•ã‚Œã€ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ†ã‚­ã‚¹ãƒˆ(ex. ã‚¢ã‚¤ãƒ†ãƒ ã®å±æ€§ã®é€£çµã€‚æœ¬è«–æ–‡ã®æ‰‹æ³•ã®ã‚±ãƒ¼ã‚¹!!)ã¨ã¯ç•°ãªã‚‹è¨€èªãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’æŒã¤è‡ªç„¶è¨€èªã‚¿ã‚¹ã‚¯ã‚’æä¾›ã™ã‚‹ã€‚ãã®ãŸã‚ã€**äº‹å‰ã«å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¾ã¯ã€é€šå¸¸ã€æœ€é©ã¨ã¯è¨€ãˆã¾ã›ã‚“**ã€‚
(2) Text representations from pre-trained language models are not able to learn the importance of different item attributes and only provide coarse-grained (sentence-level) textual features but cannot learn fine-grained (word-level) user preferences for recommendations (e.g., find the same color in recent interactions for clothing recommendations).
(2)äº‹å‰ã«è¨“ç·´ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¾ã¯ã€ç•°ãªã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã®å±æ€§ã®é‡è¦æ€§ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒã§ããšã€**ç²—ã„ç²’åº¦(æ–‡ãƒ¬ãƒ™ãƒ«)ã®ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´ã‚’æä¾›ã™ã‚‹ã ã‘**ã§ã€æ¨è–¦ã®ãŸã‚ã®ç´°ã‹ã„ç²’åº¦(å˜èªãƒ¬ãƒ™ãƒ«)ã®ãƒ¦ãƒ¼ã‚¶ã®å¥½ã¿(ex. æœã®æ¨è–¦ã®ãŸã‚ã«æœ€è¿‘ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã§åŒã˜è‰²ã‚’è¦‹ã¤ã‘ã‚‹)ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒã§ããªã„ã€‚
(3) Due to the independent training of pre-trained language models (by language understanding tasks, e.g., Masked Language Modeling) and transformation models (by recommendation tasks, e.g., next item prediction), the potential ability of models to understand language for recommendations has not been fully developed (by joint training).
(3)äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«(ex. ãƒã‚¹ã‚¯ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãªã©ã®è¨€èªç†è§£ã‚¿ã‚¹ã‚¯)ã¨å¤‰æ›ãƒ¢ãƒ‡ãƒ«(ex. æ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ äºˆæ¸¬ãªã©ã®æ¨è–¦ã‚¿ã‚¹ã‚¯)ã®ã€ç‹¬ç«‹ã—ãŸå­¦ç¿’ã«ã‚ˆã‚Šã€**æ¨è–¦ã®ãŸã‚ã®è¨€èªç†è§£ãƒ¢ãƒ‡ãƒ«**ã®æ½œåœ¨çš„ãªèƒ½åŠ›ã¯å®Œå…¨ã«ã¯é–‹ç™ºã•ã‚Œã¦ã„ãªã„ã€‚(å…±åŒå­¦ç¿’ã«ã‚ˆã‚‹)

With the above limitations in mind, we aim to unify the frameworks of natural language understanding and recommendations in an ID-free sequential recommendation paradigm.
ä»¥ä¸Šã®ã‚ˆã†ãªåˆ¶ç´„ã‚’å¿µé ­ã«ç½®ãã€æˆ‘ã€…ã¯è‡ªç„¶è¨€èªç†è§£ã¨ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®æ çµ„ã¿ã‚’**ID-freeã®é€æ¬¡æ¨è–¦ãƒ»ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã«çµ±ä¸€ã™ã‚‹**ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚
The pre-trained language models [6, 15, 23, 24] benefit various downstream natural language processing tasks due to their transferable knowledge from pre-training.
äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«[6, 15, 23, 24]ã¯ã€äº‹å‰å­¦ç¿’ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹çŸ¥è­˜ã®ä¼é”ãŒå¯èƒ½ã§ã‚ã‚‹ãŸã‚ã€æ§˜ã€…ãªè‡ªç„¶è¨€èªå‡¦ç†ã‚¿ã‚¹ã‚¯ã®ä¸‹æµã«æ©æµã‚’ã‚‚ãŸã‚‰ã™ã€‚(ã†ã‚“ã€fine-tuningã ã‘ã§è‰¯ã„ã£ã¦è¨€ã†ã‚ˆã­ã€‚)
The basic idea of this paper is to use the generality of language models through joint training of language understanding and sequential recommendations.
æœ¬ç¨¿ã®åŸºæœ¬çš„ãªè€ƒãˆæ–¹ã¯ã€**è¨€èªç†è§£ã¨é€æ¬¡æ¨è–¦ã®å…±åŒå­¦ç¿’ã‚’é€šã˜ã¦ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ±ç”¨æ€§ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨**ã§ã‚ã‚‹ã€‚
To this end, there are three major challenges to be solved.
ãã®ãŸã‚ã«ã¯ã€è§£æ±ºã™ã¹ã3ã¤ã®å¤§ããªèª²é¡ŒãŒã‚ã‚‹ã€‚
First, previous text-based methods [7, 12] usually have their specific item texts (e.g., item descriptions, concatenation of item attributes).
ç¬¬ä¸€ã«ã€ã“ã‚Œã¾ã§ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•[7, 12]ã¯ã€é€šå¸¸ã€ç‰¹å®šã®ã‚¢ã‚¤ãƒ†ãƒ ãƒ†ã‚­ã‚¹ãƒˆ(ex. ã‚¢ã‚¤ãƒ†ãƒ ã®èª¬æ˜ã€ã‚¢ã‚¤ãƒ†ãƒ å±æ€§ã®é€£çµ)ã‚’æŒã£ã¦ã„ã‚‹ã€‚
Instead of specific data types, we need to find a universal input data format of items for language models that is flexible enough to different kinds of textual item information.
ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿å‹ã®ä»£ã‚ã‚Šã«ã€ç•°ãªã‚‹ç¨®é¡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ æƒ…å ±ã«å¯¾ã—ã¦ååˆ†ã«æŸ”è»Ÿãªã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®ã‚¢ã‚¤ãƒ†ãƒ ã®æ™®éçš„ãªå…¥åŠ›ãƒ‡ãƒ¼ã‚¿å½¢å¼(??)ã‚’è¦‹ã¤ã‘ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚(=ã“ã‚ŒãŒå¾Œè¿°ã•ã‚Œã‚‹key-value attributesã®ã‚„ã¤!!)
Second, it is not clear how to model languages and sequential transitions of items in one framework.
ç¬¬äºŒã«ã€**è¨€èªã¨ã‚¢ã‚¤ãƒ†ãƒ ã®é€æ¬¡é·ç§»ã‚’ä¸€ã¤ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§(=joint trainingå¯èƒ½ãªã‚„ã¤!:thinking:)ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹æ–¹æ³•**ãŒæ˜ç¢ºã§ãªã„ã€‚
Existing language models are not able to incorporate sequential patterns of items and cannot learn the alignment between items and item texts.
æ—¢å­˜ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ã®é€£ç¶šçš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ããšã€ã‚¢ã‚¤ãƒ†ãƒ ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ†ã‚­ã‚¹ãƒˆé–“ã®ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒã§ããªã„ã€‚
Third, a training and inference framework is necessary to bridge the gap between natural languages and recommendations like how to efficiently rank items based on language models without trained item embeddings.
ç¬¬ä¸‰ã«ã€è‡ªç„¶è¨€èªã¨ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®é–“ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã«ã€å­¦ç¿’ã¨æ¨è«–ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒå¿…è¦ã§ã‚ã‚‹ã€‚ä¾‹ãˆã°ã€å­¦ç¿’æ¸ˆã¿ã®ã‚¢ã‚¤ãƒ†ãƒ åŸ‹ã‚è¾¼ã¿ãªã—ã§ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ã¦ã‚¢ã‚¤ãƒ†ãƒ ã‚’åŠ¹ç‡çš„ã«ãƒ©ãƒ³ã‚¯ä»˜ã‘ã™ã‚‹æ–¹æ³•ãªã©ã§ã‚ã‚‹ã€‚

![fig]()

To address the above problems, we propose Recformer, a framework that can learn language representations for sequential recommendation.
ä¸Šè¨˜ã®å•é¡Œç‚¹ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€æˆ‘ã€…ã¯**é€æ¬¡æ¨è–¦ã®ãŸã‚ã®è¨€èªè¡¨ç¾ã‚’å­¦ç¿’ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**ã§ã‚ã‚‹Recformerã‚’ææ¡ˆã™ã‚‹ã€‚
Overall, our approach takes a text sequence of historical items as input and predicts the next item based on language understanding.
å…¨ä½“ã¨ã—ã¦ã€æˆ‘ã€…ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€**historical items ã®ãƒ†ã‚­ã‚¹ãƒˆã‚·ãƒ¼ã‚±ãƒ³ã‚¹(sequences of sequence)ã‚’å…¥åŠ›ã¨ã—**ã€è¨€èªç†è§£ã«åŸºã¥ã„ã¦next-itemã‚’äºˆæ¸¬ã™ã‚‹ã€‚
Specifically, as shown in Figure 1, we first formulate an item as key-value attribute pairs which can include any textual information such as the title, color, brand of an item.
å…·ä½“çš„ã«ã¯ã€å›³1ã«ç¤ºã™ã‚ˆã†ã«ã€ã¾ãšã€ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚¿ã‚¤ãƒˆãƒ«ã€è‰²ã€ãƒ–ãƒ©ãƒ³ãƒ‰ãªã©ã®ä»»æ„ã®ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’å«ã‚€ã“ã¨ãŒã§ãã‚‹æ§˜ãªã€**key-value attributeãƒšã‚¢(ex. key="Title", value="å…·ä½“çš„ãªtitle")ã¨ã—ã¦ã‚¢ã‚¤ãƒ†ãƒ ã‚’å®šå¼åŒ–**ã—ã¾ã™ã€‚(å›³1ã‚’è¦‹ã‚‹ã¨ã‚ã‹ã‚Šã‚„ã™ã„)
Different items can include different attributes as item texts.
ç•°ãªã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ç•°ãªã‚‹å±æ€§ã‚’å«ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
Then, to encode a sequence of key-value attribute pairs, we propose a novel bi-directional Transformer [30] based on Longformer structure [2] but with different embeddings for item texts to learn item sequential patterns.
æ¬¡ã«ã€ã‚­ãƒ¼ã¨å€¤ã®å±æ€§ãƒšã‚¢ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã«ã€**Longformeræ§‹é€ [2]ã«åŸºã¥ã**(??)ãŒã€ã‚¢ã‚¤ãƒ†ãƒ ã®sequentialãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã«ã€**ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ†ã‚­ã‚¹ãƒˆã®ç‚ºã®ç•°ãªã‚‹ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã‚’æŒã¤ã€æ–°ã—ã„åŒæ–¹å‘ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼**[30]ã‚’ææ¡ˆã™ã‚‹ã€‚(Transformerã®è«–æ–‡èª­ã‚“ã§ãŸã‚‰ãªã‚“ã¨ã‹ç†è§£ã§ãã‚‹ã‹...!)
Finally, to effectively learn language representations for recommendation, we design the learning framework for the model including pre-training, finetuning and inference processes.
æœ€å¾Œã«ã€æ¨è–¦ã®ãŸã‚ã®è¨€èªè¡¨ç¾ã‚’åŠ¹æœçš„ã«å­¦ç¿’ã™ã‚‹ãŸã‚ã«ã€äº‹å‰å­¦ç¿’ã€å¾®èª¿æ•´ã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’å«ã‚€ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’è¨­è¨ˆã™ã‚‹ã€‚
Based on the above methods, Recformer can effectively recommend the next items based on item text representations.
ä»¥ä¸Šã®æ–¹æ³•ã«åŸºã¥ã„ã¦ã€**Recformerã¯ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¾ã«åŸºã¥ã„ã¦æ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’åŠ¹æœçš„ã«æ¨è–¦**ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
Furthermore, the knowledge learned from training can be transferred to cold-start items or a new recommendation scenario.
ã•ã‚‰ã«ã€**ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‹ã‚‰å­¦ã‚“ã çŸ¥è­˜ã¯ã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã‚„æ–°ã—ã„æ¨è–¦ã‚·ãƒŠãƒªã‚ª(=cross domainæ¨è–¦!)ã«ç§»ã™ã“ã¨ãŒã§ãã‚‹**ã€‚

To evaluate Recformer, we conduct extensive experiments on real-world datasets from different domains.
Recformerã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€æˆ‘ã€…ã¯æ§˜ã€…ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã®å®Ÿä¸–ç•Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§åºƒç¯„ãªå®Ÿé¨“ã‚’è¡Œã£ãŸã€‚
Experimental results show that our method can achieve 15.83% and 39.78% (NDCG@10) performance improvements under fully-supervised and zero-shot sequential recommendation settings respectively.1
å®Ÿé¨“çµæœã«ã‚ˆã‚Œã°ã€æˆ‘ã€…ã®æ‰‹æ³•ã¯ã€å®Œå…¨æ•™å¸«ã‚ã‚Šæ¨è–¦ã¨ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆé€æ¬¡æ¨è–¦ã®è¨­å®šã«ãŠã„ã¦ã€ãã‚Œãã‚Œ15.83ï¼…ã¨39.78ï¼…ï¼ˆNDCG@10ï¼‰ã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã§ãã‚‹ã€‚

Our contributions in this paper can be summarized as follows:
æœ¬è«–æ–‡ã®è²¢çŒ®ã¯ä»¥ä¸‹ã«ã¾ã¨ã‚ãŸ:

- We formulate items as key-value attribute pairs for the IDfree sequential recommendation and propose a novel bidirectional Transformer structure to encode sequences of key-value pairs. æˆ‘ã€…ã¯ã€**ID-freeã®é€æ¬¡æ¨è–¦**ã®ãŸã‚ã«ã€**ã‚¢ã‚¤ãƒ†ãƒ ã‚’key-value attribute pairsã¨ã—ã¦å®šå¼åŒ–**ã—ã€**key-value pairsã®sequenceã‚’encodeã™ã‚‹ãŸã‚ã®æ–°ã—ã„åŒæ–¹å‘ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼æ§‹é€ **ã‚’ææ¡ˆã™ã‚‹ã€‚

- We design the learning framework that helps the model learn usersâ€™ preferences and then recommend items based on language representations and transfer knowledge into different recommendation domains and cold-start items. æˆ‘ã€…ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒãƒ¦ãƒ¼ã‚¶ã®å—œå¥½ã‚’å­¦ç¿’ã—ã€è¨€èªè¡¨ç¾ã«åŸºã¥ã„ã¦ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ¨è–¦ã—ã€ç•°ãªã‚‹æ¨è–¦ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚„ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã«çŸ¥è­˜ã‚’è»¢é€ã™ã‚‹ã“ã¨ã‚’æ”¯æ´ã™ã‚‹å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’è¨­è¨ˆã™ã‚‹ã€‚

- Extensive experiments are conducted to show the effectiveness of our method. Results show that Recformer outperforms baselines for sequential recommendation and largely improves knowledge transfer as shown by zero-shot and cold-start settings. æœ¬æ‰‹æ³•ã®æœ‰åŠ¹æ€§ã‚’ç¤ºã™ãŸã‚ã€åºƒç¯„ãªå®Ÿé¨“ã‚’è¡Œã£ãŸã€‚ ãã®çµæœã€Recformerã¯é€æ¬¡æ¨è–¦ã«ãŠã„ã¦ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€ã‚¼ãƒ­ãƒ»ã‚·ãƒ§ãƒƒãƒˆã¨ã‚³ãƒ¼ãƒ«ãƒ‰ãƒ»ã‚¹ã‚¿ãƒ¼ãƒˆè¨­å®šã«ã‚ˆã£ã¦ç¤ºã•ã‚Œã‚‹ã‚ˆã†ã«ã€çŸ¥è­˜ä¼é”(knowledge transfer)ã‚’å¤§ããæ”¹å–„ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚(æ¯æ—¥full-batchå­¦ç¿’ã‚’ã—ãªãã‚ƒã„ã‘ãªã„ãƒ¢ãƒ‡ãƒ«ã¯ã€æ—¢å­˜ã®çŸ¥è­˜ã®å¿œç”¨ãŒå…¨ç„¶ã§ããªã„ã‚¤ãƒ¡ãƒ¼ã‚¸ãªã®ã‹ãª:thinking:)

# 2. Methodology æ–¹æ³•è«–

In this section, we present Recformer which can learn language representations for sequential recommendation and effectively transfer and generalize to new recommendation scenarios.
æœ¬ç¯€ã§ã¯ã€é€æ¬¡æ¨è–¦ã®ãŸã‚ã®è¨€èªè¡¨ç¾ã‚’å­¦ç¿’ã—ã€æ–°ã—ã„æ¨è–¦ã‚·ãƒŠãƒªã‚ªã«åŠ¹æœçš„ã«ç§»è¡Œãƒ»æ±åŒ–ã§ãã‚‹Recformerã‚’ç´¹ä»‹ã™ã‚‹ã€‚

## 2.1. Problem Setup and Formulation å•é¡Œã®è¨­å®šã¨å®šå¼åŒ–

In the setting of sequential recommendation, we are given an item set I and a userâ€™s interaction sequence $s = {i_1, i_2,\cdos, i_n}$ in temporal order where $n$ is the length of $s$ and $i \in I$.
é€æ¬¡æ¨è–¦ã®è¨­å®šã§ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ é›†åˆ $I$ ã¨ãƒ¦ãƒ¼ã‚¶ã®interaction sequence $s = {i_1, i_2, Ë¶cdos, i_n}$ ãŒæ™‚é–“é †ã«ä¸ãˆã‚‰ã‚Œã‚‹ã€‚
Based on $s$, we seek to predict the next item.
$s$ ã«åŸºã¥ã„ã¦ã€æ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’äºˆæ¸¬ã™ã‚‹ã€‚
In previous sequential recommendation methods, each interacted itemğ‘– is associated with a unique item ID.
ã“ã‚Œã¾ã§ã®é€æ¬¡æ¨è–¦æ³•ã§ã¯ã€å„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒˆã‚¢ã‚¤ãƒ†ãƒ  $i$ ã¯ä¸€æ„ã®ã‚¢ã‚¤ãƒ†ãƒ IDã¨é–¢é€£ä»˜ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã€‚
In this paper, each item $i$ has a corresponding attribute dictionary $D_i$ containing key-value attribute pairs ${(k_1, v_1), (k_2, v_2), \cdots, (k_m, v_m)}$ where $k$ denotes an attribute name (e.g., Color) and ğ‘£ is the corresponding value (e.g., Black).
æœ¬è«–æ–‡ã§ã¯ã€å„ã‚¢ã‚¤ãƒ†ãƒ  $i$ ã¯å¯¾å¿œã™ã‚‹ attribute dictionary $D_i$ ã‚’æŒã¤ã€‚ $D_i$ ã¯ key-value attribute pairs ${(k_1, v_1), (k_2, v_2), \cdots, (k_m, v_m)}$ ã‚’å«ã‚“ã§ã„ã‚‹ã€‚ã“ã“ã§ $k$ ã¯ã‚ã‚‹attributeå(ex. Color), $v$ ã¯å¯¾å¿œã™ã‚‹å€¤(ex. Black)ã§ã‚ã‚‹ã€‚
$k$ and $v$ are both described by natural languages and contain words $(k, v) = {w_1^{k}, \cdots, w_c^{k}, w_1^{v}, \cdots, w_c^{v}}$, where $w^{k}$ and $w^{v}$ are words of $k$ and $v$ from a shared vocabulary in the language model and $c$ denotes the truncated length of text.
**$k$ ã¨ $v$ ã¯å…±ã«è‡ªç„¶è¨€èªã§è¨˜è¿°ã•ã‚Œ**ã€words $(k, v) = {w_1^{k}, \cdots, w_c^{k}, w_1^{v}, \cdots, w_c^{v}}$ ã‚’å«ã‚€ã€‚
ã“ã“ã§ $w^{k}$ ã¨ $w^{v}$ ã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã®å…±æœ‰èªå½™ã«ã‚ã‚‹ $k$ ã¨ $v$ ã®å„å˜èªã€$c$ ã¯ãƒ†ã‚­ã‚¹ãƒˆã®åˆ‡ã‚Šæ¨ã¦(truncated)é•·ã•ã‚’è¡¨ã™ã€‚
An attribute dictionary ğ·ğ‘– can include all kinds of item textual information such as titles, descriptions, colors, etc.
ã‚¢ã‚¤ãƒ†ãƒ  $i$ ã®å±æ€§è¾æ›¸ $D_i$ ã«ã¯ã€ã‚¿ã‚¤ãƒˆãƒ«ã€èª¬æ˜ã€è‰²ãªã©ã€ã‚ã‚‰ã‚†ã‚‹ç¨®é¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’å«ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
As shown in Figure 2, to feed the attribute dictionary $D_i$ into a language model, we flatten key-value attribute pairs into $T_{i} = {k_1, v_1, k_2, v_2, \cdots, k_m, v_m}$ to obtain an item â€œsentenceâ€ as the input data.
å›³2ã§ç¤ºã™æ§˜ã«ã€attribute dictionary $D_i$ã‚’è¨€èªãƒ¢ãƒ‡ãƒ«ã«æŠ•å…¥ã™ã‚‹ç‚ºã«ã€æˆ‘ã€…ã¯key-value attribute ãƒšã‚¢é”ã‚’ $T_{i} = {k_1, v_1, k_2, v_2, \cdots, k_m, v_m}$ ã®æ§˜ã«å¹³æ»‘åŒ–ã—ã¦ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ item "sentence"ã‚’å¾—ã‚‹ã€‚
Unlike previous sequential recommenders [12, 37] using both text and item IDs, in this study, we use only text for the sequential recommendation.
**ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚¢ã‚¤ãƒ†ãƒ IDã®ä¸¡æ–¹ã‚’ä½¿ç”¨ã™ã‚‹ä»¥å‰ã®é€æ¬¡æ¨è–¦å™¨[12, 37]ã¨ã¯ç•°ãªã‚Šã€æœ¬ç ”ç©¶ã§ã¯é€æ¬¡æ¨è–¦ã«ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹**ã€‚

![fig2]()

## 2.2. Recformer

![fig]()

Figure 3 (a) shows the architecture of Recformer.
å›³3ï¼ˆaï¼‰ã¯Recformerã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
The model has a similar structure as Longformer [2] which adopts a multi-layer bidirectional Transformer [30] with an attention mechanism that scales linearly with sequence length.
ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯**Longformer[2]ã¨åŒæ§˜ã®æ§‹é€ ã‚’æŒã¡**ã€**å¤šå±¤åŒæ–¹å‘ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼[30]ã‚’æ¡ç”¨**ã—ã€é…åˆ—ã®é•·ã•ã«å¿œã˜ã¦ç·šå½¢ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹(=è¨ˆç®—é‡ãŒ??)ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æŒã¤ã€‚
We consider only computing efficiency for using Longformer but our method is open to other bidirectional Transformer structures such as BERT [6] and BigBird [36].
æˆ‘ã€…ã¯ã€Longformerã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã®è¨ˆç®—åŠ¹ç‡ã®ã¿ã‚’è€ƒæ…®ã™ã‚‹ãŒã€æˆ‘ã€…ã®æ–¹æ³•ã¯ã€BERT [6]ã‚„BigBird [36]ã®ã‚ˆã†ãªä»–ã®åŒæ–¹å‘ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼æ§‹é€ ã«ã‚‚ã‚ªãƒ¼ãƒ—ãƒ³(é©ç”¨å¯èƒ½)ã§ã‚ã‚‹ã€‚

### 2.2.1. Model Inputs. ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ã€‚

As introduced in Section 2.1, for each item $i$ and corresponding attribute dictionary $D_i$, we flatten the dictionary into an **item â€œsentenceâ€** $T_{i} = {k_1, v_1, k_2, v_2, \cdots, k_m, v_m}$ where $k$ and $v$ are described by words, formally $(k, v) = {w_1^{k}, \cdots, w_c^{k}, w_1^{v}, \cdots, w_c^{v}}$.
èª­ã‚ã‚‹ã€‚
To encode a userâ€™s interaction sequence $s = {i_{1}, i_{2}, \cdots, i_{n}}$, we first reverse items in a sequence to ${i_{n},i_{n-1}, \cdots, $i_{1}}$ because intuitively recent items (i.e.$, i_n, i_{n-1}, \cdots$) are important for the next item prediction and reversed sequences can make sure recent items are included in the input data.
ãƒ¦ãƒ¼ã‚¶ã®å¯¾è©±ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ $s = {i_{1}, i_{2}, \cdots, i_{n}}$ ã‚’ç¬¦å·åŒ–ã™ã‚‹ãŸã‚ã«ã€ã¾ãšã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’ ${i_{n},i_{n-1}, \cdots, $i_{1}}$ ã«é€†å¤‰æ›ã™ã‚‹ã€‚
ã“ã‚Œã¯ç›´æ„Ÿçš„ã«æœ€è¿‘ã®ã‚¢ã‚¤ãƒ†ãƒ  (i.e.$, i_n, i_{n-1}, \cdots$) ã¯æ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ äºˆæ¸¬ã«é‡è¦ã§ã‚ã‚Šã€é€†å¤‰æ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«ã‚ˆã‚Šæœ€è¿‘ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒå…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã«ç¢ºå®Ÿã«å«ã¾ã‚Œã‚‹æ§˜ã«ã§ãã‚‹ã‹ã‚‰ã§ã‚ã‚‹ã€‚(è¦ã™ã‚‹ã«ã€sequenceã‚’truncateã™ã‚‹ã®ã§ã€æœ€æ–°ã®interactionãŒåˆ‡ã‚Œãªã„æ§˜ã«!)
Then, we use the item â€œsentencesâ€ to replace items and add a special token [CLS] at the beginning of sequences.
ãã—ã¦ã€ã‚¢ã‚¤ãƒ†ãƒ ã®ç½®æ›ã«item â€œsentencesâ€ã‚’ä½¿ç”¨ã—ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®å…ˆé ­ã«ç‰¹åˆ¥ãªãƒˆãƒ¼ã‚¯ãƒ³[CLS]ã‚’è¿½åŠ ã™ã‚‹ã€‚
Hence, model inputs are denoted as:
ã—ãŸãŒã£ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ã¯æ¬¡ã®ã‚ˆã†ã«è¡¨è¨˜ã•ã‚Œã‚‹ï¼š

$$
X = \{ [CLS], T_n, T_{n-1}, \cdots, T_{1}\}
\tag{1}
$$

where ğ‘‹ is a **sequence of words** containing all items and corresponding attributes the user interacted with in the historical interactions.
ã“ã“ã§ $X$ ã¯ã€éå»ã®interactionã®ä¸­ã§ãƒ¦ãƒ¼ã‚¶ãŒinteractã—ãŸã™ã¹ã¦ã®ã‚¢ã‚¤ãƒ†ãƒ ã¨å¯¾å¿œã™ã‚‹å±æ€§è¾æ›¸ã‚’å«ã‚€å˜èªé”ã®sequence(=**sequence of sequences**)ã§ã‚ã‚‹ã€‚

### 2.2.2. Embedding Layer

The target of Recformer is to understand the model input ğ‘‹ from both language understanding and sequential patterns in recommendations.
**Recformerã®ç›®æ¨™ã¯ã€è¨€èªç†è§£ã¨ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®é€æ¬¡çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¸¡æ–¹ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«å…¥åŠ› $X$ ã‚’ç†è§£ã™ã‚‹ã“ã¨**ã§ã‚ã‚‹ã€‚
The key idea in our work is to combine the embedding layers from language models [6, 21] and self-attentive sequential recommenders [14, 27].
**æˆ‘ã€…ã®ç ”ç©¶ã§é‡è¦ãªã‚¢ã‚¤ãƒ‡ã‚¢ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«[6, 21]ã¨self-attentionå‹é€æ¬¡ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼[14, 27]ã®embedding layersã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨**ã§ã‚ã‚‹ã€‚
Hence, Recformer contains four embeddings as follows:
ã—ãŸãŒã£ã¦ã€Recformerã¯ä»¥ä¸‹ã®**4ã¤ã®åŸ‹ã‚è¾¼ã¿**ã‚’å«ã‚“ã§ã„ã‚‹ï¼š

- **Token embedding** represents the corresponding tokens. We denote the word token embedding by $A \in \mathbb{R}^{V_w \times d}$, where $V_w$ is the number of words in our vocabulary and $d$ is the embedding dimension. Recformer does not have item embeddings as previous sequential recommenders and hence Recformer understands items in interaction sequences mainly based on these token embeddings. The size of token embeddings is a constant for different recommendation scenarios; hence, our model size is irrelevant to the number of items. Token embeddingã¯ã€å¯¾å¿œã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¡¨ç¾ã™ã‚‹ã€‚ æˆ‘ã€…ã¯ word token embedding ã‚’ $A \in \mathbb{R}^{V_w \times d}$ ã¨ã—ã¦å®šç¾©ã™ã‚‹ã€‚ã“ã“ã§ã€$V_w$ ã¯vocabularyã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹å˜èªæ•°ã€$d$ ã¯åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒã§ã‚ã‚‹ã€‚ **Recformerã¯ã“ã‚Œã¾ã§ã®é€æ¬¡æ¨è–¦å™¨ã®ã‚ˆã†ãªã‚¢ã‚¤ãƒ†ãƒ åŸ‹ã‚è¾¼ã¿ã‚’æŒã£ã¦ã„ãªã„**ãŸã‚ã€Recformerã¯ä¸»ã«ã“ã‚Œã‚‰ã®ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ã«åŸºã¥ã„ã¦interaction sequenceã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç†è§£ã™ã‚‹ã€‚ ãƒˆãƒ¼ã‚¯ãƒ³ã®åŸ‹ã‚è¾¼ã¿ã‚µã‚¤ã‚ºã¯ã€ç•°ãªã‚‹æ¨è–¦ã‚·ãƒŠãƒªã‚ªã«å¯¾ã—ã¦ä¸€å®šã§ã‚ã‚‹ã€‚ã—ãŸãŒã£ã¦ã€**æˆ‘ã€…ã®ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã¯ã‚¢ã‚¤ãƒ†ãƒ æ•°ã«é–¢ä¿‚ãªã„**ã€‚

- **Token position embedding** represents the position of tokens in a sequence. A word appearing at the ğ‘–-th position in the sequence $X$ is represented as $B_{i} \in \mathbb{R}^{d}$ . Similar to language models, token position embedding is designed to help Transformer understand the sequential patterns of words. ãƒˆãƒ¼ã‚¯ãƒ³ä½ç½®åŸ‹ã‚è¾¼ã¿ã¯ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å†…ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ä½ç½®ã‚’è¡¨ç¾ã™ã‚‹ã€‚ sequence $X$ ã® $i$ ç•ªç›®ã®ä½ç½®ã«ç¾ã‚Œã‚‹å˜èª(=å®Ÿéš›ã«ã¯ $T_{n-i+1}$ ??)ã¯ã€$B_{i} \in \mathbb{R}^{d}$ ã¨è¡¨ã•ã‚Œã‚‹ã€‚ **è¨€èªãƒ¢ãƒ‡ãƒ«ã¨åŒæ§˜ã«ã€ãƒˆãƒ¼ã‚¯ãƒ³ä½ç½®åŸ‹ã‚è¾¼ã¿ã¯ã€TransformerãŒå˜èªã®é€£ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç†è§£ã™ã‚‹ã®ã‚’åŠ©ã‘ã‚‹**ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã‚‹ã€‚(ã“ã®position embeddingã¯ã€é€šå¸¸ã®Transformerã¨åŒã˜æ„å‘³åˆã„...!)

- **Token type embedding** represents where a token comes from. Specifically, the token type embedding totally contains three vectors C[CLS], CKey, CValue âˆˆ R ğ‘‘ to represent if a token comes from [CLS], attribute keys, or attribute values respectively. Different types of tokens usually have different importance for the next item prediction. For example, because most items usually have the same attribute keys in a recommendation dataset, models with token type embedding will recognize repeated words from the same attribute keys. ãƒˆãƒ¼ã‚¯ãƒ³å‹ã®åŸ‹ã‚è¾¼ã¿ã¯ã€**ãƒˆãƒ¼ã‚¯ãƒ³ãŒã©ã“ã‹ã‚‰æ¥ãŸã‹**ã‚’è¡¨ã™ã€‚ å…·ä½“çš„ã«ã¯ã€token type embedding ã¯ã€3ã¤ã®ãƒ™ã‚¯ãƒˆãƒ« $C_{[CLS]}, C_{Key}, C_{Value} \in \mathbb{R}^{d}$ ã‚’å«ã¿ã€tokenãŒãã‚Œãã‚Œ[CLS]ã€å±æ€§ã‚­ãƒ¼ã€å±æ€§å€¤ã‹ã‚‰æ¥ã‚‹ã‹ã©ã†ã‹ã‚’è¡¨ã—ã¾ã™ã€‚ ç•°ãªã‚‹token typeã¯é€šå¸¸ã€next-item-predictionã®ç‚ºã®ç•°ãªã‚‹é‡è¦æ€§ã‚’æŒã¤ã€‚ ä¾‹ãˆã°ã€æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ã€ã»ã¨ã‚“ã©ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒåŒã˜å±æ€§keyã‚’æŒã£ã¦ã„ã‚‹ã®ã§ã€token type embeddingã‚’è¡Œã†ãƒ¢ãƒ‡ãƒ«ã¯ã€åŒã˜å±æ€§keyã‹ã‚‰ç¹°ã‚Šè¿”ã•ã‚Œã‚‹å˜èªã‚’èªè­˜ã™ã‚‹ã€‚(=ã“ã‚Œã¯æ„å‘³ãªã„ã‚ˆã£ã¦æƒ…å ±ã‹ã‚’èªè­˜ã™ã‚‹ç‚º??)

- **Item position embedding** represents the position of items in a sequence. A word from attributes of the ğ‘˜-th item in the sequence ğ‘‹ is represented as $D_{k} \in \mathbb{R}^{d}$ and $D \in \mathbb{n \times d}$ where ğ‘› is the maximum length of a userâ€™s interaction sequence ğ‘ . Same as previous self-attentive sequential recommenders [14, 27], the item position embedding is a key component for item sequential pattern learning. In Recformer, the item position embedding can also help the model learn the alignment between word tokens and items ã‚¢ã‚¤ãƒ†ãƒ ä½ç½®åŸ‹ã‚è¾¼ã¿ã¯ã€**sequenceå†…ã®ã‚¢ã‚¤ãƒ†ãƒ ã®ä½ç½®**ã‚’è¡¨ç¾ã™ã‚‹ã€‚ sequence $X$ ã® $k$ ç•ªç›®ã®ã‚¢ã‚¤ãƒ†ãƒ ã®å±æ€§ã‹ã‚‰ã®å˜èªã¯ã€$D_{k} \in \mathbb{R}^{d}$ ã¨ $D \in \mathbb{n \times d}$ ã¨ã—ã¦è¡¨ç¾ã•ã‚Œã‚‹ ($n$ ã¯ãƒ¦ãƒ¼ã‚¶ã®interaction sequence $s$ ã®æœ€å¤§é•·)ã€‚**ã“ã‚Œã¾ã§ã®self-attentionå‹é€æ¬¡æ¨è–¦å™¨[14, 27]ã¨åŒæ§˜ã«ã€ã‚¢ã‚¤ãƒ†ãƒ ä½ç½®åŸ‹ã‚è¾¼ã¿ã¯ã‚¢ã‚¤ãƒ†ãƒ é€æ¬¡ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ã®é‡è¦ãªè¦ç´ **ã§ã‚ã‚‹ã€‚ Recformerã§ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ä½ç½®åŸ‹ã‚è¾¼ã¿ã¯ã€word tokensã¨ã‚¢ã‚¤ãƒ†ãƒ ã®é–“ã®alignment(é€£æº?)ã‚’å­¦ç¿’ã™ã‚‹ã®ã«ã‚‚å½¹ç«‹ã¤ã€‚

Therefore, given a word ğ‘¤ from the input sequence ğ‘‹, the input embedding is calculated as the summation of four different embeddings followed by layer normalization [1]:
ã—ãŸãŒã£ã¦ã€å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ $X$ ã‹ã‚‰å˜èªtoken $w$ ãŒä¸ãˆã‚‰ã‚Œã‚‹ã¨ã€input embeddng ã¯ã€4ã¤ã®ç•°ãªã‚‹embeggings ã® layer æ­£è¦åŒ–å¾Œã®å’Œã¨ã—ã¦è¨ˆç®—ã•ã‚Œã‚‹[1]ï¼š
(ã“ã“ã§ã®word $w$ ã¯ã€itemã‚’æ„å‘³ã™ã‚‹ã®ã§ã¯ãªãã€ã‚ã‚‹itemã®"item sentence" $T_i$ ã«å«ã¾ã‚Œã‚‹ä¸€ã¤ã®å˜èªã€ã¨ã„ã†èªè­˜ã§ã‚ã£ã¦ã‚‹ã ã‚ã†ã‹??:thinking:)

$$
\mathbf{E}_{w} = LayerNorm(\mathbf{A}_{w} + \mathbf{B}_{w} + \mathbf{C}_{w} + \mathbf{D}_{w})
\tag{2}
$$

where $\mathbf{E}_{w} \in \mathbb{R}^{d}$.
ã“ã“ã§ã€$\mathbf{E}_{w} \in \mathbb{R}^{d}$ã€‚
The embedding of model inputs ğ‘‹ is a sequence of Eğ‘¤,
ãƒ¢ãƒ‡ãƒ«å…¥åŠ› $X$ ã®embedding ã¯ã€$\mathbf{E}_{w}$ ã®sequenceã§ã‚ã‚‹ã€

$$
\mathbf{E}_{X} = [E_{[CLS]}, E_{w_1}, \cdots, E_{w_l}]
\tag{3}
$$

where $\mathbf{E}_{X} \in \mathbb{R}^{(l+1) \times d}$ and $l$ is the maximum length of tokens in a userâ€™s interaction sequence.
ã“ã“ã§ã€$\mathbf{E}_{X} \in \mathbb{R}^{(l+1) \times d}$ ã§ã‚ã‚Šã€$l$ ã¯ãƒ¦ãƒ¼ã‚¶ã®interaction sequence ã«ãŠã‘ã‚‹tokenã®æœ€å¤§é•·ã§ã‚ã‚‹ã€‚($s$ ã®æœ€å¤§é•·ã§ã¯ãªãã€$X$ ã®æœ€å¤§é•·...!)

### 2.2.3. Item or Sequence Representations. ã‚¢ã‚¤ãƒ†ãƒ ã¾ãŸã¯ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®è¡¨ç¾ã€‚

To encode Eğ‘‹ , we employ the bidirectional Transformer structure Longformer [2] as our encoder.
$E_{X}$ ã‚’ç¬¦å·åŒ–ã™ã‚‹ãŸã‚ã«ã€**åŒæ–¹å‘ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼æ§‹é€ Longformer [2]ã‚’encoderã¨ã—ã¦æ¡ç”¨**ã™ã‚‹ã€‚(Longformer = Long Document Transformer...!)
Because ğ‘‹ is usually a long sequence, the local windowed attention in Longformer can help us efficiently encode Eğ‘‹ .
**$X$ ã¯é€šå¸¸é•·ã„sequenceãªã®ã§ã€Longformerã®local windowed attention(?)ã¯ã€$E_{x}$ ã‚’åŠ¹ç‡çš„ã«encodeã™ã‚‹ã®ã«å½¹ç«‹ã¤**ã€‚(=å¯¾è±¡tokenã®ã™ãè¿‘ãã®tokené”ã«å¯¾ã™ã‚‹attention weightã®ã¿ã‚’ä¿æŒã™ã‚‹attention patternã€‚è¦ã¯sparceãªattention weight distributionã«ãªã‚‹å·¥å¤«!)
As the standard settings in Longformer for document understanding, the special token [CLS] has global attention but other tokens use the local windowed attention.
æ–‡æ›¸ç†è§£ã®ãŸã‚ã®Longformerã®æ¨™æº–è¨­å®šã¨ã—ã¦ã€ç‰¹åˆ¥ãªãƒˆãƒ¼ã‚¯ãƒ³[CLS]ã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’æŒã¤ãŒã€ä»–ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¯local windowed attentionã‚’ä½¿ã†ã€‚
Hence, Recformer computes ğ‘‘-dimensional word representations as follows:
ã—ãŸãŒã£ã¦ã€Recformerã¯æ¬¡ã®ã‚ˆã†ã« $d$ æ¬¡å…ƒã®å˜èªè¡¨ç¾ã‚’è¨ˆç®—ã™ã‚‹:

$$
[\mathbf{h}_{[CLS]}, \mathbf{h}_{w_1}, \cdots, \mathbf{h}_{w_l}]
= Longformer([E_{[CLS]}, E_{w_1}, \cdots, E_{w_l}])
\tag{4}
$$

where $\mathbf{h}_{w_1} \in \mathbb{R}^{d}$.
ã“ã“ã§ $\mathbf{h}_{w} \in \mathbb{R}^{d}$ ã§ã‚ã‚‹ã€‚
Similar to the language models used for sentence representations, the representation of the first token h[CLS] is used as the sequence representation.
**sentenceè¡¨ç¾ã«ä½¿ç”¨ã•ã‚Œã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã¨åŒæ§˜ã«ã€æœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³h[CLS]ã®è¡¨ç¾ãŒsequenceè¡¨ç¾ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã‚‹**ã€‚
In Recformer, we do not maintain an embedding table for items.
Recformerã§ã¯ã€**ã‚¢ã‚¤ãƒ†ãƒ ã®åŸ‹ã‚è¾¼ã¿ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä¿æŒã—ãªã„**ã€‚(Recformerã¯ID-freeãªãƒ¢ãƒ‡ãƒ«ã ã‹ã‚‰...!:thinking:)
Instead, we view the item as a special case of the interaction sequence with only one item.
ãã®ä»£ã‚ã‚Šã«ã€**æˆ‘ã€…ã¯ã‚¢ã‚¤ãƒ†ãƒ ã‚’ã€Œinteraction sequence $s$ ã«itemãŒä¸€ã¤ã—ã‹ç„¡ã„ã€ç‰¹åˆ¥ãªã‚±ãƒ¼ã‚¹ã¨ã¿ãªã™**ã€‚
For each item $i$, we construct its item â€œsentenceâ€ $T_{i}$ and use $X = \{[CLS],T_i\}$ as the model input to get the sequence representation h[CLS] as the item representation hğ‘– .
å„ã‚¢ã‚¤ãƒ†ãƒ  $i$ ã«ã¤ã„ã¦ã€ãã®item sentence $T_i$ ã‚’æ§‹æˆã—ã€$X = \{[CLS],T_i\}$ ã‚’ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ã¨ã—ã¦ã€sequenceè¡¨ç¾ $h_{[CLS]}$ ã‚’ã‚¢ã‚¤ãƒ†ãƒ è¡¨ç¾ $\mathbf{h}_{i}$ ã¨ã—ã¦å¾—ã‚‹ã€‚

### 2.2.4. Prediction. æ¨è«–

We predict the next item based on the cosine similarity between a userâ€™s interaction sequence ğ‘  and item ğ‘–.
ãƒ¦ãƒ¼ã‚¶ã®interaction sequence $s$ ã¨ã‚¢ã‚¤ãƒ†ãƒ  $i$ ã®cosine similarityã«åŸºã¥ã„ã¦æ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’äºˆæ¸¬ã™ã‚‹ã€‚
Formally, after obtaining the sequence representation hğ‘  and the item representation hğ‘– as introduced in Section 2.2.3, we calculate the scores between ğ‘  and ğ‘– as follows:
å½¢å¼çš„ã«ã¯ã€2.2.3ç¯€ã§ç´¹ä»‹ã—ãŸsequenceè¡¨ç¾ $\mathbf{h}_{s}$ ã¨itemè¡¨ç¾ $\mathbf{h}_{i}$ ã‚’å¾—ãŸå¾Œã€$s$ ã¨ $i$ ã®ã‚¹ã‚³ã‚¢ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«è¨ˆç®—ã™ã‚‹:

$$
r_{i, s} = \frac{\mathbf{h}_{i}^T \mathbf{h}_{s}}{|\mathbf{h}_{i}| \cdot |\mathbf{h}_{s}|}
\tag{5}
$$

where $r_{i, s} \in \mathbb{R}$ is the relevance of item $i$ being the next item given $s$.
ã“ã“ã§ã€$r_{i, s} \in \mathbb{R}$ ã¯ã€ğ‘ ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€item $i$ ãŒnext itemã§ã‚ã‚‹ã“ã¨ã®relevanceã§ã‚ã‚‹ã€‚
To predict the next item, we calculate ğ‘Ÿğ‘–,ğ‘  for all items 2 in the item set I and select item with the highest ğ‘Ÿğ‘–,ğ‘  as the next item:
æ¬¡ã®itemã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã«ã€itemã‚»ãƒƒãƒˆ $I$ ã®ã™ã¹ã¦ã®item ã«ã¤ã„ã¦ relevance ã‚’è¨ˆç®—ã—ã€æœ€ã‚‚é«˜ã„ relevance ã‚’æŒã¤itemã‚’next-itemã¨ã—ã¦é¸æŠã™ã‚‹:
(äºˆã‚å…¨ã¦ã®itemã‚’encode=itemè¡¨ç¾ã‚’å–å¾—ã—ã¦ãŠãã¨ã€åŠ¹ç‡çš„ã«ã‚¹ã‚³ã‚¢è¨ˆç®—ã§ãã‚‹)

$$
\hat{i}_{s} = argmax_{i \in I} (r_{i, s})
\tag{6}
$$

where $\hat{i}_{s}$ is the predicted item given user interaction sequence ğ‘ .
ã“ã“ã§ã€$\hat{i}_{s}$ ã¯user interaction sequence $s$ ã‹ã‚‰äºˆæ¸¬ã•ã‚Œã‚‹itemã§ã‚ã‚‹ã€‚

## 2.3. Learning Framework å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

To have an effective and efficient language model for the sequential recommendation, we propose our learning framework for Recformer including pre-training and two-stage finetuning.
é€æ¬¡æ¨è–¦ã®ãŸã‚ã®åŠ¹æœçš„ã§åŠ¹ç‡çš„ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æŒã¤ãŸã‚ã«ã€äº‹å‰å­¦ç¿’ã¨2æ®µéšã®fine-tuningã‚’å«ã‚€Recformerã®å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã™ã‚‹ã€‚

### 2.3.1. Pre-training. äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

The target of pre-training is to obtain a highquality parameter initialization for downstream tasks.
**äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ç›®çš„ã¯ã€ä¸‹æµã‚¿ã‚¹ã‚¯ã®ãŸã‚ã®é«˜å“è³ªãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆæœŸåŒ–ã‚’å¾—ã‚‹ã“ã¨**ã§ã‚ã‚‹ã€‚
Different from previous sequential recommendation pre-training methods which consider only recommendations, we need to consider both language understanding and recommendations.
æ¨è–¦ã®ã¿ã‚’è€ƒæ…®ã—ãŸå¾“æ¥ã®é€æ¬¡ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³äº‹å‰å­¦ç¿’æ³•ã¨ã¯ç•°ãªã‚Šã€è¨€èªç†è§£ã¨ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ä¸¡æ–¹ã‚’è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
Hence, to pre-train Recformer, we adopt two tasks: (1) Masked Language Modeling (MLM) and (2) an item-item contrastive task.
ãã“ã§ã€Recformerã‚’äº‹å‰ã«å­¦ç¿’ã•ã›ã‚‹ãŸã‚ã«ã€2ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’æ¡ç”¨ã—ãŸï¼š
**(1)ãƒã‚¹ã‚¯è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°(MLM)** ã¨ **(2)item-item contrastive**ã‚¿ã‚¹ã‚¯ã§ã‚ã‚‹ã€‚

Masked Language Modeling (MLM) [6] is an effective pre-training method for language understanding and has been widely used for various NLP pre-training tasks such as sentence understanding [8], phrase understanding [18].
ãƒã‚¹ã‚¯è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°(MLM)[6]ã¯ã€è¨€èªç†è§£ã®ãŸã‚ã®åŠ¹æœçš„ãªäº‹å‰å­¦ç¿’æ‰‹æ³•ã§ã‚ã‚Šã€æ–‡ã®ç†è§£[8]ã€ãƒ•ãƒ¬ãƒ¼ã‚ºã®ç†è§£[18]ãªã©ã€æ§˜ã€…ãªNLPã®äº‹å‰å­¦ç¿’ã‚¿ã‚¹ã‚¯ã«åºƒãåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚
Adding MLM as an auxiliary task will prevent language models from forgetting the word semantics when models are jointly trained with other specific tasks.
**è£œåŠ©ã‚¿ã‚¹ã‚¯ã¨ã—ã¦MLMã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ãŒä»–ã®ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã¨å…±åŒã§å­¦ç¿’ã•ã‚Œã‚‹éš›ã«ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒå˜èªã®æ„å‘³ã‚’å¿˜ã‚Œã¦ã—ã¾ã†ã“ã¨ã‚’é˜²ãã“ã¨ãŒã§ãã‚‹**ã€‚
For recommendation tasks, MLM can also eliminate the language domain gap between a general language corpus and item texts.
æ¨è–¦ã‚¿ã‚¹ã‚¯ã®å ´åˆã€MLMã¯ä¸€èˆ¬çš„ãªè¨€èªã‚³ãƒ¼ãƒ‘ã‚¹ã¨ã‚¢ã‚¤ãƒ†ãƒ ãƒ†ã‚­ã‚¹ãƒˆã¨ã®é–“ã®è¨€èªãƒ‰ãƒ¡ã‚¤ãƒ³ã‚®ãƒ£ãƒƒãƒ—ã‚’ãªãã™ã“ã¨ã‚‚ã§ãã‚‹ã€‚
In particular, following BERT [6], the training data generator chooses 15% of the token positions at random for prediction.
**ç‰¹ã«ã€BERT [6]ã«å¾“ã„ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨ã¯token positionsã®15%ã‚’äºˆæ¸¬ç”¨ã«ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã™ã‚‹ã€‚(ãƒ©ãƒ³ãƒ€ãƒ ã«maskã™ã‚‹ã€‚masked-token-predictionã‚¿ã‚¹ã‚¯!)**
If the token is selected, we replace the token with (1) the [MASK] with probability 80%; (2) a random token with probability 10%; (3) the unchanged token with probability 10%.
ãƒˆãƒ¼ã‚¯ãƒ³ãŒé¸æŠã•ã‚ŒãŸå ´åˆã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚’(1) 80%ã®ç¢ºç‡ã§[MASK]ã€(2) 10%ã®ç¢ºç‡ã§ãƒ©ãƒ³ãƒ€ãƒ ãªãƒˆãƒ¼ã‚¯ãƒ³ã€(3) 10%ã®ç¢ºç‡ã§å¤‰æ›´å‰ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«ç½®ãæ›ãˆã‚‹ã€‚
The MLM loss is calculated as:
MLMã®æå¤±ã¯æ¬¡ã®ã‚ˆã†ã«è¨ˆç®—ã•ã‚Œã‚‹ï¼š

$$
\mathbf{m} = LayerNorm(GELU(\mathbf{W}_h \mathbf{h}_w + \mathbf{b}_h))
\tag{7}
$$

$$
p = Softmax(\mathbf{W}_0 \mathbf{m} + \mathbf{b}_0)
\tag{8}
$$

$$
L_{MLM} = - \sum_{i=0}^{|V|} y_{i} \log(p_{i})
\tag{9}
$$

where $\mathbf{W}_h \in \mathbb{R}^{d \times d}$, $\mathbf{b}_h \in \mathbb{R}^{d}$ , $\mathbf{W}_0 \in \mathbb{R}^{|V| \times d}$, $\mathbf{b}_0 \in \mathbb{R}^{|V|}$ , GELU is the GELU activation function [10] and $V$ is the vocabulary used in the language model.

Another pre-training task for Recformer is the item-item contrastive (IIC) task which is widely used in the next item prediction for recommendations.
Recformerã®ã‚‚ã†ä¸€ã¤ã®äº‹å‰å­¦ç¿’ã‚¿ã‚¹ã‚¯ã¯ã€**ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®æ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ äºˆæ¸¬ã«åºƒãä½¿ã‚ã‚Œã¦ã„ã‚‹IICï¼ˆitem-item contrastiveï¼‰ã‚¿ã‚¹ã‚¯**ã§ã‚ã‚‹ã€‚
We use the ground-truth next items as positive instances following previous works [12, 14, 27].
æˆ‘ã€…ã¯ã€å…ˆè¡Œç ”ç©¶[12, 14, 27](=æœ‰åãªself-attentionå‹é€æ¬¡æ¨è–¦ã®æ—¢å­˜ç ”ç©¶é”!)ã«å¾“ã„ã€**ground-truthã§ã‚ã‚‹next-itemã‚’ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹(=positive example)ã¨ã—ã¦ä½¿ç”¨**ã™ã‚‹ã€‚
However, for negative instances, we adopt in-batch next items as negative instances instead of negative sampling [14] or fully softmax [12, 27].
ãŸã ã—ã€è² ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«ã¤ã„ã¦ã¯ã€è² ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°[14]ã‚„å®Œå…¨ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹[12, 27]ã®ä»£ã‚ã‚Šã«ã€**in-batch next itemsã‚’è² ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹(=negative example)ã¨ã—ã¦æ¡ç”¨ã™ã‚‹**ã€‚(in-batch next-items = ãŸã¶ã‚“åŒã˜batchå†…ã®ä»–ã®training examplesã®ground truthã®äº‹??:thinking: å¾Œè¿°ã•ã‚Œã¦ã‚‹ã‘ã©ã€false negativeã«ãªã‚‹å¯èƒ½æ€§ã¯ã‚ã‚‹ã‚ˆã­...!!)
Previous recommenders maintain an item embedding table, hence they can easily retrieve item embeddings for training and update embeddings.
ã“ã‚Œã¾ã§ã®æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã¯ã€itemåŸ‹ã‚è¾¼ã¿ãƒ†ãƒ¼ãƒ–ãƒ«(=ID-embeddingã®vocabularyçš„ãª??)ã‚’ä¿æŒã—ã¦ãŠã‚Šã€å­¦ç¿’ã‚„åŸ‹ã‚è¾¼ã¿æ›´æ–°ã®ãŸã‚ã«itemåŸ‹ã‚è¾¼ã¿ã‚’ç°¡å˜ã«å–ã‚Šå‡ºã™ã“ã¨ãŒã§ãã‚‹ã€‚
In our case, item embeddings are from Recformer, so it is infeasible to re-encode items (from sampling or full set) per batch for training.
ç§ãŸã¡ã®å ´åˆã€itemåŸ‹ã‚è¾¼ã¿ã¯Recformerã«ã‚ˆã‚‹ã‚‚ã®ã§ã‚ã‚‹ãŸã‚ã€å­¦ç¿’ã®ãŸã‚ã«ãƒãƒƒãƒã”ã¨ã«(ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¾ãŸã¯ãƒ•ãƒ«ã‚»ãƒƒãƒˆã‹ã‚‰)item ã‚’å†encodeã™ã‚‹ã“ã¨ã¯ä¸å¯èƒ½ã§ã‚ã‚‹ã€‚
In-batch negative instances [3] are using ground truth items of other instance sequences in the same batch as negative items.
**ãƒãƒƒãƒå†…è² ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹[3]ã¯ã€è² ã‚¢ã‚¤ãƒ†ãƒ ã¨ã—ã¦ã€åŒã˜ãƒãƒƒãƒå†…ã®ä»–ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®ã‚°ãƒ©ãƒ³ãƒ‰ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ã‚¢ã‚¤ãƒ†ãƒ ã‚’ä½¿ç”¨ã™ã‚‹**ã€‚
Although it is possible to provide false negatives, false negatives are less likely in the pre-training dataset with a large size.
å½é™°æ€§(=æœ¬å½“ã¯positiveãªã®ã«negativeã¨ã—ã¦ãƒ©ãƒ™ãƒ«ä»˜ã‘ã—ã¦ã—ã¾ã†ã‚±ãƒ¼ã‚¹)ã‚’æä¾›ã™ã‚‹å¯èƒ½æ€§ã¯ã‚ã‚‹ãŒã€ã‚µã‚¤ã‚ºãŒå¤§ãã„äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯å½é™°æ€§ã®å¯èƒ½æ€§ã¯ä½ã„ã€‚
Furthermore, the target of pre-training is to provide high-quality initialized parameters and we have the finetuning with accurate supervision for downstream tasks.
ã•ã‚‰ã«ã€**äº‹å‰å­¦ç¿’ã®ç›®æ¨™ã¯ã€é«˜å“è³ªã®åˆæœŸåŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æä¾›ã™ã‚‹ã“ã¨**ã§ã‚ã‚Šã€ä¸‹æµã®ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã«æ­£ç¢ºãªç›£è¦–ã«ã‚ˆã‚‹fine-tuningã‚’è¡Œã†ã€‚
Therefore, we claim that inbatch negatives will not hurt the recommendation performance but have much higher training efficiency than accurate supervision.
ã—ãŸãŒã£ã¦ã€**in-batch negatives ã¯æ¨è–¦æ€§èƒ½ã‚’æãªã‚ãšã€æ­£ç¢ºãªç›£è¦–ã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«é«˜ã„å­¦ç¿’åŠ¹ç‡ãŒå¾—ã‚‰ã‚Œã‚‹ã¨ä¸»å¼µ**ã™ã‚‹ã€‚
Formally, the item-item contrastive loss is calculated as:
æ­£å¼ã«ã¯ã€item-item contrastiveã‚¿ã‚¹ã‚¯ã®æå¤±ã¯æ¬¡ã®ã‚ˆã†ã«è¨ˆç®—ã•ã‚Œã‚‹ï¼š

$$
L_{IIC} = - \log \frac{
    e^{sim(h_s, h_{i}^{+}) / \tau}
    }{
    \sum_{i \in \mathcal{B}} e^{sim(h_s, h_{i}) / \tau}
}
\tag{10}
$$

where sim is the similarity introduced in Equation (5); h + ğ‘– is the representation of the ground truth next item; B is the ground truth item set in one batch and ğœ is a temperature parameter.
ã“ã“ã§ã€simã¯å¼(5)ã§å°å…¥ã•ã‚ŒãŸé¡ä¼¼åº¦ã§ã‚ã‚Šã€$h_{i}^{+}$ ã¯ground-truthã®next-itemè¡¨ç¾ã§ã‚ã‚Šã€$\mathcal{B}$ ã¯1 batchã§è¨­å®šã•ã‚ŒãŸ ground-truth items ã§ã‚ã‚Šã€$\tau$ ã¯**temperatureãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**ã§ã‚ã‚‹ã€‚

At the pre-training stage, we use a multi-task training strategy to jointly optimize Recformer:
äº‹å‰å­¦ç¿’æ®µéšã§ã¯ã€**ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’æˆ¦ç•¥ã‚’ç”¨ã„ã¦Recformerã‚’å…±åŒæœ€é©åŒ–ã™ã‚‹**:

$$
L_{pre-training} = L_{IIC} + \lambda L_{MLM}
\tag{11}
$$

where ğœ† is a hyper-parameter to control the weight of MLM task loss.
ã“ã“ã§ã€$\lambda$ ã¯MLMã‚¿ã‚¹ã‚¯lossã®é‡ã¿ã‚’åˆ¶å¾¡ã™ã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚ã‚‹ã€‚
The pre-trained model will be fine-tuned for new scenarios.
äº‹å‰ã«è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€æ–°ã—ã„ã‚·ãƒŠãƒªã‚ªã®ãŸã‚ã«fine-tuningã•ã‚Œã‚‹ã€‚

### 2.3.2. Two-Stage Finetuning. 2æ®µéšã®å¾®èª¿æ•´ã€‚

![algo1]()

Similar to pre-training, we do not maintain an independent item embedding table.
äº‹å‰å­¦ç¿’ã¨åŒæ§˜ã«ã€ç‹¬ç«‹ã—ãŸã‚¢ã‚¤ãƒ†ãƒ åŸ‹ã‚è¾¼ã¿ãƒ†ãƒ¼ãƒ–ãƒ«ã¯ä¿æŒã—ãªã„ã€‚(ID-freeãªæ‰‹æ³•ãªã®ã§...!)
Instead, we encode items by Recformer.
ãã®ä»£ã‚ã‚Šã«ã€Recformerã«ã‚ˆã£ã¦ã‚¢ã‚¤ãƒ†ãƒ ã‚’encodeã™ã‚‹ã€‚(item "sentence"ã‚’ä½¿ã†ã‚“ã ã‚ˆã­...!)
However, in-batch negatives cannot provide accurate supervision in a small dataset because it is likely to have false negatives which undermine recommendation performance.
ã—ã‹ã—ã€in-batch negative(æ‰‹æ³•)ã¯ã€æ¨è–¦æ€§èƒ½ã‚’æãªã†false-negativeãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ãŸã‚ã€å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯æ­£ç¢ºãªç›£è¦–ã‚’æä¾›ã§ããªã„ã€‚(pre-trainingã§ã¯ãƒ‡ãƒ¼ã‚¿ãŒå¤šã„ã‹ã‚‰OKã ã‘ã©...!)
To solve this problem, we propose two-stage finetuning as shown in Algorithm 1.
ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 1ã«ç¤ºã™ã‚ˆã†ãª2æ®µéšã®å¾®èª¿æ•´ã‚’ææ¡ˆã™ã‚‹ã€‚
The key idea is to maintain an item feature matrix $I \in \mathbb{R}^{|I| \times d}$.
é‡è¦ãªã‚¢ã‚¤ãƒ‡ã‚¢ã¯ã€item feature matrix $\mathbf{I} \in \mathbb{R}^{|I| \times d}$ ã‚’ç¶­æŒã™ã‚‹äº‹ã§ã‚ã‚‹ã€‚
Different from the item embedding table, I is not learnable and all item features are encoded from Recformer.
ã‚¢ã‚¤ãƒ†ãƒ åŸ‹ã‚è¾¼ã¿ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã¯ç•°ãªã‚Šã€$I$ ã¯å­¦ç¿’å¯èƒ½ã§ã¯ãªãã€ã™ã¹ã¦ã®item featureã¯Recformerã‹ã‚‰ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã€‚(item featureã£ã¦ $\mathbf{h}_{i}$ ã®äº‹??)
As shown in Algorithm 1, our proposed finetuning method has two stages.
ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 1ã«ç¤ºã™ã‚ˆã†ã«ã€æˆ‘ã€…ã®ææ¡ˆã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ³•ã«ã¯2ã¤ã®æ®µéšãŒã‚ã‚‹ã€‚
In stage 1, I is updated (line 4) per epoch,3 whereas, in stage 2 we freeze I and update only parameters in model ğ‘€.
ã‚¹ãƒ†ãƒ¼ã‚¸1ã§ã¯ã€$\mathbf{I}$ ã¯epochã”ã¨ã«æ›´æ–°ã•ã‚Œã‚‹(4è¡Œç›®)ãŒã€ã‚¹ãƒ†ãƒ¼ã‚¸2ã§ã¯ $\mathbf{I}$ ã‚’å‡çµã—ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $M$ ã®ã¿ã‚’æ›´æ–°ã™ã‚‹ã€‚
(ã“ã“ã§æ›´æ–°ã¨ã¯ã€å…¨ã¦ã®itemã‚’Recformerã§encodeã™ã‚‹ã“ã¨ã‚’æ„å‘³ã™ã‚‹)
The basic idea is that although the model is already pre-trained, item representations from the pre-trained model can still be improved by further training on downstream datasets.
åŸºæœ¬çš„ãªè€ƒãˆæ–¹ã¯ã€ãƒ¢ãƒ‡ãƒ«ã¯ã™ã§ã«äº‹å‰å­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ãŒã€**äº‹å‰å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®itemè¡¨ç¾ã¯ã€ä¸‹æµã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã•ã‚‰ã«è¨“ç·´ã™ã‚‹ã“ã¨ã§æ”¹å–„ã§ãã‚‹**ã¨ã„ã†ã“ã¨ã§ã‚ã‚‹ã€‚(ã†ã‚“ã†ã‚“ã€‚ãã‚Šã‚ƒãã†ã˜ã‚ƒãªã„??:thinking:)
It is expensive to re-encode all items in every batch hence we re-encode all items in every epoch to update I (line 4) and use I as supervision for item-item contrastive learning (line 5).
batchã”ã¨ã«å…¨itemã‚’å†encodeã™ã‚‹ã®ã¯ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã®ã§ã€epochã”ã¨ã«å…¨itemã‚’å†encodeã—ã¦ $\mathbf{I}$ ã‚’æ›´æ–°ã—(4è¡Œç›®)ã€$\mathbf{I}$ ã‚’item-item contrastiveå­¦ç¿’ã®supervisionã¨ã—ã¦ä½¿ç”¨ã™ã‚‹(5è¡Œç›®)(supervisionã£ã¦ä½•?)ã€‚
After obtaining the best item representations, we re-initialize the model with the corresponding parameters (line 12) and start stage 2.
æœ€é©ãªitemè¡¨ç¾ãŒå¾—ã‚‰ã‚ŒãŸã‚‰ã€å¯¾å¿œã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’å†åˆæœŸåŒ–ã—(12è¡Œç›®)ã€ã‚¹ãƒ†ãƒ¼ã‚¸2ã‚’é–‹å§‹ã™ã‚‹ã€‚
Since I keeps updating in stage 1, the supervision for finetuning is also changing.
ç¬¬1ã‚¹ãƒ†ãƒ¼ã‚¸ã§ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã‚’ç¹°ã‚Šè¿”ã—ã¦ã„ã‚‹ã®ã§ã€fine-tuningã®ãŸã‚ã®supervisionã‚‚å¤‰ã‚ã£ã¦ãã¦ã„ã‚‹ã€‚
In this case, the model is hard to be optimized to have the best performance.
ã“ã®å ´åˆã€bestãªæ€§èƒ½ã‚’æŒã¤ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«ã‚’æœ€é©åŒ–ã™ã‚‹ã®ã¯é›£ã—ã„ã€‚(supervision=ç›£ç£ãŒãã®éƒ½åº¦å¤‰ã‚ã‚‹ã‹ã‚‰??)
Therefore, we freeze I and continue training the model until achieving the best performance on the validation dataset.
ãã“ã§ã€$\mathbf{I}$ ã‚’å‡çµã—ã€**æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ€é«˜ã®æ€§èƒ½ã‚’é”æˆã™ã‚‹ã¾ã§ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‚’ç¶šã‘ã‚‹**ã€‚

The learning task used in finetuning is item-item contrastive learning which is the same as pre-training but with fully softmax instead of in-batch negatives.
ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ä½¿ç”¨ã•ã‚Œã‚‹å­¦ç¿’ã‚¿ã‚¹ã‚¯ã¯item-item contrastiveå­¦ç¿’ã§ã‚ã‚Šã€ã“ã‚Œã¯äº‹å‰å­¦ç¿’ã¨åŒã˜ã§ã‚ã‚‹ãŒã€in-batch negativeæ‰‹æ³•ã®ä»£ã‚ã‚Šã«fully softmax(=negative exampleã‚’å¾—ã‚‹ç‚ºã®åˆ¥ã®æ‰‹æ³•??)ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
The finetuning loss is calculated as:
å¾®èª¿æ•´ãƒ­ã‚¹ã¯æ¬¡ã®ã‚ˆã†ã«è¨ˆç®—ã•ã‚Œã‚‹ï¼š

$$
L_{fine-tuning} = - \log \frac{e^{sim(\mathbf{h}_s, \mathbf{I}_{i}^{+}) / \tau}}{\sum_{i \in \mathcal{I}} e^{sim(\mathbf{h}_s, \mathbf{I}_{i}) / \tau}}
\tag{12}
$$

where Iğ‘– is the item feature of item ğ‘–.
ã“ã“ã§ã€$\mathbf{I}_{i}$ ã¯item $i$ ã®item featureã§ã‚ã‚‹ã€‚(Recformerã«ã‚ˆã£ã¦encodeã•ã‚ŒãŸã‚¢ã‚¤ãƒ†ãƒ è¡¨ç¾ $\mathbf{h}_{i}$ ã¨ã„ã†èªè­˜ã§ã‚ã£ã¦ã‚‹?)

## 2.4. Discussion

In this section, we briefly compare Recformer to other sequential recommendation methods to highlight the novelty of our method.
ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€Recformerã¨ä»–ã®é€æ¬¡æ¨è–¦æ³•ã‚’ç°¡å˜ã«æ¯”è¼ƒã—ã€æˆ‘ã€…ã®æ‰‹æ³•ã®æ–°è¦æ€§ã‚’å¼·èª¿ã™ã‚‹ã€‚

**Traditional sequential recommenders** such as GRU4Rec [11], SASRec [14] and BERT4Rec [27] rely on item IDs and corresponding trainable item embeddings to train a sequential model for recommendations.
GRU4Rec [11]ã€SASRec [14]ã€BERT4Rec [27]ã®ã‚ˆã†ãªå¾“æ¥ã®é€æ¬¡ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã¯ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ãŸã‚ã®é€æ¬¡ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã«ã€**ã‚¢ã‚¤ãƒ†ãƒ IDã¨å¯¾å¿œã™ã‚‹å­¦ç¿’å¯èƒ½ãªã‚¢ã‚¤ãƒ†ãƒ åŸ‹ã‚è¾¼ã¿ã«ä¾å­˜ã—ã¦ã„ã‚‹**ã€‚
These item embeddings are learned from sequential patterns of user interactions.
ã“ã‚Œã‚‰ã®ã‚¢ã‚¤ãƒ†ãƒ åŸ‹ã‚è¾¼ã¿ã¯ã€ãƒ¦ãƒ¼ã‚¶ã¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã®é€£ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰å­¦ç¿’ã•ã‚Œã‚‹ã€‚
However, as mentioned in [20], these approaches suffer from data sparsity and can not perform well with cold-start items.
ã—ã‹ã—ã€[20]ã§è¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€ã“ã‚Œã‚‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ãƒ‡ãƒ¼ã‚¿ã®sparseæ€§ã«æ‚©ã¾ã•ã‚Œã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã§ã¯ã†ã¾ãæ©Ÿèƒ½ã—ãªã„ã€‚

To reduce the dependence on item IDs, **some context-aware sequential recommenders** such as UniSRec [12], S3-Rec [38], ZESRec [7] are proposed to incorporate side information (e.g., categories, titles) as prior knowledge for recommendations.
**ã‚¢ã‚¤ãƒ†ãƒ IDã¸ã®ä¾å­˜ã‚’æ¸›ã‚‰ã™ãŸã‚ã«**ã€UniSRec [12]ã€S3 -Rec [38]ã€ZESRec [7]ã®ã‚ˆã†ãª**context-awareãªé€æ¬¡æ¨è–¦å™¨**ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚
All of these approaches rely on a feature extractor such as BERT [6] to obtain item feature vectors and then fuse these vectors into item representations with an independent sequential model.
ã“ã‚Œã‚‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã™ã¹ã¦ã€**BERT [6]ã®ã‚ˆã†ãªç‰¹å¾´æŠ½å‡ºå™¨ã«ä¾å­˜**ã—ã¦ã€itemç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—ã—ã€æ¬¡ã«ã“ã‚Œã‚‰ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç‹¬ç«‹é€æ¬¡ãƒ¢ãƒ‡ãƒ«ã§itemè¡¨ç¾ã«èåˆã™ã‚‹ã€‚

In this paper, we explore conducting sequential recommendations in a new paradigm that learns language representations for the next item recommendations.
æœ¬ç¨¿ã§ã¯ã€**next-itemã‚’æ¨è–¦ã™ã‚‹ãŸã‚ã®è¨€èªè¡¨ç¾ã‚’å­¦ç¿’ã™ã‚‹æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ **ã§ã€é€æ¬¡æ¨è–¦ã‚’è¡Œã†ã“ã¨ã‚’æ¢æ±‚ã™ã‚‹ã€‚
Instead of trainable item embeddings or fixed item features from language models, we bridge the gap between natural language understanding and sequential recommendation to directly learn representations of items and user sequences based on words.
å­¦ç¿’å¯èƒ½ãªitemåŸ‹ã‚è¾¼ã¿ã‚„è¨€èªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å›ºå®šitemç‰¹å¾´ã®ä»£ã‚ã‚Šã«ã€è‡ªç„¶è¨€èªç†è§£ã¨sequentialæ¨è–¦ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã€**å˜èªã«åŸºã¥ã„ã¦itemã¨user sequenceã®è¡¨ç¾ã‚’ç›´æ¥å­¦ç¿’ã™ã‚‹**ã€‚
We expect the generality of natural language can improve the transferability of recommenders in order to benefit new domain adaptation and cold-start item understanding
è‡ªç„¶è¨€èªã®ä¸€èˆ¬æ€§ã¯ã€æ–°ãŸãªãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œã‚„ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã®itemç†è§£ã®ãŸã‚ã«ã€**ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã®ç§»æ¤æ€§(transferability)ã‚’å‘ä¸Š(cross-domainæ¨è–¦ã®è©±...!)**ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã¨æœŸå¾…ã—ã¦ã„ã‚‹ã€‚

# 3. Experiments å®Ÿé¨“

In this section, we empirically show the effectiveness of our proposed model Recformer and learning framework.
ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€æˆ‘ã€…ã®ææ¡ˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«Recformerã¨å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æœ‰åŠ¹æ€§ã‚’å®Ÿè¨¼çš„ã«ç¤ºã™ã€‚

## 3.1. Experimental Setup å®Ÿé¨“ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 3.1.1. Datasets. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

![table1]()

To evaluate the performance of Recformer, we conduct pre-training and finetuning on different categories of Amazon review datasets [22].
Recformerã®æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€æˆ‘ã€…ã¯Amazonãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç•°ãªã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«å¯¾ã—ã¦äº‹å‰å­¦ç¿’ã¨å¾®èª¿æ•´ã‚’è¡Œã£ãŸ[22]ã€‚
The statistics of datasets after preprocessing are shown in Table 1.
å‰å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±è¨ˆã‚’è¡¨1ã«ç¤ºã™ã€‚

**For pre-training**, seven categories are selected as training data including â€œAutomotiveâ€, â€œCell Phones and Accessoriesâ€, â€œClothing Shoes and Jewelryâ€, â€œElectronicsâ€, â€œGrocery and Gourmet Foodâ€, â€œHome and Kitchenâ€, â€œMovies and TVâ€, and one category â€œCDs and Vinylâ€ is left out as validation data.
äº‹å‰å­¦ç¿’ã§ã¯ã€ã€Œè‡ªå‹•è»Šã€ã€ã€Œæºå¸¯é›»è©±ãƒ»ã‚¢ã‚¯ã‚»ã‚µãƒªãƒ¼ã€ã€ã€Œè¡£é¡ãƒ»é´ãƒ»å®é£¾å“ã€ã€ã€Œé›»å­æ©Ÿå™¨ã€ã€ã€Œé£Ÿæ–™å“ãƒ»ã‚°ãƒ«ãƒ¡é£Ÿå“ã€ã€ã€Œå®¶åº­ãƒ»å°æ‰€ã€ã€ã€Œæ˜ ç”»ãƒ»ãƒ†ãƒ¬ãƒ“ã€ã®**7ã‚«ãƒ†ã‚´ãƒªã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦é¸æŠ**ã—ã€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã€ŒCDãƒ»ãƒ¬ã‚³ãƒ¼ãƒ‰ã€ã®1ã‚«ãƒ†ã‚´ãƒªã‚’é™¤å¤–ã—ãŸã€‚
Datasets from these categories are used as source domain datasets.
ã“ã‚Œã‚‰ã®ã‚«ãƒ†ã‚´ãƒªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã€ã‚½ãƒ¼ã‚¹ãƒ»ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã‚‹ã€‚

**For fine-tuning**, we select six categories including â€œIndustrial and Scientificâ€, â€œMusical Instrumentsâ€, â€œArts, Crafts and Sewingâ€, â€œOffice Productsâ€, â€œVideo Gamesâ€, â€œPet Suppliesâ€, as target domain datasets to evaluate Recformer.
Recformerã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€"Industrial and Scientific"ã€"Musical Instruments"ã€"Arts, Crafts and Sewing"ã€"Office Products"ã€"Video Games"ã€"Pet Supplies "ã®6ã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ»ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã—ã¦é¸æŠã™ã‚‹ã€‚

For pre-training and finetuning, we use the five-core datasets provided by the data source and filter items whose title is missing.
äº‹å‰å­¦ç¿’ã¨fine-tuningã«ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰æä¾›ã•ã‚ŒãŸ5ã‚³ã‚¢ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã€ã‚¿ã‚¤ãƒˆãƒ«ãŒæ¬ è½ã—ã¦ã„ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã€‚
Then we group the interactions by users and sort them by timestamp ascendingly.
æ¬¡ã«ã€ãƒ¦ãƒ¼ã‚¶ã”ã¨ã«interactionã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®æ˜‡é †ã§ã‚½ãƒ¼ãƒˆã™ã‚‹ã€‚(=sequentialãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹ã€‚)
Following previous work [12], we select item attributes title, categories and brand as key-value pairs for items.
å…ˆè¡Œç ”ç©¶[12]ã«å¾“ã„ã€**ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚¿ã‚¤ãƒˆãƒ«ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã€ãƒ–ãƒ©ãƒ³ãƒ‰ã®å±æ€§ã‚’ã‚¢ã‚¤ãƒ†ãƒ ã®key-valueãƒšã‚¢ã¨ã—ã¦é¸æŠ**ã™ã‚‹ã€‚

### 3.1.2. Baselines. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³

We compare three groups of works as our baselines which include methods with only item IDs; methods using item IDs and treating item text as side information; and methods using only item texts as inputs.
æˆ‘ã€…ã¯**3ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—**ã‚’ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã—ã¦æ¯”è¼ƒã™ã‚‹: ã‚¢ã‚¤ãƒ†ãƒ IDã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã€ã‚¢ã‚¤ãƒ†ãƒ IDã‚’ä½¿ç”¨ã—item textã‚’ã‚µã‚¤ãƒ‰æƒ…å ±ã¨ã—ã¦æ‰±ã†æ–¹æ³•ã€ã‚¢ã‚¤ãƒ†ãƒ ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’å…¥åŠ›ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã€‚

#### (1) ID-Only methods:

- GRU4Rec [11] adopts RNNs to model user action sequences for session-based recommendations. We treat each userâ€™s interaction sequence as a session.
- GRU4Rec [11]ã¯ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®æ¨è–¦ã®ãŸã‚ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¡Œå‹•ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ãŸã‚ã«RNNã‚’æ¡ç”¨ã™ã‚‹ã€‚å„ãƒ¦ãƒ¼ã‚¶ã®å¯¾è©±ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¨ã—ã¦æ‰±ã†ã€‚
- SASRec [14] uses a directional self-attentive model to capture item correlations within a sequence.
- SASRec [14]ã¯ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å†…ã®ã‚¢ã‚¤ãƒ†ãƒ ã®ç›¸é–¢ã‚’æ•æ‰ã™ã‚‹ãŸã‚ã«ã€æ–¹å‘æ€§ã®ã‚ã‚‹è‡ªå·±æ³¨è¦–ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã‚‹ã€‚
- BERT4Rec [27] employs a bi-directional self-attentive model with the cloze objective for modeling user behavior sequences.
- BERT4Rec [27]ã¯ã€ãƒ¦ãƒ¼ã‚¶ã®è¡Œå‹•ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ãŸã‚ã«ã€ã‚¯ãƒ­ãƒ¼ã‚ºç›®çš„ã«ã‚ˆã‚‹åŒæ–¹å‘è‡ªå·±æ³¨æ„ãƒ¢ãƒ‡ãƒ«ã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚
- RecGURU [16] proposes to pre-train sequence representations with an autoencoder in an adversarial learning paradigm. We do not consider overlapped users for this method in our setting.
- RecGURU[16]ã¯ã€æ•µå¯¾çš„å­¦ç¿’ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã«ãŠã„ã¦ã€ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’ç”¨ã„ã¦ã‚·ãƒ¼ã‚±ãƒ³ã‚¹è¡¨ç¾ã‚’äº‹å‰å­¦ç¿’ã™ã‚‹ã“ã¨ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚ã“ã®æ–¹æ³•ã§ã¯ã€é‡è¤‡ãƒ¦ãƒ¼ã‚¶ã¯è€ƒæ…®ã—ãªã„ã€‚

#### (2) ID-Text methods:

- FDSA [37] uses a self-attentive model to capture item and feature transition patterns. FDSA[37]ã¯ã€itemã¨featureã®é·ç§»ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ•æ‰ã™ã‚‹ãŸã‚ã«è‡ªå·±æ³¨æ„ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
- S3 -Rec [38] pre-trains sequential models with mutual information maximization to learn the correlations among attributes, items, subsequences, and sequences. S3-Rec [38] ã¯ã€å±æ€§ã€ã‚¢ã‚¤ãƒ†ãƒ ã€ã‚µãƒ–ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é–“ã®ç›¸é–¢ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã«ã€ç›¸äº’æƒ…å ±æœ€å¤§åŒ–ã§é€æ¬¡ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰å­¦ç¿’ã™ã‚‹ã€‚

#### (3) Text-Only methods:

- ZESRec [7] encodes item texts with a pre-trained language model as item features. We pre-train this method and finetune the model on six downstream datasets. ZESRec [7]ã¯**äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«(sentence BERTã¨ã‹?)ã‚’item featureã¨ã—ã¦ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹**(ã“ã‚Œã¯æ¥½ãã†...!OpenAIã®APIã‚’ä½¿ã£ã¦ä½œã£ãŸembeddingã§ã‚‚è‰¯ã„ã®ã‹ãª)ã€‚æˆ‘ã€…ã¯ã“ã®æ‰‹æ³•ã‚’äº‹å‰å­¦ç¿’ã—ã€6ã¤ã®ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã¦ã„ã‚‹ã€‚
- UniSRec [12] uses textual item representations from a pretrained language model and adapts to a new domain using an MoE-enhance adaptor. We initialize the model with the pre-trained parameters provided by the authors and finetune the model on target domains. UniSRec[12]ã¯**äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«(sentence BERTã¨ã‹?)ã‹ã‚‰ã‚¢ã‚¤ãƒ†ãƒ ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¾ã‚’ä½¿ç”¨**ã—ã€MoE-enhanceã‚¢ãƒ€ãƒ—ã‚¿ã‚’ä½¿ç”¨ã—ã¦**æ–°ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã«é©å¿œ**(fine-tuningã™ã‚‹ã£ã¦ã“ã¨ã‹ãª?)ã™ã‚‹ã€‚æˆ‘ã€…ã¯ã€è‘—è€…ã«ã‚ˆã£ã¦æä¾›ã•ã‚ŒãŸäº‹å‰è¨“ç·´ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‰ãƒ¡ã‚¤ãƒ³ä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹ã€‚

### 3.1.3. Evaluation Settings. è©•ä¾¡è¨­å®šã€‚

To evaluate the performance of sequential recommendation, we adopt three widely used metrics NDCG@N, Recall@N and MRR, where N is set to 10.
é€æ¬¡æ¨è–¦ã®æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€NDCG@Nã€Recall@Nã€MRRã®3ã¤ã®åºƒãä½¿ã‚ã‚Œã¦ã„ã‚‹æŒ‡æ¨™ã‚’æ¡ç”¨ã™ã‚‹ã€‚
For data splitting of finetuning datasets, we apply the leave-one-out strategy [14] for evaluation: the most recent item in an interaction sequence is used for testing, the second most recent item for validation and the remaining data for training.
ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã®ãŸã‚ã«ã€è©•ä¾¡ã®ãŸã‚ã«**leave-one-outæˆ¦ç•¥**[14]ã‚’é©ç”¨ã™ã‚‹:
interaction sequenceã®ä¸­ã§æœ€ã‚‚æ–°ã—ã„itemãŒãƒ†ã‚¹ãƒˆã«ã€2ç•ªç›®ã«æ–°ã—ã„itemãŒæ¤œè¨¼ã«ã€ãã—ã¦æ®‹ã‚Šã®ãƒ‡ãƒ¼ã‚¿ãŒãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ä½¿ç”¨ã•ã‚Œã‚‹ã€‚(ãªã‚‹ã»ã©ã€ã‚ã‹ã‚Šã‚„ã™ã„...!)
We rank the ground-truth item of each sequence among all items for evaluation and report the average scores of all sequences in the test data.
å„sequenceã®ground-truthã‚¢ã‚¤ãƒ†ãƒ ã‚’å…¨ã‚¢ã‚¤ãƒ†ãƒ ã®ä¸­ã§ãƒ©ãƒ³ã‚¯ä»˜ã‘ã—ã¦è©•ä¾¡ã—ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹å…¨sequenceã®å¹³å‡ã‚¹ã‚³ã‚¢ã‚’å ±å‘Šã™ã‚‹ã€‚

### 3.1.4. Implementation Details. å®Ÿè£…ã®è©³ç´°

We build Recformer based on Longformer implemented by Huggingface.
Huggingface4ã§å®Ÿè£…ã•ã‚ŒãŸLongformerã‚’ãƒ™ãƒ¼ã‚¹ã«Recformerã‚’æ§‹ç¯‰ã™ã‚‹ã€‚(https://huggingface.co/docs/transformers/index)
For efficient computing, we set the size of the local attention windows in Longformer to 64.
åŠ¹ç‡çš„ãªè¨ˆç®—ã®ãŸã‚ã«ã€Longformerã®local attention windowã®ã‚µã‚¤ã‚ºã‚’64ã«è¨­å®šã—ãŸã€‚
The maximum number of tokens is 32 for each attribute and 1,024 for each interaction sequence (i.e., ğ‘‹ in Equation (1)).
**ãƒˆãƒ¼ã‚¯ãƒ³ã®æœ€å¤§æ•°**(= $l$ ã ã£ã‘?)ã¯ã€å„å±æ€§(=attribute)ã«ã¤ã„ã¦32å€‹ã€å„interaction sequence(i.e. å¼ï¼ˆ1ï¼‰ã®$X$)ã«ã¤ã„ã¦1,024å€‹ã§ã‚ã‚‹ã€‚
The maximum number of items in a user sequence is 50 for all baselines and Recformer.
**ãƒ¦ãƒ¼ã‚¶ãƒ»ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®æœ€å¤§ã‚¢ã‚¤ãƒ†ãƒ æ•°**(= $n$ ã ã£ã‘??)ã¯ã€ã™ã¹ã¦ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨Recformerã§50ã§ã‚ã‚‹ã€‚
The temperature parameter ğœ is 0.05 and the weight of MLM loss ğœ† is 0.1.Other than token type embedding and item position embedding in Recformer, other parameters are initialized with pre-trained parameters of Longformer 5 before pre-training.
æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $\tau$ ã¯0.05ã€MLMæå¤±ã®é‡ã¿ $\lambda$ ã¯0.1ã§ã‚ã‚‹ã€‚Recformerã®**token typeåŸ‹ã‚è¾¼ã¿ ã¨item positionåŸ‹ã‚è¾¼ã¿ä»¥å¤–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã€äº‹å‰å­¦ç¿’å‰ã«Longformerã®äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (https://huggingface.co/allenai/longformer-base-4096) ã§åˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹**ã€‚
(ã‚ã€ãªã‚‹ã»ã©ã€‚ãã‚Œã‚’fine-tuningã™ã‚‹çš„ãªã‚¤ãƒ¡ãƒ¼ã‚¸ãªã®ã‹ãª??)
The batch size is 64 for pre-training and 16 for finetuning.
batch sizeã¯ã€äº‹å‰å­¦ç¿’ç”¨ã«64ã€å¾®èª¿æ•´ç”¨ã«16ã§ã‚ã‚‹ã€‚
We optimize Recformer with Adam optimizer with learning rate 5e-5 and adopt early stop with the patience of 5 epochs to prevent overfitting.
å­¦ç¿’ç‡5e-5ã®ã‚¢ãƒ€ãƒ ãƒ»ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã§Recformerã‚’æœ€é©åŒ–ã—ã€ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚’é˜²ããŸã‚ã«5 epochã®å¿è€ã§æ—©æœŸåœæ­¢ã‚’æ¡ç”¨ã™ã‚‹ã€‚
For baselines, we use the suggested settings introduced in [12].
ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«ã¤ã„ã¦ã¯ã€[12]ã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹æ¨å¥¨è¨­å®šã‚’ä½¿ç”¨ã™ã‚‹ã€‚

## 3.2. Overall Performance ç·åˆæˆç¸¾

![table2]()

We compare Recformer to baselines on six datasets across different recommendation domains.
Recformerã¨ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒã‚’ã€ç•°ãªã‚‹æ¨è–¦é ˜åŸŸã«ã‚ãŸã‚‹6ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¡Œã†ã€‚
Results are shown in Table 2.
çµæœã‚’è¡¨2ã«ç¤ºã™ã€‚

For baselines, ID-Text methods (i.e., FDSA and S3 -Rec) achieve better results compared to ID-Only and Text-Only methods in general.
ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«ã¤ã„ã¦ã¯ã€**ID-Textæ³•ï¼ˆã™ãªã‚ã¡ã€FDSAã¨S3 -Recï¼‰ã¯ã€ä¸€èˆ¬çš„ã«ID-Onlyæ³•ã‚„Text-Onlyæ³•ã‚ˆã‚Šã‚‚è‰¯ã„çµæœã‚’é”æˆã—ã¦ã„ã‚‹**ã€‚
Because ID-Text methods include item IDs and content features, they can learn both content-based information and sequential patterns from finetuning.
ID-Textãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ IDã¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç‰¹å¾´ã‚’å«ã‚€ãŸã‚ã€**ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ™ãƒ¼ã‚¹ã®æƒ…å ±ã¨ã€fine-tuningã«ã‚ˆã‚‹ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¸¡æ–¹ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒã§ãã‚‹**ã€‚
Comparing Text-Only methods and ID-Only methods, we can find that on the Scientific, Instruments, and Pet datasets, Text-Only methods perform better than ID-Only methods.
ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¨IDã®ã¿ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æ¯”è¼ƒã™ã‚‹ã¨ã€**ç§‘å­¦ã€æ©Ÿå™¨ã€ãƒšãƒƒãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®ãƒ¡ã‚½ãƒƒãƒ‰ã®æ–¹ãŒIDã®ã¿ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒè‰¯ã„**ã“ã¨ãŒã‚ã‹ã‚‹ã€‚
A possible reason is that the item transitions in these three datasets are highly related to item texts (i.e., title, brand) hence text-only methods can recommend the next item based on content similarity.
è€ƒãˆã‚‰ã‚Œã‚‹ç†ç”±ã¨ã—ã¦ã¯ã€**ã“ã‚Œã‚‰3ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãŠã‘ã‚‹ã‚¢ã‚¤ãƒ†ãƒ é·ç§»ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ†ã‚­ã‚¹ãƒˆ(ã‚¿ã‚¤ãƒˆãƒ«ã‚„ãƒ–ãƒ©ãƒ³ãƒ‰ãªã©)ã¨é–¢é€£æ€§ãŒé«˜ã„**ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®æ‰‹æ³•ã§ã¯ã€å†…å®¹ã®é¡ä¼¼æ€§ã«åŸºã¥ã„ã¦æ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ¨è–¦ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚

Our proposed method Recformer, achieves the best overall performance on all datasets except the Recall@10 of Instruments.
ææ¡ˆæ‰‹æ³•Recformerã¯ã€Instrumentsã®Recall@10ã‚’é™¤ã**å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ€é«˜ã®ç·åˆæ€§èƒ½ã‚’é”æˆã—ãŸ**ã€‚
Recformer improves the NDCG@10 by 15.83% and MRR by 15.99% on average over the second best results.
Recformerã¯NDCG@10ã‚’15.83%æ”¹å–„ã—ã€MRRã‚’15.99%æ”¹å–„ã—ãŸã€‚
Different from baselines, Recformer learns language representations for sequential recommendation without pre-trained language models or item IDs.
ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã¯ç•°ãªã‚Šã€**Recformerã¯äº‹å‰å­¦ç¿’ã—ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚„ã‚¢ã‚¤ãƒ†ãƒ IDã‚’ä½¿ã‚ãšã«ã€é€æ¬¡æ¨è–¦ã®ãŸã‚ã®è¨€èªè¡¨ç¾ã‚’å­¦ç¿’ã™ã‚‹**ã€‚
With two-stage finetuning, Recformer can be effectively adapted to downstream domains and transferred knowledge from pre-training can consistently benefit finetuning tasks.
2æ®µéšã®å¾®èª¿æ•´ã«ã‚ˆã‚Šã€Recformerã¯ä¸‹æµã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«åŠ¹æœçš„ã«é©å¿œã™ã‚‹ã“ã¨ãŒã§ãã€äº‹å‰å­¦ç¿’ã‹ã‚‰ä¼é”ã•ã‚ŒãŸçŸ¥è­˜ã¯å¾®èª¿æ•´ã‚¿ã‚¹ã‚¯ã«ä¸€è²«ã—ã¦å½¹ç«‹ã¤ã€‚
The results illustrate the effectiveness of the proposed Recformer.
ã“ã®çµæœã¯ã€ææ¡ˆã™ã‚‹Recformerã®æœ‰åŠ¹æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚

## 3.3. Low-Resource Performance ä½ãƒªã‚½ãƒ¼ã‚¹ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

### 3.3.1. Zero-Shot. ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã€‚(fine-tuningã—ãªã„ã£ã¦äº‹?)

![fig4]()

To show the effectiveness of pre-training, we evaluate the zero-shot recommendation performance of three TextOnly methods (i.e., UniSRec, ZESRec, Recformer) and compare results to the average scores of three ID-Only methods fully trained on downstream datasets.
äº‹å‰å­¦ç¿’ã®æœ‰åŠ¹æ€§ã‚’ç¤ºã™ãŸã‚ã«ã€3ã¤ã®Text-Onlyæ‰‹æ³•(UniSRecã€ZESRecã€Recformer)ã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ¨è–¦æ€§èƒ½ã‚’è©•ä¾¡ã—ã€ä¸‹æµãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å®Œå…¨ã«è¨“ç·´ã•ã‚ŒãŸ3ã¤ã®ID-Onlyæ‰‹æ³•ã®å¹³å‡ã‚¹ã‚³ã‚¢ã¨çµæœã‚’æ¯”è¼ƒã™ã‚‹ã€‚
The zero-shot recommendation setting requires models to learn knowledge from pre-training datasets and directly test on downstream datasets without further training.
**ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ¨è–¦ã®è¨­å®šã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒäº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰çŸ¥è­˜ã‚’å­¦ç¿’ã—ã€ã•ã‚‰ã«å­¦ç¿’(=fine-tuning!)ã™ã‚‹ã“ã¨ãªãä¸‹æµã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ç›´æ¥ãƒ†ã‚¹ãƒˆã™ã‚‹å¿…è¦ãŒã‚ã‚‹**ã€‚
Hence, traditional ID-based methods cannot be evaluated in this setting.
ã—ãŸãŒã£ã¦ã€å¾“æ¥ã®IDãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã¯ã€ã“ã®è¨­å®šã§ã¯è©•ä¾¡ã§ããªã„ã€‚
We evaluate the knowledge transferability of Text-Only methods in different recommendation scenarios.
æ§˜ã€…ãªæ¨è–¦ã‚·ãƒŠãƒªã‚ªã«ãŠã„ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®æ‰‹æ³•ã®çŸ¥è­˜ä¼é”æ€§ã‚’è©•ä¾¡ã™ã‚‹ã€‚
All results in six downstream datasets are shown in Figure 4.
6ã¤ã®ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å…¨çµæœã‚’å›³4ã«ç¤ºã™ã€‚
Overall, Recformer improves the zero-shot recommendation performance compared to UniSRec and ZESRec on six datasets.
å…¨ä½“ã¨ã—ã¦ã€Recformerã¯6ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãŠã„ã¦UniSRecã‚„ZESRecã¨æ¯”è¼ƒã—ã¦ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ¨è–¦ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ãŸã€‚
On the Scientific dataset, Recformer performs better than the average performance of three ID-Only methods trained with full training sets.
Scientificãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ã€Recformerã¯ã€å®Œå…¨ãªè¨“ç·´ã‚»ãƒƒãƒˆã§è¨“ç·´ã•ã‚ŒãŸ3ã¤ã®ID-Onlyæ‰‹æ³•ã®å¹³å‡æ€§èƒ½ã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã€‚
These results show that (1) natural language is promising as a general item representation across different recommendation scenarios; (2) Recformer can effectively learn knowledge from pre-training and transfer learned knowledge to downstream tasks based on language understanding.
ã“ã‚Œã‚‰ã®çµæœã¯ã€**(1)è‡ªç„¶è¨€èªãŒæ§˜ã€…ãªæ¨è–¦ã‚·ãƒŠãƒªã‚ªã«æ¸¡ã‚‹ä¸€èˆ¬çš„ãªitemè¡¨ç¾ã¨ã—ã¦æœ‰æœ›ã§ã‚ã‚‹ã“ã¨**ã€**(2)Recformerã¯äº‹å‰å­¦ç¿’ã‹ã‚‰çŸ¥è­˜ã‚’åŠ¹æœçš„ã«å­¦ç¿’ã—ã€å­¦ç¿’ã—ãŸçŸ¥è­˜ã‚’è¨€èªç†è§£ã«åŸºã¥ã„ã¦ä¸‹æµã®ã‚¿ã‚¹ã‚¯ã«è»¢é€ã§ãã‚‹ã“ã¨**ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚

### 3.3.2. Low-Resource. ä½è³‡æºã€‚

![fig5]()

We conduct experiments with SASRec, UniSRec and Recformer in low-resource settings.
SASRecã€UniSRecã€Recformerã‚’ä½¿ã£ãŸå®Ÿé¨“ã‚’**ä½ãƒªã‚½ãƒ¼ã‚¹ç’°å¢ƒ**ã§è¡Œã£ãŸã€‚
In this setting, we train models on downstream datasets with different ratios of training data and results are shown in Figure 5.
ã“ã®è¨­å®šã§ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡ã‚’å¤‰ãˆãŸä¸‹æµãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€çµæœã‚’å›³5ã«ç¤ºã™ã€‚
We can see that methods with item text (i.e., UniSRec and Recformer) outperform ID-only method SASRec especially when less training data is available.
**ç‰¹ã«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„å ´åˆã€itemãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€æ–¹æ³•ï¼ˆã™ãªã‚ã¡UniSRecã¨Recformerï¼‰ãŒIDã®ã¿ã®æ–¹æ³•SASRecã‚’ä¸Šå›ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹**ã€‚
This indicates UniSRec and Recformer can incorporate prior knowledge and do recommendations based on item texts.
ã“ã‚Œã¯ã€UniSRecã¨RecformerãŒäº‹å‰çŸ¥è­˜ã‚’å–ã‚Šå…¥ã‚Œã€ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ãŸæ¨è–¦ã‚’è¡Œãˆã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
In low-resource settings, most items in the test set are unseen during training for SASRec.
ä½ãƒªã‚½ãƒ¼ã‚¹ç’°å¢ƒã§ã¯ã€SASRecã®å­¦ç¿’ä¸­ã«ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®ã»ã¨ã‚“ã©ã®itemãŒæœªè¦‹(unseen)ã¨ãªã‚‹ã€‚
Therefore, the embeddings of unseen items are randomly initialized and cannot provide high-quality representations for recommendations.
ãã®ãŸã‚ã€**æœªè¦‹ã®ã‚¢ã‚¤ãƒ†ãƒ ã®åŸ‹ã‚è¾¼ã¿ã¯ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã•ã‚Œã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ãŸã‚ã®é«˜å“è³ªãªè¡¨ç¾ã‚’æä¾›ã™ã‚‹ã“ã¨ã¯ã§ããªã„**ã€‚(IDãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã¯ã©ã†ã—ã¦ã‚‚ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„ã¨ã„ã†ã‹ã€sparseæ€§ãŒé«˜ã„ã‚±ãƒ¼ã‚¹ã§ã¯åŠ›ã‚’ç™ºæ®ã—ãšã‚‰ã„ã®ã‹ãªã€‚ãŸã å¾Œè¿°ã®æ§˜ã«ã€**sparseæ€§ãŒä¸‹ãŒã£ã¦ãã‚‹ã¨æ€¥æ¿€ã«åŠ¹æœãŒä¸ŠãŒã‚‹æ„Ÿã˜**??è©•ä¾¡è¡Œåˆ—ã®sparseæ€§ã‚’ä¸‹ã’ã‚‹æ§˜ã«ã€ãƒ¦ãƒ¼ã‚¶ & ã‚¢ã‚¤ãƒ†ãƒ ã‚’èª¿æ•´ã—ãŸã‚‰ã€ã‚‚ã£ã¨é«˜å“è³ªãªembeddingã‚’ä½œã‚Œã‚‹ã ã‚ã†ã‹...??)
After being trained with adequate data, SASRec could rapidly improve its performance.
é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚ŒãŸå¾Œã€**SASRecã¯æ€¥é€Ÿã«æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ããŸ**ã€‚
Recformer achieves the best performance over different ratios of training data.
Recformerã¯ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡ã‚’å¤‰ãˆã¦ã‚‚æœ€é«˜ã®æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã€‚
On the Scientific dataset, Recformer outperforms other methods by a large margin with 1% and 5% of training data.
Scientificãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ã€Recformerã¯1%ã¨5%ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿(=å‡„ãä½ãƒªã‚½ãƒ¼ã‚¹ç’°å¢ƒ)ã§ä»–ã®æ‰‹æ³•ã«å¤§ããªå·®ã‚’ã¤ã‘ãŸã€‚

## 3.4. Further Analysis ã•ã‚‰ãªã‚‹åˆ†æ

### 3.4.1. Performance w.r.t. Cold-Start Items. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆãƒ»ã‚¢ã‚¤ãƒ†ãƒ 

In this section, we simulate this scenario by splitting a dataset into two parts, i.e., an in-set dataset and cold-start dataset.
ã“ã®ç¯€ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’2ã¤ã®éƒ¨åˆ†ã€ã™ãªã‚ã¡**in-setãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨cold-startãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«åˆ†å‰²ã—ã¦**ã€ã“ã®ã‚·ãƒŠãƒªã‚ªã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã€‚
Specifically, for the in-set dataset, we make sure all test items appear in the training data and all other test items (never appearing in training data) will be sent to the cold-start dataset.
å…·ä½“çš„ã«ã¯ã€**in-setãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆitemãŒãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»ãƒ‡ãƒ¼ã‚¿ã«ç¾ã‚Œã‚‹**ã‚ˆã†ã«ã—ã€ãã‚Œä»¥å¤–ã®ãƒ†ã‚¹ãƒˆitem(ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«ç¾ã‚Œãªã„test item)ã¯cold-startãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é€ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚
We train models on in-set datasets and test on both in-set and cold-start datasets.
**in-setãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€in-setãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨cold-startãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸¡æ–¹ã§ãƒ†ã‚¹ãƒˆã™ã‚‹**ã€‚
In this case, models never see the cold-start items during training and item embedding tables do not contain cold-start items.
ã“ã®å ´åˆã€ãƒ¢ãƒ‡ãƒ«ã¯å­¦ç¿’ä¸­ã«ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’è¦‹ã‚‹ã“ã¨ã¯ãªãã€ã‚¢ã‚¤ãƒ†ãƒ åŸ‹ã‚è¾¼ã¿ãƒ†ãƒ¼ãƒ–ãƒ«(=ãã‚‚ãã‚‚Recformerã¯ã“ã®æƒ…å ±ã‚’ä½¿ã‚ãªã„èªè­˜...!)ã«ã¯ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã®ã‚¢ã‚¤ãƒ†ãƒ ã¯å«ã¾ã‚Œãªã„ã€‚
We compare the ID-only method SASRec and the Text-only method UniSRec to Recformer.
IDã®ã¿ã®SASRecã¨ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®UniSRecã‚’Recformerã¨æ¯”è¼ƒã™ã‚‹ã€‚
For ID-based SASRec, we substitute items appearing only once in the training set with a cold token and after training, we add this cold token embedding to cold-start item embeddings to provide prior knowledge. (We try to provide a reasonable method for ID-based baselines with cold-start items)
IDãƒ™ãƒ¼ã‚¹ã®SASRecã§ã¯ã€**å­¦ç¿’ã‚»ãƒƒãƒˆã«ä¸€åº¦ã ã‘å‡ºç¾ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã‚’ã‚³ãƒ¼ãƒ«ãƒ‰ãƒˆãƒ¼ã‚¯ãƒ³ã§ç½®ãæ›ãˆ**ã€å­¦ç¿’å¾Œã€ã“ã®ã‚³ãƒ¼ãƒ«ãƒ‰ãƒˆãƒ¼ã‚¯ãƒ³ã®åŸ‹ã‚è¾¼ã¿ã‚’ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã®ã‚¢ã‚¤ãƒ†ãƒ åŸ‹ã‚è¾¼ã¿ã«è¿½åŠ ã—ã€äº‹å‰çŸ¥è­˜ã‚’æä¾›ã™ã‚‹ã€‚(ç§ãŸã¡ã¯ã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆé …ç›®ã‚’æŒã¤IDãƒ™ãƒ¼ã‚¹ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«ã¤ã„ã¦ã€åˆç†çš„ãªæ–¹æ³•ã‚’æä¾›ã—ã‚ˆã†ã¨è©¦ã¿ã¦ã„ã‚‹)
For UniSRec, cold-start items are represented by item texts and encoded by BERT which is identical to seen items.
**UniSRecã§ã¯ã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆitemã¯itemãƒ†ã‚­ã‚¹ãƒˆã§è¡¨ç¾ã•ã‚Œã€BERTã§ç¬¦å·åŒ–ã•ã‚Œã‚‹**ã€‚(ã“ã®æ‰‹æ³•ã¯Content-basedæ‰‹æ³•ã¨ã‚‚è¨€ãˆãã†)
Recformer directly encode item texts to represent cold-start items.
Recformerã¯ã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’è¡¨ç¾ã™ã‚‹ãŸã‚ã«ã€ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›´æ¥ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã€‚

![fig3]()

Experimental results are shown in Table 3.
å®Ÿé¨“çµæœã‚’è¡¨3ã«ç¤ºã™ã€‚
We can see that Text-Only methods significantly outperform SASRec, especially on datasets with a large size (i.e., Arts, Pet).
ç‰¹ã«ã‚µã‚¤ã‚ºã®å¤§ãã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆArtsã‚„Petãªã©ï¼‰ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®æ‰‹æ³•ãŒSASRecã‚’å¤§ããä¸Šå›ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚
Because of randomly initialized cold-start item representations, the performance of SASRec is largely lower on cold-start items than in-set items.
ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆitemã®è¡¨ç¾ãŒãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã•ã‚Œã‚‹ãŸã‚ã€**SASRecã®æ€§èƒ½ã¯ã‚¤ãƒ³ã‚»ãƒƒãƒˆitemsã‚ˆã‚Šã‚‚ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆitemsã§å¤§ããä½ä¸‹ã™ã‚‹**ã€‚
Hence, IDonly methods are not able to handle cold-start items and applying text is a promising direction.
**ã—ãŸãŒã£ã¦ã€IDã®ã¿ã®æ–¹æ³•ã§ã¯ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ‰±ã†ã“ã¨ãŒã§ããšã€ãƒ†ã‚­ã‚¹ãƒˆã‚’é©ç”¨ã™ã‚‹ã“ã¨ãŒæœ‰æœ›ãªæ–¹å‘æ€§ã§ã‚ã‚‹**ã€‚
For Text-only methods, Recformer greatly improves performance on both in-set and cold-start datasets compared to UniSRec which indicates learning language representations is superior to obtaining text features for recommendations.
ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®æ‰‹æ³•ã®å ´åˆã€Recformerã¯UniSRecã¨æ¯”è¼ƒã—ã¦ã€ã‚¤ãƒ³ã‚»ãƒƒãƒˆã¨ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã®ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã€‚ã“ã‚Œã¯ã€**æ¨è–¦ã®ãŸã‚ã®ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´é‡ã‚’å¾—ã‚‹ã‚ˆã‚Šã‚‚ã€è¨€èªè¡¨ç¾ã‚’å­¦ç¿’ã™ã‚‹æ–¹ãŒå„ªã‚Œã¦ã„ã‚‹**ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚(å›ºå®šã®å­¦ç¿’æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆembeddingã‚’å˜ã«ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ã†ã‚ˆã‚Šã‚‚ã€æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã®ä¸€éƒ¨ã¨ã—ã¦è¨€èªè¡¨ç¾ã‚’å­¦ç¿’ã•ã›ã‚‹æ–¹ãŒã‚ˆã‚Šrichã§åŠ¹æœçš„ãªè¡¨ç¾ã«ãªã‚‹ã€ã£ã¦ã“ã¨??:thinking:)

### 3.4.2. Ablation(=åˆ‡é™¤) Study. ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç ”ç©¶ã€‚

![table4]()

We analyze how our proposed components influence the final sequential recommendation performance.
ææ¡ˆã™ã‚‹æ§‹æˆè¦ç´ ãŒæœ€çµ‚çš„ãªé€æ¬¡æ¨è–¦ã®æ€§èƒ½ã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã‹ã‚’åˆ†æã™ã‚‹ã€‚
The results are shown in Table 4.
çµæœã‚’è¡¨4ã«ç¤ºã™ã€‚
We introduce the variants and analyze their results respectively.
ãã‚Œãã‚Œã®å¤‰ç¨®ã‚’ç´¹ä»‹ã—ã€ãã®çµæœã‚’åˆ†æã™ã‚‹ã€‚

We first test the effectiveness of our proposed two-stage finetuning.
ã¾ãšã€æˆ‘ã€…ã®ææ¡ˆã™ã‚‹**2æ®µéšã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æœ‰åŠ¹æ€§**ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã€‚
In variant (1) w/o two-stage finetuning, we do not update item feature matrix I and only conduct finetuning based on I from pre-trained parameters.
2æ®µéšã®å¾®èª¿æ•´ã‚’è¡Œã‚ãªã„ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³(1)ã§ã¯ã€item feature è¡Œåˆ— $\mathbf{I}$ ã®æ›´æ–°ã¯è¡Œã‚ãšã€äº‹å‰ã«å­¦ç¿’ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹ å›ºå®šã® $\mathbf{I}$ ã«åŸºã¥ãfine-tuningã®ã¿ã‚’è¡Œã†ã€‚
We find that compared to (0) Recformer, (1) has similar results on Scientific but has a large margin on Instruments since the pre-trained model has better pre-trained item representations on Scientific compared to Instruments (shown in Figure 4).
ãã®çµæœã€(0)ã®Recformerã¨æ¯”è¼ƒã—ã¦ã€(1)ã¯Scientificã§ã¯åŒã˜ã‚ˆã†ãªçµæœã‚’ç¤ºã™ãŒã€Instrumentsã§ã¯å¤§ããªãƒãƒ¼ã‚¸ãƒ³ã‚’æŒã¤ã“ã¨ãŒã‚ã‹ã£ãŸï¼ˆå›³4ï¼‰ã€‚
Hence, our proposed two-stage finetuning can effectively improve the sub-optimal item representations from pre-training and further improve performance on downstream datasets.
å¾“ã£ã¦ã€æˆ‘ã€…ã®ææ¡ˆã™ã‚‹**2æ®µéšã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€äº‹å‰å­¦ç¿’ã«ã‚ˆã‚‹æœ€é©ã§ãªã„itemè¡¨ç¾ã‚’åŠ¹æœçš„ã«æ”¹å–„ã—ã€ä¸‹æµã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®æ€§èƒ½ã‚’ã•ã‚‰ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹**ã€‚

Then, we investigate the effects of freezing/trainable word embeddings and item embeddings.
æ¬¡ã«ã€**å‡çµ(freezing)/å­¦ç¿’å¯èƒ½(trainable)ãªwordåŸ‹ã‚è¾¼ã¿ã¨itemåŸ‹ã‚è¾¼ã¿ã®åŠ¹æœ**ã‚’èª¿ã¹ã‚‹ã€‚
In our default setting (1), we freeze the item feature matrix I and train word embeddings of Recformer.
ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è¨­å®š(1)ã§ã¯ã€item featureè¡Œåˆ— $\mathbf{I}$ ã‚’å‡çµã—ã€Recformerã®wordåŸ‹ã‚è¾¼ã¿ã‚’å­¦ç¿’ã™ã‚‹ã€‚
In variants (2)(3)(4), we try to train the item feature matrix or freeze word embeddings.
ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³(2)(3)(4)ã§ã¯ã€item featureè¡Œåˆ—ã‚’å­¦ç¿’ã€ã¾ãŸã¯å˜èªåŸ‹ã‚è¾¼ã¿ã‚’freezeã•ã›ã‚‹ã€‚(ä¸¡æ–¹ã¨ã‚‚freezeã€ã©ã¡ã‚‰ã‹trainableã®è¨ˆ3patterns)
Overall, on the Scientific dataset, the model with fixed item embeddings performs better than the model with trainable item embeddings, whereas on the Instruments dataset, our model performs well when item embeddings are trainable.
å…¨ä½“ã¨ã—ã¦ã€Scientificãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ã€itemåŸ‹ã‚è¾¼ã¿ã‚’å›ºå®šã—ãŸãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒã€itemåŸ‹ã‚è¾¼ã¿ã‚’å­¦ç¿’å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒè‰¯ã„ãŒã€Instrumentsãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ã€itemåŸ‹ã‚è¾¼ã¿ãŒå­¦ç¿’å¯èƒ½ãªå ´åˆã€æˆ‘ã€…ã®ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒæ€§èƒ½ãŒè‰¯ã„ã€‚
The divergence can be eliminated by our two-stage finetuning strategy.
**ã“ã®å¤šæ§˜æ€§ã¯ã€2æ®µéšã®fine-tuningæˆ¦ç•¥ã«ã‚ˆã£ã¦è§£æ¶ˆã§ãã‚‹**ã€‚(ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚ˆã£ã¦çµæœãŒé•ã†ã‘ã©ã€ã“ã®å•é¡Œã¯fine-tuningã—ãŸã‚‰è§£æ±ºã™ã‚‹ã£ã¦ã“ã¨ã‹)

Variant (5) w/o pre-training finetunes Recformer from scratch.
ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³(5) pre-trainingãªã— ã‚¼ãƒ­ã‹ã‚‰Recformerã‚’èª¿æ•´ã™ã‚‹ã€‚
We can see that (0) Recformer significantly outperforms Variant (5) in both datasets because without pre-training, the item feature matrix I is not trained and cannot provide informative supervision during finetuning even if we update I by two-stage finetuning.
ã“ã‚Œã¯ã€äº‹å‰å­¦ç¿’ãªã—ã§ã¯ã€itemç‰¹å¾´è¡Œåˆ— $\mathbf{I}$ ãŒå­¦ç¿’ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€2æ®µéšã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã£ã¦ $\mathbf{I}$ ã‚’æ›´æ–°ã—ã¦ã‚‚ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«æœ‰ç›Šãªç›£è¦–ã‚’æä¾›ã§ããªã„ã‹ã‚‰ã§ã‚ã‚‹ã€‚
These results show the effectiveness of pre-training.
ã“ã‚Œã‚‰ã®çµæœã¯ã€**äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®æœ‰åŠ¹æ€§**ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚

Finally, we explore the effectiveness of our proposed model structure (i.e., item position embeddings and token type embeddings).
æœ€å¾Œã«ã€ææ¡ˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«æ§‹é€ (ã™ãªã‚ã¡ã€**item positionåŸ‹ã‚è¾¼ã¿ã¨token typeåŸ‹ã‚è¾¼ã¿)ã®æœ‰åŠ¹æ€§**ã‚’æ¢ã‚‹ã€‚
Variant (6) removes the two embeddings and results show that the model in (6) causes performance decay on the instruments dataset which indicates the two embeddings are necessary when the gap between pre-training and finetuning is large.
å¤‰å½¢(6)ã¯2ã¤ã®åŸ‹ã‚è¾¼ã¿ã‚’å‰Šé™¤ã—ãŸã‚‚ã®ã€‚çµæœã¯ã€(6)ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€instrumentãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸Šã§æ€§èƒ½æ¸›è¡°ã‚’å¼•ãèµ·ã“ã™ã€‚ã“ã®çµæœã¯ã€**äº‹å‰å­¦ç¿’ã¨å¾®èª¿æ•´ã®é–“ã®ã‚®ãƒ£ãƒƒãƒ—ãŒå¤§ãã„å ´åˆã«2ã¤ã®åŸ‹ã‚è¾¼ã¿ãŒå¿…è¦**ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚

### 3.4.3. Pre-training Steps vs. Performance. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã®æ¯”è¼ƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

![fig6]()

We investigate the zeroshot sequential recommendation performance on downstream tasks over different pre-training steps and results on four datasets are shown in Figure 6.
ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆ(=fine-tuningãªã—)é€æ¬¡ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®æ€§èƒ½ã‚’ã€ç•°ãªã‚‹äº‹å‰å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—ã®ä¸‹æµã‚¿ã‚¹ã‚¯ã§èª¿æŸ»ã—ã€4ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®çµæœã‚’å›³6ã«ç¤ºã™ã€‚
The pre-training of natural language understanding usually requires a large number of training steps to achieve a promising result.
**è‡ªç„¶è¨€èªç†è§£ã®äº‹å‰å­¦ç¿’ã¯é€šå¸¸ã€æœ‰æœ›ãªçµæœã‚’å¾—ã‚‹ãŸã‚ã«å¤šãã®å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—ã‚’å¿…è¦ã¨ã™ã‚‹**ã€‚
However, we have a different situation in sequential recommendation.
**ã—ã‹ã—ã€é€æ¬¡æ¨è–¦ã§ã¯äº‹æƒ…ãŒç•°ãªã‚‹**ã€‚
From Figure 6, we can see that most datasets already achieve their best performance after around 4,000 training steps and further pre-training may hurt the knowledge transferability on downstream tasks.
å›³6ã‹ã‚‰ã€**ã»ã¨ã‚“ã©ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯4,000ã‚¹ãƒ†ãƒƒãƒ—ç¨‹åº¦ã®å­¦ç¿’ã§ã™ã§ã«æœ€é«˜ã®æ€§èƒ½ã‚’é”æˆã—ã¦ãŠã‚Š**ã€ã“ã‚Œä»¥ä¸Šã®äº‹å‰å­¦ç¿’ã¯ä¸‹æµã®ã‚¿ã‚¹ã‚¯ã§ã®çŸ¥è­˜ä¼é”æ€§ã‚’æãªã†å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚

We think there are two possible reasons:
è€ƒãˆã‚‰ã‚Œã‚‹ç†ç”±ã¯2ã¤ã‚ã‚‹ï¼š
(1) We initialize most parameters from a Longformer model pre-trained by the MLM task.
(1) **MLMã‚¿ã‚¹ã‚¯ã«ã‚ˆã£ã¦äº‹å‰ã«è¨“ç·´ã•ã‚ŒãŸLongformerãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã»ã¨ã‚“ã©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–ã™ã‚‹**ã€‚
In this case, the model already has some essential knowledge of natural languages.
ã“ã®å ´åˆã€**ãƒ¢ãƒ‡ãƒ«ã¯ã™ã§ã«è‡ªç„¶è¨€èªã«é–¢ã™ã‚‹æœ¬è³ªçš„ãªçŸ¥è­˜ã‚’æŒã£ã¦ã„ã‚‹**ã€‚
The domain adaptation from a general language understanding to the item text understanding for recommendations should be fast.
**ä¸€èˆ¬çš„ãªè¨€èªç†è§£ã‹ã‚‰æ¨è–¦ã®ãŸã‚ã®ã‚¢ã‚¤ãƒ†ãƒ ãƒ†ã‚­ã‚¹ãƒˆç†è§£ã¸ã®ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œ**ã¯é«˜é€Ÿã§ã‚ã‚‹ã¹ãã§ã‚ã‚‹ã€‚
(2) Even if we include seven categories in the training data, there is still a language domain difference between pre-training data and downstream data since different item categories have their own specific vocabularies.
(2) å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«7ã¤ã®ã‚«ãƒ†ã‚´ãƒªã‚’å«ã‚ãŸã¨ã—ã¦ã‚‚ã€ã‚¢ã‚¤ãƒ†ãƒ ã‚«ãƒ†ã‚´ãƒªã«ã¯ãã‚Œãã‚Œå›ºæœ‰ã®èªå½™ãŒã‚ã‚‹ãŸã‚ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ä¸‹æµãƒ‡ãƒ¼ã‚¿ã«ã¯è¨€èªãƒ‰ãƒ¡ã‚¤ãƒ³ã®é•ã„ãŒã‚ã‚‹ã€‚(ã ã‹ã‚‰ã„ãã‚‰äº‹å‰å­¦ç¿’é ‘å¼µã£ã¦ã‚‚ã€é ­æ‰“ã¡ã«ãªã‚‹ã£ã¦ã“ã¨??:thinking:)
For instance, the category Electronics has quite different words in item text compared to the Pets category.
ä¾‹ãˆã°ã€ã€Œã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨ã€Œãƒšãƒƒãƒˆã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã§ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ†ã‚­ã‚¹ãƒˆã«å«ã¾ã‚Œã‚‹å˜èªãŒã‹ãªã‚Šç•°ãªã£ã¦ã„ã‚‹ã€‚

# 4. Related Work é–¢é€£ä½œå“

## 4.1. Sequential Recommendation

Sequential recommendation [11, 14, 27] aims to predict the next item based on historical user interactions.
é€æ¬¡æ¨è–¦[11, 14, 27]ã¯ã€éå»ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã«åŸºã¥ã„ã¦æ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚
Proposed methods model user interactions as a sequence ordered by their timestamps.
ææ¡ˆã•ã‚ŒãŸæ–¹æ³•ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«ã‚ˆã£ã¦ä¸¦ã¹ã‚‰ã‚ŒãŸã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ã€‚
Due to the ability to capture the long-term preferences and short-term dynamics of users, sequential recommendation methods show their effectiveness for personalization and attract a lot of studies.
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é•·æœŸçš„ãªå—œå¥½ã¨çŸ­æœŸçš„ãªãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’æ‰ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ãŸã‚ã€é€æ¬¡ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ‰‹æ³•ã¯ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã«æœ‰åŠ¹ã§ã‚ã‚Šã€å¤šãã®ç ”ç©¶ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã€‚
Early works [9, 25] apply the Markov Chain to model item-item transition relations based on matrix factorization.
åˆæœŸã®ç ”ç©¶[9, 25]ã§ã¯ã€ãƒãƒ«ã‚³ãƒ•é€£é–ã‚’å¿œç”¨ã—ã¦ã€è¡Œåˆ—åˆ†è§£ã«åŸºã¥ã„ã¦é …ç›®-é …ç›®ã®é·ç§»é–¢ä¿‚ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¦ã„ã‚‹ã€‚
For deep learning methods, Convolutional Sequence Embedding (Caser) [28] views the embedding matrix of previous items as an â€œimageâ€ and applies convolutional operations to extract transitions.
ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ‰‹æ³•ã¨ã—ã¦ã¯ã€Convolutional Sequence Embeddingï¼ˆCaserï¼‰[28]ãŒã€éå»ã®ã‚¢ã‚¤ãƒ†ãƒ ã®åŸ‹ã‚è¾¼ã¿è¡Œåˆ—ã‚’ã€Œç”»åƒã€ã¨ã¿ãªã—ã€ç•³ã¿è¾¼ã¿æ¼”ç®—ã‚’é©ç”¨ã—ã¦é·ç§»ã‚’æŠ½å‡ºã™ã‚‹ã€‚
GRU4Rec [11] introduces Gated Recurrent Units (GRU) [5] to model user sequential patterns.
GRU4Rec [11]ã¯ã€Gated Recurrent Units (GRU) [5]ã‚’å°å…¥ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ã€‚
With the development of the Transformer [30], recent studies [14, 27] widely use self-attention model for sequential recommendation.
Transformer[30]ã®é–‹ç™ºã«ã‚ˆã‚Šã€æœ€è¿‘ã®ç ”ç©¶[14, 27]ã§ã¯ã€é€æ¬¡æ¨è–¦ã«è‡ªå·±æ³¨æ„ãƒ¢ãƒ‡ãƒ«ãŒåºƒãä½¿ã‚ã‚Œã¦ã„ã‚‹ã€‚
Although these approaches achieve promising performance, they struggle to learn transferable knowledge or understand cold-start items due to the dependence on IDs and item embeddings which are specific to items and datasets.
ã“ã‚Œã‚‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯æœ‰æœ›ãªæ€§èƒ½ã‚’é”æˆã—ã¦ã„ã‚‹ãŒã€é …ç›®ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å›ºæœ‰ã®IDã‚„é …ç›®åŸ‹ã‚è¾¼ã¿ã«ä¾å­˜ã—ã¦ã„ã‚‹ãŸã‚ã€è»¢ç§»å¯èƒ½ãªçŸ¥è­˜ã‚’å­¦ç¿’ã—ãŸã‚Šã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆé …ç›®ã‚’ç†è§£ã—ãŸã‚Šã™ã‚‹ã®ã«è‹¦åŠ´ã—ã¦ã„ã‚‹ã€‚
Recently, researchers attempt to employ textual features as transferable item representations [7, 12].
æœ€è¿‘ã§ã¯ã€è»¢é€å¯èƒ½ãªé …ç›®è¡¨ç¾ã¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆç‰¹å¾´ã‚’æ¡ç”¨ã™ã‚‹è©¦ã¿ãŒãªã•ã‚Œã¦ã„ã‚‹[7, 12]ã€‚
These methods first obtain item features by encoding item texts with language models and then learn transferable item representations with an independent sequential model.
ã“ã‚Œã‚‰ã®æ–¹æ³•ã¯ã€ã¾ãšè¨€èªãƒ¢ãƒ‡ãƒ«ã§é …ç›®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¬¦å·åŒ–ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦é …ç›®ã®ç‰¹å¾´ã‚’å–å¾—ã—ã€æ¬¡ã«ç‹¬ç«‹ã—ãŸé€æ¬¡ãƒ¢ãƒ‡ãƒ«ã§è»¢é€å¯èƒ½ãªé …ç›®è¡¨ç¾ã‚’å­¦ç¿’ã™ã‚‹ã€‚
Independent language understanding and sequential pattern learning still limit the capacity of the model to learn user interactions based on languages.
ç‹¬ç«‹ã—ãŸè¨€èªç†è§£ã¨é€æ¬¡çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ã¯ã€è¨€èªã«åŸºã¥ã„ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’å­¦ç¿’ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’ã¾ã åˆ¶é™ã—ã¦ã„ã‚‹ã€‚
In this paper, we explore unifying the language understanding and sequential recommendations into one Transformer framework.
æœ¬ç¨¿ã§ã¯ã€è¨€èªç†è§£ã¨é€æ¬¡ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’1ã¤ã®Transformerãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«çµ±åˆã™ã‚‹ã“ã¨ã‚’æ¢æ±‚ã™ã‚‹ã€‚
We aim to have a sequential recommendation method that can effectively model cold-start items and learn transferable sequential patterns for different recommendation scenarios.
æˆ‘ã€…ã¯ã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆé …ç›®ã‚’åŠ¹æœçš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€æ§˜ã€…ãªæ¨è–¦ã‚·ãƒŠãƒªã‚ªã«å¯¾ã—ã¦è»¢é€å¯èƒ½ãªé †åºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã§ãã‚‹é€æ¬¡æ¨è–¦æ‰‹æ³•ã‚’æŒã¤ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚

## 4.2. Transfer Learning for Recommendation æ¨è–¦ã®ãŸã‚ã®è»¢ç§»å­¦ç¿’

Data sparsity and cold-start item understanding issues are challenging in recommender systems and recent studies [33, 39, 40] explore transferring knowledge across different domains to improve the recommendation at the target domain.
æœ€è¿‘ã®ç ”ç©¶[33, 39, 40]ã§ã¯ã€**ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®æ¨è–¦ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³é–“ã§çŸ¥è­˜ã‚’è»¢é€ã™ã‚‹ã“ã¨**ã‚’æ¢æ±‚ã—ã¦ã„ã‚‹ã€‚
Previous methods for knowledge transfer mainly rely on shared information between the source and target domains including common users [13, 31, 32, 35], items [26, 39] or attributes [29].
ã“ã‚Œã¾ã§ã®çŸ¥è­˜ç§»è»¢ã®æ–¹æ³•ã¯ã€ä¸»ã«å…±é€šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼[13, 31, 32, 35]ã€é …ç›®[26, 39]ã€å±æ€§[29]ãªã©ã€ã‚½ãƒ¼ã‚¹ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒ‰ãƒ¡ã‚¤ãƒ³é–“ã§å…±æœ‰ã•ã‚Œã‚‹æƒ…å ±ã«ä¾å­˜ã—ã¦ã„ã‚‹ã€‚
To learn common item features from different domains, pre-trained language models [6, 21] provide high-quality item features by encoding item texts (e.g., title, brand).
ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ã‚‰å…±é€šã®ã‚¢ã‚¤ãƒ†ãƒ ç‰¹å¾´ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã«ã€äº‹å‰ã«å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«[6, 21]ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä¾‹ï¼šã‚¿ã‚¤ãƒˆãƒ«ã€ãƒ–ãƒ©ãƒ³ãƒ‰ï¼‰ã‚’ç¬¦å·åŒ–ã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€é«˜å“è³ªã®ã‚¢ã‚¤ãƒ†ãƒ ç‰¹å¾´ã‚’æä¾›ã™ã‚‹ã€‚
Based on pre-trained item features, several methods [7, 12] are proposed to learn universal item representations by applying additional layers.
**äº‹å‰å­¦ç¿’ã•ã‚ŒãŸã‚¢ã‚¤ãƒ†ãƒ ç‰¹å¾´é‡ã«åŸºã¥ãã€è¿½åŠ ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§æ™®éçš„ãªã‚¢ã‚¤ãƒ†ãƒ è¡¨ç¾ã‚’å­¦ç¿’ã™ã‚‹æ–¹æ³•**[7, 12]ãŒã„ãã¤ã‹ææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚
In this work, we have the same target as previous transfer learning for recommendation (i.e., alleviate data sparsity and cold-start item issues).
**æœ¬ç ”ç©¶ã§ã¯ã€ã“ã‚Œã¾ã§ã®æ¨è–¦ã®ãŸã‚ã®è»¢ç§»å­¦ç¿’ã¨åŒã˜ç›®æ¨™ã‚’æ²ã’ã¦ã„ã‚‹ï¼ˆã™ãªã‚ã¡ã€ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã¨ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆé …ç›®ã®å•é¡Œã‚’ç·©å’Œã™ã‚‹ï¼‰**ã€‚
However, instead of relying on common users, items and attributes or encoding items with pre-trained language models, we directly learn language representations for sequential recommendation and hence transfer knowledge based on the generality of natural languages.
ã—ã‹ã—ã€ä¸€èˆ¬çš„ãªãƒ¦ãƒ¼ã‚¶ã€ã‚¢ã‚¤ãƒ†ãƒ ã€å±æ€§ã«ä¾å­˜ã—ãŸã‚Šã€**äº‹å‰ã«è¨“ç·´ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚¢ã‚¤ãƒ†ãƒ ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸã‚Šã™ã‚‹ã®ã§ã¯ãªãã€é€æ¬¡æ¨è–¦ã®ãŸã‚ã®è¨€èªè¡¨ç¾ã‚’ç›´æ¥å­¦ç¿’ã™ã‚‹ã“ã¨**ã§ã€è‡ªç„¶è¨€èªã®ä¸€èˆ¬æ€§ã«åŸºã¥ãçŸ¥è­˜ã®ä¼é”ã‚’è¡Œã†ã€‚

# 5. Conclusion çµè«–

In this paper, we propose Recformer, a framework that can effectively learn language representations for sequential recommendation.
æœ¬ç¨¿ã§ã¯ã€é€æ¬¡æ¨è–¦ã®ãŸã‚ã®è¨€èªè¡¨ç¾ã‚’åŠ¹æœçš„ã«å­¦ç¿’ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯Recformerã‚’ææ¡ˆã™ã‚‹ã€‚
To recommend the next item based on languages, we first formulate items as key-value attribute pairs instead of item IDs.
è¨€èªã«åŸºã¥ã„ã¦æ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ¨è–¦ã™ã‚‹ãŸã‚ã«ã€**ã¾ãšã‚¢ã‚¤ãƒ†ãƒ ã‚’ã‚¢ã‚¤ãƒ†ãƒ IDã§ã¯ãªãã€ã‚­ãƒ¼ã¨å€¤ã®å±æ€§ãƒšã‚¢ã¨ã—ã¦å®šå¼åŒ–**ã™ã‚‹ã€‚
Then, we propose a novel bi-directional Transformer model for sequence and item representations.
æ¬¡ã«ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹è¡¨ç¾ã¨ã‚¢ã‚¤ãƒ†ãƒ è¡¨ç¾ã®ãŸã‚ã®æ–°ã—ã„åŒæ–¹å‘å¤‰æ›ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã™ã‚‹ã€‚
The proposed structure can learn both natural languages and sequential patterns for recommendations.
ææ¡ˆã•ã‚ŒãŸæ§‹é€ ã¯ã€**æ¨è–¦ã®ãŸã‚ã®è‡ªç„¶è¨€èªã¨é€æ¬¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¸¡æ–¹ã‚’å­¦ç¿’ã™ã‚‹**ã“ã¨ãŒã§ãã‚‹ã€‚
Furthermore, we design a learning framework including pretraining and finetuning that helps the model learn to recommend based on languages and transfer knowledge into different recommendation scenarios.
ã•ã‚‰ã«ã€äº‹å‰å­¦ç¿’ã¨å¾®èª¿æ•´ã‚’å«ã‚€å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’è¨­è¨ˆã—ã€è¨€èªã«åŸºã¥ã„ã¦æ¨è–¦ã™ã‚‹ã“ã¨ã‚’å­¦ç¿’ã—ã€ç•°ãªã‚‹æ¨è–¦ã‚·ãƒŠãƒªã‚ªã«çŸ¥è­˜ã‚’ä¼é”ã™ã‚‹ã“ã¨ã‚’æ”¯æ´ã™ã‚‹ã€‚
Finally, extensive experiments are conducted to evaluate the effectiveness of Recformer under full-supervised and low-resource settings.
æœ€å¾Œã«ã€Recformerã®æœ‰åŠ¹æ€§ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€å®Œå…¨æ•™å¸«ã‚ã‚Šã®è¨­å®šã¨ä½ãƒªã‚½ãƒ¼ã‚¹è¨­å®šã®ä¸‹ã§åºƒç¯„ãªå®Ÿé¨“ã‚’è¡Œã£ãŸã€‚
Results show that Recformer largely outperforms existing methods in different settings, especially for the zero-shot and cold-start items recommendation which indicates Recformer can effectively transfer knowledge from training.
ãã®çµæœã€Recformerã¯æ§˜ã€…ãªè¨­å®šã«ãŠã„ã¦æ—¢å­˜ã®æ‰‹æ³•ã‚’å¤§ããä¸Šå›ã£ãŸã€‚**ç‰¹ã«ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã¨ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆitemsã®æ¨è–¦ã«ãŠã„ã¦ã¯ã€RecformerãŒè¨“ç·´ã‹ã‚‰åŠ¹æœçš„ã«çŸ¥è­˜ã‚’ä¼é”ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹**ã€‚
An ablation study is conducted to show the effectiveness of our proposed components.
ææ¡ˆã—ãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®æœ‰åŠ¹æ€§ã‚’ç¤ºã™ãŸã‚ã€ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³(=åˆ‡é™¤)è©¦é¨“ã‚’å®Ÿæ–½ã—ãŸã€‚
