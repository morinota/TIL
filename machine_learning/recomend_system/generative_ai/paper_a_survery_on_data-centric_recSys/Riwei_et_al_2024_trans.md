## 0.1. refs: refsï¼š

https://arxiv.org/abs/2401.17878
https://arxiv.org/abs/2401.17878

## 0.2. title ã‚¿ã‚¤ãƒˆãƒ«

A Survey on Data-Centric Recommender Systems
ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒã®æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã«é–¢ã™ã‚‹èª¿æŸ»

## 0.3. abstract æŠ„éŒ²

Recommender systems (RSs) have become an essential tool for mitigating information overload in a range of real-world applications.
ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ï¼ˆRSï¼‰ã¯ã€å®Ÿä¸–ç•Œã®æ§˜ã€…ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ã€æƒ…å ±éå¤šã‚’ç·©å’Œã™ã‚‹ãŸã‚ã®ä¸å¯æ¬ ãªãƒ„ãƒ¼ãƒ«ã¨ãªã£ã¦ã„ã‚‹ã€‚
Recent trends in RSs have revealed a major paradigm shift, moving the spotlight from model-centric innovations to data-centric efforts (e.g., improving data quality and quantity).
RSã®æœ€è¿‘ã®å‹•å‘ã¯ã€**ãƒ¢ãƒ‡ãƒ«ä¸­å¿ƒã®é©æ–°ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒã®å–ã‚Šçµ„ã¿ï¼ˆä¾‹ãˆã°ã€ãƒ‡ãƒ¼ã‚¿ã®è³ªã¨é‡ã®æ”¹å–„ï¼‰ã¸ã¨ã‚¹ãƒãƒƒãƒˆãƒ©ã‚¤ãƒˆã‚’ç§»ã—**ã€å¤§ããªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚·ãƒ•ãƒˆã‚’æ˜ã‚‰ã‹ã«ã—ã¦ã„ã‚‹ã€‚
This evolution has given rise to the concept of data-centric recommender systems (Data-Centric RSs), marking a significant development in the field.
ã“ã®é€²åŒ–ã¯ã€data-centric recommender systemsï¼ˆData-Centric RSs, ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒå‹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ï¼‰ã¨ã„ã†æ¦‚å¿µã‚’ç”Ÿã¿å‡ºã—ã€ã“ã®åˆ†é‡ã«ãŠã‘ã‚‹é‡è¦ãªç™ºå±•ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
This survey provides the first systematic overview of Data-Centric RSs, covering 1) the foundational concepts of recommendation data and Data-Centric RSs; 2) three primary issues of recommendation data; 3) recent research developed to address these issues; and 4) several potential future directions of Data-Centric RSs.
æœ¬ã‚µãƒ¼ãƒ™ã‚¤ã§ã¯ã€1ï¼‰æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã¨ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒå‹RSã®åŸºç¤æ¦‚å¿µã€2ï¼‰æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã®3ã¤ã®ä¸»è¦ãªå•é¡Œã€3ï¼‰ã“ã‚Œã‚‰ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«é–‹ç™ºã•ã‚ŒãŸæœ€è¿‘ã®ç ”ç©¶ã€4ï¼‰ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒå‹RSã®ã„ãã¤ã‹ã®æ½œåœ¨çš„ãªå°†æ¥ã®æ–¹å‘æ€§ã‚’ç¶²ç¾…ã—ã€**Deata-Centric RSsã®åˆã®ä½“ç³»çš„ãªæ¦‚è¦**ã‚’æä¾›ã™ã‚‹ã€‚

# 1. Introduction ã¯ã˜ã‚ã«

Recommender systems (RSs) have been widely adopted to alleviate information overload in various real-world applications, such as social media, e-commerce, and online advertising.
ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ï¼ˆRSï¼‰ã¯ã€ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ã€é›»å­å•†å–å¼•ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åºƒå‘Šãªã©ã®æ§˜ã€…ãªå®Ÿä¸–ç•Œã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ã€æƒ…å ±éå¤šã‚’ç·©å’Œã™ã‚‹ãŸã‚ã«åºƒãæ¡ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚
The past few decades have witnessed the rapid development of recommendation models, evolving from traditional collaborative-filtering-based models Rendle et al.(2009) to more advanced deep-learning-based ones Ge et al.(2023), which have markedly improved the accuracy, diversity, and interpretability of recommendation results Li et al.(2020).
éå»æ•°åå¹´é–“ã€æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã®æ€¥é€Ÿãªç™ºå±•ãŒç›®è¦šã¾ã—ã„ã€‚å¾“æ¥ã®å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«Rendle et al.(2009)ã‹ã‚‰ã€ã‚ˆã‚Šé«˜åº¦ãªãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«Ge et al.(2023)ã¸ã¨é€²åŒ–ã—ã€æ¨è–¦çµæœã®ç²¾åº¦ã€å¤šæ§˜æ€§ã€è§£é‡ˆæ€§ãŒè‘—ã—ãå‘ä¸Šã—ã¦ã„ã‚‹ Li et al.(2020)ã€‚
(Rendle el al. 2009ã¯ explicit ALSã®ã‚„ã¤ã ã£ã‘! Ge et al. 2023ã¯ä½•ã®è«–æ–‡ã ã‚ã†ã‹...?)

However, as recommendation models are growing larger and increasingly complex, as exemplified by the P5 recommendation model Geng et al.(2022) that integrates five recommendation-related tasks into a shared language generation framework, the primary constraint impacting recommendation performance gradually transitions towards recommendation data.
ã—ã‹ã—ã€ä¾‹ãˆã°**5ã¤ã®æ¨è–¦é–¢é€£ã‚¿ã‚¹ã‚¯ã‚’å…±æœ‰è¨€èªç”Ÿæˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«çµ±åˆã™ã‚‹P5æ¨è–¦ãƒ¢ãƒ‡ãƒ« Geng et al.(2022)** ã®ã‚ˆã†ã«ã€æ¨è–¦ãƒ¢ãƒ‡ãƒ«ãŒå¤§ããè¤‡é›‘ã«ãªã‚‹ã«ã¤ã‚Œã¦ã€**æ¨è–¦æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ä¸»è¦ãªåˆ¶ç´„ã¯å¾ã€…ã«æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã«ç§»è¡Œã—ã¦ã„ã‚‹**ã€‚
(P5æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã¯ã€5ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’å­¦ç¿’ã•ã›ãŸãƒ¢ãƒ‡ãƒ«ã£ã¦ã“ã¨ã‹ãª? ã‚‚ã—ãã¯5ã¤ã®usecaseã«å¯¾å¿œã—ãŸãƒ¢ãƒ‡ãƒ«??)
Instead of focusing solely on developing even more advanced models, an increasing number of researchers have been advocating for the enhancement of recommendation data, leading to the emergence of the novel concept of data-centric recommender systems (Data-Centric RSs) Zha et al.(2023).
ã‚ˆã‚Šé«˜åº¦ãªãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã«ã®ã¿ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã®ã§ã¯ãªãã€æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã®å¼·åŒ–ã‚’æå”±ã™ã‚‹ç ”ç©¶è€…ãŒå¢—ãˆã¦ãŠã‚Šã€**ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒå‹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ï¼ˆData-Centric RSsï¼‰ã¨ã„ã†æ–°ã—ã„æ¦‚å¿µãŒç™»å ´**ã—ã¦ã„ã‚‹(Zha et al.(2023))ã€‚

The fundamental rationale behind Data-Centric RSs is that data ultimately dictates the upper limits of model capabilities.
**Data-Centric RSsã®æ ¹æœ¬çš„ãªç†è«–ã¯ã€ãƒ‡ãƒ¼ã‚¿ãŒæœ€çµ‚çš„ã«ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã®ä¸Šé™ã‚’æ±ºå®šã™ã‚‹ã¨ã„ã†ã“ã¨**ã§ã‚ã‚‹ã€‚(ãªã‚‹ã»ã©...!)
Large and high-quality data constitutes the essential prerequisite for breakthroughs in performance.
å¤§é‡ã‹ã¤é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã¯ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é£›èºçš„ã«å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®å¿…é ˆæ¡ä»¶ã§ã‚ã‚‹ã€‚
For instance, the remarkable advancements of GPT models in natural language processing are mainly originated from the use of huge and high-quality datasets Ouyang et al.(2022).
ä¾‹ãˆã°ã€è‡ªç„¶è¨€èªå‡¦ç†ã«ãŠã‘ã‚‹GPTãƒ¢ãƒ‡ãƒ«ã®ç›®è¦šã¾ã—ã„é€²æ­©ã¯ã€ä¸»ã«å·¨å¤§ã§é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½¿ç”¨ã«ç”±æ¥ã™ã‚‹ (Ouyang et al.2022)ã€‚(ãªã‚‹ã»ã©...!)
Similarly, in computer vision, convolutional neural networks exhibit performance on par with vision transformers when they have access to web-scale datasets Smith et al.(2023).
åŒæ§˜ã«ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã«ãŠã„ã¦ã‚‚ã€ã‚¦ã‚§ãƒ–ã‚¹ã‚±ãƒ¼ãƒ«(i.e. ã‚ã¡ã‚ƒã‚ã¡ã‚ƒå¤§é‡ã®?)ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã¨ã€ç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ãƒ“ã‚¸ãƒ§ãƒ³ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹ Smith et al.(2023)ã€‚(CVã§ã‚‚åŒã˜ã“ã¨ãŒè¨€ãˆã‚‹ã®ã‹...!:thinking:)
For RSs, the implication is clear: the greater the quality Wang et al.(2021a) and/or the quantity Liu et al.(2023) of recommendation data, the more proficiently RSs can characterize user preferences, resulting in recommendations that resonate well with users.
RSã«ãŠã„ã¦ã¯ã€ãã®æ„å‘³ã¯æ˜ç¢ºã§ã‚ã‚‹ï¼š**æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã®è³ª Wang et al.(2021a) ã¨/ã¾ãŸã¯é‡ Liu et al.(2023) ãŒå¤§ãã„ã»ã©ã€RSã¯ãƒ¦ãƒ¼ã‚¶ã®å—œå¥½ã‚’ã‚ˆã‚ŠåŠ¹æœçš„ã«ç‰¹å¾´ä»˜ã‘ã‚‹ã“ã¨ãŒã§ãã€ãƒ¦ãƒ¼ã‚¶ã«ã‚ˆãéŸ¿ãæ¨è–¦ã‚’æä¾›ã™ã‚‹ã“ã¨ãŒã§ãã‚‹**ã€‚(ã†ã‚“ã†ã‚“...!:thinking:)

Despite considerable attention from researchers and a great variety of methods that have been put forth in Data-Centric RSs, to the best of our knowledge, there has been no effort to gather and provide a summary of works in this promising and fast-developing research field.
Data-Centric RSsã«é–¢ã™ã‚‹ç ”ç©¶è€…ã®å¤šå¤§ãªé–¢å¿ƒã¨ã€ã“ã®æœ‰æœ›ã§æ€¥é€Ÿã«ç™ºå±•ã—ã¦ã„ã‚‹ç ”ç©¶åˆ†é‡ã«ãŠã„ã¦ææ¡ˆã•ã‚Œã¦ããŸå¤šæ§˜ãªæ‰‹æ³•ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€æˆ‘ã€…ã®çŸ¥ã‚‹é™ã‚Šã€ã“ã®åˆ†é‡ã«ãŠã‘ã‚‹ç ”ç©¶ã®è¦ç´„ã‚’ã¾ã¨ã‚ã¦æä¾›ã™ã‚‹å–ã‚Šçµ„ã¿ã¯ãªã„ã€‚
To fulfill this gap, we conduct a systematic review of the literature on Data-Centric RSs and provide insights from the following four aspects.
ã“ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã«ã€Data-Centric RSsã«é–¢ã™ã‚‹æ–‡çŒ®ã®ä½“ç³»çš„ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã„ã€ä»¥ä¸‹ã®**4ã¤ã®å´é¢ã‹ã‚‰æ´å¯Ÿã‚’æä¾›**ã™ã‚‹ã€‚
We first detail the specifics of data that could be used for recommendation and present the formalization of Data-Centric RSs (Section 2).
ã¾ãšã€æ¨è–¦ã«ä½¿ç”¨ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’è¿°ã¹ã€ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒå‹RSã®å½¢å¼åŒ–ã‚’ç¤ºã™ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³2ï¼‰ã€‚
Next, we identify three key issues in recommendation data, i.e., data incompleteness, data noise, and data bias (Section 3), and categorize the existing literature in accordance with these issues (Section 4).
æ¬¡ã«ã€æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹3ã¤ã®ä¸»è¦ãªå•é¡Œã‚’ç‰¹å®šã™ã‚‹(ã‚»ã‚¯ã‚·ãƒ§ãƒ³3)ã€‚ã™ãªã‚ã¡ã€data imcompleteness(ãƒ‡ãƒ¼ã‚¿ã®ä¸å®Œå…¨æ€§), data noise(ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ã‚º) data bias(ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ã‚¢ã‚¹)ã§ã‚ã‚‹ã€‚ãã—ã¦ã€ã“ã‚Œã‚‰ã®å•é¡Œã«å¾“ã£ã¦æ—¢å­˜ã®æ–‡çŒ®ã‚’åˆ†é¡ã™ã‚‹ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³4ï¼‰ã€‚
Finally, we spotlight a number of encouraging research directions in Data-Centric RSs (Section 5).
æœ€å¾Œã«ã€Data-Centric RSsã«ãŠã‘ã‚‹ã„ãã¤ã‹ã®æœ‰æœ›ãªç ”ç©¶æ–¹å‘ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³5ï¼‰ã€‚

<!-- ã“ã“ã¾ã§èª­ã‚“ã ï¼ -->

# 2. Formulation ãƒ•ã‚©ãƒ¼ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

![figure1]()
Figure 1:Three types of recommendation data.

## 2.1. Recommendation Data æ¨è–¦ãƒ‡ãƒ¼ã‚¿

The goal of RSs is to help users discover potential items of interest and then generate personalized recommendations.
RSã®ç›®çš„ã¯ã€ãƒ¦ãƒ¼ã‚¶ãŒèˆˆå‘³ã‚’æŒã¤å¯èƒ½æ€§ã®ã‚ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç™ºè¦‹ã—ã€ãã®å¾Œã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸæ¨è–¦ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
To achieve this goal, as shown in Figure 1, we summarize three types of data that can be used in RSs:
ã“ã®ç›®æ¨™ã‚’é”æˆã™ã‚‹ãŸã‚ã«ã€å›³1ã«ç¤ºã™ã‚ˆã†ã«ã€**RSã§ä½¿ç”¨ã§ãã‚‹3ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿**ã‚’ã¾ã¨ã‚ã‚‹ï¼š

- User profiles: User profiles refer to a collection of information and characteristics that describe an individual user.
  ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼š ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã¯ã€å€‹ã€…ã®ãƒ¦ãƒ¼ã‚¶ã‚’è¨˜è¿°ã™ã‚‹æƒ…å ±ã¨ç‰¹æ€§ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŒ‡ã™ã€‚
  In the context of recommendation, user profiles typically include demographics, preferences, behavior patterns, and other relevant data that helps define and understand a userâ€™s characteristics, needs, and interests.
  æ¨è–¦ã®æ–‡è„ˆã«ãŠã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã«ã¯ã€é€šå¸¸ã€äººå£çµ±è¨ˆã€å¥½ã¿ã€è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ãã®ä»–ã®é–¢é€£ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã€ãƒ¦ãƒ¼ã‚¶ã®ç‰¹æ€§ã€ãƒ‹ãƒ¼ã‚ºã€èˆˆå‘³ã‚’å®šç¾©ã—ç†è§£ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚

- Item attributes: Item attributes involve the specific details or characteristics that describe an item.
  ã‚¢ã‚¤ãƒ†ãƒ ã®å±æ€§ï¼š ã‚¢ã‚¤ãƒ†ãƒ ã®å±æ€§ã«ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ã‚’è¨˜è¿°ã™ã‚‹ç‰¹å®šã®è©³ç´°ã‚„ç‰¹æ€§ãŒå«ã¾ã‚Œã¾ã™ã€‚
  These details can include color, material, brand, price, and other relevant information that helps identify or categorize the item.
  ã“ã‚Œã‚‰ã®è©³ç´°ã«ã¯ã€è‰²ã€ç´ æã€ãƒ–ãƒ©ãƒ³ãƒ‰ã€ä¾¡æ ¼ã€ãã®ä»–ã®é–¢é€£æƒ…å ±ãŒå«ã¾ã‚Œã€ã‚¢ã‚¤ãƒ†ãƒ ã‚’è­˜åˆ¥ã¾ãŸã¯åˆ†é¡ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚

- User-item interactions: User-item interactions represent usersâ€™ actions or involvements with items.
  ãƒ¦ãƒ¼ã‚¶ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ç›¸äº’ä½œç”¨: ãƒ¦ãƒ¼ã‚¶ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã¯ã€ãƒ¦ãƒ¼ã‚¶ã®ã‚¢ã‚¤ãƒ†ãƒ ã«å¯¾ã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚„é–¢ä¸ã‚’è¡¨ã™ã€‚
  Additional contextual information such as ratings, behaviors, timestamps, and reviews can also be utilized to provide a more comprehensive picture of the interactions between users and items.
  è©•ä¾¡ã€è¡Œå‹•(ã®ç¨®é¡)ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã©ã®è¿½åŠ ã®æ–‡è„ˆæƒ…å ±ã‚‚åˆ©ç”¨ã•ã‚Œã€ãƒ¦ãƒ¼ã‚¶ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ç›¸äº’ä½œç”¨ã®ã‚ˆã‚ŠåŒ…æ‹¬çš„ãªã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æä¾›ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚

## 2.2. Data-Centric RSs ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒRS

![figure2]()
Figure 2:Model-Centric RSs v.s. Data-Centric RSs.

As shown in Figure 2, different from Model-Centric RSs which improve recommendation performance by refining models, Data-Centric RSs shift the focus from model to data and emphasize the importance of data enhancement.
å›³2ã«ç¤ºã™ã‚ˆã†ã«ã€**ãƒ¢ãƒ‡ãƒ«ã‚’æ”¹è‰¯ã™ã‚‹ã“ã¨ã§æ¨è–¦æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹Model-Centric RSsã¨ã¯ç•°ãªã‚Šã€Data-Centric RSsã¯ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã«ç„¦ç‚¹ã‚’ç§»ã—ã€ãƒ‡ãƒ¼ã‚¿ã®å¼·åŒ–ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¦ã„ã‚‹**ã€‚
More specifically, given the recommendation data ğ’Ÿ (e.g., user-item interactions), Data-Centric RSs aim to determine a strategy ï¿½ , which takes the original data ğ’Ÿ as input and outputs the enhanced data ğ’Ÿ â€² :
ã‚ˆã‚Šå…·ä½“çš„ã«ã¯ã€ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒå‹RSã¯ã€æ¨è–¦ãƒ‡ãƒ¼ã‚¿(ä¾‹ãˆã°ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ç›¸äº’ä½œç”¨)ãŒä¸ãˆã‚‰ã‚Œã‚‹ã¨ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿($D$)ã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã€å¼·åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿($D'$)ã‚’å‡ºåŠ›ã™ã‚‹æˆ¦ç•¥ã‚’æ±ºå®šã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚

$$
D'= f(D)
\tag{1}
$$

The enhanced data ğ’Ÿ â€² could be used by different recommendation models to further improve their performance.
å¼·åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ $D'$ ã¯ã€ç•°ãªã‚‹æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ä½¿ç”¨ã•ã‚Œã€ãã®æ€§èƒ½ã‚’ã•ã‚‰ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
We also attempt to answer the following questions to clarify the definition of Data-Centric RSs:
æˆ‘ã€…ã¯ã¾ãŸã€Data-Centric RSsã®å®šç¾©ã‚’æ˜ç¢ºã«ã™ã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã®è³ªå•ã«ç­”ãˆã‚ˆã†ã¨è©¦ã¿ã‚‹:

### Q1: Are Data-Centric RSs the same as Data-Driven RSs? Q1: ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒRSã¯ãƒ‡ãƒ¼ã‚¿é§†å‹•RSã¨åŒã˜ã§ã™ã‹ï¼Ÿ

Data-Centric RSs and Data-Driven RSs are fundamentally different, as the latter only emphasize the use of recommendation data to guide the design of recommendation models without modifying the data, which are essentially still Model-Centric RSs Zha et al.(2023).
ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒRSã¨ãƒ‡ãƒ¼ã‚¿é§†å‹•RSã¯åŸºæœ¬çš„ã«ç•°ãªã‚‹ã€‚å¾Œè€…ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã›ãšã«æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã®è¨­è¨ˆã‚’ã‚¬ã‚¤ãƒ‰ã™ã‚‹ã“ã¨ã‚’å¼·èª¿ã™ã‚‹ã ã‘ã§ã‚ã‚Šã€æœ¬è³ªçš„ã«ã¯ãƒ¢ãƒ‡ãƒ«ä¸­å¿ƒRSã§ã‚ã‚‹(Zha et al.(2023))ã€‚

### Q2: Why Data-Centric RSs are necessary? Q2: ãªãœãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒRSãŒå¿…è¦ãªã®ã‹ï¼Ÿ

The objective of a recommendation model is to fit the recommendation data.
æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã®ç›®çš„ã¯ã€æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã«é©åˆã•ã›ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚(ãªã‚‹ã»ã©ã€ãƒ¢ãƒ‡ãƒ«ã¯ãã®ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã¨ã„ãˆã°ãã†ã‹...! æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®ç›®çš„ã¯é•ã†ã‘ã©...!)
Without changing the data, Model-Centric RSs may generalize or even amplify errors (e.g., noise or bias) in the data, resulting in suboptimal recommendations Zhang et al.(2023a).
ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã›ãšã«ã€ãƒ¢ãƒ‡ãƒ«ä¸­å¿ƒRSã¯ã€ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ãƒ©ãƒ¼(ex. ãƒã‚¤ã‚ºã‚„ãƒã‚¤ã‚¢ã‚¹)ã‚’ä¸€èˆ¬åŒ–ã—ãŸã‚Šã€æ‹¡å¤§ã—ãŸã‚Šã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€æœ€é©ã§ãªã„æ¨è–¦ã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ãŒã‚ã‚‹(Zhang et al.(2023a))ã€‚
Therefore, Data-Centric RSs are necessary.
ã—ãŸãŒã£ã¦ã€ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒã®RSãŒå¿…è¦ã¨ãªã‚‹ã€‚

### Q3: Will Data-Centric RSs substitute Model-Centric RSs? Q3: ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒRSã¯ãƒ¢ãƒ‡ãƒ«ä¸­å¿ƒRSã®ä»£ã‚ã‚Šã«ãªã‚‹ã®ã‹ï¼Ÿ

Data-Centric RSs do not diminish the value of Model-Centric RSs.
ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒRSãŒãƒ¢ãƒ‡ãƒ«ä¸­å¿ƒRSã®ä¾¡å€¤ã‚’ä¸‹ã’ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
Instead, these two paradigms complement each other to build more effective recommender systems.
ã‚€ã—ã‚ã€**ã“ã‚Œã‚‰2ã¤ã®paradigms(=ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã€ã‚‚ã®ã®è¦‹æ–¹ã‚„è€ƒãˆæ–¹ãƒ»èªè­˜ã®æ çµ„ã¿ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯?)ã¯ã€ã‚ˆã‚ŠåŠ¹æœçš„ãªæ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã«äº’ã„è£œå®Œã—åˆã†**ã€‚(ã†ã‚“ã†ã‚“)
Interestingly, model-centric methods can be used to achieve data-centric goals.
èˆˆå‘³æ·±ã„ã“ã¨ã«ã€model-centricãªæ‰‹æ³•ã¯ã€data-centricãªç›®æ¨™ã‚’é”æˆã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
For example, diffusion models Liu et al.(2023) can be an effective tool for data augmentation.
ä¾‹ãˆã°ã€æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«Liu et al.(2023)ã¯ã€ãƒ‡ãƒ¼ã‚¿è£œå¼·ã®ãŸã‚ã®åŠ¹æœçš„ãªãƒ„ãƒ¼ãƒ«ã¨ãªã‚Šå¾—ã‚‹ã€‚
Data-centric methods can facilitate the improvement of model-centric outcomes.
Data-Centric RSsã¯ã€model-centricãªæˆæœã‚’å‘ä¸Šã•ã›ã‚‹ã®ã«å½¹ç«‹ã¤ã“ã¨ãŒã§ãã‚‹ã€‚
For instance, high-quality synthesized data could inspire further advancements in model design Sachdeva et al.(2022).
ä¾‹ãˆã°ã€é«˜å“è³ªã«åˆæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯ã€ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆã®ã•ã‚‰ãªã‚‹é€²æ­©ã‚’ä¿ƒã™å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚(Sacdeva et al. 2022)

# 3. Data Issues ãƒ‡ãƒ¼ã‚¿ã®å•é¡Œ

![figure3]()
Figure 3:Overview of data issues in RSs.

As illustrated in Figure 3, we identify three key issues from which recommendation data may suffer, including data incompleteness, data noise, and data bias.
å›³3ã«ç¤ºã™ã‚ˆã†ã«ã€æ¨è–¦ãƒ‡ãƒ¼ã‚¿ãŒè¢«ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹å•é¡Œã¨ã—ã¦ã€**data incompleteness(ãƒ‡ãƒ¼ã‚¿ã®ä¸å®Œå…¨æ€§)**ã€**data noise(ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ã‚º)**ã€**data bias(ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ã‚¢ã‚¹)**ã®3ã¤ã®ä¸»è¦ãªå•é¡Œã‚’ç‰¹å®šã™ã‚‹ã€‚

## 3.1. Data Incompleteness ãƒ‡ãƒ¼ã‚¿ã®ä¸å®Œå…¨æ€§

The data incompleteness issue refers to the scenarios where data used for making recommendations is inadequate, consequently resulting in information gaps or missing details regarding users or items.
data incompletenessã®å•é¡Œã¯ã€æ¨è–¦ã‚’è¡Œã†ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ãŒä¸ååˆ†ã§ã‚ã‚‹å ´åˆã‚’æŒ‡ã—ã€ãã®çµæœã€ãƒ¦ãƒ¼ã‚¶ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã«é–¢ã™ã‚‹æƒ…å ±ã®æ¬ å¦‚ã‚„è©³ç´°ã®ä¸è¶³ãŒç”Ÿã˜ã‚‹ã€‚
Specifically, the forms and reasons in which recommendation data can be incomplete include:
å…·ä½“çš„ã«ã¯ã€æ¨è–¦ãƒ‡ãƒ¼ã‚¿ãŒä¸å®Œå…¨ã§ã‚ã‚‹ç†ç”±ã‚„å½¢æ…‹ã¯ä»¥ä¸‹ã®é€šã‚Šï¼š

- **Missing user profiles**: During the registration or setup process, users may fail to fully complete their profiles.
  ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¬ è½ï¼š ç™»éŒ²ã‚„ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã®éç¨‹ã§ã€ãƒ¦ãƒ¼ã‚¶ãŒãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Œå…¨ã«å…¥åŠ›ã§ããªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
  Key information may be omitted as they might bypass certain fields or provide inadequate information Wei et al.(2023).
  ç‰¹å®šã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿‚å›(=ã‚ã‹ã‚‹ã€å…¥åŠ›ã‚’é£›ã°ã™ã‚ˆã­!:thinking:)ã—ãŸã‚Šã€ä¸ååˆ†ãªæƒ…å ±ã‚’æä¾›ã—ãŸã‚Šã™ã‚‹ã“ã¨ã§ã€é‡è¦ãªæƒ…å ±ãŒçœç•¥ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™Wei et al.(2023)ã€‚
  For example, a user may neglect to add age or gender, resulting in a profile that is less informative than it could be.
  ãŸã¨ãˆã°ã€ãƒ¦ãƒ¼ã‚¶ãŒå¹´é½¢ã‚„æ€§åˆ¥ã‚’è¿½åŠ ã—ãªã‹ã£ãŸãŸã‚ã«ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã®æƒ…å ±é‡ãŒå°‘ãªããªã£ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚

- **Limited item attributes**: Similarly, data regarding item attributes may also be lacking.
  é™ã‚‰ã‚ŒãŸã‚¢ã‚¤ãƒ†ãƒ å±æ€§ï¼š åŒæ§˜ã«ã€ã‚¢ã‚¤ãƒ†ãƒ ã®å±æ€§ã«é–¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚‚ä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
  This incompleteness hinders the ability to precisely portray items and capture their distinct characteristics Wu et al.(2020).
  ã“ã®ä¸å®Œå…¨ã•ãŒã€ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ­£ç¢ºã«æå†™ã—ã€ãã®ç‹¬è‡ªã®ç‰¹æ€§ã‚’æ‰ãˆã‚‹èƒ½åŠ›ã‚’å¦¨ã’ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™Wu et al.(2020)ã€‚
  For instance, an online bookshop may only provide basic data about a book such as the title and author, neglecting additional details like genre or publication year that can enhance the recommendation accuracy.
  ä¾‹ãˆã°ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ›¸åº—ã¯ã€ã‚¿ã‚¤ãƒˆãƒ«ã‚„è‘—è€…ãªã©ã®åŸºæœ¬çš„ãªæ›¸ç±ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æä¾›ã—ã€ã‚¸ãƒ£ãƒ³ãƒ«ã‚„å‡ºç‰ˆå¹´ãªã©ã®è¿½åŠ æƒ…å ±ã‚’ç„¡è¦–ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã€ã“ã‚Œã‚‰ã®æƒ…å ±ã¯æ¨è–¦ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

- **Sparse user-item interactions**: RSs can encounter the â€œcold startâ€ problem when new users join.
  ãƒ¦ãƒ¼ã‚¶ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ç–ãªç›¸äº’ä½œç”¨ï¼š RSã¯ã€æ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãŒå‚åŠ ã™ã‚‹ã¨ã€Œã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã€å•é¡Œã«é­é‡ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
  With limited or no historical interactions for these users, providing accurate recommendations becomes challenging Wang et al.(2019).
  ã“ã®ã‚ˆã†ãªãƒ¦ãƒ¼ã‚¶ã®éå»ã®interactionãŒé™ã‚‰ã‚Œã¦ã„ã‚‹ã‹å­˜åœ¨ã—ãªã„å ´åˆã€æ­£ç¢ºãªæ¨è–¦ã‚’æä¾›ã™ã‚‹ã“ã¨ã¯å›°é›£ã«ãªã‚Šã¾ã™ã€‚Wang et al.(2019)ã€‚
  Additionally, users usually do not engage with every item.
  ã•ã‚‰ã«ã€ãƒ¦ãƒ¼ã‚¶ã¯é€šå¸¸ã€ã™ã¹ã¦ã®ã‚¢ã‚¤ãƒ†ãƒ ã¨é–¢ã‚ã‚‹ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
  For example, in a movie recommender system, a user may only rate a handful of thousands of movies available, leading to an incomplete picture of true preferences.
  ä¾‹ãˆã°ã€æ˜ ç”»æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ã¯åˆ©ç”¨å¯èƒ½ãªä½•åƒã‚‚ã®æ˜ ç”»ã®ã†ã¡ã‚ãšã‹æ•°æœ¬ã—ã‹è©•ä¾¡ã—ãªã„ã‹ã‚‚ã—ã‚Œãšã€çœŸã®å—œå¥½ã®ä¸å®Œå…¨ãªã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ã‚‚ãŸã‚‰ã™ã€‚

- **Inadequate contextual information**: Contextual information like timestamps, ratings, locations, or user reviews significantly contributes to generating effective recommendations.
  ä¸é©åˆ‡ãªæ–‡è„ˆæƒ…å ±ï¼š ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã€è©•ä¾¡ã€å ´æ‰€ã€ãƒ¦ãƒ¼ã‚¶ãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã©ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã¯ã€åŠ¹æœçš„ãªãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆã«å¤§ããè²¢çŒ®ã™ã‚‹ã€‚(=interactionã®sequenceçš„ãªãƒ‡ãƒ¼ã‚¿ã‚‚contextã«å«ã¾ã‚Œã‚‹ã®ã‹ãª...!:thinking:)
  However, due to privacy issues or constraints in user feedback, the available contextual information may be incomplete or lack details Chae et al.(2019).
  ã—ã‹ã—ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã®å•é¡Œã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ãŠã‘ã‚‹åˆ¶ç´„ã®ãŸã‚ã«ã€åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã¯ä¸å®Œå…¨ã§ã‚ã£ãŸã‚Šã€è©³ç´°ãŒæ¬ ã‘ã¦ã„ãŸã‚Šã™ã‚‹å ´åˆãŒã‚ã‚‹ (Chae et al.2019)ã€‚(ã¾ã‚ratingã¯ä¸­ã€…å¾—ã‚‰ã‚Œãªã„ã‚ˆã­ã€‚locationã‚‚ãƒ¦ãƒ¼ã‚¶ãŒä½ç½®æƒ…å ±ã®é–‹ç¤ºã‚’æœ‰åŠ¹ã«ã—ã¦ãªã„ã¨ã„ã‘ãªã„ã—...!:thinking:)
  For instance, a user might give a high rating for a hotel visit but does not provide a review that could offer useful insights about his/her preferences for future recommendations.
  ä¾‹ãˆã°ã€ãƒ¦ãƒ¼ã‚¶ãŒãƒ›ãƒ†ãƒ«è¨ªå•ã«é«˜ã„è©•ä¾¡ã‚’ã¤ã‘ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ãŒã€å°†æ¥ã®æ¨è–¦ã«å½¹ç«‹ã¤æ´å¯Ÿã‚’æä¾›ã™ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æä¾›ã—ãªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚

<!-- ã“ã“ã¾ã§èª­ã‚“ã ! -->

## 3.2. Data Noise ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒã‚¤ã‚º

Data noise arises when a portion of the recommendation data is irrelevant or erroneous, which negatively impacts the quality of recommendations provided.
ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚ºã¯ã€æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã«ç„¡é–¢ä¿‚ãªã‚‚ã®ã‚„èª¤ã‚ŠãŒã‚ã‚‹å ´åˆã«ç™ºç”Ÿã—ã€æä¾›ã•ã‚Œã‚‹æ¨è–¦ã®å“è³ªã«æ‚ªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã€‚
Noisy recommendation data can appear in several forms:
ãƒã‚¤ã‚¸ãƒ¼ãªæ¨è–¦ãƒ‡ãƒ¼ã‚¿ã¯ã€ã„ãã¤ã‹ã®å½¢ã§ç¾ã‚Œã‚‹:

- **Redundant data**: An abundance of identical data is often the consequence of errors during the data collection process.
  å†—é•·ãªãƒ‡ãƒ¼ã‚¿ï¼š åŒä¸€ãƒ‡ãƒ¼ã‚¿ãŒå¤§é‡ã«å­˜åœ¨ã™ã‚‹ã®ã¯ã€ãƒ‡ãƒ¼ã‚¿åé›†éç¨‹ã«ãŠã‘ã‚‹ã‚¨ãƒ©ãƒ¼ã®çµæœã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã€‚
  RSs might incorrectly identify and log certain identical item attributes multiple times, such as the same item category appearing repeatedly.
  RSã¯ã€åŒã˜ã‚¢ã‚¤ãƒ†ãƒ ã‚«ãƒ†ã‚´ãƒªãŒç¹°ã‚Šè¿”ã—è¡¨ç¤ºã•ã‚Œã‚‹ãªã©ã€ç‰¹å®šã®åŒä¸€ã®ã‚¢ã‚¤ãƒ†ãƒ å±æ€§ã‚’èª¤ã£ã¦è¤‡æ•°å›è­˜åˆ¥ã—ã¦è¨˜éŒ²ã™ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚
  Alternatively, it might record a user interacting with the same item multiple times â€“ a shop page refresh mistake, for example.
  ã‚ã‚‹ã„ã¯ã€ã‚·ãƒ§ãƒƒãƒ—ãƒšãƒ¼ã‚¸ã®æ›´æ–°ãƒŸã‚¹ãªã©ã€ãƒ¦ãƒ¼ã‚¶ãŒåŒã˜ã‚¢ã‚¤ãƒ†ãƒ ã‚’ä½•åº¦ã‚‚æ“ä½œã—ãŸã“ã¨ã‚’è¨˜éŒ²ã™ã‚‹å ´åˆã‚‚ã‚ã‚‹ã€‚

- Inconsistent data: Inconsistencies in data occur mainly due to human errors, such as users unintentionally clicking or providing incorrect ratings to an item Lin et al.(2023b).
  ãƒ‡ãƒ¼ã‚¿ã®çŸ›ç›¾ï¼š ãƒ‡ãƒ¼ã‚¿ã®ä¸æ•´åˆã¯ä¸»ã«ã€ãƒ¦ãƒ¼ã‚¶ãŒæ„å›³ã›ãšã«ã‚¢ã‚¤ãƒ†ãƒ ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ãŸã‚Šã€èª¤ã£ãŸè©•ä¾¡ã‚’æä¾›ã—ãŸã‚Šã™ã‚‹ãªã©ã®äººç‚ºçš„ãªã‚¨ãƒ©ãƒ¼ã«ã‚ˆã£ã¦ç™ºç”Ÿã™ã‚‹ã“ã¨ãŒå¤šã„(Lin et al.(2023b))ã€‚
  Additionally, different data sources, like explicit ratings, implicit signals, and textual reviews, can present conflicting information about a userâ€™s current preferences.
  ã•ã‚‰ã«ã€æ˜ç¤ºçš„ãªè©•ä¾¡ã€æš—é»™çš„ãªã‚·ã‚°ãƒŠãƒ«ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã©ã€**ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹(=å¤šç¨®ã®feedbackãƒ‡ãƒ¼ã‚¿ãŸã¡...!)ã¯ã€ãƒ¦ãƒ¼ã‚¶ã®ç¾åœ¨ã®å—œå¥½ã«ã¤ã„ã¦ç›¸åã™ã‚‹æƒ…å ±ã‚’æç¤ºã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹**ã€‚
  For example, a user might provide a low rating for a product, but the text in his/her review might be generally positive, which creates confusion.
  ä¾‹ãˆã°ã€ã‚ã‚‹ãƒ¦ãƒ¼ã‚¶ãŒã‚ã‚‹è£½å“ã«ä½ã„è©•ä¾¡ã‚’ä»˜ã‘ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ãŒã€ãã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ãƒ†ã‚­ã‚¹ãƒˆãŒä¸€èˆ¬çš„ã«è‚¯å®šçš„ã§ã‚ã‚‹å ´åˆã€æ··ä¹±ãŒç”Ÿã˜ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚(ç¢ºã‹ã«ã€ã“ã‚Œã¯ratingã‚’èª¤ã£ã¦æ“ä½œã—ã¦ãã†...!:thinking:)

- Spam or fake data: At a more malicious level, RSs can be susceptible to spam or fake data generated by either malicious users or automated bots trying to harm the system.
  ã‚¹ãƒ‘ãƒ ã¾ãŸã¯å½ãƒ‡ãƒ¼ã‚¿ï¼š **ã‚ˆã‚Šæ‚ªè³ªãªãƒ¬ãƒ™ãƒ«ã§ã¯ã€RSã¯æ‚ªæ„ã®ã‚ã‚‹ãƒ¦ãƒ¼ã‚¶ã‚„ã‚·ã‚¹ãƒ†ãƒ ã‚’å®³ã™ã‚‹ãŸã‚ã«ç”Ÿæˆã•ã‚ŒãŸè‡ªå‹•åŒ–ã•ã‚ŒãŸãƒœãƒƒãƒˆã«ã‚ˆã‚‹ã‚¹ãƒ‘ãƒ ã‚„å½ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦è„†å¼±ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹**ã€‚(ãªã‚‹ã»ã©ç¢ºã‹ã«...! åŸºæœ¬çš„ã«CFã¨ã‹ã ã¨ã€è‡ªå‹•åŒ–ã•ã‚ŒãŸbotã®interactionãƒ‡ãƒ¼ã‚¿ã¯é™¤å¤–ã—ãŸã»ã†ãŒè‰¯ã„ã‚ˆãª...!:thinking:)
  This undesired data can significantly contaminate the pool of authentic user data and can drastically impact the quality of recommendations, leading to decreased user satisfaction Wu et al.(2023).
  ã“ã®ã‚ˆã†ãªæœ›ã¾ã—ããªã„ãƒ‡ãƒ¼ã‚¿ã¯ã€**æœ¬ç‰©ã®ãƒ¦ãƒ¼ã‚¶ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¼ãƒ«ã‚’è‘—ã—ãæ±šæŸ“ã—**ã€æ¨è–¦ã®å“è³ªã«å¤§ããªå½±éŸ¿ã‚’ä¸ãˆã€ãƒ¦ãƒ¼ã‚¶ã®æº€è¶³åº¦ã‚’ä½ä¸‹ã•ã›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹(Wu et al.(2023))ã€‚
  A typical example is â€œreview bombingâ€, where orchestrated attempts by certain users or bots fill a productâ€™s review section with negative feedback to harm its overall rating, even though the product may be generally well-received by the majority.
  å…¸å‹çš„ãªä¾‹ãŒ **"review bombing"(ãƒ¬ãƒ“ãƒ¥ãƒ¼çˆ†æ’ƒ)**ã§ã€ç‰¹å®šã®ãƒ¦ãƒ¼ã‚¶ã‚„ãƒœãƒƒãƒˆã«ã‚ˆã‚‹çµ„ç¹”çš„ãªè©¦ã¿ã«ã‚ˆã‚Šã€è£½å“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒnegative feedbackã§åŸ‹ã‚å°½ãã•ã‚Œã€ãã®è£½å“ãŒä¸€èˆ¬çš„ã«å¥½è©•ã§ã‚ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€ãã®ç·åˆè©•ä¾¡ã‚’æãªã†ã“ã¨ãŒã‚ã‚‹ã€‚
  (ãªã‚‹ã»ã©...!:thinking:)

## 3.3. Data Bias ãƒ‡ãƒ¼ã‚¿ã®åã‚Š

![figure4]()
Figure 4:An illustration of data bias in RSs.

A significant data bias issue arises when there is a significant distribution shift between the data collected and the real-world data.
é‡è¦ãªãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚¢ã‚¹ã®å•é¡Œã¯ã€åé›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¨å®Ÿä¸–ç•Œã®ãƒ‡ãƒ¼ã‚¿ã¨ã®é–“ã«è‘—ã—ã„åˆ†å¸ƒã‚·ãƒ•ãƒˆãŒã‚ã‚‹å ´åˆã«ç™ºç”Ÿã™ã‚‹ã€‚
This problem mainly originates from:
ã“ã®å•é¡Œã¯ä¸»ã«ä»¥ä¸‹ã®ç‚¹ã‹ã‚‰ç™ºç”Ÿã™ã‚‹:

- **Shifts in user preferences**: As illustrated in Figure 4, usersâ€™ preferences can change due to shifts in wider environmental factors or their personal circumstances like pregnancy.
  ãƒ¦ãƒ¼ã‚¶ã®å—œå¥½ã®å¤‰åŒ–ï¼š å›³4ã«ç¤ºã™ã‚ˆã†ã«ã€ãƒ¦ãƒ¼ã‚¶ã®å—œå¥½ã¯ã€ã‚ˆã‚Šåºƒã„ç’°å¢ƒè¦å› ã®å¤‰åŒ–ã‚„ã€å¦Šå¨ ãªã©ã®å€‹äººçš„ãªçŠ¶æ³ã®å¤‰åŒ–ã«ã‚ˆã£ã¦å¤‰åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
  In these scenarios, data collected in the past may no longer provide an accurate representation of the userâ€™s current preferences Wang et al.(2023a).
  **ã“ã®ã‚ˆã†ãªã‚·ãƒŠãƒªã‚ªã§ã¯ã€éå»ã«åé›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯ã€ã‚‚ã¯ã‚„ãƒ¦ãƒ¼ã‚¶ã®ç¾åœ¨ã®å—œå¥½ã‚’æ­£ç¢ºã«è¡¨ç¾ã—ã¦ã„ãªã„ã‹ã‚‚ã—ã‚Œãªã„**(Wang et al.(2023a))ã€‚(ã†ã‚“ã†ã‚“...!:thinking:)

- **Changes in item popularity**: Similarly, the popularity of certain items or categories is not static and can significantly vary over time.
  ã‚¢ã‚¤ãƒ†ãƒ äººæ°—ã®å¤‰åŒ–ï¼š åŒæ§˜ã«ã€ç‰¹å®šã®ã‚¢ã‚¤ãƒ†ãƒ ã‚„ã‚«ãƒ†ã‚´ãƒªã®äººæ°—ã¯å›ºå®šçš„ãªã‚‚ã®ã§ã¯ãªãã€æ™‚é–“ã®çµŒéã¨ã¨ã‚‚ã«å¤§ããå¤‰åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
  Items or trends that were once prevalent may lose their charm and relevance as time passes.
  ã‹ã¤ã¦æµè¡Œã—ãŸã‚¢ã‚¤ãƒ†ãƒ ã‚„ãƒˆãƒ¬ãƒ³ãƒ‰ã¯ã€æ™‚ãŒçµŒã¤ã«ã¤ã‚Œã¦ãã®é­…åŠ›ã‚„é–¢é€£æ€§ã‚’å¤±ã†ã‹ã‚‚ã—ã‚Œãªã„ã€‚
  For example, as shown in Figure 4, a certain genre of products like the watch that was the rage a few years ago may not hold the same appeal to the audience in the present day as tastes evolve and new genres emerge Zhang et al.(2023a).
  ä¾‹ãˆã°ã€å›³4ã«ç¤ºã™ã‚ˆã†ã«ã€æ•°å¹´å‰ã«æµè¡Œã—ãŸæ™‚è¨ˆã®ã‚ˆã†ãªç‰¹å®šã®è£½å“ã‚¸ãƒ£ãƒ³ãƒ«ã¯ã€å‘³è¦šãŒå¤‰åŒ–ã—ã€æ–°ã—ã„ã‚¸ãƒ£ãƒ³ãƒ«ãŒç™»å ´ã™ã‚‹ã«ã¤ã‚Œã¦ã€ç¾åœ¨ã®è¦³å®¢ã«åŒã˜é­…åŠ›ã‚’æŒãŸãªã„ã‹ã‚‚ã—ã‚Œãªã„(Zhang et al.(2023a))ã€‚
  (ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã§è¨€ã†ã¨ã“ã‚ã®ã€ä¾‹ãˆã°ä»Šã¯AIé–¢é€£ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒäººæ°—ã§æµè¡Œã£ã¦ã‚‹ã‘ã©ã€æ•°å¹´å¾Œã«ã¯å¿…ãšã—ã‚‚ãã†ã§ã¯ãªã„ã€‚ãã®æ™‚ã«ä»Šã®è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ã§ãƒ¦ãƒ¼ã‚¶ã®å—œå¥½ã‚’æ‰ãˆã‚ˆã†ã¨ã™ã‚‹ã¨æ™‚ä»£é…ã‚Œãªæ„Ÿã˜ã«ãªã£ã¡ã‚ƒã†ã‚ˆã­....!:thinking:)

<!-- ã“ã“ã¾ã§èª­ã‚“ã ! -->

# 4. Research Progress ç ”ç©¶ã®é€²å±•

![table1]()
Table 1:Representative works and key techniques used in handling different data issues
ãƒ‡ãƒ¼ã‚¿èª²é¡Œ

We organize the existing literature according to the data issues in RSs outlined before.
æ—¢å­˜ã®æ–‡çŒ®ã‚’ã€å…ˆã«æ¦‚èª¬ã—ãŸRSã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿ã®å•é¡Œç‚¹ã«å¾“ã£ã¦æ•´ç†ã™ã‚‹ã€‚
Specific categorization as well as representative works and techniques are shown in Table 1.
å…·ä½“çš„ãªåˆ†é¡ã¨ä»£è¡¨çš„ãªä½œå“ãƒ»æŠ€è¡“ã‚’è¡¨1ã«ç¤ºã™ã€‚

## 4.1. Handling Incomplete Data ä¸å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†

The key to handling incomplete data is to fill in the missing information.
ä¸å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã®éµã¯ã€**æ¬ è½ã—ã¦ã„ã‚‹æƒ…å ±ã‚’è£œå®Œã™ã‚‹ã“ã¨**ã§ã‚ã‚‹ã€‚(data augmentationçš„ãª?:thinking:)
According to the different forms of incomplete data introduced in Section 3.1, we divide existing methods into two categories: attribute completion and interaction augmentation.
ã‚»ã‚¯ã‚·ãƒ§ãƒ³3.1ã§ç´¹ä»‹ã—ãŸä¸å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã®ç•°ãªã‚‹å½¢æ…‹ã«åŸºã¥ã„ã¦ã€æ—¢å­˜ã®æ–¹æ³•ã‚’**attribute completion(å±æ€§ã®è£œå®Œ)ã¨interaction augmentation(ç›¸äº’ä½œç”¨ã®æ‹¡å¼µ)ã®2ã¤ã®ã‚«ãƒ†ã‚´ãƒª**ã«åˆ†ã‘ã‚‹ã€‚

### 4.1.1. Attribute Completion å±æ€§ã®å®Œæˆ

Let ğ’± be the set of users and items.
ãƒ¦ãƒ¼ã‚¶ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®é›†åˆã‚’$V$ã¨ã™ã‚‹ã€‚
In practice, the profiles or attributes of some users or items may not be available.
å®Ÿéš›ã«ã¯ã€ä¸€éƒ¨ã®ãƒ¦ãƒ¼ã‚¶ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚„å±æ€§ãŒåˆ©ç”¨ã§ããªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
Therefore, the set ğ’± can be divided into two subsets, i.e., ğ’± + and ğ’± âˆ’ , which denote the attributed set and the no-attribute set, respectively.
ã—ãŸãŒã£ã¦ã€**é›†åˆ $V$ ã¯ã€ãã‚Œãã‚Œå±æ€§ä»˜ãã‚»ãƒƒãƒˆ $V^{+}$ ã¨ç„¡å±æ€§ã‚»ãƒƒãƒˆ $V^{-}$ ã‚’ç¤ºã™2ã¤ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã«åˆ†å‰²ã§ãã‚‹**ã€‚
Let $A = \{a_{v}|v \in V^{+}\}$ denote the input attribute set.
$A = \{a_{v}|v \in V^{+}\}$ ã¨ã—ã¦ã€å…¥åŠ›å±æ€§ã‚»ãƒƒãƒˆã‚’ç¤ºã™ã€‚
Attribute completion aims to complete the attribute for each no-attribute user or item ï¿½ âˆˆ ğ’± âˆ’ :
**Attribute completionã¯ã€å„ç„¡å±æ€§ãƒ¦ãƒ¼ã‚¶orã‚¢ã‚¤ãƒ†ãƒ  $v \in V^{-}$ ã®å±æ€§ã‚’è£œå®Œã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹**ã€‚

$$
A^{c} = \{a^{c}_{v}|v \in V^{-}\} = f_{ac}(A)
\tag{2}
$$

where ï¿½ ï¿½ ï¿½ denotes the completed attribute of ï¿½ .
ã“ã“ã§ $a^{c}_{v}$ ã¯ $v$ ã®è£œå®Œã•ã‚ŒãŸå±æ€§ã‚’ç¤ºã™ã€‚
The enhanced input attribute set ğ’œ â€² is formulated as:
å¼·åŒ–ã•ã‚ŒãŸå…¥åŠ›å±æ€§ã‚»ãƒƒãƒˆ $A'$ ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å®šå¼åŒ–ã•ã‚Œã‚‹:

$$
A' = A \cup A^{c} = \{a_{v}|v \in V^{+}\} \cup \{a^{c}_{v}|v \in V^{-}\}
$$

Existing works on attribute completion mainly rely on utilizing the topological structure of given graphs (e.g., user-item interaction, knowledge graphs, and social networks) Wu et al.(2020); You et al.(2020); Jin et al.(2021); Tu et al.(2022); Zhu et al.(2023); Guo et al.(2023).
**å±æ€§è£œå®Œã«é–¢ã™ã‚‹æ—¢å­˜ã®ç ”ç©¶ã¯ã€ä¸»ã«ä¸ãˆã‚‰ã‚ŒãŸã‚°ãƒ©ãƒ•(ä¾‹: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ç›¸äº’ä½œç”¨ã€çŸ¥è­˜ã‚°ãƒ©ãƒ•ã€ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯)ã®ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«æ§‹é€ ã‚’åˆ©ç”¨**ã—ã¦ã„ã‚‹(Wu et al.(2020); You et al.(2020); Jin et al.(2021); Tu et al.(2022); Zhu et al.(2023); Guo et al.(2023)
For instance, by modeling user-item interactions with respective user or item attributes into an attributed user-item bipartite graph, AGCN Wu et al.(2020) proposes an adaptive graph convolutional network for joint item recommendation and attribute completion, which iteratively performs two steps: graph embedding learning with previously learned attribute values, and attribute update procedure to update the input of graph embedding learning.
ä¾‹ãˆã°ã€ãƒ¦ãƒ¼ã‚¶ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®å±æ€§ã‚’ãã‚Œãã‚Œã®ãƒ¦ãƒ¼ã‚¶ã¾ãŸã¯ã‚¢ã‚¤ãƒ†ãƒ ã®å±æ€§ã¨ã¨ã‚‚ã«å±æ€§ä»˜ããƒ¦ãƒ¼ã‚¶ãƒ»ã‚¢ã‚¤ãƒ†ãƒ äºŒéƒ¨ã‚°ãƒ©ãƒ•ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ã“ã¨ã§ã€AGCN Wu et al.(2020)ã¯ã€å±æ€§è£œå®Œã¨ã‚¢ã‚¤ãƒ†ãƒ æ¨è–¦ã‚’åŒæ™‚ã«è¡Œã†ãŸã‚ã®é©å¿œçš„ã‚°ãƒ©ãƒ•ç•³ã¿è¾¼ã¿ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¦ãŠã‚Šã€ä»¥å‰ã«å­¦ç¿’ã—ãŸå±æ€§å€¤ã‚’ç”¨ã„ãŸã‚°ãƒ©ãƒ•åŸ‹ã‚è¾¼ã¿å­¦ç¿’ã¨ã€ã‚°ãƒ©ãƒ•åŸ‹ã‚è¾¼ã¿å­¦ç¿’ã®å…¥åŠ›ã‚’æ›´æ–°ã™ã‚‹å±æ€§æ›´æ–°æ‰‹é †ã‚’åå¾©çš„ã«å®Ÿè¡Œã™ã‚‹ã€‚
Moreover, given a knowledge graph, HGNN-AC Jin et al.(2021) leverages the topological relationship between nodes as guidance and completes attributes of no-attribute nodes by weighted aggregation of the attributes of linked attributed nodes.
ã•ã‚‰ã«ã€HGNN-AC Jin et al.(2021)ã¯ã€çŸ¥è­˜ã‚°ãƒ©ãƒ•ãŒä¸ãˆã‚‰ã‚Œã‚‹ã¨ã€ãƒãƒ¼ãƒ‰é–“ã®ä½ç›¸çš„é–¢ä¿‚ã‚’ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã¨ã—ã¦æ´»ç”¨ã—ã€ãƒªãƒ³ã‚¯ã•ã‚ŒãŸå±æ€§ãƒãƒ¼ãƒ‰ã®å±æ€§ã®é‡ã¿ä»˜ãé›†ç´„ã«ã‚ˆã£ã¦ã€ç„¡å±æ€§ãƒãƒ¼ãƒ‰ã®å±æ€§ã‚’è£œå®Œã™ã‚‹ã€‚
AutoAC Zhu et al.(2023) identifies that different attribute completion operations should be taken for different no-attribute nodes and models the attribute completion problem as an automated search problem for the optimal completion operation of each no-attribute node.
AutoAC Zhuã‚‰(2023)ã¯ã€ç•°ãªã‚‹ç„¡å±æ€§ãƒãƒ¼ãƒ‰ã«å¯¾ã—ã¦ç•°ãªã‚‹å±æ€§è£œå®Œæ“ä½œã‚’å–ã‚‹ã¹ãã§ã‚ã‚‹ã“ã¨ã‚’ç‰¹å®šã—ã€å±æ€§è£œå®Œå•é¡Œã‚’å„ç„¡å±æ€§ãƒãƒ¼ãƒ‰ã®æœ€é©è£œå®Œæ“ä½œã®è‡ªå‹•æ¢ç´¢å•é¡Œã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ã€‚
Instead of focusing on attribute completion accuracy, FairAC Guo et al.(2023) pays attention to the unfairness issue caused by attributes and completes missing attributes fairly.
FairAC Guoã‚‰(2023)ã¯ã€å±æ€§ã®è£œå®Œç²¾åº¦ã«æ³¨ç›®ã™ã‚‹ä»£ã‚ã‚Šã«ã€å±æ€§ã«èµ·å› ã™ã‚‹ä¸å…¬å¹³å•é¡Œã«æ³¨ç›®ã—ã€æ¬ è½ã—ãŸå±æ€§ã‚’å…¬å¹³ã«è£œå®Œã™ã‚‹ã€‚

Given the extensive knowledge base and powerful reasoning capabilities of large language models (LLMs) Zhao et al.(2023), some recent works have focused on leveraging LLMs to complete missing attributes.
å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®åºƒç¯„ãªçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã¨å¼·åŠ›ãªæ¨è«–èƒ½åŠ›ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€**Zhaoã‚‰(2023)ã¯ã€ã„ãã¤ã‹ã®æœ€è¿‘ã®ç ”ç©¶ã¯ã€æ¬ è½ã—ãŸå±æ€§ã‚’è£œå®Œã™ã‚‹ãŸã‚ã«LLMã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹**ã€‚(ãªã‚‹ã»ã©??)
For example, LLMRec Wei et al.(2023) carefully designs some prompts as the inputs of ChatGPT Ouyang et al.(2022) to generate user profiles or item attributes that were not originally part of the dataset.
ä¾‹ãˆã°ã€LLMRec Weiã‚‰(2023)ã¯ã€å…ƒã€…ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸€éƒ¨ã§ã¯ãªã‹ã£ãŸãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ã‚¢ã‚¤ãƒ†ãƒ å±æ€§ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã€ChatGPT(Ouyangã‚‰(2022))ã®å…¥åŠ›ã¨ã—ã¦ã„ãã¤ã‹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ…é‡ã«è¨­è¨ˆã—ã¦ã„ã‚‹ã€‚
An example of designed prompts is as follows:
ãƒ‡ã‚¶ã‚¤ãƒ³ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¾‹ã‚’ä»¥ä¸‹ã«ç¤ºã™:

> Provide the inquired information of the given movie.
> æŒ‡å®šã•ã‚ŒãŸæ˜ ç”»ã®æƒ…å ±ã‚’æä¾›ã™ã‚‹ã€‚
> Heart and Souls (1993), Comedy/Fantasy The inquired information is: director, country, language.
> Heart and Souls (1993), ã‚³ãƒ¡ãƒ‡ã‚£ï¼ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ ãŠå•ã„åˆã‚ã›ã®ã‚ã£ãŸæƒ…å ±ã§ã™ï¼š ç›£ç£, å›½, è¨€èª.
> Please output them in form of: director, country, language
> å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š ç›£ç£ã€å›½ã€è¨€èª

(ç¢ºã‹ã«ã€LLMã§æ—¢çŸ¥ã®ã‚¢ã‚¤ãƒ†ãƒ å±æ€§ã¯è£œå®Œã§ããã†...!:thinking:)

Similar to FairAC, some works [Xu et al., 2023] are exploring the ability of LLMs in generating sensitive user profiles or item attributes and considering the risks it may bring to privacy leakage and unfairness issues.
FairACã¨åŒæ§˜ã«ã€ä¸€éƒ¨ã®ç ”ç©¶[Xu et al., 2023]ã¯ã€LLMãŒæ©Ÿå¯†æ€§æ¼æ´©ã‚„ä¸å…¬å¹³å•é¡Œã«ã‚‚ãŸã‚‰ã™ãƒªã‚¹ã‚¯ã‚’è€ƒæ…®ã—ã€sensitiveãªãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ã‚¢ã‚¤ãƒ†ãƒ å±æ€§ã‚’ç”Ÿæˆã™ã‚‹èƒ½åŠ›ã‚’æ¢ã£ã¦ã„ã‚‹ã€‚

### 4.1.2. Interaction Augmentation

Let ğ’ª = { ( ï¿½ , ï¿½ ) âˆ£ ï¿½ , ï¿½ âˆˆ ğ’± } be the set of user-item pair ( ï¿½ , ï¿½ ) with observed interactions.
$O = \{(u, i)|u,i \in V\}$ ã‚’ã€è¦³æ¸¬ã•ã‚ŒãŸç›¸äº’ä½œç”¨ã‚’æŒã¤ãƒ¦ãƒ¼ã‚¶-ã‚¢ã‚¤ãƒ†ãƒ ãƒšã‚¢ã®é›†åˆã¨ã™ã‚‹ã€‚
We denote â„› = { ï¿½ ï¿½ , ï¿½ âˆ£ ( ï¿½ , ï¿½ ) âˆˆ ğ’ª } as the input interaction set.
$R = \{r_{u,i}|(u,i) \in O\}$ ã‚’ã€å…¥åŠ›interactioné›†åˆã¨ã™ã‚‹ã€‚
For inactive users and unpopular items, insufficient observed interactions can lead to inaccurate characterization of user preferences and item features.
éæ´»å‹•çš„ãªãƒ¦ãƒ¼ã‚¶ã‚„äººæ°—ã®ãªã„ã‚¢ã‚¤ãƒ†ãƒ ã®å ´åˆã€è¦³æ¸¬ã•ã‚ŒãŸinteractionãŒä¸ååˆ†ã§ã‚ã‚‹ã¨ã€ãƒ¦ãƒ¼ã‚¶ã®å—œå¥½ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã®ç‰¹å¾´ãŒæ­£ç¢ºã«ç‰¹å¾´ä»˜ã‘ã•ã‚Œãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
Therefore, interaction augmentation aims to augment the interaction information of some specific unobserved user-item pairs ( ï¿½ , ï¿½ ) âˆ‰ ğ’ª :
ã—ãŸãŒã£ã¦ã€**interaction augmentationã¯ã€ç‰¹å®šã®è¦³æ¸¬ã•ã‚Œã¦ã„ãªã„ãƒ¦ãƒ¼ã‚¶-ã‚¢ã‚¤ãƒ†ãƒ ãƒšã‚¢ $(u,i) \notin O$ ã®interactionæƒ…å ±ã‚’æ‹¡å¼µã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹**:

$$
R^{A} = \{r^{a}_{u,i}|(u,i) \notin O\} = f_{ia}(R)
\tag{3}
$$

where ï¿½ ï¿½ , ï¿½ ï¿½ denotes the augmented interaction information of ( ï¿½ , ï¿½ ) .
ã“ã“ã§ã€$r^{a}_{u,i}$ ã¯ $(u,i)$ ã®æ‹¡å¼µã•ã‚ŒãŸinteractionæƒ…å ±ã‚’ç¤ºã™ã€‚
The enhanced input interaction set â„› â€² is:
å¼·åŒ–ã•ã‚ŒãŸå…¥åŠ›interactioné›†åˆ $R'$ ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚‹:

$$
R' = R \cup R^{A} = \{r_{u,i}|(u,i) \in O\} \cup \{r^{a}_{u,i}|(u,i) \notin O\}
$$

![figure5]()
Figure 5:Categorization of data denoising methods in RSs.
æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚ºé™¤å»æ–¹æ³•ã®åˆ†é¡ã€‚

For implicit information such as like/dislike, the critical focus of interaction augmentation lies in how to choose an interaction.
å¥½ãå«Œã„ã®ã‚ˆã†ãªæš—é»™çš„ãªæƒ…å ±ã®å ´åˆã€interaction augmentationã®é‡è¦ãªç„¦ç‚¹ã¯ã€**ã©ã®interactionã‚’é¸æŠã™ã‚‹ã‹**ã«ã‚ã‚‹ã€‚(æ­£ç¢ºã«ã¯ã€like/dislikeã ã¨explicit feedbackã ã‚ˆã­ã€‚implicit feedbackã®å ´åˆã¯dislikeã‹unknownã‹ãŒåˆ¤åˆ¥ã§ããªã„ã‚ã‘ãªã®ã§...!)
Negative sampling pays attention to how to choose an interaction as dislike Rendle et al.(2009); Zhang et al.(2013); Chen et al.(2017); Ding et al.(2020); Huang et al.(2021); Lai et al.(2023); Shi et al.(2023); Lai et al.(2024).
negative samplingã¯ã€dislikeã¨ã—ã¦interactionã‚’é¸æŠã™ã‚‹æ–¹æ³•ã«æ³¨ç›®ã™ã‚‹ (Rendle et al.(2009); Zhang et al.(2013); Chen et al.(2017); Ding et al.(2020); Huang et al.(2021); Lai et al.(2023); Shi et al.(2023); Lai et al.(2024)ã€‚)
(=ã“ã“ã§negative samplingã®æ„å‘³ã¯ã€negative exampleã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ–¹æ³•...!:thinking:)
Specifically, negative sampling aims to identify uninteracted items of a user as negative items.
å…·ä½“çš„ã«ã¯ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¯ã€ãƒ¦ãƒ¼ã‚¶ã®æœªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã‚’ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚¢ã‚¤ãƒ†ãƒ ã¨ã—ã¦ç‰¹å®šã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚
The simplest and most prevalent idea is to randomly select uninteracted items, BPR Rendle et al.(2009) is a well-known instantiation of this idea.
**æœ€ã‚‚å˜ç´”ã§ä¸€èˆ¬çš„ãªã‚¢ã‚¤ãƒ‡ã‚¢ã¯ã€ãƒ©ãƒ³ãƒ€ãƒ ã«æœªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’é¸æŠã™ã‚‹ã“ã¨**ã§ã‚ã‚Šã€BPR(Rendle et al.(2009))ã¯ã€ã“ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã®ã‚ˆãçŸ¥ã‚‰ã‚ŒãŸå…·ä½“ä¾‹ã§ã‚ã‚‹ã€‚
Inspired by the word-frequency-based negative sampling distribution for network embedding Mikolov et al.(2013), NNCF Chen et al.(2017) adopts an item-popularity-based sampling distribution to select more popular items as negative.
ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸ‹ã‚è¾¼ã¿ã®ãŸã‚ã®å˜èªé »åº¦ãƒ™ãƒ¼ã‚¹ã®ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°åˆ†å¸ƒã«è§¦ç™ºã•ã‚Œã¦(Mikolov et al.(2013))ã€NNCF Chen et al.(2017)ã¯ã€**ã‚¢ã‚¤ãƒ†ãƒ ã®äººæ°—åº¦ã«åŸºã¥ã„ãŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°åˆ†å¸ƒã‚’æ¡ç”¨ã—ã€ã‚ˆã‚Šäººæ°—ã®ã‚ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã‚’ãƒã‚¬ãƒ†ã‚£ãƒ–ã¨ã—ã¦é¸æŠã™ã‚‹**ã€‚(ã†ã‚“ã†ã‚“ã€ä¸€èˆ¬çš„)
DNS Zhang et al.(2013) proposes to select uninteracted items with higher prediction scores (e.g., the inner product of a user embedding and an item embedding).
DNS Zhang et al.(2013)ã¯ã€ã‚ˆã‚Šé«˜ã„äºˆæ¸¬ã‚¹ã‚³ã‚¢ï¼ˆä¾‹ãˆã°ã€ãƒ¦ãƒ¼ã‚¶åŸ‹ã‚è¾¼ã¿ã¨ã‚¢ã‚¤ãƒ†ãƒ åŸ‹ã‚è¾¼ã¿ã®å†…ç©ï¼‰ã‚’æŒã¤æœªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’é¸æŠã™ã‚‹ã“ã¨ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚(ã†ã‚“ã†ã‚“ã€æƒ³åƒã§ãã‚‹...!)
Such hard negative items can provide more informative training signals so that user interests can be better characterized.
ã“ã®ã‚ˆã†ãªãƒãƒ¼ãƒ‰ãƒã‚¬ãƒ†ã‚£ãƒ–ãªã‚¢ã‚¤ãƒ†ãƒ ã¯ã€ã‚ˆã‚Šæƒ…å ±é‡ã®å¤šã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚°ãƒŠãƒ«ã‚’æä¾›ã—ã€ãƒ¦ãƒ¼ã‚¶ã®èˆˆå‘³ã‚’ã‚ˆã‚Šã‚ˆãç‰¹å¾´ä»˜ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚(hard negativeã¯ã€ç¢ºã‹äºˆæ¸¬ãŒé›£ã—ã„negative exampleã®ã“ã¨ã ã£ã‘...!:thinking:)
SRNS Ding et al.(2020) oversamples items with both high predicted scores and high variances during training to tackle the false negative problem.
SRNS Ding et al.(2020)ã¯ã€å½é™°æ€§ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€å­¦ç¿’ä¸­ã«äºˆæ¸¬å¾—ç‚¹ã¨åˆ†æ•£ã®ä¸¡æ–¹ãŒé«˜ã„ã‚¢ã‚¤ãƒ†ãƒ ã‚’ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã€‚
DENS Lai et al.(2023) points out the importance of disentangling item factors in negative sampling and designs a factor-aware sampling strategy to identify the best negative item.
DENS Lai et al.(2023)ã¯ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ãŠã‘ã‚‹ã‚¢ã‚¤ãƒ†ãƒ factorã®åˆ†é›¢ã®é‡è¦æ€§ã‚’æŒ‡æ‘˜ã—ã€æœ€é©ãªãƒã‚¬ãƒ†ã‚£ãƒ–ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã®**factor-awareã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥**ã‚’è¨­è¨ˆã—ã¦ã„ã‚‹ã€‚(ã“ã“ã§factorã£ã¦ã€ã‚¢ã‚¤ãƒ†ãƒ ã®ç‰¹å¾´é‡ã®ã“ã¨??:thinking:)
MixGCF Huang et al.(2021) synthesizes harder negative items by mixing information from positive items while AHNS Lai et al.(2024) proposes to adaptively select negative items with different hardness levels.
MixGCF Huangã‚‰(2021)ã¯ã€ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚¢ã‚¤ãƒ†ãƒ ã‹ã‚‰æƒ…å ±ã‚’æ··ãœåˆã‚ã›ã¦ã‚ˆã‚Šé›£ã—ã„ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚¢ã‚¤ãƒ†ãƒ ã‚’åˆæˆã—ã€AHNS Laiã‚‰(2024)ã¯ã€ç•°ãªã‚‹é›£æ˜“åº¦ãƒ¬ãƒ™ãƒ«ã®ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚¢ã‚¤ãƒ†ãƒ ã‚’é©å¿œçš„ã«é¸æŠã™ã‚‹ã“ã¨ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚

Different from negative sampling, positive augmentation focuses on how to choose an interaction as like Wang et al.(2019, 2021b); Yang et al.(2021); Zhang et al.(2021a); Lai et al.(2022); Liu et al.(2023); Wei et al.(2023).
**negative samplingã¨ã¯ç•°ãªã‚Šã€positive augmentationã¯ã€likeã¨ã—ã¦interactionã‚’é¸æŠã™ã‚‹æ–¹æ³•ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹**(Wang et al.(2019, 2021b); Yang et al.(2021); Zhang et al.(2021a); Lai et al.(2022); Liu et al.(2023); Wei et al.(2023))ã€‚
(positiveãƒ‡ãƒ¼ã‚¿ã‚’æ‹¡å¼µã™ã‚‹å¿…è¦ã‚ã‚‹ã®??ãã‚Œã£ã¦ã‚‚ã¯ã‚„å—œå¥½ã®äºˆæ¸¬ãã®ã‚‚ã®ã§ã¯??)
For example, EGLN Yang et al.(2021) selects uninteracted items with higher prediction scores and labels them as positive to enrich usersâ€™ interactions.
ä¾‹ãˆã°ã€EGLN Yangã‚‰(2021)ã¯ã€ãƒ¦ãƒ¼ã‚¶ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’è±Šã‹ã«ã™ã‚‹ãŸã‚ã«ã€ã‚ˆã‚Šé«˜ã„äºˆæ¸¬ã‚¹ã‚³ã‚¢ã‚’æŒã¤æœªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’é¸æŠã—ã€ãã‚Œã‚‰ã‚’æ­£ã¨ã—ã¦ãƒ©ãƒ™ãƒ«ä»˜ã‘ã™ã‚‹ã€‚
CASR Wang et al.(2021b) leverages counterfactual reasoning to generate user interaction sequences in the counterfactual world.
CASR Wangã‚‰(2021b)ã¯ã€åå®Ÿä»®æƒ³çš„æ¨è«–ã‚’æ´»ç”¨ã—ã¦ã€åå®Ÿä»®æƒ³çš„ä¸–ç•Œã«ãŠã‘ã‚‹ãƒ¦ãƒ¼ã‚¶ã¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ã€‚
MNR-GCF Lai et al.(2022) constructs heterogeneous information networks and fully exploits the contextual information therein to identify potential user-item interactions.
MNR-GCF Lai et al.(2022)ã¯ã€ç•°ç¨®æƒ…å ±ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã—ã€ãã“ã«å«ã¾ã‚Œã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’å®Œå…¨ã«åˆ©ç”¨ã—ã¦ã€æ½œåœ¨çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ç›¸äº’ä½œç”¨ã‚’ç‰¹å®šã™ã‚‹ã€‚
Based on generative adversarial nets (GANs), AugCF Wang et al.(2019) generates high-quality augmented interactions that mimic the distribution of original interactions.
ç”Ÿæˆçš„æ•µå¯¾ãƒãƒƒãƒˆï¼ˆGANï¼‰ã«åŸºã¥ãAugCF Wangã‚‰(2019)ã¯ã€å…ƒã®ç›¸äº’ä½œç”¨ã®åˆ†å¸ƒã‚’æ¨¡å€£ã—ãŸé«˜å“è³ªã®å¢—å¼·ç›¸äº’ä½œç”¨ã‚’ç”Ÿæˆã™ã‚‹ã€‚
Inspired by the superior performance of diffusion models in image generation, DiffuASR Liu et al.(2023) adapts diffusion models to user interaction sequence generation, and a sequential U-Net is designed to capture the sequence information and predict the added noise of generated interactions.
ç”»åƒç”Ÿæˆã«ãŠã‘ã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®å„ªã‚ŒãŸæ€§èƒ½ã«è§¦ç™ºã•ã‚Œã€DiffuASR Liuã‚‰(2023)ã¯æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”Ÿæˆã«é©å¿œã•ã›ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æƒ…å ±ã‚’æ•æ‰ã—ã€ç”Ÿæˆã•ã‚ŒãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã®ä»˜åŠ ãƒã‚¤ã‚ºã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã«é€æ¬¡U-Netã‚’è¨­è¨ˆã—ãŸã€‚
Leveraging the capabilities of LLMs, LLMRec Wei et al.(2023) also seeks to identify both positive and negative interactions from a candidate set using well-designed prompts.
LLMRec Wei et al.(2023)ã¯ã€LLMã®èƒ½åŠ›ã‚’æ´»ç”¨ã—ã€é©åˆ‡ã«è¨­è¨ˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€å€™è£œã‚»ãƒƒãƒˆã‹ã‚‰è‚¯å®šçš„ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã¨å¦å®šçš„ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã®ä¸¡æ–¹ã‚’è­˜åˆ¥ã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã€‚

<!-- positive augumentationã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚ã‚“ã¾ã‚Šèª­ã‚“ã§ãªã„...! -->

For contextual information like rating, the critical focus of interaction augmentation shifts to how to infer the missing value Ren et al.(2012, 2013); Yoon et al.(2018); Chae et al.(2019); Li et al.(2019); Chae et al.(2020); Hwang and Chae (2022).
**ratingã®ã‚ˆã†ãªæ–‡è„ˆæƒ…å ±ã®å ´åˆã€interaction augmentationã®é‡è¦ãªç„¦ç‚¹ã¯ã€æ¬ è½ã—ã¦ã„ã‚‹å€¤ã‚’ã©ã®ã‚ˆã†ã«æ¨æ¸¬ã™ã‚‹ã‹**ã«ç§»ã‚‹(Ren et al.(2012, 2013); Yoon et al.(2018); Chae et al.(2019); Li et al.(2019); Chae et al.(2020); Hwang and Chae (2022))ã€‚
(ã“ã‚Œã‚‚ã‚‚ã¯ã‚„å—œå¥½ã®äºˆæ¸¬ãã®ã‚‚ã®ã˜ã‚ƒãªã„...??)
For instance, AutAI Ren et al.(2012) and AdaM Ren et al.(2013) calculate missing ratings according to heuristic similarity-based metrics, such as Pearson correlation coefficient or cosine similarity.
ä¾‹ãˆã°ã€AutAI Renã‚‰(2012)ã‚„AdaM Renã‚‰(2013)ã¯ã€ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢ä¿‚æ•°ã‚„ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã®ã‚ˆã†ãªç™ºè¦‹çš„é¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«å¾“ã£ã¦ã€æ¬ è½ã—ãŸè©•ä¾¡ã‚’è¨ˆç®—ã—ã¦ã„ã‚‹ã€‚
RAGAN Chae et al.(2019) and UA-MI Hwang and Chae (2022) leverage GANs for rating augmentation.
RAGAN Chae et al.(2019)ã¨UA-MI Hwang and Chae(2022)ã¯ã€è¦–è´ç‡è£œå¼·ã®ãŸã‚ã«GANã‚’æ´»ç”¨ã—ã¦ã„ã‚‹ã€‚
Instead of augmenting ratings of interactions between real users and items, AR-CF Chae et al.(2020) proposes to generate virtual users and items and then adopts GANs to predict ratings between them.
AR-CF Chae et al.(2020)ã¯ã€ç¾å®Ÿã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ é–“ã®ç›¸äº’ä½œç”¨ã®è©•ä¾¡ã‚’è£œå¼·ã™ã‚‹ä»£ã‚ã‚Šã«ã€**ä»®æƒ³ã®ãƒ¦ãƒ¼ã‚¶ã¨ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç”Ÿæˆã—**(??)ã€ãã‚Œã‚‰ã®é–“ã®è©•ä¾¡ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã«GANã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚

<!-- ã“ã“ã¾ã§é›‘ã«èª­ã‚“ã ! -->

### 4.1.3. Discussion ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³

While a variety of methods exist for addressing the incomplete data issue, the fact remains that no single method is capable of comprehensively addressing all scenarios involving missing data.
ä¸å®Œå…¨ãƒ‡ãƒ¼ã‚¿å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®æ§˜ã€…ãªæ–¹æ³•ãŒå­˜åœ¨ã™ã‚‹ä¸€æ–¹ã§ã€ãƒ‡ãƒ¼ã‚¿ã®æ¬ è½ã‚’å«ã‚€ã™ã¹ã¦ã®ã‚·ãƒŠãƒªã‚ªã«åŒ…æ‹¬çš„ã«å¯¾å‡¦ã§ãã‚‹å˜ä¸€ã®æ–¹æ³•ã¯å­˜åœ¨ã—ãªã„ã¨ã„ã†äº‹å®Ÿã«å¤‰ã‚ã‚Šã¯ãªã„ã€‚
Consequently, a considerable amount of time and effort must be devoted to identifying missing information and selecting enhancement strategies.
ãã®çµæœã€ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±ã‚’ç‰¹å®šã—ã€å¼·åŒ–æˆ¦ç•¥ã‚’é¸æŠã™ã‚‹ãŸã‚ã«ã€ã‹ãªã‚Šã®æ™‚é–“ã¨åŠ´åŠ›ã‚’å‰²ã‹ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚
Furthermore, evaluating the quality of enhanced data is not straightforward â€“ improvements in RSs might be misleadingly attributed to the simple expansion of data volume, which can cloud the actual effects of refinements in data quality.
**ã•ã‚‰ã«ã€å¼·åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®è³ªã‚’è©•ä¾¡ã™ã‚‹ã®ã¯ç°¡å˜ã§ã¯ãªã„**(ã†ã‚“ã†ã‚“...!)ã€‚RSã®æ”¹å–„ã¯ã€å˜ç´”ãªãƒ‡ãƒ¼ã‚¿é‡ã®æ‹¡å¤§ã«ã‚ˆã‚‹ã‚‚ã®ã¨èª¤è§£ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€ãƒ‡ãƒ¼ã‚¿ã®è³ªã®å‘ä¸Šã«ã‚ˆã‚‹å®Ÿéš›ã®åŠ¹æœã‚’æ›‡ã‚‰ã›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚

<!-- ã“ã“ã¾ã§èª­ã‚“ã ! -->

## 4.2. Handling Noisy Data ãƒã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†

The key to handling the data noise issue is to filter out the noisy information.
ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ã‚ºå•é¡Œã«å¯¾å‡¦ã™ã‚‹éµã¯ã€ãƒã‚¤ã‚ºã¨ãªã‚‹æƒ…å ±ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã ã€‚
According to the varying severity of noisy data presented in Section 3.2, we divide existing denoising methods into three categories: reweighting-based methods, selection-based methods, and dataset distillation/condensation, which are illustrated in Figure 5.
ã‚»ã‚¯ã‚·ãƒ§ãƒ³3.2ã§ç¤ºã—ãŸãƒã‚¤ã‚ºã®å¤šã„ãƒ‡ãƒ¼ã‚¿ã®æ·±åˆ»åº¦ã®é•ã„ã«ã‚ˆã‚Šã€æ—¢å­˜ã®ãƒã‚¤ã‚ºé™¤å»æ³•ã‚’3ã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«åˆ†é¡ã™ã‚‹ï¼š é‡ã¿ä»˜ã‘ã«åŸºã¥ãæ–¹æ³•ã€é¸æŠã«åŸºã¥ãæ–¹æ³•ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è’¸ç•™ï¼å‡ç¸®ã§ã‚ã‚‹ã€‚

### 4.2.1. Reweighting-Based Denoising ãƒªãƒ¯ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã«åŸºã¥ããƒã‚¤ã‚ºé™¤å»

The reweighting-based method aims to assign lower weights to the noisy data (or assign higher weights to the noiseless data) Wang et al.(2021a); Gao et al.(2022); Zhou et al.(2022); Zhang et al.(2023d); Ge et al.(2023); Wang et al.(2023c).
å†é‡ã¿ä»˜ã‘ã«åŸºã¥ãæ–¹æ³•ã¯ã€ãƒã‚¤ã‚ºã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚Šä½ã„é‡ã¿ã‚’å‰²ã‚Šå½“ã¦ã‚‹ï¼ˆã¾ãŸã¯ãƒã‚¤ã‚ºã®ãªã„ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚Šé«˜ã„é‡ã¿ã‚’å‰²ã‚Šå½“ã¦ã‚‹ï¼‰ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚
Wang et al.Wang et al.(2021a) experimentally observe that noisy interactions are harder to fit in the early training stages, and, based on this observation, they regard the interactions with large loss values as noise and propose an adaptive denoising training strategy called R-CE, which assigns different weights to noisy interactions according to their loss values during training.
Wang et al.Wangã‚‰(2021a)ã¯ã€ãƒã‚¤ã‚ºã®å¤šã„ç›¸äº’ä½œç”¨ã¯å­¦ç¿’åˆæœŸã«é©åˆã—ã«ãã„ã“ã¨ã‚’å®Ÿé¨“çš„ã«è¦³å¯Ÿã—ã€ã“ã®è¦³å¯Ÿã«åŸºã¥ã„ã¦ã€æå¤±å€¤ã®å¤§ãã„ç›¸äº’ä½œç”¨ã‚’ãƒã‚¤ã‚ºã¨ã¿ãªã—ã€å­¦ç¿’ä¸­ã«æå¤±å€¤ã«å¿œã˜ã¦ãƒã‚¤ã‚ºã®å¤šã„ç›¸äº’ä½œç”¨ã«ç•°ãªã‚‹é‡ã¿ã‚’å‰²ã‚Šå½“ã¦ã‚‹R-CEã¨å‘¼ã°ã‚Œã‚‹é©å¿œçš„ãƒã‚¤ã‚ºé™¤å»å­¦ç¿’æˆ¦ç•¥ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚
SLED Zhang et al.(2023d) identifies and determines the reliability of interactions based on their related structural patterns learned on multiple large-scale recommendation datasets.
SLED Zhang et al.(2023d)ã¯ã€è¤‡æ•°ã®å¤§è¦æ¨¡æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å­¦ç¿’ã•ã‚ŒãŸé–¢é€£æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãã€ç›¸äº’ä½œç”¨ã®ä¿¡é ¼æ€§ã‚’è­˜åˆ¥ãƒ»åˆ¤å®šã™ã‚‹ã€‚
FMLP-Rec Zhou et al.(2022) adopts learnable filters for denoising in sequential recommendation.
FMLP-Rec Zhouã‚‰(2022)ã¯ã€é€æ¬¡æ¨è–¦ã«ãŠã‘ã‚‹ãƒã‚¤ã‚ºé™¤å»ã«å­¦ç¿’å¯èƒ½ãªãƒ•ã‚£ãƒ«ã‚¿ã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚
The learnable filters perform a fast Fourier transform (FFT) to convert the input sequence into the frequency domain and filter out noise through an inverse FFT procedure.
å­¦ç¿’å¯èƒ½ãªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯ã€é«˜é€Ÿãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ï¼ˆFFTï¼‰ã‚’å®Ÿè¡Œã—ã¦å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å‘¨æ³¢æ•°é ˜åŸŸã«å¤‰æ›ã—ã€é€†FFTæ‰‹é †ã«ã‚ˆã£ã¦ãƒã‚¤ã‚ºã‚’é™¤å»ã™ã‚‹ã€‚
SGDL Gao et al.(2022) leverages the self-labeled memorized data as guidance to offer denoising signals without requiring any auxiliary information or defining any weighting functions.
SGDL Gaoã‚‰(2022)ã¯ã€è‡ªå·±ãƒ©ãƒ™ãƒ«ä»˜ã‘ã•ã‚ŒãŸè¨˜æ†¶ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã¨ã—ã¦æ´»ç”¨ã—ã€è£œåŠ©æƒ…å ±ã‚’å¿…è¦ã¨ã›ãšã€é‡ã¿ä»˜ã‘é–¢æ•°ã‚’å®šç¾©ã™ã‚‹ã“ã¨ãªãã€ãƒã‚¤ã‚ºé™¤å»ä¿¡å·ã‚’æä¾›ã™ã‚‹ã€‚
AutoDenoise Ge et al.(2023) adopts reinforcement learning to automatically and adaptively learn the most appropriate weight for each interaction.
AutoDenoise Geã‚‰(2023)ã¯å¼·åŒ–å­¦ç¿’ã‚’æ¡ç”¨ã—ã€å„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã«æœ€é©ãªé‡ã¿ã‚’è‡ªå‹•çš„ã«é©å¿œçš„ã«å­¦ç¿’ã™ã‚‹ã€‚

### 4.2.2. Selection-Based Denoising é¸æŠãƒ™ãƒ¼ã‚¹ã®ãƒã‚¤ã‚ºé™¤å»

Instead of assigning lower weights, the selection-based method directly removes the noisy data Tong et al.(2021); Wang et al.(2021a); Yuan et al.(2021); Zhang et al.(2022b); Lin et al.(2023a); Zhang et al.(2023c); Quan et al.(2023); Wang et al.(2023b); Lin et al.(2023b).
ã‚ˆã‚Šä½ã„é‡ã¿ã‚’å‰²ã‚Šå½“ã¦ã‚‹ä»£ã‚ã‚Šã«ã€é¸æŠãƒ™ãƒ¼ã‚¹ã®æ–¹æ³•ã¯ãƒã‚¤ã‚ºã®å¤šã„ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥é™¤å»ã™ã‚‹ Tong et al.(2021); Wang et al.(2021a); Yuan et al.(2021); Zhang et al.(2022b); Lin et al.(2023a); Zhang et al.(2023c); Quan et al.
For instance, different from R-CE, Wang et al.Wang et al.(2021a) propose another adaptive denoising training strategy called T-CE, which discards the interactions with large loss values.
ä¾‹ãˆã°ã€R-CEã¨ã¯ç•°ãªã‚Šã€Wangã‚‰(2021a)ã¯T-CEã¨å‘¼ã°ã‚Œã‚‹åˆ¥ã®é©å¿œçš„ãƒã‚¤ã‚ºé™¤å»å­¦ç¿’æˆ¦ç•¥ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚
RAP Tong et al.(2021) formulates the denoising process as a Markov decision process and proposes to learn a policy network to select the appropriate action (i.e., removing or keeping an interaction) to maximize long-term rewards.
RAP Tongã‚‰(2021)ã¯ã€ãƒã‚¤ã‚ºé™¤å»ãƒ—ãƒ­ã‚»ã‚¹ã‚’ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹ã¨ã—ã¦å®šå¼åŒ–ã—ã€é•·æœŸçš„ãªå ±é…¬ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã«é©åˆ‡ãªè¡Œå‹•ï¼ˆã™ãªã‚ã¡ã€ç›¸äº’ä½œç”¨ã‚’é™¤å»ã™ã‚‹ã‹ç¶­æŒã™ã‚‹ã‹ï¼‰ã‚’é¸æŠã™ã‚‹ãŸã‚ã®ãƒãƒªã‚·ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚
DSAN Yuan et al.(2021) suggests using the entmax function to automatically eliminate the weights of irrelevant interactions.
DSAN Yuanã‚‰(2021)ã¯ã€ç„¡é–¢ä¿‚ãªç›¸äº’ä½œç”¨ã®é‡ã¿ã‚’è‡ªå‹•çš„ã«é™¤å»ã™ã‚‹ãŸã‚ã«entmaxé–¢æ•°ã‚’ä½¿ã†ã“ã¨ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚
HSD Zhang et al.(2022b) learns both user-level and sequence-level inconsistency signals to further identify inherent noisy interactions.
HSD Zhangã‚‰(2022b)ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¬ãƒ™ãƒ«ã¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ã®ä¸æ•´åˆã‚·ã‚°ãƒŠãƒ«ã®ä¸¡æ–¹ã‚’å­¦ç¿’ã—ã€å›ºæœ‰ã®ãƒã‚¤ã‚ºã®å¤šã„ç›¸äº’ä½œç”¨ã‚’ã•ã‚‰ã«è­˜åˆ¥ã™ã‚‹ã€‚
DeCA Wang et al.(2023b) finds that different models tend to make more consistent agreement predictions for noise-free interactions, and utilizes predictions from different models as the denoising signal.
DeCA Wangã‚‰(2023b)ã¯ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ãŒãƒã‚¤ã‚ºã®ãªã„ç›¸äº’ä½œç”¨ã«ã¤ã„ã¦ã‚ˆã‚Šä¸€è²«ã—ãŸä¸€è‡´äºˆæ¸¬ã‚’ã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®äºˆæ¸¬ã‚’ãƒã‚¤ã‚ºé™¤å»ä¿¡å·ã¨ã—ã¦åˆ©ç”¨ã—ã¦ã„ã‚‹ã€‚
GDMSR Quan et al.(2023) designs a self-correcting curriculum learning mechanism and an adaptive denoising strategy to alleviate noise in social networks.
GDMSR Quanã‚‰(2023)ã¯ã€ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒã‚¤ã‚ºã‚’ç·©å’Œã™ã‚‹ãŸã‚ã«ã€è‡ªå·±ä¿®æ­£ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ å­¦ç¿’ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¨é©å¿œçš„ãƒã‚¤ã‚ºé™¤å»æˆ¦ç•¥ã‚’è¨­è¨ˆã—ã¦ã„ã‚‹ã€‚
STEAM Lin et al.(2023b) further designs a corrector that can adaptively apply â€œkeepâ€, â€œdeleteâ€, and â€œinsertâ€ operations to correct an interaction sequence.
STEAM Linã‚‰(2023b)ã¯ã•ã‚‰ã«ã€ç›¸äº’ä½œç”¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ä¿®æ­£ã™ã‚‹ãŸã‚ã«ã€Œkeepã€ã€ã€Œdeleteã€ã€ã€Œinsertã€æ“ä½œã‚’é©å¿œçš„ã«é©ç”¨ã§ãã‚‹ã‚³ãƒ¬ã‚¯ã‚¿ã‚’è¨­è¨ˆã—ã¦ã„ã‚‹ã€‚

Some studies integrate the reweighting-based method with the selection-based method for better denoising Tian et al.(2022); Ye et al.(2023).
ã‚ˆã‚Šè‰¯ã„ãƒã‚¤ã‚ºé™¤å»ã®ãŸã‚ã«ã€å†é‡ã¿ä»˜ã‘ãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã¨é¸æŠãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã‚’çµ±åˆã—ãŸç ”ç©¶ã‚‚ã‚ã‚‹ã€‚
For instance, RGCF Tian et al.(2022) and RocSE Ye et al.(2023) estimate the reliability of user-item interactions using normalized cosine similarity between their respective embeddings.
ä¾‹ãˆã°ã€RGCF Tian et al.(2022)ã‚„RocSE Ye et al.(2023)ã¯ã€ãã‚Œãã‚Œã®åŸ‹ã‚è¾¼ã¿é–“ã®æ­£è¦åŒ–ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’ç”¨ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã®ä¿¡é ¼æ€§ã‚’æ¨å®šã—ã¦ã„ã‚‹ã€‚
Subsequently, they filter out interactions and only retain those whose weights exceed a pre-defined threshold value.
ãã®å¾Œã€ç›¸äº’ä½œç”¨ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã€é‡ã¿ãŒäº‹å‰ã«å®šç¾©ã•ã‚ŒãŸã—ãã„å€¤ã‚’è¶…ãˆã‚‹ã‚‚ã®ã ã‘ã‚’ä¿æŒã™ã‚‹ã€‚

### 4.2.3. Dataset Distillation/Condensation ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ è’¸ç•™ï¼å‡ç¸®

Dataset distillation or dataset condensation techniques Yu et al.(2023) aim to synthesize data points with the goal of condensing the comprehensive knowledge from the entire dataset into a small, synthetic data summary.
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè’¸ç•™ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‡ç¸®æŠ€è¡“ Yuã‚‰(2023)ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‹ã‚‰ã®åŒ…æ‹¬çš„ãªçŸ¥è­˜ã‚’å°ã•ãªåˆæˆãƒ‡ãƒ¼ã‚¿è¦ç´„ã«å‡ç¸®ã™ã‚‹ã“ã¨ã‚’ç›®æ¨™ã«ã€ãƒ‡ãƒ¼ã‚¿ç‚¹ã‚’åˆæˆã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚
This process retains the essence of the data, enabling models to be trained more efficiently.
ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã¯ãƒ‡ãƒ¼ã‚¿ã®æœ¬è³ªã‚’ä¿æŒã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’ã‚ˆã‚ŠåŠ¹ç‡çš„ã«å­¦ç¿’ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
Recently, some works Sachdeva et al.(2022); Wu et al.(2023) observe that dataset distillation has a strong data denoising effect in recommendation.
æœ€è¿‘ã€Sachdevaã‚‰(2022); Wuã‚‰(2023)ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè’¸ç•™ãŒæ¨è–¦ã«ãŠã„ã¦å¼·ã„ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚ºé™¤å»åŠ¹æœã‚’æŒã¤ã“ã¨ã‚’è¦³å¯Ÿã—ã¦ã„ã‚‹ã€‚
For example, DISTILL-CF Sachdeva et al.(2022) applies dataset meta-learning to synthetic user-item interactions.
ä¾‹ãˆã°ã€DISTILL-CF Sachdeva et al.(2022)ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ¡ã‚¿å­¦ç¿’ã‚’åˆæˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã«é©ç”¨ã—ã¦ã„ã‚‹ã€‚
Remarkably, models trained on the condensed dataset synthesized by DISTILL-CF have demonstrated improved performance compared to those trained on the full, original dataset.
é©šãã¹ãã“ã¨ã«ã€DISTILL-CFã«ã‚ˆã£ã¦åˆæˆã•ã‚ŒãŸå‡ç¸®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€å®Œå…¨ãªã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã€‚

### 4.2.4. Discussion ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³

Normally, data collected from real-world scenarios are frequently contaminated with noise stemming from system bugs or user mistakes.
é€šå¸¸ã€å®Ÿä¸–ç•Œã®ã‚·ãƒŠãƒªã‚ªã‹ã‚‰åé›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ã®ãƒã‚°ã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒŸã‚¹ã«èµ·å› ã™ã‚‹ãƒã‚¤ã‚ºã§æ±šæŸ“ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒå¤šã„ã€‚
However, obtaining labels for this noise is often impractical or even impossible, due to the lack of expert knowledge required for identifying noise, the high costs associated with manual labeling, or the dynamic nature of some noise which makes it hard to give fixed labels.
ã—ã‹ã—ã€ãƒã‚¤ã‚ºã®è­˜åˆ¥ã«å¿…è¦ãªå°‚é–€çŸ¥è­˜ãŒä¸è¶³ã—ã¦ã„ãŸã‚Šã€æ‰‹ä½œæ¥­ã«ã‚ˆã‚‹ãƒ©ãƒ™ãƒ«ä»˜ã‘ã«é«˜ã„ã‚³ã‚¹ãƒˆãŒã‹ã‹ã£ãŸã‚Šã€ã‚ã‚‹ã„ã¯ãƒã‚¤ã‚ºã®å‹•çš„ãªæ€§è³ªã«ã‚ˆã£ã¦å›ºå®šçš„ãªãƒ©ãƒ™ãƒ«ä»˜ã‘ãŒå›°é›£ã§ã‚ã£ãŸã‚Šã™ã‚‹ãŸã‚ã€ã“ã®ã‚ˆã†ãªãƒã‚¤ã‚ºã®ãƒ©ãƒ™ãƒ«ã‚’å¾—ã‚‹ã“ã¨ã¯ç¾å®Ÿçš„ã§ãªã‹ã£ãŸã‚Šã€ä¸å¯èƒ½ã§ã‚ã£ãŸã‚Šã™ã‚‹ã“ã¨ãŒå¤šã„ã€‚
In the absence of the ground truth, it is difficult to determine whether the denoising method achieves the optimal situation â€“ no over-denoising or under-denoising.
ã‚°ãƒ©ãƒ³ãƒ‰ãƒ»ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ãŒãªã„å ´åˆã€ãƒã‚¤ã‚ºé™¤å»æ³•ãŒæœ€é©ãªçŠ¶æ³ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ‡ãƒã‚¤ã‚ºã‚„ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒã‚¤ã‚ºï¼‰ã‚’é”æˆã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã™ã‚‹ã®ã¯é›£ã—ã„ã€‚
Taking into account this limitation, it may be preferable to synthesize a noise-free dataset via dataset distillation/condensation rather than attempting to adjust or filter the existing dataset through reweighting-based or selection-based methods.
ã“ã®åˆ¶é™ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€é‡ã¿ä»˜ã‘ã«åŸºã¥ãæ–¹æ³•ã‚„é¸æŠã«åŸºã¥ãæ–¹æ³•ã§æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª¿æ•´ã‚„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’è©¦ã¿ã‚‹ã‚ˆã‚Šã‚‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è’¸ç•™ï¼å‡ç¸®ã«ã‚ˆã£ã¦ãƒã‚¤ã‚ºã®ãªã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆæˆã™ã‚‹æ–¹ãŒæœ›ã¾ã—ã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚

## 4.3. Handling Biased Data ãƒã‚¤ã‚¢ã‚¹ã®ã‹ã‹ã£ãŸãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†

The key to handling biased data is to align the biased training distribution with the unbiased test distribution.
åã£ãŸãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†éµã¯ã€åã£ãŸè¨“ç·´åˆ†å¸ƒã¨ä¸åã®ãƒ†ã‚¹ãƒˆåˆ†å¸ƒã‚’ä¸€è‡´ã•ã›ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
According to the causes of biased data explained in Section 3.2, we divide existing debiasing methods into two categories: user preference alignment and item popularity alignment.
ã‚»ã‚¯ã‚·ãƒ§ãƒ³3.2ã§èª¬æ˜ã—ãŸåã£ãŸãƒ‡ãƒ¼ã‚¿ã®åŸå› ã«å¾“ã£ã¦ã€æ—¢å­˜ã®ãƒ‡ãƒ“ã‚¢ã‚¹æ–¹æ³•ã‚’2ã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«åˆ†é¡ã™ã‚‹ï¼š ãƒ¦ãƒ¼ã‚¶å—œå¥½ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã¨é …ç›®äººæ°—ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã§ã‚ã‚‹ã€‚

### 4.3.1. User Preference Alignment ãƒ¦ãƒ¼ã‚¶ãƒ¼å—œå¥½ã®èª¿æ•´

User preferences may shift due to a variety of reasons, such as temporal changes Zafari et al.(2019); Wangwatcharakul and Wongthanavasu (2021); Ding et al.(2022), locational moves Yin et al.(2016), or alterations in personal and environmental conditions Zheng et al.(2021); He et al.(2022); Wang et al.(2023a).
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å—œå¥½ã¯ã€æ™‚é–“çš„ãªå¤‰åŒ–Zafariã‚‰(2019); Wangwatcharakul and Wongthanavasu(2021);Dingã‚‰(2022)ã€å ´æ‰€çš„ãªç§»å‹•Yinã‚‰(2016)ã€ã¾ãŸã¯å€‹äººçš„ãªæ¡ä»¶ã‚„ç’°å¢ƒæ¡ä»¶ã®å¤‰åŒ–Zhengã‚‰(2021); Heã‚‰(2022); Wangã‚‰(2023a)ãªã©ã€ã•ã¾ã–ã¾ãªç†ç”±ã§å¤‰åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
Existing methods are designed to track and adjust to these changes, thereby maintaining alignment with the ever-evolving user preferences.
æ—¢å­˜ã®æ–¹æ³•ã¯ã€ã“ã®ã‚ˆã†ãªå¤‰åŒ–ã‚’è¿½è·¡ã—ã€èª¿æ•´ã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€å¸¸ã«é€²åŒ–ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å—œå¥½ã¨ã®æ•´åˆæ€§ã‚’ç¶­æŒã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
For example, Aspect-MF Zafari et al.(2019) analyzes and models temporal preference drifts using a component-based factorized latent approach.
ä¾‹ãˆã°ã€Aspect-MF Zafari et al.(2019)ã¯ã€æˆåˆ†ãƒ™ãƒ¼ã‚¹ã®å› æ•°åˆ†è§£æ½œåœ¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç”¨ã„ã¦ã€æ™‚é–“çš„å—œå¥½ãƒ‰ãƒªãƒ•ãƒˆã‚’åˆ†æã—ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¦ã„ã‚‹ã€‚
MTUPD Wangwatcharakul and Wongthanavasu (2021) adopts a forgetting curve function to calculate the correlations of user preferences across time.
MTUPD Wangwatcharakul and Wongthanavasu (2021)ã¯ã€å¿˜å´æ›²ç·šé–¢æ•°ã‚’æ¡ç”¨ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å—œå¥½ã®æ™‚é–“çš„ç›¸é–¢ã‚’è¨ˆç®—ã—ã¦ã„ã‚‹ã€‚
ST-LDA Yin et al.(2016) learns region-dependent personal interests and crowd preferences to align locational preference drifts.
ST-LDA Yin et al.(2016)ã¯ã€åœ°åŸŸã«ä¾å­˜ã—ãŸå€‹äººã®èˆˆå‘³ã¨ç¾¤è¡†ã®å—œå¥½ã‚’å­¦ç¿’ã—ã€å ´æ‰€çš„å—œå¥½ã®ãƒ‰ãƒªãƒ•ãƒˆã‚’èª¿æ•´ã™ã‚‹ã€‚
Wang et al.Wang et al.(2023a) review user preference shifts across environments from a causal perspective and inspect the underlying causal relations through causal graphs.
Wangã‚‰.Wangã‚‰(2023a)ã¯ã€å› æœçš„ãªè¦³ç‚¹ã‹ã‚‰ç’°å¢ƒé–“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å—œå¥½ã®å¤‰åŒ–ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å› æœé–¢ä¿‚ã‚°ãƒ©ãƒ•ã‚’é€šã—ã¦ãã®æ ¹åº•ã«ã‚ã‚‹å› æœé–¢ä¿‚ã‚’æ¤œè¨¼ã—ã¦ã„ã‚‹ã€‚
Based on the causal relations, they further propose the CDR framework, which adopts a temporal variational autoencoder to capture preference shifts.
ã•ã‚‰ã«ã€å› æœé–¢ä¿‚ã«åŸºã¥ãã€å—œå¥½ã®å¤‰åŒ–ã‚’æ‰ãˆã‚‹ãŸã‚ã«æ™‚é–“å¤‰åˆ†ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’æ¡ç”¨ã—ãŸCDRãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚

### 4.3.2. Item Popularity Alignment ã‚¢ã‚¤ãƒ†ãƒ äººæ°—ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ

Existing methods for item popularity alignment roughly fall into five groups Zhang et al.(2023a).
é …ç›®äººæ°—ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®ãŸã‚ã®æ—¢å­˜ã®æ–¹æ³•ã¯ã€å¤§ã¾ã‹ã«5ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†é¡ã•ã‚Œã‚‹ã€‚
Inverse propensity scoring Schnabel et al.(2016); Saito et al.(2020) utilizes the inverse of item popularity as a propensity score to rebalance the loss for each user-item interaction.
é€†å‚¾å‘ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° Schnabel et al.(2016); Saito et al.(2020) ã¯ï¼Œé …ç›®äººæ°—ã®é€†æ•°ã‚’å‚¾å‘ã‚¹ã‚³ã‚¢ã¨ã—ã¦åˆ©ç”¨ã—ï¼Œå„ãƒ¦ãƒ¼ã‚¶ãƒ¼-é …ç›®ç›¸äº’ä½œç”¨ã®æå¤±ã‚’ãƒªãƒãƒ©ãƒ³ã‚¹ã™ã‚‹ï¼
Domain adaptation Bonner and Vasile (2018); Chen et al.(2020) leverages a small sample of unbiased data as the target domain to guide the training process on the larger but biased data in the source domain.
Domain adaptation Bonner and Vasile (2018); Chen et al. (2020)ã¯ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ»ãƒ‰ãƒ¡ã‚¤ãƒ³ã¨ã—ã¦ãƒã‚¤ã‚¢ã‚¹ã®ã‹ã‹ã£ã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ã®å°ã•ãªã‚µãƒ³ãƒ—ãƒ«ã‚’æ´»ç”¨ã—ã€ã‚½ãƒ¼ã‚¹ãƒ»ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã‚ˆã‚Šå¤§ããªã€ã—ã‹ã—ãƒã‚¤ã‚¢ã‚¹ã®ã‹ã‹ã£ãŸãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’å°ãã€‚
Causal estimation Wei et al.(2021); Zhang et al.(2021b); Wang et al.(2022) identifies the effect of popularity bias through assumed causal graphs and mitigates its impact on predictions.
å› æœæ¨å®š Wei et al.(2021); Zhang et al.(2021b); Wang et al.(2022) ã¯ã€ä»®å®šã•ã‚ŒãŸå› æœã‚°ãƒ©ãƒ•ã‚’é€šã˜ã¦äººæ°—ãƒã‚¤ã‚¢ã‚¹ã®å½±éŸ¿ã‚’ç‰¹å®šã—ã€äºˆæ¸¬ã¸ã®å½±éŸ¿ã‚’ç·©å’Œã™ã‚‹ã€‚
Regularization-based methods Boratto et al.(2021) explore regularization strategies to adjust recommendation results, aligning them more closely with the actual popularity distribution.
æ­£å‰‡åŒ–ã«åŸºã¥ãæ–¹æ³• Boratto et al.(2021) ã¯ã€æ¨è–¦çµæœã‚’èª¿æ•´ã—ã€å®Ÿéš›ã®äººæ°—åˆ†å¸ƒã«ã‚ˆã‚Šè¿‘ã¥ã‘ã‚‹ãŸã‚ã®æ­£å‰‡åŒ–æˆ¦ç•¥ã‚’æ¢æ±‚ã—ã¦ã„ã‚‹ã€‚
Generalization methods Zhang et al.(2022a, 2023b, 2023a) aim to learn invariant features that counteract popularity bias, thereby enhancing the stability and generalization capabilities of recommendation models.
æ±åŒ–æ‰‹æ³• Zhangã‚‰(2022a, 2023b, 2023a)ã¯ã€äººæ°—ãƒã‚¤ã‚¢ã‚¹ã‚’æ‰“ã¡æ¶ˆã™ä¸å¤‰ç‰¹å¾´ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã®å®‰å®šæ€§ã¨æ±åŒ–èƒ½åŠ›ã‚’é«˜ã‚ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚

### 4.3.3. Discussion ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³

Traditional evaluation settings in RSs may not be appropriate for assessing debiasing methods because they typically entail that the distribution of a test set is representative of the distribution in the training set (independent and identically distributed evaluation settings).
RSã«ãŠã‘ã‚‹å¾“æ¥ã®è©•ä¾¡è¨­å®šã¯ã€ãƒ†ã‚¹ãƒˆé›†åˆã®åˆ†å¸ƒãŒè¨“ç·´é›†åˆã®åˆ†å¸ƒã‚’ä»£è¡¨ã™ã‚‹ã“ã¨ãŒä¸€èˆ¬çš„ã§ã‚ã‚‹ãŸã‚ï¼ˆç‹¬ç«‹åŒåˆ†å¸ƒã®è©•ä¾¡è¨­å®šï¼‰ã€ãƒ‡ãƒ“ã‚¢ã‚¹æ‰‹æ³•ã®è©•ä¾¡ã«ã¯é©åˆ‡ã§ã¯ãªã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚
Therefore, in this part, we discuss two out-of-distribution evaluation settings to assess debiasing methods:
ãã“ã§ã“ã®ãƒ‘ãƒ¼ãƒˆã§ã¯ã€ãƒ‡ãƒ“ã‚¢ã‚¹æ³•ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®2ã¤ã®åˆ†å¸ƒå¤–è©•ä¾¡è¨­å®šã«ã¤ã„ã¦è­°è«–ã™ã‚‹ï¼š

â€¢ Temporal split setting: Temporal split setting slices the historical interactions into the training, validation, and test sets according to the timestamps Zhang et al.(2022a, 2023b).

- æ™‚é–“åˆ†å‰²è¨­å®šï¼š æ™‚é–“çš„åˆ†å‰²è¨­å®šï¼šæ™‚é–“çš„åˆ†å‰²è¨­å®šã¯ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«å¾“ã£ã¦ã€éå»ã®ç›¸äº’ä½œç”¨ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚»ãƒƒãƒˆã€æ¤œè¨¼ã‚»ãƒƒãƒˆã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«ã‚¹ãƒ©ã‚¤ã‚¹ã™ã‚‹ã€‚
  In this case, any shift in user preferences or item popularity over time is appropriately represented and accounted for during the evaluation.
  ã“ã®å ´åˆã€æ™‚é–“ã®çµŒéã«ä¼´ã†ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å—œå¥½ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã®äººæ°—ã®å¤‰åŒ–ã¯ã€è©•ä¾¡ä¸­ã«é©åˆ‡ã«è¡¨ç¾ã•ã‚Œã€èª¬æ˜ã•ã‚Œã‚‹ã€‚

â€¢ Popularity split setting: Popularity split setting constructs the training, validation, and test sets based on various popularity distributions Wei et al.(2021); Zheng et al.(2021).

- äººæ°—åº¦åˆ†å‰²è¨­å®šï¼š äººæ°—åº¦åˆ†å‰²è¨­å®šã¯ã€æ§˜ã€…ãªäººæ°—åº¦åˆ†å¸ƒã«åŸºã¥ã„ã¦è¨“ç·´ã€æ¤œè¨¼ã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
  For example, the training interactions are sampled to be a long-tail distribution over items while the validation and test interactions are sampled with equal probability in terms of items (uniform popularity distribution).
  ä¾‹ãˆã°ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ç›¸äº’ä½œç”¨ã¯é …ç›®ã«é–¢ã™ã‚‹ãƒ­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ«åˆ†å¸ƒã«ãªã‚‹ã‚ˆã†ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚Œã€ä¸€æ–¹ã€æ¤œè¨¼ãŠã‚ˆã³ãƒ†ã‚¹ãƒˆã®ç›¸äº’ä½œç”¨ã¯é …ç›®ã«é–¢ã—ã¦ç­‰ç¢ºç‡ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚Œã‚‹ï¼ˆä¸€æ§˜ãªäººæ°—åˆ†å¸ƒï¼‰ã€‚
  However, such a split setting has an inherent drawback: it may inadvertently lead to information leakage.
  ã—ã‹ã—ã€ã“ã®ã‚ˆã†ãªåˆ†å‰²è¨­å®šã«ã¯å›ºæœ‰ã®æ¬ ç‚¹ãŒã‚ã‚‹ï¼š ãã‚Œã¯ã€ä¸æ³¨æ„ã«ã‚ˆã£ã¦æƒ…å ±ãŒæ¼ã‚Œã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚‹ã¨ã„ã†ã“ã¨ã ã€‚
  By explicitly tailoring the test set to a known distribution of item popularity, the debiasing methods might be unduly influenced by this information.
  ã‚¢ã‚¤ãƒ†ãƒ ã®äººæ°—åº¦ã®æ—¢çŸ¥ã®åˆ†å¸ƒã«åˆã‚ã›ã¦ãƒ†ã‚¹ãƒˆãƒ»ã‚»ãƒƒãƒˆã‚’æ˜ç¤ºçš„ã«èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒã‚¤ã‚¢ã‚·ãƒ³ã‚°æ‰‹æ³•ãŒã“ã®æƒ…å ±ã«ä¸å½“ã«å½±éŸ¿ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚

# 5. Future Directions ä»Šå¾Œã®æ–¹å‘æ€§

## 5.1. Data-Centric RSs with Multimodal Data ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒRS

Multimodal data refers to data that consists of multiple modalities or types of information, such as text, images, audio, video, or any combination thereof.
ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã¨ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€éŸ³å£°ã€æ˜ åƒã€ã¾ãŸã¯ãã‚Œã‚‰ã®çµ„ã¿åˆã‚ã›ãªã©ã€è¤‡æ•°ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚„ã‚¿ã‚¤ãƒ—ã®æƒ…å ±ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã“ã¨ã§ã‚ã‚‹ã€‚
Traditionally, RSs have primarily relied on user-item interaction data, such as ratings or click-through data, to generate recommendations.
å¾“æ¥ã€RSã¯ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã€ä¸»ã«è©•ä¾¡ã‚„ã‚¯ãƒªãƒƒã‚¯ã‚¹ãƒ«ãƒ¼ãƒ‡ãƒ¼ã‚¿ãªã©ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜ã—ã¦ããŸã€‚
By incorporating multimodal data, RSs can capture richer and more diverse user preferences and item characteristics, leading to more personalized and relevant recommendations Truong and Lauw (2019).
ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ã§ã€RSã¯ã‚ˆã‚Šè±Šã‹ã§å¤šæ§˜ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å—œå¥½ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã®ç‰¹å¾´ã‚’æ‰ãˆã‚‹ã“ã¨ãŒã§ãã€ã‚ˆã‚Šãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸé©åˆ‡ãªãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ãªãŒã‚‹ Truong and Lauw (2019).
However, the data issues mentioned before (i.e., incomplete data, noisy data, and biased data) also exist in multimodal data, and they can pose additional challenges in the context of multimodal RSs:
ã—ã‹ã—ã€å…ˆã«è¿°ã¹ãŸã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã®å•é¡Œï¼ˆä¸å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã€ãƒã‚¤ã‚ºã®å¤šã„ãƒ‡ãƒ¼ã‚¿ã€åã£ãŸãƒ‡ãƒ¼ã‚¿ãªã©ï¼‰ã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã«ã‚‚å­˜åœ¨ã—ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RSã®æ–‡è„ˆã§ã¯ã•ã‚‰ãªã‚‹èª²é¡Œã¨ãªã‚Šã†ã‚‹ï¼š

â€¢ Heterogeneity: Multimodal data can be highly heterogeneous, with different modalities having distinct data formats, scales, and distributions.

- ç•°è³ªæ€§ï¼š ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã¯ã€ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ãŒç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿å½¢å¼ã€ã‚¹ã‚±ãƒ¼ãƒ«ã€åˆ†å¸ƒã‚’æŒã¡ã€éå¸¸ã«ç•°è³ªã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
  For example, text data may require natural language processing techniques, while image data may need computer vision algorithms.
  ä¾‹ãˆã°ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ã¯è‡ªç„¶è¨€èªå‡¦ç†æŠ€è¡“ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œãªã„ã—ã€ç”»åƒãƒ‡ãƒ¼ã‚¿ã«ã¯ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ»ãƒ“ã‚¸ãƒ§ãƒ³ãƒ»ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œãªã„ã€‚

â€¢ Imbalance: Multimodal datasets may exhibit imbalances in the distributions of different modalities.

- ä¸å‡è¡¡ï¼š ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®åˆ†å¸ƒã«ä¸å‡è¡¡ã‚’ç¤ºã™ã“ã¨ãŒã‚ã‚‹ã€‚
  For example, there may be a larger number of text samples compared to images or audio samples.
  ä¾‹ãˆã°ã€ç”»åƒã‚„éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«ã«æ¯”ã¹ã€ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«ã®æ•°ãŒå¤šã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
  Modality imbalance can affect the performance and generalization of recommendation models trained on such data.
  ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®ä¸å‡è¡¡ã¯ã€ãã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã‚ŒãŸæ¨è–¦ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¨ä¸€èˆ¬åŒ–ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚

â€¢ Scalability: Multimodal data, especially when it includes high-dimensional modalities like images or videos, can be computationally expensive to process and analyze.

- ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ï¼š ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã¯ã€ç‰¹ã«ç”»åƒã‚„å‹•ç”»ã®ã‚ˆã†ãªé«˜æ¬¡å…ƒã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’å«ã‚€å ´åˆã€å‡¦ç†ã‚„åˆ†æã«è¨ˆç®—ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã€‚
  Therefore, handling large-scale multimodal data may require efficient algorithms or distributed computing frameworks to ensure scalability.
  ã—ãŸãŒã£ã¦ã€å¤§è¦æ¨¡ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†ã«ã¯ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã®åŠ¹ç‡çš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚„åˆ†æ•£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒå¿…è¦ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚

## 5.2. Data-Centric RSs with LLMs LLMã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒRS

With the emergence of large language models (LLMs) in natural language processing, there has been a growing interest in harnessing the power of these models to enhance recommender systems.
è‡ªç„¶è¨€èªå‡¦ç†ã«ãŠã‘ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®å‡ºç¾ã«ä¼´ã„ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã«ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã®åŠ›ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã¸ã®é–¢å¿ƒãŒé«˜ã¾ã£ã¦ã„ã‚‹ã€‚
In Data-Centric RSs, LLMs can serve as:
ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒã®RSã§ã¯ã€LLMã¯æ¬¡ã®ã‚ˆã†ãªå½¹å‰²ã‚’æœãŸã™ï¼š

â€¢ Recommendation models: Pre-trained LLMs can take as input a sequence that includes user profiles, item attributes, user-item interactions, and task instructions.

- æ¨è–¦ãƒ¢ãƒ‡ãƒ«ï¼š äº‹å‰ã«è¨“ç·´ã•ã‚ŒãŸLLMã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã€ã‚¢ã‚¤ãƒ†ãƒ ã®å±æ€§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ç›¸äº’ä½œç”¨ã€ã‚¿ã‚¹ã‚¯ã®æŒ‡ç¤ºã‚’å«ã‚€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
  Then LLMs analyze this information to understand the context and the userâ€™s preferences.
  ãã—ã¦LLMã¯ã“ã®æƒ…å ±ã‚’åˆ†æã—ã€æ–‡è„ˆã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã‚’ç†è§£ã™ã‚‹ã€‚
  Based on this understanding, LLMs can generate a sequence that directly represents the recommendation results, which could be a list of items, a ranking of items, or even detailed descriptions or reasons for the recommendations.
  ã“ã®ç†è§£ã«åŸºã¥ã„ã¦ã€LLMã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒªã‚¹ãƒˆã€ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ã‚ã‚‹ã„ã¯è©³ç´°ãªèª¬æ˜ã‚„æ¨è–¦ç†ç”±ãªã©ã€æ¨è–¦çµæœã‚’ç›´æ¥è¡¨ã™ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
  However, using LLMs as recommendation models also raises some challenges such as limited token length or latency, especially for users with a large amount of interactions.
  ã—ã‹ã—ã€LLMã‚’æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ã¨ã€ãƒˆãƒ¼ã‚¯ãƒ³ã®é•·ã•ã‚„å¾…ã¡æ™‚é–“ãŒåˆ¶é™ã•ã‚Œã‚‹ãªã©ã®èª²é¡Œã‚‚ç”Ÿã˜ã‚‹ã€‚
  With data denoising techniques to improve the design of input sequences, the ability of LLMs as recommendation models can be further explored.
  å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®è¨­è¨ˆã‚’æ”¹å–„ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚ºé™¤å»æŠ€è¡“ã«ã‚ˆã‚Šã€æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã®LLMã®èƒ½åŠ›ã‚’ã•ã‚‰ã«æ¢æ±‚ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚

â€¢ Data processors: As mentioned before, given the extensive knowledge base and powerful reasoning capabilities of LLMs, some recent work has attempted to augment data with LLMs, for example, through carefully designed prompts, LLMRec Wei et al.(2023) employs three simple yet effective LLM-based data augmentation strategies to augment implicit feedback, user profiles, and item attributes, respectively.

- ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ã‚»ãƒƒã‚µï¼š ä¾‹ãˆã°ã€LLMRec Wei et al.(2023)ã¯ã€æš—é»™ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã€ã‚¢ã‚¤ãƒ†ãƒ å±æ€§ã‚’ãã‚Œãã‚Œæ‹¡å¼µã™ã‚‹ãŸã‚ã«ã€3ã¤ã®ã‚·ãƒ³ãƒ—ãƒ«ã‹ã¤åŠ¹æœçš„ãªLLMãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæˆ¦ç•¥ã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚
  Moving forward, itâ€™s crucial to investigate the capability of LLMs in managing tasks such as data denoising and data debiasing.
  ä»Šå¾Œã€LLMãŒãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚ºé™¤å»ã‚„ãƒ‡ãƒ¼ã‚¿ãƒ‡ãƒ“ã‚¢ã‚¹ã®ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã‚’ç®¡ç†ã™ã‚‹èƒ½åŠ›ã‚’èª¿æŸ»ã™ã‚‹ã“ã¨ã¯æ¥µã‚ã¦é‡è¦ã§ã‚ã‚‹ã€‚
  This could pave the way for LLMs to harmonize Data-Centric RSs effectively.
  ã“ã‚Œã¯ã€LLMãŒãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒRSã‚’åŠ¹æœçš„ã«èª¿å’Œã•ã›ã‚‹é“ã‚’é–‹ãå¯èƒ½æ€§ãŒã‚ã‚‹ã€‚

## 5.3. Automatic Data-Centric RSs è‡ªå‹•ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒRS

Automatic machine learning (AutoML) He et al.(2021) refers to the process of automating the end-to-end process of applying machine learning to real-world problems, which typically involves automating a variety of tasks that are part of the machine learning workflow.
è‡ªå‹•æ©Ÿæ¢°å­¦ç¿’ï¼ˆAutoMLï¼‰He et al.(2021)ã¯ã€å®Ÿä¸–ç•Œã®å•é¡Œã«æ©Ÿæ¢°å­¦ç¿’ã‚’é©ç”¨ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒ»ãƒ„ãƒ¼ãƒ»ã‚¨ãƒ³ãƒ‰ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’æŒ‡ã—ã€é€šå¸¸ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ä¸€éƒ¨ã§ã‚ã‚‹æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã®è‡ªå‹•åŒ–ã‚’ä¼´ã†ã€‚
In the context of Data-Centric RSs, these tasks encompass data augmentation, data denoising, and data debiasing.
ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒRSã®æ–‡è„ˆã§ã¯ã€ã“ã‚Œã‚‰ã®ã‚¿ã‚¹ã‚¯ã¯ã€ãƒ‡ãƒ¼ã‚¿ã®å¢—å¼·ã€ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¤ã‚ºé™¤å»ã€ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒã‚¤ã‚¢ã‚·ãƒ³ã‚°ã‚’å«ã‚€ã€‚
Consequently, AutoML can automatically streamline and enhance the efficiency of these tasks, enabling more accurate recommendations, which is of great significance in practice.
ãã®çµæœã€AutoMLã¯ã“ã‚Œã‚‰ã®ä½œæ¥­ã‚’è‡ªå‹•çš„ã«åˆç†åŒ–ã—ã€åŠ¹ç‡åŒ–ã™ã‚‹ã“ã¨ãŒã§ãã€ã‚ˆã‚Šæ­£ç¢ºãªæ¨è–¦ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚

## 5.4. Transparent Data-Centric RSs é€æ˜ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒRS

Transparent Data-Centric RSs refer to Data-Centric RSs that not only offer enhanced data for model training but also provide insights into how and why particular enhancements are made, thereby allowing users and developers to understand the underlying decision-making processes.
é€æ˜ãªãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒRSã¨ã¯ã€ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãŸã‚ã«å¼·åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã™ã‚‹ã ã‘ã§ãªãã€ç‰¹å®šã®å¼·åŒ–ãŒã©ã®ã‚ˆã†ã«è¡Œã‚ã‚Œã€ãªãœè¡Œã‚ã‚ŒãŸã®ã‹ã«ã¤ã„ã¦ã®æ´å¯Ÿã‚‚æä¾›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒRSã®ã“ã¨ã§ã€ã“ã‚Œã«ã‚ˆã‚Šãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„é–‹ç™ºè€…ã¯åŸºæœ¬çš„ãªæ„æ€æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹ã‚’ç†è§£ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
Research in transparent Data-Centric RSs is tackling complex challenges, such as the trade-off between transparency and complexity, ensuring user privacy while providing explanations, and developing standards for explainability and interpretability.
é€æ˜æ€§ã®é«˜ã„ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒå‹RSã®ç ”ç©¶ã¯ã€é€æ˜æ€§ã¨è¤‡é›‘æ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã€èª¬æ˜ã‚’æä¾›ã—ãªãŒã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚’ç¢ºä¿ã™ã‚‹ã“ã¨ã€èª¬æ˜å¯èƒ½æ€§ã¨è§£é‡ˆå¯èƒ½æ€§ã®åŸºæº–ã‚’é–‹ç™ºã™ã‚‹ã“ã¨ãªã©ã€è¤‡é›‘ãªèª²é¡Œã«å–ã‚Šçµ„ã‚“ã§ã„ã‚‹ã€‚

# 6. Conclusion çµè«–

In this survey, we presented a comprehensive literature review of Data-Centric RSs.
æœ¬ã‚µãƒ¼ãƒ™ã‚¤ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒå‹RSã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªæ–‡çŒ®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã£ãŸã€‚
We systematically analyzed three critical issues inherent in recommendation data and subsequently categorized existing works in accordance with their focus on these issues.
æˆ‘ã€…ã¯ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã«å†…åœ¨ã™ã‚‹3ã¤ã®é‡è¦ãªå•é¡Œã‚’ä½“ç³»çš„ã«åˆ†æã—ã€ãã®å¾Œã€ã“ã‚Œã‚‰ã®å•é¡Œã¸ã®ç„¦ç‚¹ã«å¾“ã£ã¦æ—¢å­˜ã®ç ”ç©¶ã‚’åˆ†é¡ã—ãŸã€‚
Additionally, we point out a range of prospective research directions to advance Data-Centric RSs.
ã•ã‚‰ã«ã€ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒå‹RSã‚’ç™ºå±•ã•ã›ã‚‹ãŸã‚ã®æ§˜ã€…ãªç ”ç©¶ã®æ–¹å‘æ€§ã‚’æŒ‡æ‘˜ã™ã‚‹ã€‚
We expect that this survey can help readers easily grasp the big picture of this emerging field and equip them with the basic techniques and valuable future research ideas.
ã“ã®ã‚µãƒ¼ãƒ™ã‚¤ãŒã€èª­è€…ãŒã“ã®æ–°èˆˆåˆ†é‡ã®å…¨ä½“åƒã‚’å®¹æ˜“ã«æŠŠæ¡ã—ã€åŸºæœ¬çš„ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã¨è²´é‡ãªå°†æ¥ã®ç ”ç©¶ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’èº«ã«ã¤ã‘ã‚‹ä¸€åŠ©ã¨ãªã‚‹ã“ã¨ã‚’æœŸå¾…ã—ã¦ã„ã‚‹ã€‚
