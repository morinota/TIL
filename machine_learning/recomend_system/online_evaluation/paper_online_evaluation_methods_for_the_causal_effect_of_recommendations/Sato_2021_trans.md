## 0.1. link 0.1. ãƒªãƒ³ã‚¯

- [pdf](https://arxiv.org/pdf/2107.06630.pdf) pdf](https:

- [ã“ã®æ–¹ã®ãƒ–ãƒ­ã‚°ã‚’è¦‹ã¦æœ¬è«–æ–‡ã‚’è¦‹ã¤ã‘ãŸ.](https://ayakobaba.hatenablog.com/entry/2021/09/25/190642) [I found this paper through this person's blog. ](https:

## 0.2. title 0.2. ã‚¿ã‚¤ãƒˆãƒ«

Online Evaluation Methods for the Causal Effect of Recommendations
ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®å› æœé–¢ä¿‚ã«å¯¾ã™ã‚‹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©•ä¾¡æ‰‹æ³•

## 0.3. abstract 0.3. æŠ½è±¡çš„

Evaluating the causal effect of recommendations is an important objective because the causal effect on user interactions can directly leads to an increase in sales and user engagement.
ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®å› æœé–¢ä¿‚ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã®å› æœé–¢ä¿‚ãŒå£²ä¸Šã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã®å¢—åŠ ã«ç›´çµã™ã‚‹ãŸã‚ã€é‡è¦ãªç›®çš„ã§ã‚ã‚‹ã€‚
To select an optimal recommendation model, it is common to conduct A
æœ€é©ãªãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã‚‹ãŸã‚ã«ã€ä¸€èˆ¬çš„ã«ã¯A

# 1. Introduction 1. ã¯ã˜ã‚ã«

A recommendation is a treatment that can affect user behavior.
ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¡Œå‹•ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ãŒã§ãã‚‹æ²»ç™‚æ³•ã§ã‚ã‚‹ã€‚
An increase in user actions, such as purchases or views, by the recommendation is the treatment effect (also called the causal effect).
ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã£ã¦ã€è³¼å…¥ã‚„é–²è¦§ãªã©ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒå¢—åŠ ã™ã‚‹ã“ã¨ãŒã€ãƒˆãƒªãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆåŠ¹æœï¼ˆå› æœåŠ¹æœã¨ã‚‚ã„ã†ï¼‰ã§ã‚ã‚‹ã€‚
Because this leads to improved sales or user engagement, the causal effect of recommendations is important for businesses.
ã“ã‚Œã¯å£²ä¸Šã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã®å‘ä¸Šã«ã¤ãªãŒã‚‹ãŸã‚ã€ä¼æ¥­ã«ã¨ã£ã¦ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®å› æœé–¢ä¿‚ã¯é‡è¦ã§ã‚ã‚‹ã€‚
While most recommendation methods aim for accurate predictions of user behaviors, there may be a discrepancy between the accuracy and the causal effect of recommendations [25].
å¤šãã®æ¨è–¦æ‰‹æ³•ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¡Œå‹•ã‚’æ­£ç¢ºã«äºˆæ¸¬ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ãŒã€æ¨è–¦ã®ç²¾åº¦ã¨å› æœåŠ¹æœã®é–“ã«ä¹–é›¢ãŒã‚ã‚‹å ´åˆãŒã‚ã‚‹[25]ã€‚
Several recent works have thus proposed recommendation methods to rank items by the causal effect of recommendations [1, 24, 25, 27, 28].
ãã“ã§ï¼Œè¿‘å¹´ã§ã¯ï¼Œæ¨è–¦ã®å› æœé–¢ä¿‚ã«ã‚ˆã£ã¦é …ç›®ã‚’ãƒ©ãƒ³ã‚¯ä»˜ã‘ã™ã‚‹æ¨è–¦æ‰‹æ³•ãŒã„ãã¤ã‹ææ¡ˆã•ã‚Œã¦ã„ã‚‹[1, 24, 25, 27, 28]ï¼

Online experiments are commonly conducted to compare model performance and select the best recommendation model.
ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ¯”è¼ƒã—ã€æœ€é©ãªæ¨è–¦ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã‚‹ãŸã‚ã«ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å®Ÿé¨“ãŒä¸€èˆ¬çš„ã«è¡Œã‚ã‚Œã¦ã„ã‚‹ã€‚
However, evaluating the causal effect is not straightforward; we cannot naively compare the outcomes of recommended items because the causal effect is the difference between the potential outcomes with and without the treatment [12, 22].
ã—ã‹ã—ã€å› æœé–¢ä¿‚ã®è©•ä¾¡ã¯ä¸€ç­‹ç¸„ã§ã¯ã„ã‹ãªã„ã€‚å› æœé–¢ä¿‚ã¨ã¯ã€å‡¦ç†ã‚’è¡Œã£ãŸå ´åˆã¨è¡Œã‚ãªã‹ã£ãŸå ´åˆã®æ½œåœ¨çš„ãªçµæœã®å·®ã§ã‚ã‚‹ãŸã‚ã€æ¨è–¦é …ç›®ã®çµæœã‚’å˜ç´”ã«æ¯”è¼ƒã™ã‚‹ã“ã¨ã¯ã§ããªã„[12, 22]ã€‚
A
A

In this paper, we propose efficient online evaluation methods for the causal effect of recommendations based on interleaving.
æœ¬è«–æ–‡ã§ã¯ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ“ãƒ³ã‚°ã«åŸºã¥ãæ¨è–¦ã®å› æœé–¢ä¿‚ã®åŠ¹ç‡çš„ãªã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©•ä¾¡æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚
Interleaving generates a list from the lists ranked by the two models to be compared [3].
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ“ãƒ³ã‚°ã¯ã€æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ãƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚ŒãŸãƒªã‚¹ãƒˆã‹ã‚‰ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹[3]ã€‚
Whereas previous interleaving methods only measure the outcomes of items in the intersection of the original and interleaved lists, our proposed methods also measure the outcomes of items in the original lists but not in the interleaved list.
å¾“æ¥ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ³•ã¯ã€å…ƒã®ãƒªã‚¹ãƒˆã¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã•ã‚ŒãŸãƒªã‚¹ãƒˆã®äº¤ç‚¹ã«ã‚ã‚‹é …ç›®ã®çµæœã®ã¿ã‚’æ¸¬å®šã™ã‚‹ã®ã«å¯¾ã—ã€æˆ‘ã€…ã®ææ¡ˆã™ã‚‹æ–¹æ³•ã¯ã€å…ƒã®ãƒªã‚¹ãƒˆã«ã‚ã‚‹ãŒã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã•ã‚ŒãŸãƒªã‚¹ãƒˆã«ãªã„é …ç›®ã®çµæœã‚‚æ¸¬å®šã™ã‚‹ã€‚
We propose an interleaving method that selects items with equal probability for unbiased evaluation.
æˆ‘ã€…ã¯ã€åã‚Šã®ãªã„è©•ä¾¡ã‚’è¡Œã†ãŸã‚ã«ã€é …ç›®ã‚’ç­‰ç¢ºç‡ã§é¸æŠã™ã‚‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ‰‹æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚
With unequal selection probabilities, the evaluation might be biased due to confounding [8] between recommendation and potential outcomes, leading to inaccurate judgments of the recommendation models.
é¸æŠç¢ºç‡ãŒç­‰ã—ããªã„å ´åˆï¼Œæ¨è–¦ã¨æ½œåœ¨çš„ãªçµæœã®äº¤çµ¡[8]ã«ã‚ˆã‚Šè©•ä¾¡ã«åã‚ŠãŒç”Ÿã˜ï¼Œæ¨è–¦ãƒ¢ãƒ‡ãƒ«ã®åˆ¤å®šãŒä¸æ­£ç¢ºã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ï¼
We remove the possible bias by properly weighting the outcomes based on the inverse propensity score (IPS) method used in causal inference [16, 21].
æˆ‘ã€…ã¯ï¼Œå› æœæ¨è«–ã§ç”¨ã„ã‚‰ã‚Œã‚‹é€†æ€§å‘ã‚¹ã‚³ã‚¢ï¼ˆIPSï¼‰æ³• [16, 21]ã«åŸºã¥ã„ã¦ï¼Œã‚¢ã‚¦ãƒˆã‚«ãƒ ã‚’é©åˆ‡ã«é‡ã¿ä»˜ã‘ã™ã‚‹ã“ã¨ã§ï¼Œã“ã®å¯èƒ½æ€§ã®ã‚ã‚‹ãƒã‚¤ã‚¢ã‚¹ã‚’é™¤å»ã—ã¦ã„ã‚‹ï¼
This enables the use of a more general interleaving framework that only requires non-zero probabilities to be selected for any item in the original lists.
ã“ã‚Œã«ã‚ˆã‚Šã€ã‚ˆã‚Šä¸€èˆ¬çš„ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã€å…ƒã®ãƒªã‚¹ãƒˆå†…ã®ä»»æ„ã®ã‚¢ã‚¤ãƒ†ãƒ ã«ã¤ã„ã¦é¸æŠã•ã‚Œã‚‹éã‚¼ãƒ­ã®ç¢ºç‡ã‚’å¿…è¦ã¨ã™ã‚‹ã®ã¿ã§ã‚ã‚‹ã€‚
As an instance of the framework, we propose a causal balanced interleaving method that balances the number of items chosen from the two compared lists.
ã“ã®æ çµ„ã¿ã®ä¸€ä¾‹ã¨ã—ã¦ã€æˆ‘ã€…ã¯ã€æ¯”è¼ƒã•ã‚ŒãŸ2ã¤ã®ãƒªã‚¹ãƒˆã‹ã‚‰é¸æŠã•ã‚Œã‚‹é …ç›®ã®æ•°ã‚’å‡è¡¡ã•ã›ã‚‹å› æœçš„å‡è¡¡ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚
To verify the unbiasedness and efficiency of the proposed interleaving methods, we simulate online experiments to compare ranking models.
ææ¡ˆã™ã‚‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ³•ã®ä¸åæ€§ã¨åŠ¹ç‡æ€§ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã™ã‚‹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å®Ÿé¨“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã†ã€‚

The contributions of this paper are summarized as follows.
æœ¬è«–æ–‡ã®è²¢çŒ®ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ã¾ã¨ã‚ã‚‰ã‚Œã‚‹ã€‚

- We propose the first interleaving methods to compare recommendation models in terms of their causal effect. æˆ‘ã€…ã¯ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’å› æœé–¢ä¿‚ã®è¦³ç‚¹ã‹ã‚‰æ¯”è¼ƒã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ‰‹æ³•ã‚’åˆã‚ã¦ææ¡ˆã™ã‚‹ã€‚

- We verify the unbiasedness and efficiency of the proposed methods through simulated online experiments ææ¡ˆæ‰‹æ³•ã®ä¸åæ€§ã¨åŠ¹ç‡æ€§ã‚’æ¨¡æ“¬ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å®Ÿé¨“ã«ã‚ˆã‚Šæ¤œè¨¼ã™ã‚‹

# 2. Related Work 2. é–¢é€£ä½œå“

## 2.1. Interleaving Methods 2.1. ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ–¹æ³•

Interleaving is an online evaluation method for comparing two ranking models by observing user interactions with an interleaved list that is generated from lists ranked by the two models to be compared [3].
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã¨ã¯ï¼Œæ¯”è¼ƒã™ã‚‹2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ãƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚ŒãŸãƒªã‚¹ãƒˆã‹ã‚‰ç”Ÿæˆã•ã‚Œã‚‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ãƒªã‚¹ãƒˆã«å¯¾ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¦³å¯Ÿã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ï¼Œ2ã¤ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã™ã‚‹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©•ä¾¡æ‰‹æ³•ã§ã‚ã‚‹[3]ï¼
Several interleaving methods have been proposed for evaluating information retrieval systems.
æƒ…å ±æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡æ‰‹æ³•ã¨ã—ã¦ï¼Œã„ãã¤ã‹ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ‰‹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ï¼
Balanced interleaving [14, 15] generates an interleaved list from two rankings to be compared such that the highest ranks in the interleaved list ğ‘˜ğ´ and ğ‘˜ğµ from the two rankings ğ´ and ğµ, respectively, are the same or different by at most one.
Balanced interleaving [14, 15] ã¯ã€æ¯”è¼ƒã™ã‚‹äºŒã¤ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‹ã‚‰ã€äºŒã¤ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°áµ…ã¨ğ‘˜ã‹ã‚‰ãã‚Œãã‚Œã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã•ã‚ŒãŸãƒªã‚¹ãƒˆã®æœ€é«˜ãƒ©ãƒ³ã‚¯ğ‘˜ğµãŒåŒã˜ã‹æœ€å¤§1ã ã‘ç•°ãªã‚‹ã‚ˆã†ã«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã€‚
Team draft interleaving [19] alternatively selects items from compared rankings, analogously to selecting teams for a friendly team-sports match.
ãƒãƒ¼ãƒ ãƒ‰ãƒ©ãƒ•ãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–[19]ã¯ã€ãƒãƒ¼ãƒ ã‚¹ãƒãƒ¼ãƒ„ã®è¦ªå–„è©¦åˆã®ãƒãƒ¼ãƒ ã‚’é¸ã¶ã‚ˆã†ã«ã€æ¯”è¼ƒã—ãŸãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‹ã‚‰é …ç›®ã‚’é¸æŠã™ã‚‹æ–¹æ³•ã§ã‚ã‚‹ã€‚
Probabilistic interleaving [9] selects items according to probabilities that depend on the item ranks.
ç¢ºç‡çš„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–(Probabilistic interleaving) [9] ã¯é …ç›®ã®ãƒ©ãƒ³ã‚¯ã«ä¾å­˜ã™ã‚‹ç¢ºç‡ã«å¾“ã£ã¦é …ç›®ã‚’é¸æŠã™ã‚‹ã€‚
Optimized interleaving [18] makes the properties required for interleaving in information retrieval explicit and then generates interleaved lists by solving an optimization problem to fulfill those properties.
æœ€é©åŒ–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–[18]ã¯ï¼Œæƒ…å ±æ¤œç´¢ã«ãŠã‘ã‚‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã«å¿…è¦ãªç‰¹æ€§ã‚’æ˜ç¤ºã—ï¼Œãã®ç‰¹æ€§ã‚’æº€ãŸã™ã‚ˆã†ã«æœ€é©åŒ–å•é¡Œã‚’è§£ã„ã¦ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ï¼
Interleaving methods have been extended to multileaving that compare multiple rankings simultaneously [30, 31].
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ“ãƒ³ã‚°ã®æ‰‹æ³•ã¯ï¼Œè¤‡æ•°ã®é †ä½ã‚’åŒæ™‚ã«æ¯”è¼ƒã™ã‚‹ãƒãƒ«ãƒãƒªãƒ¼ãƒ“ãƒ³ã‚°ã«æ‹¡å¼µã•ã‚Œã¦ã„ã‚‹[30, 31]ï¼
Multileaving has been also applied to the evaluation of a news recommender system [11].
ã¾ãŸï¼Œãƒãƒ«ãƒãƒªãƒ¼ãƒ“ãƒ³ã‚°ã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡ã«ã‚‚é©ç”¨ã•ã‚Œã¦ã„ã‚‹[11]ï¼
The objective of previous interleaving methods is to evaluate how accurately the rankings reflect queries or user preferences, whereas our goal is to evaluate rankings in terms of the causal effect.
å¾“æ¥ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ³•ã®ç›®çš„ã¯ï¼Œãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒã„ã‹ã«æ­£ç¢ºã«ã‚¯ã‚¨ãƒªã‚„ãƒ¦ãƒ¼ã‚¶ã®å—œå¥½ã‚’åæ˜ ã—ã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ãŒï¼Œæˆ‘ã€…ã®ç›®çš„ã¯ï¼Œå› æœé–¢ä¿‚ã®è¦³ç‚¹ã‹ã‚‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ï¼
To the best of our knowledge, at present there are no interleaving methods for causal effects.
æˆ‘ã€…ã®çŸ¥ã‚‹é™ã‚Šï¼Œç¾åœ¨ã®ã¨ã“ã‚å› æœé–¢ä¿‚ã‚’è€ƒæ…®ã—ãŸã‚¤ãƒ³ã‚¿ãƒªãƒ¼ãƒ“ãƒ³ã‚°æ‰‹æ³•ã¯å­˜åœ¨ã—ãªã„ï¼

## 2.2. Recommendation Methods for the Causal Effect 2.2. å› æœé–¢ä¿‚ã®æ¨å¥¨æ–¹æ³•

Recommendations can affect usersâ€™ opinions [5] and induce usersâ€™ actions [6, 13].
ã“ã®ã‚ˆã†ã«ï¼Œãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¯ãƒ¦ãƒ¼ã‚¶ã®æ„è¦‹ã«å½±éŸ¿ã‚’ä¸ãˆ [5]ï¼Œãƒ¦ãƒ¼ã‚¶ã®è¡Œå‹•ã‚’èª˜ç™ºã™ã‚‹ã“ã¨ãŒã§ãã‚‹ [6, 13]ï¼
However, usersâ€™ actions on recommended items could have occurred even without the recommendations [32].
ã—ã‹ã—ã€æ¨è–¦ã•ã‚ŒãŸã‚‚ã®ã«å¯¾ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ã®è¡Œå‹•ã¯ã€æ¨è–¦ã•ã‚Œãªã ã¦ã‚‚ç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹[32]ã€‚
Building recommendation models that target the causal effect is challenging because the ground truth data of causal effects are not observable [10].
ã“ã®ã‚ˆã†ãªå› æœé–¢ä¿‚ã‚’è€ƒæ…®ã—ãŸãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã¯ã€å› æœé–¢ä¿‚ã®ã‚°ãƒ©ãƒ³ãƒ‰ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒè¦³æ¸¬ã§ããªã„ãŸã‚ã€å›°é›£ã§ã‚ã‚‹[10]ã€‚
One approach is to train prediction models for both recommended and non-recommended outcomes and then to rank the items based on the difference between the two predictions [1, 24].
ãã®ãŸã‚ï¼Œæ¨è–¦ã•ã‚ŒãŸçµæœã¨æ¨è–¦ã•ã‚Œãª ã‹ã£ãŸçµæœã®ä¸¡æ–¹ã«ã¤ã„ã¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ï¼Œ2ã¤ã®äºˆæ¸¬å€¤ã®å·®ã«åŸº ã¥ã„ã¦é …ç›®ã‚’ãƒ©ãƒ³ã‚¯ä»˜ã‘ã™ã‚‹æ–¹æ³•ãŒã‚ã‚‹[1, 24]ï¼
Another approach is to optimize models directly for the causal effect.
ã‚‚ã†ä¸€ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€å› æœé–¢ä¿‚ã«å¯¾ã—ã¦ç›´æ¥ãƒ¢ãƒ‡ãƒ«ã‚’æœ€é©åŒ–ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
ULRMF and ULBPR [25] are respectively pointwise and pairwise optimization methods that use label transformations and training data samplings designed for causal effect optimization.
ULRMFã¨ULBPR[25]ã¯ã€ãã‚Œãã‚Œãƒã‚¤ãƒ³ãƒˆãƒ¯ã‚¤ã‚ºã¨ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã®æœ€é©åŒ–æ‰‹æ³•ã§ã€ãƒ©ãƒ™ãƒ«å¤‰æ›ã¨å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã€å› æœåŠ¹æœã®æœ€é©åŒ–ã®ãŸã‚ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚
DLCE [27] is an unbiased learning method for the causal effect that uses an IPS-based unbiased learning objective.
DLCE [27]ã¯ã€IPSã«åŸºã¥ãä¸åã®å­¦ç¿’ç›®çš„ã‚’ç”¨ã„ãŸå› æœåŠ¹æœã®ãŸã‚ã®ä¸åã®å­¦ç¿’æ–¹æ³•ã§ã‚ã‚‹ã€‚
There are also neighborhood methods for causal effects [28] that are based on a matching estimator in causal inference.
ã¾ãŸã€å› æœæ¨è«–ã«ãŠã‘ã‚‹ãƒãƒƒãƒãƒ³ã‚°æ¨å®šé‡ã«åŸºã¥ãå› æœåŠ¹æœã®è¿‘å‚æ³•[28]ã‚‚å­˜åœ¨ã™ã‚‹ã€‚
These prior works on causal effects evaluated methods offline and did not discuss protocols for online evaluation.
ã“ã‚Œã‚‰ã®å› æœåŠ¹æœã«é–¢ã™ã‚‹å…ˆè¡Œç ”ç©¶ã§ã¯ã€æ‰‹æ³•ã‚’ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§è©•ä¾¡ã—ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©•ä¾¡ã®ãŸã‚ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«ã¤ã„ã¦ã¯è­°è«–ã•ã‚Œã¦ã„ãªã„ã€‚
In this study, we develop online evaluation methods and compare some of the aforementioned recommendation methods in simulated online experiments.
æœ¬ç ”ç©¶ã§ã¯ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©•ä¾¡æ‰‹æ³•ã‚’é–‹ç™ºã—ã€æ¨¡æ“¬ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å®Ÿé¨“ã«ãŠã„ã¦å‰è¿°ã®æ¨è–¦æ‰‹æ³•ã®ã„ãã¤ã‹ã‚’æ¯”è¼ƒã™ã‚‹ã€‚

Another line of works in the area of causal recommendation aims for debiasing [4].
ã¾ãŸï¼Œå› æœé–¢ä¿‚æ¨è–¦ã®åˆ†é‡ã§ã¯ï¼Œãƒ‡ãƒ“ã‚¢ã‚¹ï¼ˆdebiasingï¼‰ ã‚’ç›®çš„ã¨ã—ãŸç ”ç©¶ã‚‚è¡Œã‚ã‚Œã¦ã„ã‚‹ [4]ï¼
Several methods have been proposed to learn usersâ€™ true preferences from biased (missing-not-at-random) feedback data [2, 23, 29, 33].1 These methods can be regarded as predicting interactions with recommendations (i.e., $Y_{ui}^T$, defined in the next section).
åã£ãŸï¼ˆmissing-not-at-randomï¼‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ã®çœŸã®å—œå¥½ã‚’å­¦ç¿’ã™ã‚‹æ–¹æ³•ãŒã„ãã¤ã‹ææ¡ˆã•ã‚Œã¦ã„ã‚‹[2, 23, 29, 33] 1ã€‚ã“ã‚Œã‚‰ã®æ–¹æ³•ã¯ã€æ¨è–¦ã¨ã®ç›¸äº’ä½œç”¨ï¼ˆã™ãªã‚ã¡ã€æ¬¡ç¯€ã§å®šç¾©ã™ã‚‹ $Y_{ui}^T$ ï¼‰ã‚’äºˆæ¸¬ã™ã‚‹ã‚‚ã®ã¨è€ƒãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
Hence, we can evaluate them using previous interleaving methods.
ã—ãŸãŒã£ã¦ï¼Œä»¥å‰ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ³•ã‚’ç”¨ã„ã¦ãã‚Œã‚‰ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ï¼

# 3. Evaluation Methods for the Causal Effect of Recommendatios 3. ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®å› æœé–¢ä¿‚ã®è©•ä¾¡æ–¹æ³•

## 3.1. Causal Effect of Recommendations 3.1. æ¨å¥¨äº‹é …ã®å› æœé–¢ä¿‚

In this subsection, we define the causal effect of recommendations.
ã“ã®ã‚µãƒ–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®å› æœé–¢ä¿‚ã‚’å®šç¾©ã™ã‚‹ã€‚
Let $U$ and $I$ be sets of users and items, respectively.
U$ã¨$I$ã‚’ãã‚Œãã‚Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®é›†åˆã¨ã™ã‚‹ã€‚
Let $Y_{ui}
ã¾ãŸã€$Y_{ui}ã¨ã™ã‚‹ã€‚
\in {0, 1}$ denote the interaction (e.g., purchase or view) of user $u \in U$ with item $i \in I$.
\U$ã¨$I$ã‚’ãã‚Œãã‚Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®é›†åˆã¨ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼$uã¨ã‚¢ã‚¤ãƒ†ãƒ $iã®ç›¸äº’ä½œç”¨ï¼ˆè³¼å…¥ã‚„é–²è¦§ãªã©ï¼‰ã‚’$Y_{ui}{in {0, 1}$ã¨ã™ã‚‹ã€‚
User interactions may differ depending on whether the item is recommended or not.
ãƒ¦ãƒ¼ã‚¶ã¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã¯ã€ãã®ã‚¢ã‚¤ãƒ†ãƒ ãŒæ¨å¥¨ã•ã‚Œã‚‹ã‹å¦ã‹ã«ã‚ˆã£ã¦ç•°ãªã‚‹å ´åˆãŒã‚ã‚‹ã€‚
We denote the binary indicator for the recommendation (also called the treatment assignment) by $Z_{ui}
ã“ã“ã§ã€æ¨å¥¨ã®2å€¤æŒ‡æ¨™ã‚’$Z_{ui}ã¨ã™ã‚‹ï¼ˆå‡¦ç†å‰²ã‚Šå½“ã¦ã¨ã‚‚ã„ã†ï¼‰ã€‚
\in {0, 1}$.
\in {0, 1}$ ã¨ã™ã‚‹ã€‚
Let $Y_{ui}^T$ and $Y_{ui}^C \in {0, 1}$ be hypothetical user interactions (also called potential outcomes [22]) when item $i$ is recommended to $u$ ($Z_{ui} = 1$) and when it is not recommended ($Z_{ui} = 0$), respectively.
ã¾ãŸã€$Y_{ui}^T$ã¨$Y_{ui}^C \in {0, 1}$ ã‚’ãã‚Œãã‚Œ$u$ã«ã‚¢ã‚¤ãƒ†ãƒ $i$ã‚’æ¨å¥¨ã—ãŸå ´åˆï¼ˆ$Z_{ui} = 1$ï¼‰ã¨æ¨å¥¨ã—ãªã„å ´åˆï¼ˆ$Z_{ui} = 0$ï¼‰ã®ä»®æƒ³ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ç›¸äº’ä½œç”¨ï¼ˆæ½œåœ¨çµæœã¨ã‚‚ã„ã†[22]ï¼‰ã§ã‚ã‚‹ã¨ã™ã‚‹ã€‚
The causal effect $\tau_{ui}$ of recommending item $i$ to user $u$ is defined as the difference between the two potential outcomes: $\tau_{ui} = Y_{ui}^T âˆ’ Y_{ui}^C$, that takes ternary values, $\tau_{ui}
ã‚¢ã‚¤ãƒ†ãƒ $i$ã‚’ãƒ¦ãƒ¼ã‚¶$u$ã«æ¨å¥¨ã™ã‚‹å› æœåŠ¹æœ$tau_{ui}$ã¯ã€2ã¤ã®æ½œåœ¨çš„ãªçµæœã®å·®ã¨ã—ã¦å®šç¾©ã•ã‚Œã‚‹ï¼š$tau_{ui} = Y_{ui}^T - Y_{ui}^C$, 3å€¤ã‚’ã¨ã‚Šã€$tau_{ui}ã¯ã€$tau_{ui} = Y_{ui}^C$, 3å€¤ã‚’ã¨ã‚‹
\in {âˆ’1, 0, 1}$.
\ã®3å€¤ã‚’ã¨ã‚‹ã€‚
Using potential outcomes, the observed interaction can be expressed as
ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚¢ã‚¦ãƒˆã‚«ãƒ ã‚’ç”¨ã„ã‚‹ã¨ã€è¦³æ¸¬ã•ã‚ŒãŸç›¸äº’ä½œç”¨ã¯æ¬¡ã®ã‚ˆã†ã«è¡¨ç¾ã§ãã‚‹ã€‚

$$
Y_{ui} = Z_{ui} Y_{ui}^T +(1 -Z_{ui})Y_{ui}^C
\tag{1}
$$

$Y_{ui} = Y_{ui}^T if $i$ is recommended ($Z_{ui}= 1$) and $Y_{ui} = Y_{ui}^C$ if it is not recommended ($Z_{ui} = 0$).
i$ã‚’æ¨å¥¨ã™ã‚‹å ´åˆ($Z_{ui}= 1$)ã¯$Y_{ui}=Y_{ui}^Tã€æ¨å¥¨ã—ãªã„å ´åˆ($Z_{ui}= 0$)ã¯$Y_{ui}=Y_{ui}^C$ã¨ã™ã‚‹ã€‚
Note that $Y_{ui}^T$ or $Y_{ui}^C$ cannot both be observed at a specific time; hence, $\tau_{ui}$ is not directly observable.
ãŸã ã—ã€$Y_{ui}^T$ã¾ãŸã¯$Y_{ui}^C$ã®ä¸¡æ–¹ã‚’ç‰¹å®šã®æ™‚é–“ã«è¦³æ¸¬ã™ã‚‹ã“ã¨ã¯ã§ããªã„ã®ã§ã€$tau_{ui}$ã¯ç›´æ¥è¦³æ¸¬ã§ããªã„ã“ã¨ã«æ³¨æ„ã€‚

The recommendation model $A$ generates a recommendation list $L_u^A$ for each user.
æ¨è–¦ãƒ¢ãƒ‡ãƒ«$A$ã¯ã€å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¨è–¦ãƒªã‚¹ãƒˆ$L_u^A$ã‚’ç”Ÿæˆã™ã‚‹ã€‚
The average causal effect of model $A$ is then defined as
ãã—ã¦ã€ãƒ¢ãƒ‡ãƒ«$A$ã®å¹³å‡çš„ãªå› æœåŠ¹æœã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã•ã‚Œã‚‹ã€‚

$$
\hat{\tau}_A = \frac{1}{n|S_A|} \sum_{u \in S_A} \sum_{i \in L_{u}^A} \tau_{ui}
\tag{2}
$$

In this work, we evaluate models using the above metric.2 That is, when comparing two models, we regard $A$ to superior to $B$ when $\tau_A > \tau_B$.
ã¤ã¾ã‚Šã€2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã™ã‚‹ã¨ãã€$A$ã¯$B$ã‚ˆã‚Š$tau_A > \tau_B$ ã®ã¨ãå„ªã‚Œã¦ã„ã‚‹ã¨ã¿ãªã™ã€‚

## 3.2. A/B testing for the Causal Effect 3.2. A

For A
For A

$$
\tag{3}
$$

This converges to $\tau_A$ as $
S_A

The typical evaluation metrics for A
ã®ä»£è¡¨çš„ãªè©•ä¾¡æŒ‡æ¨™ã¯ã€A

$$
\tag{4}
$$

Because the rightmost term in the final equation does not depend on the model, we can compare $\hat_{\tau_A}$ and $\hat_{\tau_B}$ by comparing $\hat{Y}_A^{total}$ and $\hat{Y}_B^{total}$.
æœ€çµ‚å¼ã®å³ç«¯ã®é …ã¯ãƒ¢ãƒ‡ãƒ«ã«ä¾å­˜ã—ãªã„ã®ã§ã€$hat_{tau_A}$ã¨$hat_{tau_B}$ã®æ¯”è¼ƒã¯ã€$hat{Y}_A^{total}$ã¨$hat{Y}_B^{total}$ã®æ¯”è¼ƒã§å¯èƒ½ã§ã™ã€‚
On the other hand, the average interactions with the recommended lists can be expressed as
ä¸€æ–¹ï¼Œæ¨å¥¨ãƒªã‚¹ãƒˆã¨ã®å¹³å‡çš„ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã¯ï¼Œä»¥ä¸‹ã®å¼ã§è¡¨ã™ã“ã¨ãŒã§ãã‚‹ï¼

$$
\tag{5}
$$

Hence, the evaluation based only on interactions with recommended lists is not valid testing for the causal effect.
ã—ãŸãŒã£ã¦ã€æ¨å¥¨ãƒªã‚¹ãƒˆã¨ã®ç›¸äº’ä½œç”¨ã«åŸºã¥ãè©•ä¾¡ã ã‘ã§ã¯ã€å› æœé–¢ä¿‚ã®æ¤œè¨¼ã¨ã—ã¦ã¯æœ‰åŠ¹ã§ã¯ãªã„ã€‚

Although A
ãŒã€A

## 3.3. Interleaving for the Causal Effect 3.3. å› æœé–¢ä¿‚ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–

In this subsection, we propose interleaving methods for the online evaluation of the causal effects of recommendations.
æœ¬ç¯€ã§ã¯ï¼Œæ¨è–¦ã®å› æœé–¢ä¿‚ã‚’ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§è©•ä¾¡ã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ‰‹æ³•ã‚’ææ¡ˆã™ã‚‹ï¼
Previous interleaving methods only measure outcomes in the interleaved lists: they only include $Y_{ui}^T$ and lack information on $Y_{ui}^C$.
ã“ã‚Œã¾ã§ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ³•ã¯ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã•ã‚ŒãŸãƒªã‚¹ãƒˆã®çµæœã®ã¿ã‚’æ¸¬å®šã™ã‚‹ï¼šãã‚Œã‚‰ã¯$Y_{ui}^T$ã®ã¿ã‚’å«ã¿ã€$Y_{ui}^C$ã«é–¢ã™ã‚‹æƒ…å ±ã‚’æ¬ ã„ã¦ã„ã‚‹ã€‚
Further, if the item selection for the interleaved list is not randomized controlled, the naive estimate from the observed outcomes might be biased due to the confounding between recommendations and potential outcomes.
ã•ã‚‰ã«ï¼Œã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã•ã‚ŒãŸãƒªã‚¹ãƒˆã®é …ç›®é¸æŠãŒãƒ©ãƒ³ãƒ€ãƒ åŒ–åˆ¶å¾¡ã•ã‚Œã¦ã„ãªã„å ´åˆï¼Œãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨æ½œåœ¨çš„ãªã‚¢ã‚¦ãƒˆã‚«ãƒ ã¨ã®äº¤çµ¡ã«ã‚ˆã‚Šï¼Œè¦³æ¸¬ã•ã‚ŒãŸã‚¢ã‚¦ãƒˆã‚«ãƒ ã‹ã‚‰ã®ãƒŠã‚¤ãƒ¼ãƒ–ãªæ¨å®šå€¤ã«ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ï¼
We need to remedy the bias for valid comparison.
æœ‰åŠ¹ãªæ¯”è¼ƒã®ãŸã‚ã«ã¯ã€ã“ã®åã‚Šã‚’æ˜¯æ­£ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚

Here we describe the problem setting of interleaving for the causal effect.
ã“ã“ã§ã¯ã€å› æœé–¢ä¿‚ã®ã‚ã‚‹åŠ¹æœã«å¯¾ã™ã‚‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã«é–¢ã™ã‚‹å•é¡Œè¨­å®šã‚’èª¬æ˜ã™ã‚‹ã€‚
For each user $u$, we construct the interleaved list $L_u$ from the compared lists $L_u^A$ and $L_u^B$.
å„ãƒ¦ãƒ¼ã‚¶ãƒ¼$u$ã«ã¤ã„ã¦ã€æ¯”è¼ƒã•ã‚ŒãŸãƒªã‚¹ãƒˆ$L_u^A$ã¨$L_u^B$ã‹ã‚‰ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã•ã‚ŒãŸãƒªã‚¹ãƒˆ$L_u$ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
We observe outcomes ${Y_{ui}}$ for all items $i \in I$.
I$ã®å…¨ã¦ã®é …ç›®$i \in I$ã«ã¤ã„ã¦ã€çµæœ${Y_{ui}}$ã‚’è¦³æ¸¬ã™ã‚‹ã€‚
Note that $Y_{ui} = Y_{ui}^T$ if item $i$ is in the interleaved list ($i \in L_{u}$ or equivalently, $Z_{ui} = 1$) and $Y_{ui} = Y_{ui}^C$ if it is not in the list ($i \in I \setminus L_u$ or equivalently, $Z_{ui}= 0$).
ãŸã ã—ã€é …ç›®$i$ãŒã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ãƒªã‚¹ãƒˆã«ã‚ã‚‹å ´åˆï¼ˆ$i \in L_{u}$ or equivalently, $Z_{ui} = 1$ï¼‰ã«ã¯$Y_{ui}=Y_{ui}^T$ã€ãƒªã‚¹ãƒˆã«ãªã„å ´åˆï¼ˆ$i \in Isetminus L_u$ or equivalently, $Z_{ui}= 0$)ã«ã¯$Y_{ui}^C$ã§ã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚
We want to compare the average causal effects of lists $L_u^A$ and $L_u^B$:
ãƒªã‚¹ãƒˆ$L_u^A$ã¨$L_u^B$ã®å¹³å‡çš„ãªå› æœåŠ¹æœã‚’æ¯”è¼ƒã—ãŸã„ã€‚

$$
\tag{6}
$$

We need to estimate the above values from observed outcomes because we cannot directly observe $\tau_{ui}$.
ç›´æ¥$tau_{ui}$ã‚’è¦³æ¸¬ã§ããªã„ã®ã§ã€è¦³æ¸¬ã•ã‚ŒãŸçµæœã‹ã‚‰ä¸Šè¨˜ã®å€¤ã‚’æ¨å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

If the items in $L_u^A$ and $L_u^B$ are randomly assigned to the interleaved list independent of the potential outcomes, that is, $(Y_{ui}^T, Y_{ui}^C) \perp Z_{ui}$, the case can be regarded as a randomized controlled trial (RCT) [12, 22].
L_u^A$ã¨$L_u^B$ã®é …ç›®ãŒæ½œåœ¨çš„ãªçµæœã¨ã¯ç„¡é–¢ä¿‚ã«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ãƒªã‚¹ãƒˆã«ãƒ©ãƒ³ãƒ€ãƒ ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸå ´åˆã€ã¤ã¾ã‚Š$(Y_{ui}^T, Y_{ui}^C) \perp Z_{ui}$ ãªã‚‰ã€ã“ã®äº‹ä¾‹ã¯ç„¡ä½œç‚ºå¯¾ç…§è©¦é¨“ï¼ˆRCTï¼‰ã¨è¦‹ãªã™ã“ã¨ãŒã§ãã‚‹ [12, 22]ï¼
3 We can then simply estimate $\tau_{L_u^A}$ as the difference in average outcomes for items on and not on the interleaved list:
ãã—ã¦ã€$tau_{L_u^A}$ã‚’ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ãƒ»ãƒªã‚¹ãƒˆã«ã‚ã‚‹ã‚‚ã®ã¨ãªã„ã‚‚ã®ã¨ã®å¹³å‡çµæœã®å·®ã¨ã—ã¦å˜ç´”ã«æ¨å®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚

$$
\tag{7}
$$

One way to realize such a randomized assignment is to select ğ‘› items from $L_u^A \cup L_u^B$ with equal probability: $p = n \setminus
L_u^A \cup L_u^B

The independence requirement heavily restricts the potential design space of interleaving methods. We thus derive estimates that are applicable to more general cases. Denote the probability (also called the propensity) of being included in the interleaved list $L_u$ by $p_{ui} = E[Z_{ui} = 1
X_{ui}]$. We assume that 1) the covariates $X_{ui}$ contain all confounders of $(Y_{ui}^T, Y_{ui}^C)$ and $Z_{ui}$, and 2) the treatment assignment is not deterministic ($0 < p_{ui} < 1$ for $i \in L_u^A \cup L_u^B$).4 Assumption 1 is equivalent to conditional independence: $(Y_{ui}^T,Y_{ui}^C) \perp Z_{ui}

Under these assumptions, we can construct an unbiased estimator using IPS weighting [16]:
ã“ã®ã‚ˆã†ãªä»®å®šã®ã‚‚ã¨ã€IPSé‡ã¿ä»˜ã‘ã‚’ç”¨ã„ã¦ä¸åæ¨å®šé‡ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ãŒã§ãã‚‹[16]ã€‚

$$
\tag{8}
$$

This estimator is unbiased since
ã“ã®æ¨å®šé‡ã¯ä¸åã§ã‚ã‚‹ã€‚

$$
\tag{9}
$$

We propose a general framework for interleaving as follows.
æˆ‘ã€…ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ã«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã®ä¸€èˆ¬çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã™ã‚‹ã€‚

- (1) Construct interleaved lists ${L_u}$ using an interleaving method that satisfies positivity (Assumption 2). (1) ç©æ¥µæ€§ï¼ˆä»®å®š2ï¼‰ã‚’æº€ãŸã™ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ–¹å¼ã§ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ãƒªã‚¹ãƒˆ${L_u}$ã‚’æ§‹æˆã™ã‚‹ã€‚

- (2) Conduct online experiments and obtain outcomes ${Y_{ui}}$. (2) ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å®Ÿé¨“ã‚’è¡Œã„ã€çµæœ ${Y_{ui}}$ ã‚’å¾—ã‚‹ã€‚

- (3) Estimate $\tau_{L_u^A}$ and $\tau_{L_u^B}$ by Eq. (8) and compare them. (3) $tau_{L_u^A}$ ã¨ $tau_{L_u^B}$ ã‚’å¼ï¼ˆ8ï¼‰ã§æ¨ç®—ã—ã€æ¯”è¼ƒã›ã‚ˆã€‚

As an example of a valid interleaving method that satisfies positivity, we propose causal balanced interleaving (CBI), the pseudo-code for which is shown in Algorithm $1$. CBI alternatively selects items from each list to balance the items chosen from each list. The item choice in each round is not deterministic in order to satisfy the positivity required for causal effect estimates. The propensity depends on whether an item is in the intersection, $1(i \in L_u^A \cap L_u^B)$. If an item is included in both lists, it has a greater probability of being chosen. The propensity also depends on the cardinality of the union of the compared lists, $
L_u^A \cup L_u^B

# 4. Experiments 4. å®Ÿé¨“

## 4.1. Experimental Setup 4.1. å®Ÿé¨“ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

We experimented with the following online evaluation methods.6
ä»¥ä¸‹ã®ã‚ˆã†ãªã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©•ä¾¡æ–¹æ³•ã‚’å®Ÿé¨“ã—ãŸ6ã€‚

- AB-total: A/B testing evaluated by the total user interactions, as expressed in Eq. (4). AB-åˆè¨ˆï¼šA

- AB-list: A/B testing evaluated by user interactions only with items on the recommended list, as in Eq. (5). AB-ãƒªã‚¹ãƒˆ A

- EPI-RCT: Interleaving to select items from $L_u^A \cup L_u^B$ with equal probability and evaluation using Eq. (7). EPI-RCTï¼š$L_u^A \cup L_u^B$ã‹ã‚‰ç­‰ç¢ºç‡ã§é …ç›®ã‚’é¸æŠã™ã‚‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã¨å¼(7)ã«ã‚ˆã‚‹è©•ä¾¡ã€‚

- CBI-RCT: Interleaving by Algorithm 1 and evaluation using Eq. (7), that is, no bias correction by IPS. CBI-RCT: Algorithm 1 ã§ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã—ã€å¼(7)ã§è©•ä¾¡ã€ã¤ã¾ã‚Š IPS ã«ã‚ˆã‚‹ãƒã‚¤ã‚¢ã‚¹è£œæ­£ãªã—ã€‚

- CBI-IPS: Interleaving by Algorithm 1 and evaluation using Eq. (8). CBI-IPSã€‚ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 1ã«ã‚ˆã‚‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã¨å¼(8)ã«ã‚ˆã‚‹è©•ä¾¡ã€‚

Through the experiments, we aim to answer the following research questions:
å®Ÿé¨“ã‚’é€šã—ã¦ã€æˆ‘ã€…ã¯ä»¥ä¸‹ã®ç ”ç©¶èª²é¡Œã«ç­”ãˆã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹ã€‚
RQ1) Which method produces valid (unbiased) estimates of the true differences in average causal effects (4.2.1)?, and RQ2) Are the proposed interleaving methods more efficient (do they require fewer experimental users) than AB testing (4.2.2)?
RQ1ï¼‰ã©ã®æ–¹æ³•ãŒå¹³å‡çš„ãªå› æœåŠ¹æœã®çœŸã®å·®ã®æœ‰åŠ¹ãªï¼ˆä¸åã®ï¼‰æ¨å®šå€¤ã‚’ç”Ÿã¿å‡ºã™ã‹ï¼ˆ4.2.1ï¼‰ï¼ŒRQ2ï¼‰ææ¡ˆã™ã‚‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ³•ã¯ABãƒ†ã‚¹ãƒˆã‚ˆã‚Šã‚‚åŠ¹ç‡ãŒè‰¯ã„ã‹ï¼ˆå®Ÿé¨“ãƒ¦ãƒ¼ã‚¶ã®æ•°ãŒå°‘ãªãã¦ã‚‚è‰¯ã„ã‹ï¼‰ï¼ˆ4.2.2ï¼‰ï¼ŒRQ3ï¼‰ã©ã®æ–¹æ³•ãŒå¹³å‡çš„ãªå› æœåŠ¹æœã®çœŸã®å·®ã®æœ‰åŠ¹ãªï¼ˆä¸åã®ï¼‰æ¨å®šå€¤ã‚’ç”Ÿã¿å‡ºã™ã‹ï¼ŒRQ4ï¼‰ã€‚
We first prepared semisynthetic datasets that contain both potential outcomes $Y_{ui}^T$ and $Y_{ui}^C$ for all user-item pairs.
ã¾ãšã€å…¨ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼é …ç›®ãƒšã‚¢ã«ã¤ã„ã¦ã€æ½œåœ¨çš„ãªçµæœ$Y_{ui}^T$ã¨$Y_{ui}^C$ã®ä¸¡æ–¹ã‚’å«ã‚€åŠåˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨æ„ã—ã¾ã—ãŸã€‚
Because we observe $Y_{ui} = Y_{ui}^T$ if $Z_{ui} = 1$ and $Y_{ui}= Y_{ui}^C$ if $Z_{ui}=0$, both potential outcomes are necessary to simulate user outcomes under various ranking models and online evaluation methods.
Z_{ui}=1$ãªã‚‰$Y_{ui}^T$ã€$Z_{ui}=0$ãªã‚‰$Y_{ui}=Y_{ui}^C$ã¨è¦³æ¸¬ã•ã‚Œã‚‹ã®ã§ã€æ§˜ã€…ãªãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚„ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©•ä¾¡æ³•ã§ã®ãƒ¦ãƒ¼ã‚¶æˆæœã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ãŸã‚ã«ã¯ã€ä¸¡æ–¹ã®æ½œåœ¨çš„ãªæˆæœãŒå¿…è¦ã§ã‚ã‚‹ã€‚
Following the procedure described in [28], we generated two datasets: one is based on the Dunnhumby dataset,7 and the other is based on the MovieLens-1M (ML-1M) dataset [7].8 The detail and rationale of ML one are described in Section 5.1 of [28] and that of DH one are described in 5.1.1 of [27].
1ã¤ã¯Dunnhumbyãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ7ï¼Œã‚‚ã†1ã¤ã¯MovieLens-1M (ML-1M) ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ[7]ã«åŸºã¥ãã‚‚ã®ã§ã‚ã‚‹8ï¼
Each dataset is comprised of independently generated training and testing data.
å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ç‹¬ç«‹ã«ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹ï¼
The testing data were used to simulate online evaluation, and the training data were used to train the following models:9 the causality-aware user-based neighborhood methods (CUBN) with outcome similarity (-O) and treatment similarity (-T) [28], the uplift-based pointwise and pairwise learning methods (ULRMF and ULBPR) [25], the Bayesian personalized ranking method (BPR) [20], and the user-based neighborhood method (UBN) [17].
ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©•ä¾¡ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ä½¿ç”¨ã—ï¼Œå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«ä½¿ç”¨ã—ãŸï¼š9 çµæœé¡ä¼¼åº¦ï¼ˆ-Oï¼‰ã¨æ²»ç™‚é¡ä¼¼åº¦ï¼ˆ-Tï¼‰ã«ã‚ˆã‚‹å› æœé–¢ä¿‚ã‚’è€ƒæ…®ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ™ãƒ¼ã‚¹è¿‘å‚æ³•ï¼ˆCUBNï¼‰ [28]ï¼Œéš†èµ·ã«åŸºã¥ããƒã‚¤ãƒ³ãƒˆãƒ¯ã‚¤ã‚ºåŠã³ãƒšã‚¢ãƒ¯ã‚¤ã‚ºå­¦ç¿’æ³•ï¼ˆULRMF ã¨ ULBPRï¼‰[25]ï¼Œ ãƒ™ã‚¤ã‚ºãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºãƒ‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ³•ï¼ˆBPRï¼‰ [20] åŠã³ãƒ¦ãƒ¼ã‚¶ãƒ™ãƒ¼ã‚¹è¿‘å‚æ³• (UBN) [17]ï¼
We compared two models among CUBN-T, ULRMF, BPR on the Dunnhumby data and two models among CUBN-O, ULBPR, UBN on the ML-1M data.10 The average causal effect $\bar{\tau_{L_u^{model}}}$ and the average treated outcomes $\bar{Y_{L_u^{model}}^T}$ of the trained models are listed in Table 1.
å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å¹³å‡å› æœåŠ¹æœ $bar{tau_{L_u^{model}}$ ã¨å¹³å‡å‡¦ç†çµæœ $bar{Y_{L_u^{model}}^T}$ ã‚’è¡¨1ã«ç¤ºã™ï¼
The superior models in terms of the average causal effect do not necessarily have higher average treated outcomes.
å¹³å‡å› æœåŠ¹æœã®ç‚¹ã§å„ªã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€å¿…ãšã—ã‚‚å¹³å‡æ²»ç™‚æˆç¸¾ãŒé«˜ã„ã¨ã¯é™ã‚‰ãªã„ã€‚
That is, we may mistakenly select a poor model in terms of the causal effect if we only evaluate the outcomes of the recommended items.
ã¤ã¾ã‚Šã€æ¨å¥¨é …ç›®ã®çµæœã®ã¿ã‚’è©•ä¾¡ã™ã‚‹ã¨ã€å› æœåŠ¹æœã®ç‚¹ã§åŠ£ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’èª¤ã£ã¦é¸æŠã—ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚

Table 1.
è¡¨1.
Averages of causal effect and potential outcomes under treatment with recommendation lists of size ğ‘› = 10.
ã‚µã‚¤ã‚ºğ‘› = 10ã®æ¨è–¦ãƒªã‚¹ãƒˆã‚’ç”¨ã„ãŸæ²»ç™‚ä¸‹ã§ã®å› æœåŠ¹æœã¨æ½œåœ¨çš„æˆæœã®å¹³å‡å€¤ã€‚

Our protocol for simulating online experiments is the following.
ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å®Ÿé¨“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã‚ã‚‹ã€‚
First, we randomly select a subset of users and generate lists $L_u^A, L_u^B$ using compared models.
ã¾ãšã€ãƒ¦ãƒ¼ã‚¶ã®éƒ¨åˆ†é›†åˆã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã—ã€æ¯”è¼ƒã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãƒªã‚¹ãƒˆ$L_u^A, L_u^B$ã‚’ç”Ÿæˆã™ã‚‹ã€‚
For the A
ã«å¯¾ã—ã¦ã€A

## 4.2. Results and Discussion 4.2. çµæœãŠã‚ˆã³è€ƒå¯Ÿ

### 4.2.1. Validity of the evaluation methods 4.2.1. è©•ä¾¡æ‰‹æ³•ã®å¦¥å½“æ€§

We evaluated the validity of the online evaluation methods using random subsets of 1,000 users.
1,000 äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ãªã‚‹ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ï¼Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©•ä¾¡æ‰‹æ³•ã®å¦¥å½“æ€§ã‚’è©•ä¾¡ã—ãŸï¼
The means and standard deviations of the estimated differences are shown in Table 2.
æ¨å®šã•ã‚ŒãŸå·®ã®å¹³å‡å€¤ã¨æ¨™æº–åå·®ã‚’è¡¨2ã«ç¤ºã™ã€‚
The means obtained by EPI-RCT and CBI-IPS are close to the true differences.
EPI-RCTã¨CBI-IPSã®å¹³å‡å€¤ã¯çœŸã®å·®ã«è¿‘ã„å€¤ã§ã‚ã£ãŸã€‚
The means obtained by AB-total are also close to the true value for Dunnhumby but deviate slightly for ML-1M.
AB-totalã§å¾—ã‚‰ã‚ŒãŸå¹³å‡å€¤ã‚‚Dunnhumbyã§ã¯çœŸã®å€¤ã«è¿‘ã„ãŒã€ML-1Mã§ã¯è‹¥å¹²ä¹–é›¢ã—ã¦ã„ã‚‹ã€‚
The AB-list often yields estimates that differ substantially from the true values but are similar to the differences in treated outcomes, $\bar{Y^T_{L_u^{model}}}$, as shown in Table 1.
AB-listã§ã¯ã€è¡¨1ã«ç¤ºã™ã‚ˆã†ã«ã€çœŸã®å€¤ã¨ã¯å¤§ããç•°ãªã‚‹ãŒã€æ²»ç™‚æˆç¸¾ã®å·®$Â¥bar{Y^T_{L_u^{model}}$ã«è¿‘ã„æ¨å®šå€¤ã‚’å¾—ã‚‹ã“ã¨ãŒå¤šã„ã€‚
This is expected because the AB-list evaluates $Y_{ui}^T$, not $\tau_{ui}$, as expressed in Eq. (5).
ã“ã‚Œã¯ã€å¼ï¼ˆ5ï¼‰ã§è¡¨ã•ã‚Œã‚‹ã‚ˆã†ã«ã€AB-listã¯$Y_{ui}^T$ã‚’è©•ä¾¡ã™ã‚‹ã®ã§ã‚ã£ã¦ã€$tau_{ui}$ã‚’è©•ä¾¡ã™ã‚‹ã®ã§ã¯ãªã„ãŸã‚ã€äºˆæƒ³ã•ã‚Œã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
Further, the CBI-RCT estimates also deviate from the true differences in most cases.11 This is due to the bias induced by the uneven probability of recommendation in interleaving.
ã•ã‚‰ã«ã€CBI-RCTã®æ¨å®šå€¤ã‚‚ã»ã¨ã‚“ã©ã®å ´åˆã€çœŸã®å·®ã‹ã‚‰ä¹–é›¢ã—ã¦ã„ã‚‹11ã€‚ã“ã‚Œã¯ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã«ãŠã‘ã‚‹æ¨å¥¨ç¢ºç‡ã®ä¸å‡ä¸€æ€§ã«ã‚ˆã£ã¦å¼•ãèµ·ã“ã•ã‚Œã‚‹ãƒã‚¤ã‚¢ã‚¹ã®ãŸã‚ã§ã‚ã‚‹ã€‚
Conversely, CBI-IPS successfully removes the bias and produces estimates centered around the true values.
é€†ã«ã€CBI-IPSã¯ã“ã®ãƒã‚¤ã‚¢ã‚¹ã‚’ã†ã¾ãé™¤å»ã—ã€çœŸã®å€¤ã‚’ä¸­å¿ƒã¨ã—ãŸæ¨å®šå€¤ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚

Table 2.
è¡¨2.
Estimated differences between the causal effects of the compared models (mean Â± standard deviations for 10,000 simulated runs).
æ¯”è¼ƒã—ãŸãƒ¢ãƒ‡ãƒ«ã®å› æœåŠ¹æœã®å·®ã®æ¨å®šå€¤ï¼ˆ10,000å›ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã®å¹³å‡å€¤Â±æ¨™æº–åå·®ï¼‰ã€‚
The results highlighted in bold indicate that the true values are within the 95% confidence intervals of the mean estimates
å¤ªå­—ã§è¡¨ç¤ºã•ã‚ŒãŸçµæœã¯ã€çœŸã®å€¤ãŒå¹³å‡æ¨å®šå€¤ã®95%ä¿¡é ¼åŒºé–“å†…ã«ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™

### 4.2.2. Efficiency of the interleaving methods. 4.2.2. ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ‰‹æ³•ã®åŠ¹ç‡æ€§

We compared the efficiency of AB-total, EPI-RCT, and CBI-IPS, all of which were shown to be valid in the previous section.
å‰ç¯€ã§æœ‰åŠ¹æ€§ãŒç¤ºã•ã‚ŒãŸAB-total, EPI-RCT, CBI-IPSã®åŠ¹ç‡æ€§ã‚’æ¯”è¼ƒã—ãŸï¼
We simulated user subsets of various sizes in {10, 14, 20, 30, 50, 70, 100, 140, 200, 300, 500, 700, 1000, 1400, 2000} and evaluated the ratio of false judgments (when the sign of the estimated difference is the opposite of the truth).
10, 14, 20, 30, 50, 70, 100, 140, 200, 300, 500, 700, 1000, 1400, 2000}ã®æ§˜ã€…ãªã‚µã‚¤ã‚ºã®ãƒ¦ãƒ¼ã‚¶ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’æ¨¡æ“¬ã—ï¼Œèª¤åˆ¤å®šã®å‰²åˆï¼ˆæ¨å®šå·®åˆ†ã®ç¬¦å·ãŒçœŸã¨åå¯¾ã®å ´åˆï¼‰ã‚’è©•ä¾¡ã—ãŸï¼
Figure 1 shows the ratio of false judgments according to the number of users.
å›³1ã¯ã€ãƒ¦ãƒ¼ã‚¶æ•°ã«å¿œã˜ãŸèª¤åˆ¤å®šç‡ã®æ¨ç§»ã‚’ç¤ºã—ãŸã‚‚ã®ã§ã‚ã‚‹ã€‚
As the number of users increases, the false ratios of CBI-IPS and EPI-RCT decrease more rapidly than that of AB-total does.
CBI-IPSã¨EPI-RCTã®èª¤åˆ¤å®šæ¯”ç‡ã¯ï¼Œåˆ©ç”¨è€…æ•°ã®å¢—åŠ ã¨ã¨ã‚‚ã«ï¼ŒAB-totalã®èª¤åˆ¤å®šæ¯”ç‡ã‚ˆã‚Šã‚‚æ€¥é€Ÿã«æ¸›å°‘ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ï¼
For the Dunnhumby dataset, AB-total requires around 30 times more users than CBI-IPS and EPI-RCT to achieve the same false ratio.
Dunnhumbyãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ï¼ŒAB-totalã¯CBI-IPSã¨EPI-RCTã¨åŒã˜èª¤åˆ¤å®šç‡ã‚’é”æˆã™ã‚‹ãŸã‚ã«ç´„30å€ã®ãƒ¦ãƒ¼ã‚¶æ•°ã‚’å¿…è¦ã¨ã™ã‚‹ï¼
For the ML-1M dataset, AB-total did not reach the same false ratio in the experimental range of subset sizes.
ML-1Mãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ï¼ŒAB-totalã¯å®Ÿé¨“ç¯„å›²ã®éƒ¨åˆ†é›†åˆã‚µã‚¤ã‚ºã«ãŠã„ã¦ï¼ŒåŒã˜èª¤ç­”ç‡ã«é”ã—ãªã‹ã£ãŸï¼
These results demonstrate the superior efficiency of the proposed interleaving methods.
ã“ã‚Œã‚‰ã®çµæœã¯ã€ææ¡ˆã™ã‚‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ‰‹æ³•ã®å„ªã‚ŒãŸåŠ¹ç‡æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
Furthermore, CBI-IPS tends to be slightly more efficient than EPI-RCT, as expected from the smaller standard deviations shown in Table 2.
ã•ã‚‰ã«ã€è¡¨2ã«ç¤ºã™æ¨™æº–åå·®ã®å°ã•ã•ã‹ã‚‰äºˆæƒ³ã•ã‚Œã‚‹ã‚ˆã†ã«ã€CBI-IPSã¯EPI-RCTã‚ˆã‚Šã‚‚ã‚ãšã‹ã«åŠ¹ç‡ãŒè‰¯ã„å‚¾å‘ãŒã‚ã‚‹ã€‚
This is probably because the number of items selected from the compared lists is balanced in this interleaving method.
ã“ã‚Œã¯ã€ã“ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ‰‹æ³•ã§ã¯ã€æ¯”è¼ƒã—ãŸãƒªã‚¹ãƒˆã‹ã‚‰é¸æŠã•ã‚Œã‚‹é …ç›®ã®æ•°ãŒãƒãƒ©ãƒ³ã‚¹ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚

Fig. 1.
å›³1.
Dependence on the number of users.
ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã¸ã®ä¾å­˜æ€§

# Conclusions çµè«–

In this paper, we proposed the first interleaving methods for comparing recommender models in terms of causal effects.
æœ¬è«–æ–‡ã§ã¯ï¼Œãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’å› æœé–¢ä¿‚ã®è¦³ç‚¹ã‹ã‚‰æ¯”è¼ƒã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ‰‹æ³•ã‚’åˆã‚ã¦ææ¡ˆã—ãŸï¼
To realize unbiased model comparisons, our methods either select items with equal probabilities or weight the outcomes using IPS.
æœ¬æ‰‹æ³•ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã‚’åã‚Šãªãè¡Œã†ãŸã‚ã«ã€é …ç›®ã‚’ç­‰ç¢ºç‡ã§é¸æŠã™ã‚‹ã‹ã€IPSã‚’ç”¨ã„ã¦çµæœã«é‡ã¿ä»˜ã‘ã‚’è¡Œã†ã€‚
We simulated online experiments and verified that our interleaving methods and an A
æˆ‘ã€…ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å®Ÿé¨“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã€æˆ‘ã€…ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–æ‰‹æ³•ã¨A