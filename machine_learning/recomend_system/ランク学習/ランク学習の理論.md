# 1. ランク学習における学習データ

ランク学習では「検索キーワード」・「検索キーワードに対応する検索結果リスト」が学習データとして与えられる。

数式で表すと、以下の学習データを、ランク学習で扱う。

$$
(X_{q,d}, y_{q, d}), \\
q = 1,\cdots, Q, \\
d = 1, \cdots, m_q
$$

ここで、

- $q$:ある検索キーワード$q$。
- $Q$:訓練データにおける、検索キーワードのサンプル数。各サンプルは、「検索キーワード」と「検索キーワードに対応する検索結果リスト」のペア。
- $m_q$:ある検索キーワード$q$に対応する、検索結果リストに含まれる文書の数。
- $d$:ある検索キーワード$q$に対応する、検索結果リストに含まれる各文書。
- $X_{q,d}$:検索キーワードqと文書dのペアから(+qとdのメタデータから)作られる、特徴量。
- $y_{q,d}$:ある検索キーワード$q$に対応する、検索結果リストの各文書$d$に付与されたラベル。
  - このラベルは、検索キーワード$q$と文書$d$の関連度の評価値を表している。
  - 例えば、「Perfect(4)・Excellent(3)・Good(2)・Fair(1)・Bad(0)」の5段階評価が用いられる。

なお、**レコメンドにおいては、検索キーワード$q$=ユーザ、文書$d$=アイテムに対応する**。

学習データの関係性をざっくり絵で表すと以下。

![](https://cdn-ak.f.st-hatena.com/images/fotolife/s/sz_dr/20181203/20181203233922.png)

# 2. ランク学習における特徴量

## 2.1. 文書から得られる特徴量

例えば、「文書に含まれる単語数」「特定の単語が文書に含まれるかの1-hot表現」などが挙げられる。
ECサイトでは、「商品の価格」や「商品の購入数」なども特徴量として考えられる。

## 2.2. 検索キーワードから得られる特徴量

例えば「検索キーワードの長さ」「その検索キーワードの過去1週間分のリクエスト数」などが挙げられる。

## 2.3. 文書と検索キーワードのペアから与えられる特徴量

例えば、文書と検索キーワードの**マッチングスコア**である「TF-IDF」や「BM25」などが挙げられる。

検索では、当然キーワードとマッチしている文書を取得したいので、**文書と検索キーワードのペアから与えられる特徴量**はランキングモデルにとって非常に重要。

## 2.4. その他

もちろん、上で紹介した以外の特徴量はいくらでも考えることができる。

例えば、ユーザーによって検索結果を変えたい（パーソナライズ）ならば、ユーザーのデモグラ情報(=デモグラフィックデータ=年齢、性別、居住地、家族構成、職業など、人口統計学的なデータ)を特徴量に追加すれば良い。
食べログのようなサービスならば、ユーザーの位置情報を特徴量に追加しても良いかもしれない。

# 3. ランク学習における損失関数

実際にランク学習ではどのような目的関数（損失関数）を最適化するのか。

ランク学習の損失関数は、「**1つのサンプルから損失を定義する**」「**2つのサンプルペアから損失を定義する**」「**複数のサンプルリストから損失を定義する**」という3つの方法がある。

それぞれポイントワイズ（pointwise）・ペアワイズ（pairwise）・リストワイズ（listwise）と呼ばれている。

## 3.1. ポイントワイズ(Pointwise)

上述した様に、学習データは$(X_{q,d}, y_{q, d})$の形式。
もしランキングモデル$f(X_{q, d})が出力するスコア$\hat{y}\_{q,d}$が、各文書のラベルを正確に当てる事ができれば、検索結果のランキングも正しいものになる。

そこで、ポイントワイズの損失関数は、以下で定義される。

$$
L_0 = \sum_{q, d}{L(f(X_{q, d}, y_{q,d}))}
$$

例えば、Lに二乗誤差を用いる場合は、

$$
L(f(X_{q, d}, y_{q,d})) = (y_{q,d} - f(X_{q,d}))^2
$$

の全サンプルQの和$L_0$を最小化する問題になる。

### 3.1.1. 回帰問題と同じでいいの??

お気づきのように、このアプローチは要するに、ただの回帰問題or多クラス分類問題と一致。

「だったらランク学習なんて特別なものを考えなくても、分類問題とか回帰問題として解けばいいじゃん！」と思うかもしれない。

しかしランク学習では、**「文書のランキングを正しく当てるモデル」さえあれば良くて、「文書の関連度を正しく当てるモデル」まで必要としていない**事に、注意が必要！！

例えば、以下の様な$y_{q,d}$と$\hat{y_{q,d}}$の場合を考える。

![](https://cdn-ak.f.st-hatena.com/images/fotolife/s/sz_dr/20181204/20181204002443.png)

上記の場合、単純に二乗誤差を考えると大きい損失が出てくる。

しかし、今回出力したスコアでも検索結果ランキングとしては正しい（スコアの順に文書をランキングすれば、関連度の順に並ぶ）ので、ランキングという観点から考えると損失は0であるべき...!

これに対応した損失関数が、以下の2つ。

## 3.2. ペアワイズ(Pairwise)

ポイントワイズでは1つのサンプル(qとd)から損失を定義した。
ここで、**2つの文書ペアを正しく順序付けできれば**、検索結果は正しいランキングになることを考えると、**2つのサンプルペアから損失を定義する**という発想が生まれる。

ペアワイズの損失関数の定義は以下で与えられる。

$$
L_0 = \sum_{q}{
    \sum_{i, j :y_{q,i}>y_{q,j}}^{m_q}
{L(f(X_{q, i}), f(X_{q, j}))}
}
$$

上式中のLとして、例えばスコアの差を指数関数に通した誤差を用いれば、

$$
L(f(X_{q, i}), f(X_{q, j})) = exp(f(X_{q, j}) - f(X_{q, i}))
$$

損失関数中で、$y_{q,d}$は、2つのサンプルペアiとjを選ぶ際にのみ利用される？？

### 3.2.1. 例

2つの文書iとjがあって、iはjよりも良い（関連度が高い）とする。
ここで、ランキングモデルはそれぞれの文書にスコアを1, 3とつけてしまったとする。
スコアの大小が実際の関連度$y_{q,d}$と入れ替わっているので、この文書ペアについては順序付けを間違っている。
![](https://cdn-ak.f.st-hatena.com/images/fotolife/s/sz_dr/20181204/20181204004323.png)

この状況で、上で紹介した指数関数を用いた損失関数を計算すると、7.4という損失が計算される。
損失さえ計算できれば、あとはそれを最小化していけば、良いランキングモデルが得られるはず。

## 3.3. リストワイズ(Listwise)

分類問題におけるROC-AUCやf値、回帰問題における二乗誤差のように、ランキング問題においてもいくつかの**評価指標**が存在する。

ランキング問題の評価指標は、ランキングという問題の性質上、「**検索結果のリスト全体として良い並び順になっているかどうか**」を指標として計算する。

「ランキング問題の評価指標が与えられているなら、**直接それを最適化すればいいじゃん！**」というのがリストワイズの発想。

評価指標は複数のサンプルから計算されることを考えると、リストワイズの損失関数は、

$$
L_0 = \sum_{q}{
    L(
        f(X_{q,1}, y_{q,1}),
        f(X_{q,2}, y_{q,2}),
        \cdots,
        f(X_{q,m_q}, y_{q,m_q})
    )
}
$$

例えば、ランキング問題の評価指標として、NDCGがよく用いられるが、NDCGを直接最適化する事が考えられる。
