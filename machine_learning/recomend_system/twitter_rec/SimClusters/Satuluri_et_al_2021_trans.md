## link ãƒªãƒ³ã‚¯

- https://dl.acm.org/doi/10.1145/3394486.3403370 https://dl.acm.org/doi/10.1145/3394486.3403370

## title ã‚¿ã‚¤ãƒˆãƒ«

SimClusters: Community-Based Representations for Heterogeneous Recommendations at Twitter
SimClustersï¼ˆã‚·ãƒ ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ï¼‰ï¼š Twitterã«ãŠã‘ã‚‹ç•°è³ªãªãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ãŸã‚ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ™ãƒ¼ã‚¹è¡¨ç¾

## abstract ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ

Personalized recommendation products at Twitter target a multitude of heterogeneous items: Tweets, Events, Topics, Hashtags, and users.
Twitterã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºãƒ‰ãƒ»ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è£½å“ã¯ã€å¤šæ•°ã®ç•°è³ªãªã‚¢ã‚¤ãƒ†ãƒ ã‚’å¯¾è±¡ã¨ã—ã¦ã„ã‚‹ï¼š ãƒ„ã‚¤ãƒ¼ãƒˆã€ã‚¤ãƒ™ãƒ³ãƒˆã€ãƒˆãƒ”ãƒƒã‚¯ã€ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã€ãã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€‚
Each of these targets varies in their cardinality (which affects the scale of the problem) and their "shelf life'' (which constrains the latency of generating the recommendations).
ã“ã‚Œã‚‰ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¯ãã‚Œãã‚Œã€å•é¡Œã®è¦æ¨¡ã«å½±éŸ¿ã™ã‚‹ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã¨ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆã®å¾…ã¡æ™‚é–“ã«åˆ¶ç´„ã‚’ä¸ãˆã‚‹ã€Œè³å‘³æœŸé™ã€ãŒç•°ãªã‚Šã¾ã™ã€‚
Although Twitter has built a variety of recommendation systems before dating back a decade, solutions to the broader problem were mostly tackled piecemeal.
Twitterã¯10å¹´å‰ã‹ã‚‰æ§˜ã€…ãªãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¦ãã¾ã—ãŸãŒã€åºƒã„æ„å‘³ã§ã®å•é¡Œè§£æ±ºã¯æ–­ç‰‡çš„ãªå–ã‚Šçµ„ã¿ãŒã»ã¨ã‚“ã©ã§ã—ãŸã€‚
In this paper, we present SimClusters, a general-purpose representation layer based on overlapping communities into which users as well as heterogeneous content can be captured as sparse, interpretable vectors to support a multitude of recommendation tasks.
æœ¬è«–æ–‡ã§ã¯ã€é‡è¤‡ã™ã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«åŸºã¥ãæ±ç”¨çš„ãªè¡¨ç¾å±¤ã§ã‚ã‚‹SimClustersã‚’ç´¹ä»‹ã—ã€ãƒ¦ãƒ¼ã‚¶ã‚„ç•°è³ªãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç–ãªè§£é‡ˆå¯èƒ½ãªãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦æ‰ãˆã€æ§˜ã€…ãªæ¨è–¦ã‚¿ã‚¹ã‚¯ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
We propose a novel algorithm for community discovery based on Metropolis-Hastings sampling, which is both more accurate and significantly faster than off-the-shelf alternatives.
æˆ‘ã€…ã¯ã€ãƒ¡ãƒˆãƒ­ãƒãƒªã‚¹ãƒ»ãƒ˜ã‚¤ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã‚¹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«åŸºã¥ãã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ç™ºè¦‹ã®ãŸã‚ã®æ–°ã—ã„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã€æ—¢è£½ã®ä»£æ›¿å“ã‚ˆã‚Šã‚‚é«˜ç²¾åº¦ã‹ã¤å¤§å¹…ã«é«˜é€Ÿã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚
SimClusters scales to networks with billions of users and has been effective across a variety of deployed applications at Twitter.
SimClustersã¯æ•°åå„„äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æŠ±ãˆã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ã‚¹ã‚±ãƒ¼ãƒ«ã—ã€Twitterã®æ§˜ã€…ãªãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§åŠ¹æœã‚’ç™ºæ®ã—ã¦ã„ã¾ã™ã€‚

# Introduction åºç« 

Personalized recommendations lie at the heart of many different technology-enabled products, and Twitter is no exception.
ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€ã•ã¾ã–ã¾ãªãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚’é§†ä½¿ã—ãŸè£½å“ã®ä¸­æ ¸ã‚’ãªã™ã‚‚ã®ã§ã‚ã‚Šã€Twitterã‚‚ä¾‹å¤–ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
Our highlevel goal is to make content discovery effortless and to free the user from the need for manual curation.
ç§ãŸã¡ã®é«˜ã„ç›®æ¨™ã¯ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç™ºè¦‹ã‚’å®¹æ˜“ã«ã—ã€æ‰‹å‹•ã§ã®ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å¿…è¦æ€§ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è§£æ”¾ã™ã‚‹ã“ã¨ã§ã™ã€‚
On the Twitter platform, a wide variety of content types are displayed in a multitude of contexts, requiring a variety of personalization approaches.
Twitterã§ã¯ã€æ§˜ã€…ãªç¨®é¡ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒæ§˜ã€…ãªæ–‡è„ˆã§è¡¨ç¤ºã•ã‚Œã‚‹ãŸã‚ã€æ§˜ã€…ãªãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã§ã™ã€‚
For example, recommendations of interesting Tweets are an essential component of not only the Home tab, but also for dissemination via email or push notifications.
ä¾‹ãˆã°ã€é¢ç™½ã„ãƒ„ã‚¤ãƒ¼ãƒˆã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã¯ã€ãƒ›ãƒ¼ãƒ ã‚¿ãƒ–ã ã‘ã§ãªãã€ãƒ¡ãƒ¼ãƒ«ã‚„ãƒ—ãƒƒã‚·ãƒ¥é€šçŸ¥ã§ã®é…ä¿¡ã«ã‚‚æ¬ ã‹ã›ãªã„è¦ç´ ã§ã™ã€‚
The â€œWho To Followâ€ module with user follow recommendations is crucial, especially for new users, and was one of the first recommendations products to be launched on Twitter [11].
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚©ãƒ­ãƒ¼ã‚’æ¨å¥¨ã™ã‚‹ã€ŒWho To Followã€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€ç‰¹ã«æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦é‡è¦ã§ã‚ã‚Šã€Twitterã§æœ€åˆã«ç™ºè¡¨ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è£½å“ã®1ã¤ã§ã‚ã‚‹[11]ã€‚
Trends and Events (previously called Moments) are essential for informing the user about currently ongoing news stories and topics of conversation on the platform, and the Explore tab shows the user a personalized list of these.
ãƒˆãƒ¬ãƒ³ãƒ‰ã¨ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆä»¥å‰ã®åç§°ã¯ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆï¼‰ã¯ã€ç¾åœ¨é€²è¡Œä¸­ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚„ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ä¸Šã§è©±é¡Œã«ãªã£ã¦ã„ã‚‹ã“ã¨ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«çŸ¥ã‚‰ã›ã‚‹ãŸã‚ã«ä¸å¯æ¬ ãªã‚‚ã®ã§ã€ã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ©ã‚¿ãƒ–ã§ã¯ã€ã“ã‚Œã‚‰ã®ãƒªã‚¹ãƒˆã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã—ã¦è¡¨ç¤ºã—ã¾ã™ã€‚
The recently launched Topics feature1 lets users follow Topics (such as â€œMachine Learningâ€ or â€œK-Popâ€) and see the algorithmically curated best tweets about those Topics in their Home feed.
æœ€è¿‘é–‹å§‹ã•ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯ã‚¹æ©Ÿèƒ½1ã§ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ãƒˆãƒ”ãƒƒã‚¯ã‚¹ï¼ˆã€Œæ©Ÿæ¢°å­¦ç¿’ã€ã‚„ã€ŒK-POPã€ãªã©ï¼‰ã‚’ãƒ•ã‚©ãƒ­ãƒ¼ã—ã€ãã®ãƒˆãƒ”ãƒƒã‚¯ã‚¹ã«é–¢ã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚­ãƒ¥ãƒ¬ãƒ¼ãƒˆã•ã‚ŒãŸãƒ™ã‚¹ãƒˆãƒ„ã‚¤ãƒ¼ãƒˆã‚’ãƒ›ãƒ¼ãƒ ãƒ•ã‚£ãƒ¼ãƒ‰ã§è¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

A summary of the diversity of personalized recommendation problems at Twitter is presented in Table 1.
Twitterã«ãŠã‘ã‚‹ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºãƒ‰ãƒ»ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å•é¡Œã®å¤šæ§˜æ€§ã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã‚’è¡¨1ã«ç¤ºã™ã€‚
In all cases, we are making recommendations to users, but what weâ€™re recommending can be heterogeneous.
ã©ã®ã‚ˆã†ãªå ´åˆã§ã‚‚ã€ç§ãŸã¡ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾ã—ã¦æ¨è–¦ã‚’è¡Œã£ã¦ã„ã¾ã™ãŒã€æ¨è–¦ã™ã‚‹ã‚‚ã®ã¯ç•°è³ªãªã‚‚ã®ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
For example, we could be suggesting users, Tweets, Events, Topics, or hashtags.
ä¾‹ãˆã°ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ãƒ„ã‚¤ãƒ¼ãƒˆã€ã‚¤ãƒ™ãƒ³ãƒˆã€ãƒˆãƒ”ãƒƒã‚¯ã€ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’ææ¡ˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
There are two main dimensions of interest across the different recommendations problems: the cardinality of the items being recommended and the shelf life of the computed recommendations.
ç•°ãªã‚‹ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å•é¡Œã§æ³¨ç›®ã•ã‚Œã‚‹2ã¤ã®ä¸»è¦ãªæ¬¡å…ƒãŒã‚ã‚Šã¾ã™ï¼šæ¨å¥¨ã•ã‚Œã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã¨è¨ˆç®—ã•ã‚ŒãŸæ¨å¥¨ã®è³å‘³æœŸé™ã§ã™ã€‚
The shelf life of our computed recommendations is closely related to the churn we observe in the recommended content.
è¨ˆç®—ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®è³å‘³æœŸé™ã¯ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã§è¦³å¯Ÿã•ã‚Œã‚‹è§£ç´„ã¨å¯†æ¥ã«é–¢ä¿‚ã—ã¦ã„ã¾ã™ã€‚
For example, since the follower graph changes relatively slowly, user follow recommendations can remain relevant for weeks (and thus can be computed in batch).
ä¾‹ãˆã°ã€ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã‚°ãƒ©ãƒ•ã¯æ¯”è¼ƒçš„ã‚†ã£ãã‚Šã¨å¤‰åŒ–ã™ã‚‹ãŸã‚ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚©ãƒ­ãƒ¼ã®æ¨å¥¨ã¯æ•°é€±é–“ã«ã‚ãŸã‚Šé–¢é€£æ€§ã‚’ä¿ã¤ã“ã¨ãŒã§ãã¾ã™ï¼ˆã—ãŸãŒã£ã¦ã€ãƒãƒƒãƒå‡¦ç†ã§è¨ˆç®—ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼‰ã€‚
At the other end of the spectrum, Tweet recommendations become stale much quicker and must be generated in an online system in close to real time; for this case, batch computations would not yield results fast enough to meet the product requirements.
ä¸€æ–¹ã€ãƒ„ã‚¤ãƒ¼ãƒˆãŒé™³è…åŒ–ã™ã‚‹ã®ãŒæ—©ãã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«è¿‘ã„å½¢ã§ç”Ÿæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€ã“ã®å ´åˆã€ãƒãƒƒãƒè¨ˆç®—ã§ã¯è£½å“è¦ä»¶ã‚’æº€ãŸã™ã®ã«ååˆ†ãªé€Ÿåº¦ã§çµæœã‚’å¾—ã‚‹ã“ã¨ãŒã§ããªã„ã®ã§ã™ã€‚
Naturally, in the case of recommendation problems where the item cardinality is large, being able to handle the scale of the problem is important.
å½“ç„¶ã€é …ç›®ã®ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ãŒå¤§ãã„æ¨è–¦å•é¡Œã®å ´åˆã€å•é¡Œã®è¦æ¨¡ã«å¯¾å¿œã§ãã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚

Previously, Twitter built systems to tackle each of these different recommendation problems individually with little re-use or commonality.
ã“ã‚Œã¾ã§Twitterã¯ã€ã“ã‚Œã‚‰ã®ç•°ãªã‚‹ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å•é¡Œã«å€‹åˆ¥ã«å¯¾å¿œã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¦ãŠã‚Šã€å†åˆ©ç”¨ã‚„å…±é€šåŒ–ã¯ã»ã¨ã‚“ã©è¡Œã‚ã‚Œã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚
The original example here is the â€œWho To Followâ€ system that launched a decade ago [11] for user recommendations.
ã“ã“ã§ã®å…ƒä¾‹ã¯ã€10å¹´å‰ã«ç™ºå£²ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼æ¨è–¦ã®ãŸã‚ã®ã€ŒWho To Followã€ã‚·ã‚¹ãƒ†ãƒ [11]ã§ã™ã€‚
Subsequently, Gupta et al.[12] described a specialized system to generate Tweet recommendations in real time, insights from which were later deployed in GraphJet [31].
ãã®å¾Œã€Guptaã‚‰[12]ã¯ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒ„ã‚¤ãƒ¼ãƒˆãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ç‰¹æ®Šãªã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦èª¬æ˜ã—ã€ãã“ã‹ã‚‰å¾—ãŸçŸ¥è¦‹ã¯å¾Œã«GraphJet[31]ã«å±•é–‹ã•ã‚ŒãŸã€‚
GraphJet ingested the realtime stream of user-Tweet engagements to maintain a user-Tweet bipartite graph from which to generate recommendations, but the system was expensive to extend to new use cases.
GraphJetã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ãƒ„ã‚¤ãƒ¼ãƒˆã®é–¢ä¿‚ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«å–ã‚Šè¾¼ã¿ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ãƒ„ã‚¤ãƒ¼ãƒˆã®äºŒéƒ¨ã‚°ãƒ©ãƒ•ã‚’ç¶­æŒã—ã€ãã“ã‹ã‚‰ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã—ã¾ã™ãŒã€ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯æ–°ã—ã„ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«æ‹¡å¼µã™ã‚‹ã«ã¯é«˜ä¾¡ã§ã—ãŸã€‚
These aforementioned infrastructures were built mainly to generate candidates which got blended and scored subsequently.
ã“ã‚Œã‚‰ã®ã‚¤ãƒ³ãƒ•ãƒ©ã¯ã€ä¸»ã«å€™è£œè€…ã‚’ç”Ÿã¿å‡ºã—ã€ãã‚Œã‚’ãƒ–ãƒ¬ãƒ³ãƒ‰ã—ã¦æ¡ç‚¹ã™ã‚‹ãŸã‚ã«æ§‹ç¯‰ã•ã‚ŒãŸã‚‚ã®ã§ã™ã€‚
Twitter also built custom infrastructure for feature retrieval and scoring of arbitrarily generated candidates - examples include RealGraph [14] and RecService [9].
ã¾ãŸã€Twitterã¯ã€ä»»æ„ã«ç”Ÿæˆã•ã‚ŒãŸå€™è£œã®ç‰¹å¾´æ¤œç´¢ã‚„ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã®ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ ã‚¤ãƒ³ãƒ•ãƒ©ã‚’æ§‹ç¯‰ã—ã¦ã„ã¾ã™ã€‚
All of these systems were built with the aim of solving specific sub-problems in the recommendations landscape at Twitter and require separate development and maintenance.
ã“ã‚Œã‚‰ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã™ã¹ã¦ã€Twitterã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ³ã«ãŠã‘ã‚‹ç‰¹å®šã®ã‚µãƒ–å•é¡Œã‚’è§£æ±ºã™ã‚‹ç›®çš„ã§æ§‹ç¯‰ã•ã‚Œã€å€‹åˆ¥ã®é–‹ç™ºãƒ»ä¿å®ˆãŒå¿…è¦ã§ã™ã€‚
The central motivating question of this paper is: can we build a general system that helps us advance the accuracy of all or most of the Twitter products which require personalization and recommendations?
æœ¬è«–æ–‡ã®ä¸­å¿ƒçš„ãªå‹•æ©Ÿä»˜ã‘ã¨ãªã‚‹å•ã„ã¯ã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã‚„ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãŒå¿…è¦ãªTwitterè£½å“ã®ã™ã¹ã¦ã€ã‚ã‚‹ã„ã¯ã»ã¨ã‚“ã©ã®ç²¾åº¦ã‚’é«˜ã‚ã‚‹ã®ã«å½¹ç«‹ã¤ä¸€èˆ¬çš„ãªã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã§ãã‚‹ã‹ã¨ã„ã†ã“ã¨ã§ã™ã€‚

The solution proposed in this paper is built on the insight that we can construct, from the userâ€“user graph, a general-purpose representation based on community structure, where each community is characterized by a set of influencers that many people in that community follow.
æœ¬è«–æ–‡ã§ææ¡ˆã™ã‚‹ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼-ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚°ãƒ©ãƒ•ã‹ã‚‰ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹é€ ã«åŸºã¥ãæ±ç”¨çš„ãªè¡¨ç¾ã‚’æ§‹ç¯‰ã§ãã‚‹ã¨ã„ã†æ´å¯Ÿã«åŸºã¥ã„ã¦ãŠã‚Šã€å„ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¯ã€ãã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å†…ã®å¤šãã®äººã€…ãŒãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ã„ã‚‹ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®ã‚»ãƒƒãƒˆã«ã‚ˆã£ã¦ç‰¹å¾´ã¥ã‘ã‚‰ã‚Œã‚‹ã€‚
Each of the different kinds of content (i.e., the targets in Table 1) is represented as a vector in the space of these communities, with the entry corresponding to the ğ‘–-th community for item ğ‘— indicating how interested the ğ‘–-th community is in item ğ‘—.
ç•°ãªã‚‹ç¨®é¡ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆã™ãªã‚ã¡è¡¨1ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰ã®ãã‚Œãã‚Œã¯ã€ã“ã‚Œã‚‰ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ç©ºé–“ã«ãŠã‘ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦è¡¨ã•ã‚Œã€ã‚¢ã‚¤ãƒ†ãƒ áµ…ã«å¯¾ã™ã‚‹ğ‘–ç•ªç›®ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å¯¾å¿œã™ã‚‹ã‚¨ãƒ³ãƒˆãƒªã¯ã€ğ‘–ç•ªç›®ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒã‚¢ã‚¤ãƒ†ãƒ ğ‘—ã«ã©ã‚Œã ã‘èˆˆå‘³ã‚’æŒã£ã¦ã„ã‚‹ã‹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
The end result is that we can represent heterogeneous recommendation targets as sparse, interpretable vectors in the same space, which enables solutions for a wide variety of recommendation and personalization tasks (see details in Section 6).
æœ€çµ‚çš„ã«ã¯ã€ç•°è³ªãªæ¨è–¦å¯¾è±¡ã‚’ã€åŒã˜ç©ºé–“ã®ã‚¹ãƒ‘ãƒ¼ã‚¹ã§è§£é‡ˆå¯èƒ½ãªãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦è¡¨ç¾ã™ã‚‹ã“ã¨ãŒã§ãã€æ§˜ã€…ãªæ¨è–¦ã‚„ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ï¼ˆè©³ç´°ã¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³6ã‚’å‚ç…§ï¼‰ã€‚
There are two notable aspects of our design:
ç§ãŸã¡ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã«ã¯ã€2ã¤ã®ç‰¹ç­†ã™ã¹ãç‚¹ãŒã‚ã‚Šã¾ã™ï¼š

- 1. We avoid conventional matrix factorization methods that typically require solving massive numerical optimization problems, and instead rely on a combination of similarity search and community discovery, both of which are easier to scale. A key algorithmic innovation of our work is a new approach to community discovery â€” called Neighborhood-aware MH â€” which is 10Ã—-100Ã— faster, 3Ã—-4Ã— more accurate than off-theshelf baselines, and scales easily to graphs with âˆ¼109 nodes and âˆ¼1011 edges. It helps us discover âˆ¼105 communities on Twitter that are either organized around a common topic (e.g., â€œK-Popâ€ or â€œMachine Learningâ€) or based on social relationships (e.g., those who work together or went to high-school together). We have open-sourced the implementation of the new algorithm in https://github.com/twitter/sbf. 1. ç§ãŸã¡ã¯ã€å¤§è¦æ¨¡ãªæ•°å€¤æœ€é©åŒ–å•é¡Œã‚’è§£ãå¿…è¦ãŒã‚ã‚‹å¾“æ¥ã®è¡Œåˆ—åˆ†è§£æ³•ã‚’é¿ã‘ã€ä»£ã‚ã‚Šã«ã€ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ãŒå®¹æ˜“ãªé¡ä¼¼æ€§æ¤œç´¢ã¨ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ç™ºè¦‹ã®çµ„ã¿åˆã‚ã›ã«é ¼ã£ã¦ã„ã¾ã™ã€‚ ã“ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€æ—¢å­˜ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨æ¯”è¼ƒã—ã¦ã€10å€ã‹ã‚‰100å€é«˜é€Ÿã§ã€3å€ã‹ã‚‰4å€é«˜ç²¾åº¦ã§ã‚ã‚Šã€109å€‹ã®ãƒãƒ¼ãƒ‰ã¨1011å€‹ã®ã‚¨ãƒƒã‚¸ã‚’æŒã¤ã‚°ãƒ©ãƒ•ã«å®¹æ˜“ã«æ‹¡å¼µã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ K-POPã€ã‚„ã€Œæ©Ÿæ¢°å­¦ç¿’ã€ã¨ã„ã£ãŸå…±é€šã®è©±é¡Œã‚„ã€ã€Œè·å ´ãŒä¸€ç·’ã€ã€Œé«˜æ ¡ãŒä¸€ç·’ã€ã¨ã„ã£ãŸç¤¾ä¼šçš„é–¢ä¿‚ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹Twitterä¸Šã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ï¼ˆç´„105ä»¶ï¼‰ã‚’ç™ºè¦‹ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ æ–°ã—ã„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè£…ã¯ã€https://github.com/twitter/sbfã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã¦ã„ã¾ã™ã€‚

- 2.  Our overall architecture has a modular and extensible design to enable the use of whichever computing paradigm is most suited to a specific component â€“ batch-distributed, batch-multicore, or streaming-distributed. In particular, the ability to dynamically update representations using streaming-distributed components has proved crucial for accurately modeling Tweets which are Twitterâ€™s most important type of content. 2. ç§ãŸã¡ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€ç‰¹å®šã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«æœ€ã‚‚é©ã—ãŸã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ï¼ˆãƒãƒƒãƒåˆ†æ•£ã€ãƒãƒƒãƒãƒãƒ«ãƒã‚³ã‚¢ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆ†æ•£ï¼‰ã‚’ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã€å…¨ä½“çš„ã«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å¼ã§æ‹¡å¼µå¯èƒ½ãªè¨­è¨ˆã¨ãªã£ã¦ã„ã¾ã™ã€‚ ç‰¹ã«ã€Twitterã§æœ€ã‚‚é‡è¦ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã§ã‚ã‚‹ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æ­£ç¢ºã«ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ãŸã‚ã«ã¯ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆ†æ•£ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ç”¨ã„ã¦è¡¨ç¾ã‚’å‹•çš„ã«æ›´æ–°ã™ã‚‹èƒ½åŠ›ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ãŒè¨¼æ˜ã•ã‚Œã¾ã—ãŸã€‚

We refer to our overall system as SimClusters (Similarity-based Clusters) and have deployed it in production for more than a year.
ç§ãŸã¡ã¯ã€ã“ã®ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã‚’SimClustersï¼ˆSimilarity-based Clustersï¼‰ã¨å‘¼ã³ã€1å¹´ä»¥ä¸Šã«ã‚ãŸã£ã¦å®Ÿé‹ç”¨ã«å±•é–‹ã—ã¦ã„ã¾ã™ã€‚

SimClusters also has the following features, which correspond to our design requirements:
ã¾ãŸã€SimClustersã¯ã€ç§ãŸã¡ã®è¨­è¨ˆè¦ä»¶ã«å¯¾å¿œã—ãŸä»¥ä¸‹ã®ã‚ˆã†ãªç‰¹å¾´ã‚’æŒã£ã¦ã„ã¾ã™ï¼š

- 1. Universal representations: SimClusters provides representations for both users and a variety of content in the same space. This removes the need to invest in expensive custom infrastructure for each type of content. 1. ãƒ¦ãƒ‹ãƒãƒ¼ã‚µãƒ«ãªè¡¨ç¾ï¼š SimClustersã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨æ§˜ã€…ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä¸¡æ–¹ã‚’åŒã˜ç©ºé–“ã§è¡¨ç¾ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ ã“ã‚Œã«ã‚ˆã‚Šã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç¨®é¡ã”ã¨ã«é«˜ä¾¡ãªã‚«ã‚¹ã‚¿ãƒ ã‚¤ãƒ³ãƒ•ãƒ©ã«æŠ•è³‡ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã¾ã—ãŸã€‚

- 2. Computational scale: We are able to apply SimClusters at Twitter scale, with âˆ¼109 users, âˆ¼1011 edges between them, and 108 new Tweets every day with âˆ¼109 user engagements per day. 2. è¨ˆç®—è¦æ¨¡ï¼š SimClustersã¯ã€109äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€1011äººã®ã‚¨ãƒƒã‚¸ã€æ¯æ—¥108ä»¶ã®æ–°ã—ã„ãƒ„ã‚¤ãƒ¼ãƒˆã€1æ—¥ã‚ãŸã‚Š109äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚’æŒã¤Twitterã‚¹ã‚±ãƒ¼ãƒ«ã§é©ç”¨ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚

- 3. Accuracy beyond the head: SimClusters representations are accurate beyond just the most popular content (â€œheadâ€), primarily due to the ability to scale SimClusters to a very large representational space with âˆ¼105 dimensions. 3. é ­éƒ¨ã‚’è¶…ãˆãŸæ­£ç¢ºã• SimClustersã®è¡¨ç¾ã¯ã€æœ€ã‚‚äººæ°—ã®ã‚ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆã€Œé ­ã€ï¼‰ã‚’è¶…ãˆã¦æ­£ç¢ºã§ã™ã€‚ã“ã‚Œã¯ä¸»ã«ã€SimClustersã‚’ç´„105æ¬¡å…ƒã¨ã„ã†éå¸¸ã«å¤§ããªè¡¨ç¾ç©ºé–“ã«æ‹¡å¼µã§ãã‚‹ã“ã¨ã«ã‚ˆã‚Šã¾ã™ã€‚

- 4. Item and graph churn: The modular design of SimClusters makes it easy to extend to dynamic items which rapidly rise and diminish in popularity. Many of our important recommendations and engagement prediction problem involve items that churn rapidly â€“ most Tweets, Events, and Trends stay relevant for no more than a day or two, meaning that it is crucial to be able to efficiently learn representations of new items before they lose their relevance. 4. ã‚¢ã‚¤ãƒ†ãƒ ã‚„ã‚°ãƒ©ãƒ•ã®å…¥ã‚Œæ›¿ã‚ã‚Šï¼š SimClustersã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­è¨ˆã«ã‚ˆã‚Šã€äººæ°—ãŒæ€¥ä¸Šæ˜‡ãƒ»æ€¥é™ä¸‹ã™ã‚‹å‹•çš„ã‚¢ã‚¤ãƒ†ãƒ ã¸ã®æ‹¡å¼µãŒå®¹æ˜“ã§ã™ã€‚ ç§ãŸã¡ã®é‡è¦ãªãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆäºˆæ¸¬ã®å•é¡Œã®å¤šãã¯ã€æ€¥é€Ÿã«å¤‰åŒ–ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚ã»ã¨ã‚“ã©ã®ãƒ„ã‚¤ãƒ¼ãƒˆã€ã‚¤ãƒ™ãƒ³ãƒˆã€ãƒˆãƒ¬ãƒ³ãƒ‰ã¯ã€1æ—¥ã‹2æ—¥ç¨‹åº¦ã—ã‹é–¢é€£æ€§ãŒã‚ã‚Šã¾ã›ã‚“ã€‚

- 5. Interpretability: SimClusters representations are sparse and each dimension corresponds to a specific community, making them interpretable to a degree that is hard to obtain with alternatives such as matrix factorization or graph embeddings. 5. è§£é‡ˆã®ã—ã‚„ã™ã• SimClustersã®è¡¨ç¾ã¯ç–ã§ã‚ã‚Šã€å„æ¬¡å…ƒã¯ç‰¹å®šã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å¯¾å¿œã—ã¦ã„ã‚‹ãŸã‚ã€è¡Œåˆ—åˆ†è§£ã‚„ã‚°ãƒ©ãƒ•åŸ‹ã‚è¾¼ã¿ãªã©ã®ä»£æ›¿æ‰‹æ®µã§ã¯å¾—é›£ã„è§£é‡ˆå¯èƒ½æ€§ã‚’æŒã£ã¦ã„ã¾ã™ã€‚

- 6. Efficient nearest neighbor search: Identifying nearest neighbors is core to many downstream tasks such as generating recommendations, similar item retrieval, and user targeting. The sparsity of SimClusters representations makes it easy to setup and maintain inverted indices for retrieving nearest neighbors, even for rapidly churning domains (see details in Section 4). 6. åŠ¹ç‡çš„ãªè¿‘å‚æ¢ç´¢ è¿‘å‚æ¢ç´¢ã¯ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆã€é¡ä¼¼ã‚¢ã‚¤ãƒ†ãƒ ã®æ¤œç´¢ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ãƒ¼ã‚²ãƒ†ã‚£ãƒ³ã‚°ãªã©ã€å¤šãã®ä¸‹æµã‚¿ã‚¹ã‚¯ã®ä¸­æ ¸ã¨ãªã‚‹ã€‚ SimClustersè¡¨ç¾ã®ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã¯ã€æ€¥é€Ÿã«å¤‰åŒ–ã™ã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã‚ã£ã¦ã‚‚ã€æœ€è¿‘å‚ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã®è»¢ç½®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®è¨­å®šã¨ç¶­æŒã‚’å®¹æ˜“ã«ã—ã¾ã™ï¼ˆè©³ç´°ã¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³4ã§ã”è¦§ãã ã•ã„ï¼‰ã€‚

SimClusters has been applied to many recommendations and personalization problems at Twitter â€” even for mature products such as out-of-network Tweet recommendations and Personalized Trends, SimClusters has enabled double digit improvements in the engagement rates of recommendations.
SimClustersã¯ã€Twitterã®å¤šãã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã®å•é¡Œã«é©ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¤–ã®ãƒ„ã‚¤ãƒ¼ãƒˆæ¨å¥¨ã‚„ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºãƒ‰ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ãªã©ã®æˆç†Ÿã—ãŸè£½å“ã«ãŠã„ã¦ã‚‚ã€SimClustersã¯æ¨å¥¨ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã‚’2æ¡æ”¹å–„ã™ã‚‹ã“ã¨ã‚’å¯èƒ½ã«ã—ã¾ã—ãŸã€‚
It has also accelerated the building of entirely new products, such as Similar Tweets and Topic Tweet recommendations.
ã¾ãŸã€Similar Tweetã‚„Topic Tweetã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãªã©ã€å…¨ãæ–°ã—ã„ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã®æ§‹ç¯‰ã‚‚åŠ é€Ÿã—ã¦ã„ã¾ã™ã€‚
SimClusters continues to be actively developed internally and applied to new use cases.
SimClustersã¯ã€ç¤¾å†…ã§æ´»ç™ºã«é–‹ç™ºã•ã‚Œã€æ–°ã—ã„ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«é©ç”¨ã•ã‚Œç¶šã‘ã¦ã„ã¾ã™ã€‚

# Overview of SimClusters SimClustersã®æ¦‚è¦

The SimClusters system (see Figure 1) consists of two stages:
SimClustersã‚·ã‚¹ãƒ†ãƒ ï¼ˆå›³1å‚ç…§ï¼‰ã¯ã€2ã¤ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ï¼š

- 1. In the first stage (detailed in Section 3), we discover bipartite communities from our user-user graph at scale, resulting in learning sparse, non-negative representations for our users. At the end of this stage, each user is associated with a list of communities they participate in, along with the scores quantifying the strength of their affiliation to each of those communities. We refer to this output as â€œUser Interest Representationsâ€ and it is made available in both offline data warehouses as well as low-latency online stores, indexed by the user id. This first stage is run in a batch-distributed setting, typically as a series of MapReduce jobs running on Hadoop. 1. ç¬¬1æ®µéšï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³3ã§è©³è¿°ï¼‰ã§ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚°ãƒ©ãƒ•ã‹ã‚‰äºŒéƒ¨ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’å¤§è¦æ¨¡ã«ç™ºè¦‹ã—ã€ãã®çµæœã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç–ãªéè² è¡¨ç¾ã‚’å­¦ç¿’ã—ã¾ã™ã€‚ ã“ã®æ®µéšãŒçµ‚ã‚ã‚‹ã¨ã€å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯è‡ªåˆ†ãŒå‚åŠ ã—ã¦ã„ã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãƒªã‚¹ãƒˆã¨ã€ãã‚Œãã‚Œã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¸ã®æ‰€å±ã®å¼·ã•ã‚’æ•°å€¤åŒ–ã—ãŸã‚¹ã‚³ã‚¢ã¨ã«é–¢é€£ã¥ã‘ã‚‰ã‚Œã¾ã™ã€‚ ã“ã®å‡ºåŠ›ã¯ã€ŒUser Interest Representationsã€ã¨å‘¼ã°ã‚Œã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹ã¨ä½é…å»¶ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¹ãƒˆã‚¢ã®ä¸¡æ–¹ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã«ã‚ˆã£ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã•ã‚Œã¦åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚ ã“ã®æœ€åˆã®æ®µéšã¯ã€ãƒãƒƒãƒåˆ†æ•£å‹ã®è¨­å®šã§å®Ÿè¡Œã•ã‚Œã€é€šå¸¸ã¯Hadoopä¸Šã§å®Ÿè¡Œã•ã‚Œã‚‹ä¸€é€£ã®MapReduceã‚¸ãƒ§ãƒ–ã¨ã—ã¦å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

- 2. The second stage (detailed in Section 4) consists of several jobs running in parallel, each of which calculates the representations for a specific recommendation target, using a userâ€“target bipartite graph formed from interaction logs on the platform. Each job in the second stage operates in either a batch-distributed setting or a streaming-distributed setting, depending on the shelf-life of the recommendation target and the churn in the corresponding userâ€“target bipartite graph. 2. ç¬¬2æ®µéšï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³4ã§è©³è¿°ï¼‰ã¯ã€ä¸¦è¡Œã—ã¦å®Ÿè¡Œã•ã‚Œã‚‹è¤‡æ•°ã®ã‚¸ãƒ§ãƒ–ã§æ§‹æˆã•ã‚Œã€å„ã‚¸ãƒ§ãƒ–ã¯ã€ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ä¸Šã®å¯¾è©±ãƒ­ã‚°ã‹ã‚‰å½¢æˆã•ã‚Œã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®äºŒéƒ¨ã‚°ãƒ©ãƒ•ã‚’ç”¨ã„ã¦ã€ç‰¹å®šã®æ¨è–¦å¯¾è±¡ã«å¯¾ã™ã‚‹è¡¨ç¾ã‚’è¨ˆç®—ã™ã‚‹ã€‚ ç¬¬2ã‚¹ãƒ†ãƒ¼ã‚¸ã®å„ã‚¸ãƒ§ãƒ–ã¯ã€æ¨è–¦å¯¾è±¡ã®è³å‘³æœŸé™ã¨å¯¾å¿œã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆäºŒéƒ¨ã‚°ãƒ©ãƒ•ã®ãƒãƒ£ãƒ¼ãƒ³ã«å¿œã˜ã¦ã€ãƒãƒƒãƒåˆ†æ•£è¨­å®šã¾ãŸã¯ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆ†æ•£è¨­å®šã®ã©ã¡ã‚‰ã‹ã§å‹•ä½œã™ã‚‹ã€‚

The most important detail about our design is that itâ€™s based on discovering communities from the userâ€“user graph.
ç§ãŸã¡ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã§æœ€ã‚‚é‡è¦ãªã®ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚°ãƒ©ãƒ•ã‹ã‚‰ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’ç™ºè¦‹ã™ã‚‹ã“ã¨ã«åŸºã¥ã„ã¦ã„ã‚‹ã“ã¨ã§ã™ã€‚
While the other userâ€“target graphs on Twitter evolve rapidly, the userâ€“user graph is relatively long-term and stable, and the specific communities discovered from the graph often outlive specific edges or nodes in the graph.
Twitterã®ä»–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚°ãƒ©ãƒ•ãŒæ€¥é€Ÿã«é€²åŒ–ã™ã‚‹ã®ã«å¯¾ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚°ãƒ©ãƒ•ã¯æ¯”è¼ƒçš„é•·æœŸçš„ã«å®‰å®šã—ã¦ãŠã‚Šã€ã‚°ãƒ©ãƒ•ã‹ã‚‰ç™ºè¦‹ã•ã‚ŒãŸç‰¹å®šã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¯ã€ã‚°ãƒ©ãƒ•ã®ç‰¹å®šã®ã‚¨ãƒƒã‚¸ã‚„ãƒãƒ¼ãƒ‰ã‚ˆã‚Šã‚‚é•·ç”Ÿãã™ã‚‹ã“ã¨ãŒå¤šã„ã®ã§ã™ã€‚
In addition, the user-user graph usually also has more coverage, in the sense that there are a lot more users who have a minimum number of edges in this graph compared to the other user-item graphs.
ã¾ãŸã€ãƒ¦ãƒ¼ã‚¶ãƒ¼-ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚°ãƒ©ãƒ•ã¯ã€ä»–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼-ã‚¢ã‚¤ãƒ†ãƒ ã‚°ãƒ©ãƒ•ã¨æ¯”è¼ƒã—ã¦ã€ã“ã®ã‚°ãƒ©ãƒ•ã®ã‚¨ãƒƒã‚¸æ•°ãŒæœ€å°ã¨ãªã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¤šã„ã¨ã„ã†æ„å‘³ã§ã€é€šå¸¸ã€ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒé«˜ã„ã¨ã‚‚è¨€ãˆã¾ã™ã€‚

The other important aspect of our design is its modularity.
ç§ãŸã¡ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã®ã‚‚ã†ä¸€ã¤ã®é‡è¦ãªç‚¹ã¯ã€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã§ã™ã€‚
The different parts of the pipeline depend on each other only via offline data sets or online key-value stores, meaning that they are robust to delays in the preceding steps.
ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ç•°ãªã‚‹éƒ¨åˆ†ã¯ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¾ãŸã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã‚’ä»‹ã—ã¦ã®ã¿äº’ã„ã«ä¾å­˜ã—ã€å…ˆè¡Œã‚¹ãƒ†ãƒƒãƒ—ã®é…å»¶ã«å¯¾ã—ã¦å …ç‰¢ã§ã‚ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚
It is also easy to swap out existing implementations with new variants, or run multiple implementations in parallel, as long as the output is in the format expected by the downstream jobs.
ã¾ãŸã€ä¸‹æµã®ã‚¸ãƒ§ãƒ–ãŒæœŸå¾…ã™ã‚‹å‡ºåŠ›å½¢å¼ã§ã‚ã‚Œã°ã€æ—¢å­˜ã®å®Ÿè£…ã‚’æ–°ã—ã„ã‚‚ã®ã«ç½®ãæ›ãˆãŸã‚Šã€è¤‡æ•°ã®å®Ÿè£…ã‚’ä¸¦åˆ—ã«å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚‚å®¹æ˜“ã§ã™ã€‚
The system degrades gracefully in the presence of bugs and errors - if any one of the item representation jobs has an issue, the other item representation jobs can still service their applications.
ãƒã‚°ã‚„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ã€ã‚·ã‚¹ãƒ†ãƒ ã¯å„ªé›…ã«åŠ£åŒ–ã—ã¾ã™ã€‚ã‚¢ã‚¤ãƒ†ãƒ è¡¨ç¾ã‚¸ãƒ§ãƒ–ã®1ã¤ã«å•é¡ŒãŒç™ºç”Ÿã—ã¦ã‚‚ã€ä»–ã®ã‚¢ã‚¤ãƒ†ãƒ è¡¨ç¾ã‚¸ãƒ§ãƒ–ã¯ãã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã§ãã¾ã™ã€‚
Our design also allows for gradually adding more modules to the system without needing to build it all in at the start â€” in fact, the first version of the system only output communities without any item representations, but this by itself had many useful applications.
å®Ÿéš›ã€æœ€åˆã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ã‚’è¡¨ç¾ã›ãšã«ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã ã‘ã‚’å‡ºåŠ›ã—ã¦ã„ã¾ã—ãŸãŒã€ãã‚Œã ã‘ã§å¤šãã®æœ‰ç”¨ãªç”¨é€”ãŒã‚ã‚Šã¾ã—ãŸã€‚

# Stage 1: Community Discovery ã‚¹ãƒ†ãƒ¼ã‚¸1ï¼šã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ç™ºè¦‹

This stage is about discovering communities from the Twitter userâ€“ user graph i.e.
ã“ã®æ®µéšã¯ã€Twitterã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚°ãƒ©ãƒ•ã‹ã‚‰ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’ç™ºè¦‹ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
the directed graph of Follow relationships between users.
ãƒ¦ãƒ¼ã‚¶ãƒ¼é–“ã®ãƒ•ã‚©ãƒ­ãƒ¼é–¢ä¿‚ã‚’è¡¨ã™æœ‰å‘ã‚°ãƒ©ãƒ•ã€‚
Following seminal work in the analysis of directed graphs such as HITS [17] and SALSA [20], we find it convenient to reformulate the directed graph as a bipartite graph.
HITS [17]ã‚„SALSA [20]ãªã©ã®æœ‰å‘ã‚°ãƒ©ãƒ•ã®è§£æã«ãŠã‘ã‚‹ä»£è¡¨çš„ãªç ”ç©¶ã«å€£ã£ã¦ã€æœ‰å‘ã‚°ãƒ©ãƒ•ã‚’äºŒéƒ¨ã‚°ãƒ©ãƒ•ã¨ã—ã¦å†å®šç¾©ã™ã‚‹ã“ã¨ãŒä¾¿åˆ©ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚
We now frame our task as one of identifying bipartite communities i.e.
ã“ã“ã§ã€ç§ãŸã¡ã®èª²é¡Œã¯ã€2ã¤ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã€ã™ãªã‚ã¡ã€2åˆ†å‰²ã•ã‚ŒãŸã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’è­˜åˆ¥ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
communities consisting of members from left as well as right partitions, and where the edge density between the left and right member sets is high.
å·¦ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã¨å³ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®ãƒ¡ãƒ³ãƒãƒ¼ã‹ã‚‰ãªã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã§ã€å·¦å³ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚»ãƒƒãƒˆé–“ã®ã‚¨ãƒƒã‚¸å¯†åº¦ãŒé«˜ã„å ´åˆã€‚
The bipartite reformulation lets us more flexibly assign users to communities â€” similar to HITS, we decouple the communities a user is influential in from the communities in which a user is interested.
HITSã¨åŒæ§˜ã«ã€ãƒ¦ãƒ¼ã‚¶ãŒå½±éŸ¿åŠ›ã‚’æŒã¤ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨ãƒ¦ãƒ¼ã‚¶ãŒé–¢å¿ƒã‚’æŒã¤ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’åˆ‡ã‚Šé›¢ã™ã“ã¨ã§ã€ã‚ˆã‚ŠæŸ”è»Ÿã«ãƒ¦ãƒ¼ã‚¶ã‚’ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¸å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

Problem Definition 1.
å•é¡Œå®šç¾© 1.
Given a bipartite userâ€“user graph with left-partition ğ¿ and right-partition ğ‘…, find ğ‘˜ (possibly overlapping) bipartite communities from the graph, and assign each left-node and right-node to the communities with weights to indicate the strength of their memberships.
å·¦ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³áµƒã¨å³ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³áµ…ã‚’æŒã¤äºŒåˆ†å‰²ãƒ¦ãƒ¼ã‚¶ãƒ¦ãƒ¼ã‚¶ã‚°ãƒ©ãƒ•ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€ã‚°ãƒ©ãƒ•ã‹ã‚‰â†ªL_1D45â†©ï¼ˆãŠãã‚‰ãé‡è¤‡ã™ã‚‹ï¼‰äºŒåˆ†å‰²ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’è¦‹ã¤ã‘ã€å„å·¦ãƒãƒ¼ãƒ‰ã¨å³ãƒãƒ¼ãƒ‰ã«ãã®ãƒ¡ãƒ³ãƒãƒ¼ã‚·ãƒƒãƒ—ã®å¼·ã•ã‚’ç¤ºã™é‡ã¿ã‚’ã¤ã‘ã¦ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‰²ã‚Šå½“ã¦ã¾ã™ã€‚

The other advantage of reformulating the directed graph as a bipartite graph is that we can choose to make ğ‘…, the right set of nodes, different from ğ¿, the left set of nodes â€“ in particular, since the majority of edges in a typical social network is directed towards a minority of users, it makes sense to pick a smaller ğ‘… than ğ¿.
æœ‰å‘ã‚°ãƒ©ãƒ•ã‚’äºŒéƒ¨ã‚°ãƒ©ãƒ•ã¨ã—ã¦å†å®šç¾©ã™ã‚‹ã‚‚ã†ä¸€ã¤ã®åˆ©ç‚¹ã¯ã€ãƒãƒ¼ãƒ‰ã®å³é›†åˆã§ã‚ã‚‹ğ‘…ã‚’ãƒãƒ¼ãƒ‰ã®å·¦é›†åˆã§ã‚ã‚‹ğ¿ã¨ç•°ãªã‚‹ã‚ˆã†ã«é¸æŠã§ãã‚‹ã“ã¨ã§ã™ã€‚ç‰¹ã«ã€å…¸å‹çš„ãªã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å¤§éƒ¨åˆ†ã®è¾ºã¯å°‘æ•°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å‘ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã®ã§ã€ğ¿ã‚ˆã‚Šã‚‚å°ã•ãªâ†ªLu_1D445ã‚’é¸ã¶ã“ã¨ã¯ç†ã«ã‹ãªã£ã¦ã„ã‚‹ã¨ã„ãˆã¾ã™ã€‚
In Twitterâ€™s case, we find that weâ€™re able to cover the majority of edges (numbering âˆ¼1011) in the full graph by including the top âˆ¼107 most followed users in ğ‘…, while ğ¿ continues to include all users, which is âˆ¼109 .
Twitterã®å ´åˆã€æœ€ã‚‚ãƒ•ã‚©ãƒ­ãƒ¼ã•ã‚Œã¦ã„ã‚‹ä¸Šä½107äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’áµ…ã«å«ã‚ã‚‹ã“ã¨ã§ã€ãƒ•ãƒ«ã‚°ãƒ©ãƒ•ã®å¤§åŠã®ã‚¨ãƒƒã‚¸ï¼ˆç´„1011å€‹ï¼‰ã‚’ã‚«ãƒãƒ¼ã™ã‚‹ã“ã¨ãŒã§ãã€ä¸€æ–¹ã€áµƒã¯å…¨ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å«ã¿ç¶šã‘ã€ç´„109å€‹ã¨ãªã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚
Our problem definition also asks to assign non-negative scores to both the left and the right members indicating the strength of association to a community.
ã¾ãŸã€å•é¡Œå®šç¾©ã§ã¯ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨ã®é–¢é€£æ€§ã®å¼·ã•ã‚’ç¤ºã™éè² ã®ã‚¹ã‚³ã‚¢ã‚’å·¦å³ã®ãƒ¡ãƒ³ãƒãƒ¼ã«å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚
Therefore, we represent the left and right memberships as sparse, non-negative matrices U|ğ¿|Ã—ğ‘˜ and V|ğ‘…|Ã—ğ‘˜ , where ğ‘˜ is the number of communities.
ğ¿
Hence, the problem of bipartite community discovery bears close similarities to the problem of sparse non-negative matrix factorization (NMF).
ã—ãŸãŒã£ã¦ã€2åˆ†å‰²ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ç™ºè¦‹ã®å•é¡Œã¯ã€ã‚¹ãƒ‘ãƒ¼ã‚¹éè² è¡Œåˆ—åˆ†è§£ï¼ˆNMFï¼‰ã®å•é¡Œã¨å¯†æ¥ãªé¡ä¼¼æ€§ã‚’æŒã£ã¦ã„ã‚‹ã®ã§ã‚ã‚‹ã€‚
The biggest challenge with adapting existing approaches such as NMF and their variants [1, 3, 35] is the inability to scale them to graphs with âˆ¼109 nodes and âˆ¼1011 edges â€“ all of our attempts internally to adapt these approaches (see e.g.
NMFã‚„ãã®äºœç¨®[1, 3, 35]ãªã©ã®æ—¢å­˜ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’é©å¿œã™ã‚‹éš›ã®æœ€å¤§ã®èª²é¡Œã¯ã€ãƒãƒ¼ãƒ‰æ•°ãŒç´„109ã€ã‚¨ãƒƒã‚¸æ•°ãŒç´„1011ã®ã‚°ãƒ©ãƒ•ã«æ‹¡å¼µã§ããªã„ã“ã¨ã§ã‚ã‚Šã€ã“ã‚Œã‚‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’é©å¿œã™ã‚‹ãŸã‚ã®æˆ‘ã€…ã®å†…éƒ¨ã§ã®è©¦ã¿ã¯ã™ã¹ã¦ï¼ˆä¾‹ãˆã°ã€ä»¥ä¸‹ã‚’å‚ç…§ã€‚
[30]) have only worked at smaller scales and have been very difficult to debug and maintain.
[30]ï¼‰ã¯ã€å°è¦æ¨¡ãªã‚‚ã®ã§ã—ã‹æ©Ÿèƒ½ã›ãšã€ãƒ‡ãƒãƒƒã‚°ã‚„ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãŒéå¸¸ã«å›°é›£ã§ã‚ã£ãŸã€‚

With SimClusters, we instead adopt the following 3-step approach, illustrated with a toy example in Figure 2.
SimClustersã§ã¯ã€å›³2ã«ãŠã‚‚ã¡ã‚ƒã®ä¾‹ã§ç¤ºã™ã‚ˆã†ã«ã€æ¬¡ã®3ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚

- 1. Similarity Graph of Right Nodes: We calculate the â€œright projectionâ€ of the bipartite graph, i.e., we calculate the similarity between the nodes in the right partition of the bipartite graph based on their incoming edges, and we form a weighted, undirected graph consisting only of the nodes in the right partition. More details in Section 3.1. 1. å³ãƒãƒ¼ãƒ‰ã®é¡ä¼¼åº¦ã‚°ãƒ©ãƒ• äºŒåˆ†å‰²ã‚°ãƒ©ãƒ•ã®ã€Œå³æŠ•å½±ã€ã‚’è¨ˆç®—ã™ã‚‹ã€‚ã¤ã¾ã‚Šã€äºŒåˆ†å‰²ã‚°ãƒ©ãƒ•ã®å³åˆ†å‰²ã®ãƒãƒ¼ãƒ‰é–“ã®é¡ä¼¼åº¦ã‚’å…¥åŠ›ã‚¨ãƒƒã‚¸ã«åŸºã¥ã„ã¦è¨ˆç®—ã—ã€å³åˆ†å‰²ã®ãƒãƒ¼ãƒ‰ã®ã¿ã‹ã‚‰ãªã‚‹åŠ é‡ç„¡å‘ã‚°ãƒ©ãƒ•ã‚’å½¢æˆã™ã‚‹ã€‚ è©³ç´°ã¯3.1ç¯€ã§èª¬æ˜ã—ã¾ã™ã€‚

- 2. Communities of Right Nodes: We discover communities from this similarity graph, using a novel neighborhood-based sampling algorithm that is inspired by the work of [33] but is much more accurate, faster, and scales to graphs with billions of edges. More details in Section 3.2. 2. å³ãƒãƒ¼ãƒ‰ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ ã“ã®é¡ä¼¼ã‚°ãƒ©ãƒ•ã‹ã‚‰ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’ç™ºè¦‹ã™ã‚‹ã€‚ã“ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€[33]ã®ç ”ç©¶ã«è§¦ç™ºã•ã‚Œã¦ã„ã‚‹ãŒã€ã‚ˆã‚Šæ­£ç¢ºã§é«˜é€Ÿã§ã‚ã‚Šã€æ•°åå„„ã®ã‚¨ãƒƒã‚¸ã‚’æŒã¤ã‚°ãƒ©ãƒ•ã«æ‹¡å¼µå¯èƒ½ã§ã‚ã‚‹ã€‚ è©³ç´°ã¯3.2ç¯€ã§èª¬æ˜ã—ã¾ã™ã€‚

- 3. Communities of Left Nodes: We now assign nodes from the left partition to the communities discovered in step 2, and this is described in Section 3.3. 3. å·¦ãƒãƒ¼ãƒ‰ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ æ¬¡ã«ã€å·¦ã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒãƒ¼ãƒ‰ã‚’ã‚¹ãƒ†ãƒƒãƒ—2ã§ç™ºè¦‹ã•ã‚ŒãŸã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‰²ã‚Šå½“ã¦ã¾ã™ãŒã€ã“ã‚Œã«ã¤ã„ã¦ã¯3.3ç¯€ã§èª¬æ˜ã—ã¾ã™ã€‚

We note that the broad outlines of this approach have been independently discovered and suggested in the past literature (see e.g.
ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å¤§æ ã¯ã€éå»ã®æ–‡çŒ®ã§ç‹¬è‡ªã«ç™ºè¦‹ãƒ»ææ¡ˆã•ã‚Œã¦ããŸã‚‚ã®ã§ã‚ã‚‹ã“ã¨ã«ç•™æ„ã•ã‚ŒãŸã„ï¼ˆä¾‹ãˆã°
[23, 28]), but it has been largely neglected as an option among similar deployments in industry.
[23,28]ï¼‰ãŒã€ç”£æ¥­ç•Œã«ãŠã‘ã‚‹åŒæ§˜ã®å±•é–‹ã®ä¸­ã§ã¯ã€é¸æŠè‚¢ã¨ã—ã¦ã»ã¨ã‚“ã©ç„¡è¦–ã•ã‚Œã¦ããŸã€‚
The primary reason we think this works is that while the original bipartite graph is massive and noisy, the similarity graph of right nodes is much smaller and has clearer community structure.
ã“ã®æ–¹æ³•ãŒæœ‰åŠ¹ã§ã‚ã‚‹ã¨è€ƒãˆã‚‹ä¸»ãªç†ç”±ã¯ã€å…ƒã®äºŒéƒ¨ã‚°ãƒ©ãƒ•ãŒå·¨å¤§ã§ãƒã‚¤ã‚ºãŒå¤šã„ã®ã«å¯¾ã—ã€å³ãƒãƒ¼ãƒ‰ã®é¡ä¼¼æ€§ã‚°ãƒ©ãƒ•ã¯ã¯ã‚‹ã‹ã«å°ã•ãã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹é€ ãŒæ˜ç¢ºã§ã‚ã‚‹ãŸã‚ã§ã™ã€‚
From a scalability point of view, this approach shifts most of the computational burden to the first step of identifying pairs of similar users based on their followers, which is a problem that is largely solved at Twitter (see Section 3.1).
ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®è¦³ç‚¹ã‹ã‚‰ã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€è¨ˆç®—è² è·ã®ã»ã¨ã‚“ã©ã‚’ã€ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã«åŸºã¥ã„ã¦é¡ä¼¼ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒšã‚¢ã‚’è­˜åˆ¥ã™ã‚‹æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã«ã‚·ãƒ•ãƒˆã—ã€ã“ã‚Œã¯Twitterã§ã»ã¼è§£æ±ºã•ã‚Œã¦ã„ã‚‹å•é¡Œã§ã‚ã‚‹ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³3.1å‚ç…§ï¼‰ã€‚
From a matrix-factorization point of view, this 3-step approach closely mirrors one way of performing SVD of a matrix A, via the eigen-decomposition of A ğ‘‡ A.
è¡Œåˆ—å› æ•°åˆ†è§£ã®è¦³ç‚¹ã‹ã‚‰ã€ã“ã®3ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€Aáµ„ Aã®å›ºæœ‰åˆ†è§£ã‚’ä»‹ã—ãŸè¡Œåˆ—Aã®SVDã‚’å®Ÿè¡Œã™ã‚‹1ã¤ã®æ–¹æ³•ã¨ã‚ˆãä¼¼ã¦ã„ã¾ã™ã€‚

Our 3-step approach also isolates the hard-to-parallelize step of community discovery into step 2, where it operates on a smaller graph that fits into the memory of a single machine, while the other two steps operate on much bigger inputs and out of necessity run in batch-distributed settings such as Hadoop MapReduce.
ã“ã®3ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€ä¸¦åˆ—åŒ–ãŒå›°é›£ãªã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ç™ºè¦‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¹ãƒ†ãƒƒãƒ—2ã«åˆ†é›¢ã—ã€1å°ã®ãƒã‚·ãƒ³ã®ãƒ¡ãƒ¢ãƒªã«åã¾ã‚‹å°ã•ãªã‚°ãƒ©ãƒ•ã§å‹•ä½œã•ã›ã‚‹ä¸€æ–¹ã€ä»–ã®2ã‚¹ãƒ†ãƒƒãƒ—ã¯ã¯ã‚‹ã‹ã«å¤§ããªå…¥åŠ›ã§å‹•ä½œã—ã€å¿…ç„¶çš„ã«Hadoop MapReduceãªã©ã®ãƒãƒƒãƒåˆ†æ•£è¨­å®šã§å‹•ä½œã—ã¾ã™ã€‚
This approach is also modular and allows for swapping out implementations of each of the above steps independent of the others.
ã¾ãŸã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã•ã‚Œã¦ãŠã‚Šã€ä¸Šè¨˜ã®å„ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè£…ã‚’ä»–ã®ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰ç‹¬ç«‹ã—ã¦å…¥ã‚Œæ›¿ãˆã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚
A possible concern with our 3-step approach is that it may lead to reduced accuracy compared to directly learning the communities on the input bipartite network â€“ we empirically test this in Supplemental Section A.2 and find this not to be an issue.
ã“ã®3ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§æ‡¸å¿µã•ã‚Œã‚‹ã®ã¯ã€å…¥åŠ›ã•ã‚ŒãŸ2ãƒã‚¤ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’ç›´æ¥å­¦ç¿’ã™ã‚‹å ´åˆã«æ¯”ã¹ã¦ç²¾åº¦ãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã¨ã„ã†ã“ã¨ã§ã™ã€‚è£œè¶³ã‚»ã‚¯ã‚·ãƒ§ãƒ³A.2ã§çµŒé¨“çš„ã«æ¤œè¨¼ã—ãŸã¨ã“ã‚ã€ã“ã‚Œã¯å•é¡Œã§ã¯ãªã„ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚

## Step 1: Similarity Graph of Right Nodes ã‚¹ãƒ†ãƒƒãƒ—1ï¼šå³ãƒãƒ¼ãƒ‰ã®é¡ä¼¼æ€§ã‚°ãƒ©ãƒ•

The goal of this step is to construct a much smaller unipartite, undirected graph ğº over the nodes of the right partition.
ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ç›®çš„ã¯ã€å³ã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®ãƒãƒ¼ãƒ‰ã®ä¸Šã«ã€ã‚ˆã‚Šå°ã•ãªå˜éƒ¨åˆ†ã®ç„¡å‘ã‚°ãƒ©ãƒ•áµƒã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
We define the weight between two users (ğ‘¢, ğ‘£) based on the cosine similarity of their followers on the left side of the bipartite graph.
2ã¤ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼(ğ‘¢, â†ªLl_1D463)é–“ã®é‡ã¿ã‚’ã€2åˆ†æœ¨ã‚°ãƒ©ãƒ•ã®å·¦å´ã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã«åŸºã¥ã„ã¦å®šç¾©ã™ã‚‹ã€‚
To elaborate, if ğ‘¥Â®ğ‘¢ and ğ‘¥Â®ğ‘£ represent the binary incidence vectors of ğ‘¢â€™s and ğ‘£â€™s followers, their cosine similarity is defined as ğ‘¥Â®ğ‘¢ Â· Â®ğ‘¥ğ‘£/ p âˆ¥ Â®ğ‘¥ğ‘¢ âˆ¥ âˆ¥ Â®ğ‘¥ğ‘£ âˆ¥.
è©³ã—ãèª¬æ˜ã™ã‚‹ã¨ã€ğ‘¥Â®ğ‘¢ã¨ğ‘¥ã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã®2å€¤å…¥å°„ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¡¨ã™ã¨ã€ãã®ä½™å¼¦é¡ä¼¼åº¦ã¯ğ‘¢-Â®ğ‘£/ pâˆ¥ Â®ğ‘¥Â®ğ‘¥ âˆ¥ã¨å®šç¾©ã™ã‚‹ã€‚
With this definition, two users would have non-zero similarity, or an edge in ğº simply by sharing one common neighbor in the bipartite graph.
ã“ã®å®šç¾©ã«ã‚ˆã‚Œã°ã€2ã¤ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€2åˆ†æœ¨ã‚°ãƒ©ãƒ•ã«ãŠã„ã¦1ã¤ã®å…±é€šã®éš£äººã‚’å…±æœ‰ã™ã‚‹ã ã‘ã§ã€ã‚¼ãƒ­ã§ã¯ãªã„é¡ä¼¼æ€§ã€ã™ãªã‚ã¡â†ªLu_1D43A ã®ã‚¨ãƒƒã‚¸ã‚’æŒã¤ã“ã¨ã«ãªã‚‹ã€‚
In order to avoid generating an extremely dense similarity graph, we discard the edges with similarity score lower than a certain threshold and additionally keep at most a certain number of neighbors with the largest similarity scores for each user.
æ¥µç«¯ã«å¯†ãªé¡ä¼¼ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã—ãªã„ãŸã‚ã«ã€é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ãŒã‚ã‚‹é–¾å€¤ã‚ˆã‚Šä½ã„ã‚¨ãƒƒã‚¸ã‚’ç ´æ£„ã—ã€ã•ã‚‰ã«å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ãŒæœ€ã‚‚å¤§ãã„éš£äººã‚’æœ€å¤§ã§ä¸€å®šæ•°ä¿æŒã™ã‚‹ã€‚

The difficulty is that solving the similar users problem is very challenging at Twitter scale.
é›£ã—ã„ã®ã¯ã€é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼å•é¡Œã®è§£æ±ºã¯ã€Twitterã®è¦æ¨¡ã§ã¯éå¸¸ã«å›°é›£ã§ã‚ã‚‹ã¨ã„ã†ã“ã¨ã§ã™ã€‚
But because this is a problem with important applications â€“ e.g.
ã—ã‹ã—ã€ã“ã‚Œã¯é‡è¦ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³-ä¾‹ãˆã°-ã§å•é¡Œã¨ãªã‚‹ãŸã‚ã§ã™ã€‚
it is the foundation of applying itembased collaborative filtering for the â€œWho To Followâ€ module [11] â€“ we have invested significant resources to develop a robust solution.
ã“ã‚Œã¯ã€ã€ŒWho To Followã€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«[11]ã«ã‚¢ã‚¤ãƒ†ãƒ ãƒ™ãƒ¼ã‚¹å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’é©ç”¨ã™ã‚‹ãŸã‚ã®åŸºç¤ã¨ãªã‚‹ã‚‚ã®ã§ã€ç§ãŸã¡ã¯å …ç‰¢ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹ç™ºã™ã‚‹ãŸã‚ã«å¤šå¤§ãªãƒªã‚½ãƒ¼ã‚¹ã‚’æŠ•å…¥ã—ã¦ãã¾ã—ãŸã€‚
Our solution, called WHIMP, uses a combination of wedge sampling and Locality Sensitive Hashing (LSH) to scale to the Twitter graph and lends itself to implementation on Hadoop MapReduce [32].
WHIMPã¨å‘¼ã°ã‚Œã‚‹æˆ‘ã€…ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€ã‚¦ã‚§ãƒƒã‚¸ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¨Locality Sensitive Hashingï¼ˆLSHï¼‰ã®çµ„ã¿åˆã‚ã›ã§Twitterã‚°ãƒ©ãƒ•ã«å¯¾å¿œã—ã€Hadoop MapReduceï¼ˆ32ï¼‰ä¸Šã§ã®å®Ÿè£…ã«é©ã—ã¦ã„ã¾ã™ã€‚
WHIMP is able to identify similar users for users with either large or small followings, and has been vetted in a variety of ways internally.
WHIMPã¯ã€ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ãŒå¤šã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚‚å°‘ãªã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚‚ã€ä¼¼ãŸã‚ˆã†ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ç‰¹å®šã™ã‚‹ã“ã¨ãŒã§ãã€ç¤¾å†…ã§ã•ã¾ã–ã¾ãªæ¤œè¨¼ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ãã†ã§ã™ã€‚

Ultimately, this similarity graph step takes as input a directed/bipartite graph with âˆ¼109 nodes and âˆ¼1011 edges and outputs an undirected graph with âˆ¼107 nodes and âˆ¼109 edges.
æœ€çµ‚çš„ã«ã€ã“ã®é¡ä¼¼ã‚°ãƒ©ãƒ•ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€âˆ¼109å€‹ã®ãƒãƒ¼ãƒ‰ã¨âˆ¼1011å€‹ã®ã‚¨ãƒƒã‚¸ã‚’æŒã¤æœ‰å‘/äºŒéƒ¨ã‚°ãƒ©ãƒ•ã‚’å…¥åŠ›ã¨ã—ã€âˆ¼107å€‹ã®ãƒãƒ¼ãƒ‰ã¨âˆ¼109å€‹ã®ã‚¨ãƒƒã‚¸ã‚’æŒã¤ç„¡å‘ã‚°ãƒ©ãƒ•ã‚’å‡ºåŠ›ã™ã‚‹ã€‚
In other words, we go from shared-nothing cluster-computing scale to shared-memory multi-core scale.
ã¤ã¾ã‚Šã€ã‚·ã‚§ã‚¢ãƒ¼ãƒ‰ãƒŠãƒƒã‚·ãƒ³ã‚°ã®ã‚¯ãƒ©ã‚¹ã‚¿ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°è¦æ¨¡ã‹ã‚‰ã€ã‚·ã‚§ã‚¢ãƒ¼ãƒ‰ãƒ¡ãƒ¢ãƒªã®ãƒãƒ«ãƒã‚³ã‚¢è¦æ¨¡ã«ãªã‚‹ã®ã§ã™ã€‚
The transformation wrought by this step is also reminiscent of prior research which suggested that keeping only the most important edges in a graph can benefit community discovery methods [29].
ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã«ã‚ˆã£ã¦ã‚‚ãŸã‚‰ã•ã‚Œã‚‹å¤‰æ›ã¯ã€ã‚°ãƒ©ãƒ•ã®æœ€ã‚‚é‡è¦ãªã‚¨ãƒƒã‚¸ã®ã¿ã‚’ä¿æŒã™ã‚‹ã“ã¨ã§ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ç™ºè¦‹æ‰‹æ³•ã«åˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã‚’ç¤ºå”†ã—ãŸå…ˆè¡Œç ”ç©¶[29]ã‚’ã‚‚æƒ³èµ·ã•ã›ã‚‹ã€‚

## Step 2: Communities of Right Nodes ã‚¹ãƒ†ãƒƒãƒ—2ï¼šå³ãƒãƒ¼ãƒ‰ã®å…±åŒä½“

In this step, we wish to discover communities of densely connected nodes from the undirected, possibly-weighted similarity graph from the previous step.
ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å¾—ã‚‰ã‚ŒãŸç„¡å‘ãã®ã€ãŠãã‚‰ãã¯é‡ã¿ä»˜ã‘ã•ã‚ŒãŸé¡ä¼¼æ€§ã‚°ãƒ©ãƒ•ã‹ã‚‰ã€å¯†ã«æ¥ç¶šã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’ç™ºè¦‹ã™ã‚‹ã“ã¨ã‚’æœ›ã‚“ã§ã„ã‚‹ã€‚
In order to accurately preserve the structure of the input similarity graph, we have observed that it is important for the communities to have hundreds of nodes, rather than thousands or tens or thousands.
å…¥åŠ›ã•ã‚ŒãŸé¡ä¼¼æ€§ã‚°ãƒ©ãƒ•ã®æ§‹é€ ã‚’æ­£ç¢ºã«ä¿æŒã™ã‚‹ãŸã‚ã«ã¯ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãƒãƒ¼ãƒ‰æ•°ãŒæ•°åƒã€æ•°ä¸‡ã§ã¯ãªãã€æ•°ç™¾ã§ã‚ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¦ã„ã¾ã™ã€‚
This means that we need algorithms that can process input graphs with âˆ¼107 nodes and âˆ¼109 edges to find âˆ¼105 communities.
ã¤ã¾ã‚Šã€ãƒãƒ¼ãƒ‰âˆ¼107å€‹ã€ã‚¨ãƒƒã‚¸âˆ¼109å€‹ã®å…¥åŠ›ã‚°ãƒ©ãƒ•ã‚’å‡¦ç†ã—ã¦ã€âˆ¼105å€‹ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒå¿…è¦ã§ã™ã€‚
Despite the long history of community discovery algorithms, we were unable to find any existing solution that can satisfy these scale requirements.
ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ç™ºè¦‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é•·ã„æ­´å²ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€ã“ã‚Œã‚‰ã®è¦æ¨¡è¦ä»¶ã‚’æº€ãŸã™ã“ã¨ãŒã§ãã‚‹æ—¢å­˜ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚
We next describe the algorithm we developed, called Neighborhood-aware Metropolis Hastings (henceforth Neighborhood-aware MH), to meet our requirements.
æ¬¡ã«ã€æˆ‘ã€…ã®è¦æ±‚ã‚’æº€ãŸã™ãŸã‚ã«é–‹ç™ºã—ãŸ Neighborhood-aware Metropolis Hastingsï¼ˆä»¥ä¸‹ã€Neighborhood-aware MHï¼‰ã¨å‘¼ã°ã‚Œã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã¤ã„ã¦èª¬æ˜ã™ã‚‹ã€‚

Our algorithm extends a Metropolis-Hastings sampling approach presented in [33] for discovering overlapping communities, which we first describe as background.
æˆ‘ã€…ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€é‡è¤‡ã™ã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’ç™ºè¦‹ã™ã‚‹ãŸã‚ã«[33]ã§ç™ºè¡¨ã•ã‚ŒãŸãƒ¡ãƒˆãƒ­ãƒãƒªã‚¹ãƒ»ãƒ˜ã‚¤ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã‚¹ãƒ»ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ»ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ‹¡å¼µã—ãŸã‚‚ã®ã§ã‚ã‚Šã€ã¾ãšèƒŒæ™¯ã¨ã—ã¦èª¬æ˜ã™ã‚‹ã€‚
Let Z|ğ‘…|Ã—ğ‘˜ be a sparse binary community assignments matrix and Z(ğ‘¢) denote the set of communities to which the vertex ğ‘¢ has been assigned (in other words, Z(ğ‘¢) gives the non-zero column indices from the ğ‘¢-th row in Z).
ğ‘…
Equation 1 specifies an objective function over Z.
å¼1ã¯ã€Zã«å¯¾ã™ã‚‹ç›®çš„é–¢æ•°ã‚’æŒ‡å®šã™ã‚‹ã€‚

$$
\tag{1}
$$

1 is the indicator function.
1 ã¯ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼æ©Ÿèƒ½ã§ã™ã€‚
F (Z) is the sum of two terms â€“ the first counts how many neighboring pairs of nodes in the graph share at least one community, while the second counts how many nonneighbor pairs of nodes in the graph do not share a community.2 Since most real, large-scale networks are very sparse, it is useful to upweight the contribution of the first term using the parameter ğ›¼ â€“ increasing values of ğ›¼ means that the objective function is better optimized by Z with more non-zeros.
F (Z)ã¯2ã¤ã®é …ã®åˆè¨ˆã§ã‚ã‚‹ã€‚æœ€åˆã®é …ã¯ã€ã‚°ãƒ©ãƒ•å†…ã®ãƒãƒ¼ãƒ‰ã®éš£æ¥ã™ã‚‹ãƒšã‚¢ãŒå°‘ãªãã¨ã‚‚1ã¤ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’å…±æœ‰ã™ã‚‹æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã€2ç•ªç›®ã®é …ã¯ã€ã‚°ãƒ©ãƒ•å†…ã®ãƒãƒ¼ãƒ‰ã®ééš£æ¥ãƒšã‚¢ãŒã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’å…±æœ‰ã—ãªã„æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ã€‚2 å®Ÿéš›ã®å¤§è¦æ¨¡ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã»ã¨ã‚“ã©ã¯éå¸¸ã«ã‚¹ãƒ‘ãƒ¼ã‚¹ãªã®ã§ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ğ›¼ã‚’ç”¨ã„ã¦æœ€åˆã®é …ã®å¯„ä¸ã‚’é‡ã¿ä»˜ã‘ã™ã‚‹ã“ã¨ãŒæœ‰ç”¨ã§ã™ã€‚ğ›¼ã®å€¤ãŒå¢—åŠ ã™ã‚‹ã¨ã€ç›®çš„é–¢æ•°ã¯ã‚ˆã‚Šéã‚¼ãƒ­ã®Zã«ã‚ˆã£ã¦æœ€é©åŒ–ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚
Note also that the objective function above is decomposable, in the sense that the overall objective function F (Z) can be expressed as a sum of a function ğ‘“ (ğ‘¢, Z) over individual vertices (below, N (ğ‘¢) denotes the set of neighbors of vertex ğ‘¢).
ã¾ãŸã€ä¸Šè¨˜ã®ç›®çš„é–¢æ•°ã¯ã€å…¨ä½“ã®ç›®çš„é–¢æ•°Fï¼ˆZï¼‰ãŒå€‹ã€…ã®é ‚ç‚¹ï¼ˆä»¥ä¸‹ã€Nï¼ˆğ‘¢ï¼‰ã¯é ‚ç‚¹ğ‘¢ã®è¿‘å‚é›†åˆã‚’è¡¨ã™ï¼‰ã«å¯¾ã™ã‚‹é–¢æ•°ğ‘¢ï¼ˆZï¼‰ã®å’Œã¨ã—ã¦è¡¨ç¾ã§ãã‚‹æ„å‘³ã§ã€åˆ†è§£å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã«æ³¨æ„ã™ã‚‹ã“ã¨ã€‚

$$
\tag{2}
$$

Using the above background, we first describe the approach for discovering overlapping communities in a general way in Algorithm 1.
ä»¥ä¸Šã®èƒŒæ™¯ã‚’è¸ã¾ãˆã€ã¾ãšã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 1ã«ãŠã„ã¦ã€é‡è¤‡ã™ã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’ä¸€èˆ¬çš„ãªæ–¹æ³•ã§ç™ºè¦‹ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’èª¬æ˜ã™ã‚‹ã€‚
After initializing Z, we run at most ğ‘‡ epochs of optimization, where in each epoch we iterate over all the vertices in the graph in a shuffled order.
Zã‚’åˆæœŸåŒ–ã—ãŸå¾Œã€æœ€å¤§ã§áµ„ã‚¨ãƒãƒƒã‚¯æœ€é©åŒ–ã‚’å®Ÿè¡Œã—ã€å„ã‚¨ãƒãƒƒã‚¯ã§ã¯ã‚°ãƒ©ãƒ•å†…ã®ã™ã¹ã¦ã®é ‚ç‚¹ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ãŸé †åºã§åå¾©ã™ã‚‹ã€‚
For each vertex ğ‘¢ we sample a new set of community assignments Z â€² (ğ‘¢) using the proposal function, and calculate the difference in objective function between the newly proposed Z â€² (ğ‘¢) and the current set of community assignments Z(ğ‘¢).
å„é ‚ç‚¹áµ†ã«ã¤ã„ã¦ã€ææ¡ˆé–¢æ•°ã‚’ç”¨ã„ã¦ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å‰²ã‚Šå½“ã¦ã®æ–°ã—ã„ã‚»ãƒƒãƒˆZ â€²ï¼ˆâ†ªLl_1D462ï¼‰ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€æ–°ã—ãææ¡ˆã•ã‚ŒãŸZ â€²ï¼ˆâ†ªLl_1D462ï¼‰ã¨ç¾åœ¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å‰²ã‚Šå½“ã¦ã®ã‚»ãƒƒãƒˆZï¼ˆâ†ªLl_1D462ï¼‰ã®é–“ã®ç›®çš„é–¢æ•°ã®é•ã„ã‚’è¨ˆç®—ã—ã¾ã™ã€‚
If Z â€² (ğ‘¢) is better, then it is accepted; if not, it may still be accepted with a certain probability, indicated in line 6 of Algorithm 1.
ã‚‚ã—Z â€² (â†ªLl_1D462) ã®æ–¹ãŒè‰¯ã‘ã‚Œã°ã€ãã‚Œã¯å—ã‘å…¥ã‚Œã‚‰ã‚Œã‚‹ã€‚ã‚‚ã—ãã†ã§ãªãã¦ã‚‚ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 1ã®6è¡Œç›®ã§ç¤ºã•ã‚Œã‚‹ã‚ˆã†ã«ã€ã‚ã‚‹ç¢ºç‡ã§å—ã‘å…¥ã‚Œã‚‰ã‚Œã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚
As noted in [33], one reason for preferring a randomized optimization procedure as opposed a deterministic optimization procedure is to avoid getting stuck in local minima.
33]ã§è¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ï¼Œæ±ºå®šè«–çš„ãªæœ€é©åŒ–æ‰‹é †ã§ã¯ãªãï¼Œãƒ©ãƒ³ãƒ€ãƒ ãªæœ€é©åŒ–æ‰‹é †ã‚’å¥½ã‚€ç†ç”±ã®1ã¤ã¯ï¼Œå±€æ‰€æœ€å°å€¤ã«ã¯ã¾ã‚‹ã®ã‚’é¿ã‘ã‚‹ã“ã¨ã§ã‚ã‚‹ï¼

The specific choices for the â€˜Initializeâ€™ and â€˜Proposalâ€™ functions made in [33] are described in Algorithm 2.
33]ã§è¡Œã‚ã‚ŒãŸã€ŒInitializeã€ã¨ã€ŒProposalã€é–¢æ•°ã®å…·ä½“çš„ãªé¸æŠæ–¹æ³•ã¯ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 2ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚
Because these functions are implemented using purely random sampling, we refer to this approach as â€˜Random MHâ€™.
ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã¯ã€ç´”ç²‹ã«ãƒ©ãƒ³ãƒ€ãƒ ãªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ã“ã®æ‰‹æ³•ã‚’ã€Œãƒ©ãƒ³ãƒ€ãƒ MHã€ã¨å‘¼ã‚“ã§ã„ã¾ã™ã€‚
The main practical drawback of Random MH is that it is extremely slow to obtain a satisfactorily accurate solution for even moderate values of ğ‘˜.
ãƒ©ãƒ³ãƒ€ãƒ MHã®ä¸»ãªå®Ÿç”¨ä¸Šã®æ¬ ç‚¹ã¯ã€á‘˜ã®å€¤ãŒé©åº¦ã§ã‚ã£ã¦ã‚‚ã€æº€è¶³ã®ã„ãç²¾åº¦ã®è§£ã‚’å¾—ã‚‹ã®ã«éå¸¸ã«æ™‚é–“ãŒã‹ã‹ã‚‹ã¨ã„ã†ã“ã¨ã§ã‚ã‚‹ã€‚
This is not surprising considering that in each step, the proposal function generates a completely random community assignments vector and evaluates Algorithm 3: Initialize and Proposal functions for Neighborhood-aware MH 1: Function: Initialize(ğº, ğ‘˜) 2: for ğ‘– â† 1..ğ‘˜ do 3: Set ğ‘– ğ‘¡â„ column of Z as neighbors of a randomly picked node 4: end for 5: return Z 6: 7: Function: Proposal(ğ‘¢,ğº, Z, ğ‘˜,ğ‘™) // ğ‘™ << ğ‘˜ 8: ğ‘† â† columns of Z with â‰¥ 1 non-zero in rows of ğ‘ (ğ‘¢) // enumerateSubsets(ğ‘†,ğ‘™) returns all subsets of ğ‘† of size â‰¤ ğ‘™ 9: for ğ‘  â† enumerateSubsets(ğ‘†,ğ‘™) do 10: fMap(ğ‘ ) â† ğ‘“ (ğ‘¢, ğ‘ ) // Per Eqn 2 11: end for 12: return Sample ğ‘  from ğ‘† according to softmax(fMap) it w.r.t.
ã“ã‚Œã¯ã€ææ¡ˆé–¢æ•°ãŒå„ã‚¹ãƒ†ãƒƒãƒ—ã§å®Œå…¨ã«ãƒ©ãƒ³ãƒ€ãƒ ãªã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å‰²ã‚Šå½“ã¦ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã€è©•ä¾¡ã™ã‚‹ã“ã¨ã‚’è€ƒãˆã‚Œã°é©šãã¹ãã“ã¨ã§ã¯ãªã„ã€‚ Algorithm 3: Neighborhood-aware MHã®åˆæœŸåŒ–é–¢æ•°ã¨ææ¡ˆé–¢æ•° 1: Functionï¼š Initialize(â†ªLu_1D43A) 2: for ğ‘– â† 1..ğ‘˜ do 3: Zã®ğ‘– ğ‘¡ åˆ—ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã‚“ã ãƒãƒ¼ãƒ‰ã®éš£äººã«è¨­å®š 4: end for 5: return Z 6: 7: Functionï¼š Proposal(áµ†, Z, ğº) // ğ‘™ << ğ‘˜ 8: áµ† â†Zã®åˆ—ã§â‰§1ã®è¡ŒãŒéã‚¼ãƒ­ (Ç”) // enumerateSubsets(áµ†,ğ‘™) size â‰¦áµ…ã®ã™ã¹ã¦ã®éƒ¨åˆ†é›†åˆã‚’æˆ»ã™ 9ï¼š for ğ‘  â† enumerateSubsets(ğ‘ ) do 10: fMap(ğ‘ ) â† ğ‘¢ (â†ªLl_1D460) // å¼2ã‚ãŸã‚Š 11: end for 12: return softmax(fMap) it wã«å¾“ã£ã¦ğ‘†ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ğ‘ ã‚’å¾—ã‚‹ã€‚ r.t.
the current vector; as ğ‘˜ increases, the space of community assignments increases exponentially which makes it very unlikely that the proposal will be able to generate an acceptable transition.
â†ªLl458â†©ãŒå¢—åŠ ã™ã‚‹ã¨ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å‰²ã‚Šå½“ã¦ã®ç©ºé–“ã¯æŒ‡æ•°é–¢æ•°çš„ã«å¢—åŠ ã™ã‚‹ãŸã‚ã€ææ¡ˆè€…ãŒè¨±å®¹ã§ãã‚‹é·ç§»ã‚’ç”Ÿæˆã§ãã‚‹å¯èƒ½æ€§ã¯éå¸¸ã«ä½ããªã‚Šã¾ã™ã€‚

Instead, we propose Neighborhood-aware MH, specified in Algorithm 3.
ãã®ä»£ã‚ã‚Šã«ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 3ã§è¦å®šã•ã‚Œã‚‹Neighborhood-aware MHã‚’ææ¡ˆã™ã‚‹ã€‚
The proposal function in Neighborhood-aware MH is based on two insights or assumptions â€“ the first is that it is extremely unlikely that a node should belong to a community that none of its neighbors currently belongs to; the second is that for most practical applications, it is unnecessary to assign a node to more than a small number of communities.
1ã¤ç›®ã¯ã€ã‚ã‚‹ãƒãƒ¼ãƒ‰ãŒã€ãã®éš£æ¥ã™ã‚‹ãƒãƒ¼ãƒ‰ãŒç¾åœ¨æ‰€å±ã—ã¦ã„ãªã„ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«æ‰€å±ã™ã‚‹å¯èƒ½æ€§ã¯æ¥µã‚ã¦ä½ã„ã¨ã„ã†ã“ã¨ã€2ã¤ç›®ã¯ã€ã»ã¨ã‚“ã©ã®å®Ÿç”¨çš„ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã€ãƒãƒ¼ãƒ‰ã‚’å°‘æ•°ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ä»¥ä¸Šã«æ‰€å±ã•ã›ã‚‹å¿…è¦ã¯ãªã„ã¨ã„ã†ã“ã¨ã§ã™ã€‚
We design a two-step proposal function that works as follows.
æ¬¡ã®ã‚ˆã†ãª2æ®µéšã®ææ¡ˆæ©Ÿèƒ½ã‚’è¨­è¨ˆã—ã¦ã„ã¾ã™ã€‚
In the first step, for a given node ğ‘¢ we iterate over all the neighbors of ğ‘¢, look up their community assignments in Z, and identify the set of communities which are represented at least once, call it ğ‘†.
æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€ä¸ãˆã‚‰ã‚ŒãŸãƒãƒ¼ãƒ‰ğ‘¢ã«ã¤ã„ã¦ã€ğ‘¢ã®ã™ã¹ã¦ã®è¿‘å‚ã‚’ç¹°ã‚Šè¿”ã—ã€Zã§å½¼ã‚‰ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å‰²ã‚Šå½“ã¦ã‚’æ¤œç´¢ã—ã€å°‘ãªãã¨ã‚‚ä¸€åº¦ã¯è¡¨ã•ã‚Œã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ã‚»ãƒƒãƒˆã‚’è­˜åˆ¥ã—ã€ãã‚Œã‚’ğ‘†ã¨å‘¼ã³ã¾ã™ã€‚
In the second step, we iterate over all subsets of size â‰¤ ğ‘™ of ğ‘† from the first step, where ğ‘™ is a user-provided upper bound on how many communities a node can be assigned to.
ã“ã“ã§ã€á‘™ã¯ãƒãƒ¼ãƒ‰ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®æ•°ã«å¯¾ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›ã®ä¸Šé™å€¤ã§ã‚ã‚‹ã€‚
For each subset ğ‘ , we calculate the function ğ‘“ (ğ‘¢, ğ‘ ) from Eqn 2, and finally sample the subset ğ‘  with probability proportional to ğ‘’ ğ‘“ (ğ‘¢,ğ‘ ) i.e.
å„ã‚µãƒ–ã‚»ãƒƒãƒˆğ‘ ã«ã¤ã„ã¦ã€å¼2ã‚ˆã‚Šé–¢æ•°áµ†ï¼ˆáµ†ï¼‰ã‚’è¨ˆç®—ã—ã€æœ€å¾Œã«ğ‘’ï¼ˆáµ†ï¼Œğ‘ ï¼‰ã«æ¯”ä¾‹ã™ã‚‹ç¢ºç‡ã§ã‚µãƒ–ã‚»ãƒƒãƒˆâ†ªLl460â†©ã‚’ã‚µãƒ³ãƒ—ãƒ«ã™ã‚‹ã€ã¤ã¾ã‚Š
we apply the softmax.
ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‚’é©ç”¨ã—ã¾ã™ã€‚
The result of the sampling is then either accepted or rejected, as specified in lines 6 and 7 of Algorithm 1.
ãã—ã¦ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 1ã®6è¡Œç›®ã¨7è¡Œç›®ã«è¦å®šã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®çµæœãŒå—ã‘å…¥ã‚Œã‚‰ã‚Œã‚‹ã‹ã€æ‹’å¦ã•ã‚Œã‚‹ã‹ã®ã©ã¡ã‚‰ã‹ã«ãªã‚Šã¾ã™ã€‚
As for initializing Z, we seed each community with the neighborhood for a randomly selected node in the graph.
Zã®åˆæœŸåŒ–ã«ã¤ã„ã¦ã¯ã€å„ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ã‚°ãƒ©ãƒ•å†…ã®ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã°ã‚ŒãŸãƒãƒ¼ãƒ‰ã®è¿‘å‚ã‚’ã‚·ãƒ¼ãƒ‰ã™ã‚‹ã€‚

We discuss a few important implementation details.
ã„ãã¤ã‹ã®é‡è¦ãªå®Ÿè£…ã®è©³ç´°ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚

- Most of the complexity comes from evaluating the function ğ‘“ (ğ‘¢, ğ‘ ), which requires calculating the intersection between a nodeâ€™s neighbors and the union of the communities in ğ‘ . For many members of ğ‘† (the set computed in line 8 Algorithm 3), we can incrementally compute the summary statistics required for ğ‘“ (ğ‘¢, ğ‘ ) as we go through a nodeâ€™s neighborhood when executing line 8 of Algorithm 3, so that the subsequent inner loop in line 10 can execute much faster. Similarly, the acceptance probability for line 6 of Algorithm 1 can also reuse the ğ‘“ (ğ‘¢, Z) computed during the proposal process. è¤‡é›‘ã•ã®ã»ã¨ã‚“ã©ã¯ã€é–¢æ•°ğ‘“ï¼ˆğ‘¢ï¼‰ã®è©•ä¾¡ã«ã‚ˆã‚‹ã‚‚ã®ã§ã€ãƒãƒ¼ãƒ‰ã®è¿‘å‚ã¨ğ‘ ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®çµåˆã®é–“ã®äº¤å·®ã‚’è¨ˆç®—ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ áµ†ï¼ˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 3ã®8è¡Œç›®ã§è¨ˆç®—ã•ã‚ŒãŸé›†åˆï¼‰ã®å¤šãã®ãƒ¡ãƒ³ãƒãƒ¼ã«ã¤ã„ã¦ã¯ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 3ã®8è¡Œç›®ã‚’å®Ÿè¡Œã™ã‚‹éš›ã«ã€ãƒãƒ¼ãƒ‰ã®è¿‘å‚ã‚’é€šéã™ã‚‹éš›ã«áµ†ï¼ˆáµ†ï¼Œâ†ªLl_1D460ï¼‰ ã«å¿…è¦ãªè¦ç´„çµ±è¨ˆé‡ã‚’æ®µéšçš„ã«è¨ˆç®—ã§ãã‚‹ãŸã‚ã€ç¶šã10è¡Œç›®ã®å†…éƒ¨ãƒ«ãƒ¼ãƒ—ã®å®Ÿè¡Œé€Ÿåº¦ãŒå¤§å¹…ã«å‘ä¸Šã—ã¾ã™ã€‚ åŒæ§˜ã«ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 1ã®6è¡Œç›®ã®å—ã‘å…¥ã‚Œç¢ºç‡ã‚‚ã€ææ¡ˆãƒ—ãƒ­ã‚»ã‚¹ã§è¨ˆç®—ã•ã‚ŒãŸğ‘¢ï¼ˆğ‘¢, Zï¼‰ã‚’å†åˆ©ç”¨ã§ãã‚‹ã€‚

- Sampling from a softmax distribution can be accomplished efficiently in a single pass using the Gumbel-Max trick. ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹åˆ†å¸ƒã‹ã‚‰ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¯ã€ã‚¬ãƒ³ãƒ™ãƒ«ãƒãƒƒã‚¯ã‚¹ãƒˆãƒªãƒƒã‚¯ã‚’ä½¿ã†ã“ã¨ã§1å›ã®ãƒ‘ã‚¹ã§åŠ¹ç‡çš„ã«è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚

- In the important special case where we assign each node to at most one community only, each epoch of Neighborhood-aware MH can execute in ğ‘‚(|ğ¸|) time, using both of the above mentioned tricks. 

- The algorithm lends itself well to parallelization. Specifically the for loop in line 4 of Algorithm 1 can be distributed among several threads which share access to Z, the rows of which can optionally be synchronized using read-write locks. In practice, we have found that removing synchronization has no effect on the accuracy and gives a slight boost in speed (similar to [24]). ã“ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€ä¸¦åˆ—åŒ–ã«é©ã—ã¦ã„ã‚‹ã€‚ å…·ä½“çš„ã«ã¯ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 1ã®4è¡Œç›®ã®forãƒ«ãƒ¼ãƒ—ã‚’ã€Zã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’å…±æœ‰ã™ã‚‹è¤‡æ•°ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã«åˆ†æ•£ã•ã›ã‚‹ã“ã¨ãŒã§ãã€ãã®è¡Œã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§èª­ã¿æ›¸ããƒ­ãƒƒã‚¯ã‚’ä½¿ã£ã¦åŒæœŸã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ å®Ÿéš›ã«ã¯ã€åŒæœŸã‚’å‰Šé™¤ã—ã¦ã‚‚ç²¾åº¦ã«å½±éŸ¿ã¯ãªãã€é€Ÿåº¦ãŒã‚ãšã‹ã«å‘ä¸Šã™ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ã¦ã„ã¾ã™ï¼ˆ[24]ã¨åŒæ§˜ã§ã™ï¼‰ã€‚

## Step 3: Communities of Left Nodes ã‚¹ãƒ†ãƒƒãƒ—3ï¼šå·¦ãƒãƒ¼ãƒ‰ã®å…±åŒä½“

The output of the previous step is the matrix V|ğ‘…|Ã—ğ‘˜ in which the ğ‘–- th row specifies the communities to which the right-node ğ‘– has been assigned.
ğ‘…
The remaining problem that needs to be solved is coming up with the matrix U|ğ¿|Ã—ğ‘˜ such that the ğ‘–-th row specifies the communities to which the left-node ğ‘– has been assigned.
ğ¿
A simple way to do this assignment is to assign a left-node to communities by looking at the communities that its neighbors (which will all be right-nodes, and hence already have assignments) have been assigned to.
ã“ã®å‰²ã‚Šå½“ã¦ã‚’è¡Œã†ç°¡å˜ãªæ–¹æ³•ã¯ã€å·¦ãƒãƒ¼ãƒ‰ã®éš£äººï¼ˆã™ã¹ã¦å³ãƒãƒ¼ãƒ‰ã§ã‚ã‚‹ãŸã‚ã€ã™ã§ã«å‰²ã‚Šå½“ã¦ã‚’å—ã‘ã¦ã„ã‚‹ï¼‰ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’è¦‹ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€å·¦ãƒãƒ¼ãƒ‰ã‚’ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã§ã™ã€‚
More formally, if A|ğ¿|Ã— |ğ‘…| is the adjacency matrix of the input bipartite graph, then we set U = ğ‘¡ğ‘Ÿğ‘¢ğ‘›ğ‘ğ‘ğ‘¡ğ‘’ (A Â· V), where the ğ‘¡ğ‘Ÿğ‘¢ğ‘›ğ‘ğ‘ğ‘¡ğ‘’ function keeps only up to a certain number of nonzeros per row to save on storage.
ğ¿
This equation for calculating U is motivated by the fact that in the special case when V is an orthonormal matrix, i.e.
ã“ã®Uã®è¨ˆç®—å¼ã¯ã€VãŒæ­£è¦ç›´äº¤è¡Œåˆ—ã§ã‚ã‚‹å ´åˆã®ç‰¹æ®Šãªã‚±ãƒ¼ã‚¹ã€ã™ãªã‚ã¡ã€æ¬¡ã®äº‹å®Ÿã«å‹•æ©Ÿã¥ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã€‚
V ğ‘‡ V = ğ¼, then U = A Â· V is the solution to A = U Â· V ğ‘‡ .
V áµ„ V = ğ¼ ã§ã‚ã‚Œã°ã€U = A - V ã¯ A = U - V ğ‘‡ ã®è§£ã«ãªã‚Šã¾ã™ã€‚
We have experimented with situations both where V is orthonormal (this can be achieved by assigning each right-node to at most one community) as well as situations where V is not, and have found that in each case the resulting U provides accurate representations for the left-nodes.
VãŒç›´äº¤ã™ã‚‹å ´åˆï¼ˆã“ã‚Œã¯ã€å„å³ãƒãƒ¼ãƒ‰ã‚’æœ€å¤§1ã¤ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã§å®Ÿç¾ã§ãã‚‹ï¼‰ã¨ã€ãã†ã§ãªã„å ´åˆã®ä¸¡æ–¹ã§å®Ÿé¨“ã‚’è¡Œã„ã€ã„ãšã‚Œã®å ´åˆã‚‚ã€çµæœã¨ã—ã¦å¾—ã‚‰ã‚Œã‚‹UãŒå·¦ãƒãƒ¼ãƒ‰ã‚’æ­£ç¢ºã«è¡¨ç¾ã™ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚
We refer to U as User Interest Representations, and it forms the main input for subsequent steps.
Uã‚’User Interest Representationsã¨å‘¼ã³ã€ä»¥é™ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ä¸»è¦ãªã‚¤ãƒ³ãƒ—ãƒƒãƒˆã‚’å½¢æˆã™ã‚‹ã€‚
The computation in this step can be scaled to our requirements easily by implementing in a batch-distributed computing paradigm such as Hadoop MapReduce.
ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã®è¨ˆç®—ã¯ã€Hadoop MapReduceã®ã‚ˆã†ãªãƒãƒƒãƒåˆ†æ•£ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã§å®Ÿè£…ã™ã‚‹ã“ã¨ã§ã€æˆ‘ã€…ã®è¦æ±‚ã«åˆã‚ã›ã¦ç°¡å˜ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

# Stage 2: Item Representations Stage 2: ã‚¢ã‚¤ãƒ†ãƒ è¡¨ç¾

In this section, we describe how to compute representations for different items, such as Tweets, Hashtags, or users - which can be the targets for different recommendation problems.
æœ¬ç¯€ã§ã¯ã€ãƒ„ã‚¤ãƒ¼ãƒˆã€ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãªã©ã€æ§˜ã€…ãªæ¨è–¦å•é¡Œã®å¯¾è±¡ã¨ãªã‚Šã†ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã«å¯¾ã™ã‚‹è¡¨ç¾ã‚’è¨ˆç®—ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦èª¬æ˜ã™ã‚‹ã€‚
Along with the user interest representations U from Stage 1, this stage also relies on a userâ€“item bipartite graph that is formed from historical or on-going user engagements with those items on the platform.
ã‚¹ãƒ†ãƒ¼ã‚¸1ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼é–¢å¿ƒè¡¨ç¾Uã¨ã¨ã‚‚ã«ã€ã“ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã¯ã€ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ä¸Šã®ã‚¢ã‚¤ãƒ†ãƒ ã«å¯¾ã™ã‚‹æ­´å²çš„ã¾ãŸã¯ç¶™ç¶šçš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢ä¸ã‹ã‚‰å½¢æˆã•ã‚Œã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼-ã‚¢ã‚¤ãƒ†ãƒ äºŒéƒ¨ã‚°ãƒ©ãƒ•ã«ã‚‚ä¾æ‹ ã™ã‚‹ã€‚

Our general framework is to compute an itemâ€™s representation by aggregating the representations of all the users who engaged with it, i.e., the representation for item ğ‘— is
ç§ãŸã¡ã®ä¸€èˆ¬çš„ãªæ çµ„ã¿ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ã«é–¢ã‚ã£ãŸã™ã¹ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¡¨ç¾ã‚’é›†ç´„ã—ã¦ã‚¢ã‚¤ãƒ†ãƒ ã®è¡¨ç¾ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã§ã™ã€‚ã¤ã¾ã‚Šã€ã‚¢ã‚¤ãƒ†ãƒ á‘—ã®è¡¨ç¾ã¯

$$
\tag{3}
$$

where N (ğ‘—) denotes all the users who engaged with item ğ‘— in the corresponding userâ€“item bipartite graph, and W(ğ‘—) and U(ğ‘¢) are both vectors.
ã“ã“ã§ã€Nï¼ˆâ†ªLl457â†©ï¼‰ã¯ã€å¯¾å¿œã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼-ã‚¢ã‚¤ãƒ†ãƒ äºŒéƒ¨ã‚°ãƒ©ãƒ•ã«ãŠã„ã¦ã‚¢ã‚¤ãƒ†ãƒ â†ªLl457â†©ã«é–¢ä¸ã—ãŸã™ã¹ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ç¤ºã—ã€Wï¼ˆâ†ªLl457â†©ï¼‰ã¨Uï¼ˆâ†ªLl462â†©ï¼‰ã¯ã„ãšã‚Œã‚‚ãƒ™ã‚¯ãƒˆãƒ«ã¨ã™ã‚‹ã€‚
The ğ‘ğ‘”ğ‘”ğ‘Ÿğ‘’ğ‘”ğ‘ğ‘¡ğ‘’ function can be chosen based on different applications, and can also be learned from a specific supervised task [13].
ğ‘ğ‘”ğ‘’é–¢æ•°ã¯ã€ã•ã¾ã–ã¾ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«åŸºã¥ã„ã¦é¸æŠã™ã‚‹ã“ã¨ãŒã§ãã€ç‰¹å®šã®æ•™å¸«ä»˜ãã‚¿ã‚¹ã‚¯ã‹ã‚‰å­¦ç¿’ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™[13]ã€‚
In our case, we opt for a relatively simple, interpretable ğ‘ğ‘”ğ‘”ğ‘Ÿğ‘’ğ‘”ğ‘ğ‘¡ğ‘’ function with the goal that W(ğ‘—, ğ‘) can be interpreted as the level of interest an average user of the community ğ‘ currently has in this item ğ‘—.
ã“ã®å ´åˆã€W(áµ…,áµ…)ã‚’ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ğ‘ã®å¹³å‡çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã“ã®ã‚¢ã‚¤ãƒ†ãƒ áµ…ã«ç¾åœ¨æŠ±ã„ã¦ã„ã‚‹èˆˆå‘³ã®ãƒ¬ãƒ™ãƒ«ã¨è§£é‡ˆã§ãã‚‹ã‚ˆã†ã«ã€æ¯”è¼ƒçš„å˜ç´”ã§è§£é‡ˆã—ã‚„ã™ã„ğ‘ğ‘’é–¢æ•°ã‚’é¸æŠã™ã‚‹ã“ã¨ã«ãªã‚‹ã€‚
We choose to use â€œexponentially time-decayed averageâ€ as our ğ‘ğ‘”ğ‘”ğ‘Ÿğ‘’ğ‘”ğ‘ğ‘¡ğ‘’ function, which exponentially decays the contribution of a user who interacted with the item based on how long ago that user engaged with the item.
ç§ãŸã¡ã¯ã€ğ‘ğ‘”ğ‘”é–¢æ•°ã¨ã—ã¦ã€ŒæŒ‡æ•°é–¢æ•°çš„æ™‚é–“æ¸›è¡°å¹³å‡ã€ã‚’é¸æŠã—ã¾ã—ãŸã€‚ã“ã‚Œã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ã«é–¢ã‚ã£ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è²¢çŒ®åº¦ã‚’ã€ãã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¢ã‚¤ãƒ†ãƒ ã«é–¢ã‚ã£ãŸæ™‚é–“ã«åŸºã¥ã„ã¦æŒ‡æ•°é–¢æ•°çš„ã«æ¸›è¡°ã•ã›ã¾ã™ã€‚
The half-life used for the exponential decay is item-dependent â€“ where the shelf-life of those items is longer (such as Topics), we set longer half-lives, while for shorter shelf life items such as Tweets, we set shorter half-lives.
æŒ‡æ•°é–¢æ•°çš„æ¸›è¡°ã«ä½¿ç”¨ã™ã‚‹åŠæ¸›æœŸã¯ã‚¢ã‚¤ãƒ†ãƒ ã«ä¾å­˜ã—ã€è³å‘³æœŸé™ãŒé•·ã„ã‚‚ã®ï¼ˆãƒˆãƒ”ãƒƒã‚¯ã‚¹ãªã©ï¼‰ã«ã¯é•·ã„åŠæ¸›æœŸã‚’è¨­å®šã—ã€è³å‘³æœŸé™ãŒçŸ­ã„ã‚‚ã®ï¼ˆãƒ„ã‚¤ãƒ¼ãƒˆãªã©ï¼‰ã«ã¯çŸ­ã„åŠæ¸›æœŸã‚’è¨­å®šã—ã¦ã„ã¾ã™ã€‚

The resulting matrix W is much denser than U and it is not useful to save all its non-zero values at scale.
çµæœã¨ã—ã¦å¾—ã‚‰ã‚Œã‚‹è¡Œåˆ—Wã¯Uã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«å¯†åº¦ãŒé«˜ãã€ãã®éã‚¼ãƒ­å€¤ã‚’ã™ã¹ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã§ä¿å­˜ã™ã‚‹ã“ã¨ã¯æœ‰ç›Šã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
Instead, we maintain two additional views or indexes of W, each of which keeps a top-k view.
ãã®ä»£ã‚ã‚Šã«ã€Wã®ãƒ“ãƒ¥ãƒ¼ã¾ãŸã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’2ã¤è¿½åŠ ã—ã€ãã‚Œãã‚ŒãŒãƒˆãƒƒãƒ—kãƒ“ãƒ¥ãƒ¼ã‚’ä¿æŒã™ã‚‹ã€‚
The first view is R and R (ğ‘—) tracks the top communities for the item ğ‘—.
ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãƒ“ãƒ¥ãƒ¼ã¯Rã§ã€Rï¼ˆâ†ªLl457â†©ï¼‰ã¯ã‚¢ã‚¤ãƒ†ãƒ â†ªLl457â†©ã®ãƒˆãƒƒãƒ—ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’è¿½è·¡ã—ã¾ã™ã€‚
The second view is C and C (ğ‘) tracks the top items for the community ğ‘.
ç¬¬äºŒã®ãƒ“ãƒ¥ãƒ¼ã¯Cã§ã€Cï¼ˆğ‘ï¼‰ã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ğ‘ã®ãƒˆãƒƒãƒ—ã‚¢ã‚¤ãƒ†ãƒ ã‚’è¿½è·¡ã—ã¾ã™ã€‚
In the case of items with a long shelf life, the calculation of W, R, and C is straightforwardly done in a batch setting using e.g.
è³å‘³æœŸé™ãŒé•·ã„ã‚‚ã®ã®å ´åˆã€Wã€Rã€Cã®è¨ˆç®—ã¯ã€ä¾‹ãˆã°ã€ãƒãƒƒãƒå¼ã§è¡Œã†ã®ãŒç´ ç›´ã§ã‚ã‚‹ã€‚
Hadoop MapReduce.
Hadoop MapReduceã§ã™ã€‚

However, handling items with short shelf life is more interesting.
ã—ã‹ã—ã€è³å‘³æœŸé™ãŒçŸ­ã„ã‚‚ã®ã‚’æ‰±ã†ã¨ãªã‚‹ã¨ã€ã‚‚ã£ã¨é¢ç™½ã„ã€‚
In this case, we realize a major advantage of an exponentially time-decayed average (as opposed to e.g.
ã“ã®å ´åˆã€æŒ‡æ•°é–¢æ•°çš„ã«æ™‚é–“æ¸›è¡°ã™ã‚‹å¹³å‡ã®å¤§ããªåˆ©ç‚¹ãŒå®Ÿç¾ã•ã‚Œã¾ã™ï¼ˆä¾‹ãˆã°ã€æ¬¡ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ï¼‰ã€‚
time-windowed average), which is that it lends itself to easy incremental updates for W.
time-windowed averageï¼‰ã€ã¤ã¾ã‚ŠWã®ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«ãªæ›´æ–°ãŒå®¹æ˜“ã§ã‚ã‚‹ã“ã¨ã«é©ã—ã¦ã„ã‚‹ã€‚
Specifically, we just need to keep two summary statistics for each cell in W - the current average itself and the last timestamp when it was updated.
å…·ä½“çš„ã«ã¯ã€Wã®å„ã‚»ãƒ«ã«ã¤ã„ã¦ã€ç¾åœ¨ã®å¹³å‡å€¤ãã®ã‚‚ã®ã¨ã€ãã‚ŒãŒæ›´æ–°ã•ã‚ŒãŸæœ€å¾Œã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨ã„ã†2ã¤ã®è¦ç´„çµ±è¨ˆé‡ã‚’ä¿æŒã™ã‚Œã°ã‚ˆã„ã®ã§ã™ã€‚
As detailed in Algorithm 4 lines 4â€“7, when a new userâ€“item engagement arrives, we are able to update W for the item by calculating a decay factor based on the time elapsed since the last update.
ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 4è¡Œç›®ã‹ã‚‰7è¡Œç›®ã«è©³è¿°ã™ã‚‹ã‚ˆã†ã«ã€æ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãŒåˆ°ç€ã™ã‚‹ã¨ã€å‰å›ã®æ›´æ–°ã‹ã‚‰ã®çµŒéæ™‚é–“ã«åŸºã¥ã„ã¦æ¸›è¡°ä¿‚æ•°ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã§ã€ã‚¢ã‚¤ãƒ†ãƒ ã®Wã‚’æ›´æ–°ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
In order to exactly track the row-wise and columnwise top-k views on W, it is necessary that we track the entirety of W - if it turns out that W is too big to be tracked in its entirety, then one can use sketches to keep a summary of W at the cost of introducing errors [4, 15], although we have found this unnecessary.
ã‚‚ã—WãŒå¤§ãã™ãã¦å…¨ä½“ã‚’è¿½è·¡ã§ããªã„ã“ã¨ãŒåˆ¤æ˜ã—ãŸå ´åˆã€ã‚¨ãƒ©ãƒ¼ã‚’å°å…¥ã™ã‚‹ä»£å„Ÿã¨ã—ã¦ã€ã‚¹ã‚±ãƒƒãƒã‚’ä½¿ã£ã¦Wã®è¦ç´„ã‚’ä¿æŒã™ã‚‹ã“ã¨ãŒã§ãã‚‹[4, 15]ãŒã€æˆ‘ã€…ã¯ã“ã®å¿…è¦ãŒãªã„ã¨åˆ¤æ–­ã—ã¦ã„ã‚‹ã€‚
Another way of reducing the size of W is to reduce ğ‘˜ i.e.
Wã®ã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹ã‚‚ã†ä¸€ã¤ã®æ–¹æ³•ã¯ã€â†ªLl458â†©ã‚’å°ã•ãã™ã‚‹ã€ã™ãªã‚ã¡
the dimensionality of the representations computed in Stage 1, or by further sparsifying the input user representations U.
ã‚¹ãƒ†ãƒ¼ã‚¸1ã§è¨ˆç®—ã•ã‚ŒãŸè¡¨ç¾ã®æ¬¡å…ƒã€ã¾ãŸã¯å…¥åŠ›ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼è¡¨ç¾Uã‚’ã•ã‚‰ã«ã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
Calculating streaming item representations in this manner can be implemented using frameworks such as Apache Storm/Heron/Spark/Flink.
ã“ã®ã‚ˆã†ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¢ã‚¤ãƒ†ãƒ è¡¨ç¾ã®è¨ˆç®—ã¯ã€Apache Storm/Heron/Spark/Flinkãªã©ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ã¦å®Ÿè£…ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚

The two top-k views R and C are stored in low-latency key-value stores.
2ã¤ã®top-kãƒ“ãƒ¥ãƒ¼Rã¨Cã¯ã€ä½é…å»¶ã®ã‚­ãƒ¼ãƒãƒªãƒ¥ãƒ¼ã‚¹ãƒˆã‚¢ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚
Using these two indices, it easy to retrieve nearest neighbors for any user or item â€“ we simply look up the top communities that a user or item is active in, and for each of those communities, identify the top users or items.
ã“ã®2ã¤ã®æŒ‡æ¨™ã‚’ç”¨ã„ã‚‹ã¨ã€ä»»æ„ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã®æœ€è¿‘æ¥è€…ã‚’ç°¡å˜ã«æ¤œç´¢ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ã‚¢ã‚¤ãƒ†ãƒ ãŒæ´»å‹•ã—ã¦ã„ã‚‹ä¸Šä½ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’èª¿ã¹ã€ãã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã”ã¨ã«ä¸Šä½ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç‰¹å®šã™ã‚‹ã ã‘ã§ã‚ˆã„ã®ã§ã™ã€‚
These candidates can then be ranked by fetching their full representations and computing the similarity with the representation of the query object (either user or item).
ã“ã‚Œã‚‰ã®å€™è£œã¯ã€ãã®å®Œå…¨ãªè¡¨ç¾ã‚’å–å¾—ã—ã€ã‚¯ã‚¨ãƒªãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã¾ãŸã¯ã‚¢ã‚¤ãƒ†ãƒ ã®ã„ãšã‚Œã‹ï¼‰ã®è¡¨ç¾ã¨ã®é¡ä¼¼æ€§ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ãƒ©ãƒ³ã‚¯ä»˜ã‘ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
The upshot is that we neither need to brute-force scan through all users/items nor need to build specialized nearest neighbor indices.
ãã®çµæœã€ã™ã¹ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç·å½“ãŸã‚Šã§ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹å¿…è¦ã‚‚ã€ç‰¹åˆ¥ãªæœ€è¿‘å‚ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹å¿…è¦ã‚‚ãªã„ã€‚

# Deployment Details é…ç½®ã®è©³ç´°

SimClusters has been deployed in production at Twitter for more than an year so far.
SimClustersã¯ã€Twitterç¤¾ã§1å¹´ä»¥ä¸Šå‰ã‹ã‚‰æœ¬ç•ªç’°å¢ƒã«å°å…¥ã•ã‚Œã¦ã„ã¾ã™ã€‚
All the representations output by the SimClusters system are also keyed by model-version, so that we can operate multiple models in parallel to enable the trying out of new parameters or code changes without affecting existing production.
SimClustersã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å‡ºåŠ›ã•ã‚Œã‚‹ã™ã¹ã¦ã®è¡¨ç¾ã¯ã€ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ãŠã‚Šã€è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸¦è¡Œã—ã¦é‹ç”¨ã™ã‚‹ã“ã¨ã§ã€æ—¢å­˜ã®ç”Ÿç”£ã«å½±éŸ¿ã‚’ä¸ãˆãšã«æ–°ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚„ã‚³ãƒ¼ãƒ‰ã®å¤‰æ›´ã‚’è©¦ã™ã“ã¨ãŒã§ãã¾ã™ã€‚
The main model that is currently running in production has âˆ¼105 communities in the representations, discovered from the similarity graph of the top âˆ¼107 users by follower count.
ç¾åœ¨ã€æœ¬ç•ªç¨¼åƒä¸­ã®ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ä¸Šä½âˆ¼107äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¡ä¼¼æ€§ã‚°ãƒ©ãƒ•ã‹ã‚‰ç™ºè¦‹ã•ã‚ŒãŸâˆ¼105ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒè¡¨ç¾ã•ã‚Œã¦ã„ã¾ã™ã€‚
The bipartite communities discovered by the model contain nearly 70% of the edges in the input bipartite graph, suggesting that most of the structure of the graph is captured.
ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ç™ºè¦‹ã•ã‚ŒãŸäºŒé …ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¯ã€å…¥åŠ›ã•ã‚ŒãŸäºŒé …ã‚°ãƒ©ãƒ•ã®ã‚¨ãƒƒã‚¸ã®70%è¿‘ãã‚’å«ã‚“ã§ãŠã‚Šã€ã‚°ãƒ©ãƒ•ã®æ§‹é€ ã®ã»ã¨ã‚“ã©ã‚’æ‰ãˆã¦ã„ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¾ã™ã€‚
The right member sets do not vary too much in their sizes, while the left member sets vary drastically, reflecting the variance in the original follower distribution.
å³ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚»ãƒƒãƒˆã®å¤§ãã•ã¯ã‚ã¾ã‚Šå¤‰ã‚ã‚‰ãªã„ãŒã€å·¦ã®ãƒ¡ãƒ³ãƒãƒ¼ã‚»ãƒƒãƒˆã®å¤§ãã•ã¯å¤§ããç•°ãªã‚Šã€å…ƒã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼åˆ†å¸ƒã®ã°ã‚‰ã¤ãã‚’åæ˜ ã—ã¦ã„ã‚‹ã€‚
Within Stage 1, Step 1 (similarity calculation) is the most expensive step, taking about 2 days to run end-to-end on Hadoop MapReduce, but note that this job was in production before SimClusters and therefore is not an additional cost introduced by SimClusters.
ã‚¹ãƒ†ãƒ¼ã‚¸1ã®ã†ã¡ã€ã‚¹ãƒ†ãƒƒãƒ—1ï¼ˆé¡ä¼¼åº¦è¨ˆç®—ï¼‰ã¯æœ€ã‚‚ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ã§ã€Hadoop MapReduceã§ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã§å®Ÿè¡Œã™ã‚‹ã®ã«ç´„2æ—¥ã‹ã‹ã‚Šã¾ã™ãŒã€ã“ã®ã‚¸ãƒ§ãƒ–ã¯SimClustersä»¥å‰ã‹ã‚‰é‹ç”¨ã•ã‚Œã¦ã„ãŸãŸã‚ã€SimClustersã«ã‚ˆã‚‹è¿½åŠ ã‚³ã‚¹ãƒˆã§ã¯ãªã„ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚
Step 2 was run from scratch for the very first time when SimClusters launched; subsequently, we update the V matrix to take into account changes to the userâ€“user similarity graph by running an abbreviated version of Neighborhood-aware MH initialized with the current V.
ã‚¹ãƒ†ãƒƒãƒ—2ã¯SimClustersã®èµ·å‹•æ™‚ã«åˆã‚ã¦å®Ÿè¡Œã•ã‚Œã¾ã—ãŸã€‚ãã®å¾Œã€ç¾åœ¨ã®Vã§åˆæœŸåŒ–ã—ãŸNeighborhood-aware MHã®çŸ­ç¸®ç‰ˆã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¡ä¼¼æ€§ã‚°ãƒ©ãƒ•ã®å¤‰åŒ–ã‚’è€ƒæ…®ã—ã€Vè¡Œåˆ—ã‚’æ›´æ–°ã—ã¦ã„ã¾ã™ã€‚
Step 3 is also periodically run as batch application on Hadoop MapReduce using the latest version of the userâ€“user graph and the latest V from Step 2.
ã¾ãŸã€Step3ã¯ã€æœ€æ–°ç‰ˆã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¦ãƒ¼ã‚¶ã‚°ãƒ©ãƒ•ã¨Step2ã®æœ€æ–°Vã‚’ä½¿ã„ã€Hadoop MapReduceä¸Šã§ãƒãƒƒãƒã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦å®šæœŸçš„ã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
Once we have the output from Step 3 (the U matrix), we do not directly use the V matrix anymore, which is typically too sparse for accurate modeling.
ã‚¹ãƒ†ãƒƒãƒ—3ã®å‡ºåŠ›ï¼ˆUè¡Œåˆ—ï¼‰ã‚’å¾—ãŸå¾Œã¯ã€Vè¡Œåˆ—ã‚’ç›´æ¥ä½¿ç”¨ã™ã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚Vè¡Œåˆ—ã¯ä¸€èˆ¬çš„ã«ç–ã™ãã¦æ­£ç¢ºãªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãŒã§ãã¾ã›ã‚“ã€‚

For Stage 2, we currently have four jobs â€“ two batch jobs, one for â€œuser influenceâ€ representations and one for Topic representations; and two streaming jobs, one for Tweet representations and one for Trend representations.
Stage2ã§ã¯ã€ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å½±éŸ¿åŠ›ã€è¡¨ç¾ã¨ã€Œè©±é¡Œã€è¡¨ç¾ã®2ã¤ã®ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ã¨ã€ã€Œãƒ„ã‚¤ãƒ¼ãƒˆã€è¡¨ç¾ã¨ã€Œãƒˆãƒ¬ãƒ³ãƒ‰ã€è¡¨ç¾ã®2ã¤ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã®è¨ˆ4ã¤ã®ã‚¸ãƒ§ãƒ–ã‚’ç¾åœ¨ç”¨æ„ã—ã¦ã„ã¾ã™ã€‚
The purpose of the user influence representations is to tell us what communities a user is influential in, as opposed to the user interest representations (the output of Stage 1) which tell us what communities a user is interested in, The user influence representations are better than the original original V matrix for this purpose as they cover many more users and are also denser for the original subset of users.
ãƒ¦ãƒ¼ã‚¶ãƒ¼å½±éŸ¿åŠ›è¡¨ç¾ã®ç›®çš„ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã©ã®ã‚ˆã†ãªã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«èˆˆå‘³ã‚’æŒã£ã¦ã„ã‚‹ã‹ã‚’ä¼ãˆã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼èˆˆå‘³è¡¨ç¾ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¸1ã®å‡ºåŠ›ï¼‰ã¨ã¯å¯¾ç…§çš„ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã©ã®ã‚ˆã†ãªã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹ã‹ã‚’ä¼ãˆã‚‹ã“ã¨ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼å½±éŸ¿åŠ›è¡¨ç¾ã¯ã€ã‚ˆã‚Šå¤šãã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã‚«ãƒãƒ¼ã—ã€ã¾ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®ã‚µãƒ–ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã‚ˆã‚Šå¯†ã§ã‚ã‚‹ãŸã‚ã€ã“ã®ç›®çš„ã®ãŸã‚ã«å…ƒã®å…ƒã®Vãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã¾ã™ã€‚
Topic representations tell us which communities are the most interested in a Topic, and the input to computing these is both the user interest representations as well as a userâ€“Topic engagement graph.
ãƒˆãƒ”ãƒƒã‚¯è¡¨ç¾ã¯ã€ã©ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒãƒˆãƒ”ãƒƒã‚¯ã«æœ€ã‚‚èˆˆå‘³ã‚’æŒã£ã¦ã„ã‚‹ã‹ã‚’ç¤ºã™ã‚‚ã®ã§ã€ã“ã‚Œã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®å…¥åŠ›ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èˆˆå‘³è¡¨ç¾ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ãƒˆãƒ”ãƒƒã‚¯ã®é–¢ä¿‚ã‚°ãƒ©ãƒ•ã®ä¸¡æ–¹ã§ã™ã€‚
Tweet and Trend representations are computed and updated in a streaming job which takes as input userâ€“Tweet engagements happening in real-time.
ãƒ„ã‚¤ãƒ¼ãƒˆã¨ãƒˆãƒ¬ãƒ³ãƒ‰ã®è¡¨ç¾ã¯ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç™ºç”Ÿã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ãƒ„ã‚¤ãƒ¼ãƒˆã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚’å…¥åŠ›ã¨ã™ã‚‹ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã§è¨ˆç®—ãƒ»æ›´æ–°ã•ã‚Œã¾ã™ã€‚
Both the user interest and user influence representations are protected using authentication to only allow authorized access, and users are provided the chance to opt out of unwanted inferences in their Privacy dashboard.
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒã¨å½±éŸ¿åŠ›ã®è¡¨ç¾ã¯ã€èªè¨¼ã«ã‚ˆã‚Šè¨±å¯ã•ã‚ŒãŸã‚¢ã‚¯ã‚»ã‚¹ã®ã¿ã‚’è¨±å¯ã™ã‚‹ã‚ˆã†ä¿è­·ã•ã‚Œã¦ãŠã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ä¸è¦ãªæ¨è«–ã‚’ã‚ªãƒ—ãƒˆã‚¢ã‚¦ãƒˆã™ã‚‹æ©Ÿä¼šã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

Note that we store only the non-zeros in all our representations, and in all cases we truncate entries close to zero.
ã™ã¹ã¦ã®è¡¨ç¾ã«ãŠã„ã¦ã€ã‚¼ãƒ­ã§ãªã„ã‚‚ã®ã ã‘ã‚’ä¿å­˜ã—ã€ã™ã¹ã¦ã®å ´åˆã«ãŠã„ã¦ã‚¼ãƒ­ã«è¿‘ã„ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’åˆ‡ã‚Šæ¨ã¦ã¦ã„ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚
The user interest representations cover âˆ¼109 users while the user influence representations cover âˆ¼108 users, with both representations having on average 10âˆ’100 non-zeros.
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èˆˆå‘³è¡¨ç¾ã¯ç´„109äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã‚«ãƒãƒ¼ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å½±éŸ¿è¡¨ç¾ã¯ç´„108äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã‚«ãƒãƒ¼ã—ã¦ãŠã‚Šã€ã©ã¡ã‚‰ã®è¡¨ç¾ã‚‚å¹³å‡10-100å€‹ã®éã‚¼ãƒ­ã‚’æœ‰ã—ã¦ã„ã‚‹ã€‚
There are fewer recommendable Tweets and Trends at any given point in time (refer Table 1), but their representations are denser, having on average âˆ¼102 non-zeros.
ã‚ã‚‹æ™‚ç‚¹ã§æ¨å¥¨ã•ã‚Œã‚‹ãƒ„ã‚¤ãƒ¼ãƒˆã‚„ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ•°ã¯å°‘ãªã„ãŒï¼ˆè¡¨1å‚ç…§ï¼‰ã€ãã®è¡¨ç¾ã¯ã‚ˆã‚Šå¯†ã§ã€å¹³å‡ã—ã¦ç´„102ã®ãƒãƒ³ã‚¼ãƒ­ã‚’æŒã¤ã€‚
Note that for the following four representations - user influence, Topic, Tweet, and Trend - we also maintain the inverted indices, i.e.
ãªãŠã€ä»¥ä¸‹ã®4ã¤ã®è¡¨ç¾ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å½±éŸ¿åŠ›ã€ãƒˆãƒ”ãƒƒã‚¯ã€ãƒ„ã‚¤ãƒ¼ãƒˆã€ãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰ã«ã¤ã„ã¦ã¯ã€åè»¢ã—ãŸæŒ‡æ¨™ã‚‚ç¶­æŒã—ã¦ã„ã‚‹ã€‚
given a community, what are the top-k users/Topics/Tweets/Trends for that community (denoted by C in Section 4).
ã‚ã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€ãã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãƒˆãƒƒãƒ—kãƒ¦ãƒ¼ã‚¶ãƒ¼/ãƒˆãƒ”ãƒƒã‚¯/ãƒ„ã‚¤ãƒ¼ãƒˆ/ãƒˆãƒ¬ãƒ³ãƒ‰ã¯ä½•ã‹ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³4ã§ã¯Cã¨è¡¨è¨˜ã™ã‚‹ï¼‰ã€‚
Having C is essential to retrieving the items whose representation has the largest dot product or cosine similarity with another representation.
Cã¯ã€ä»–ã®è¡¨ç¾ã¨ã®ãƒ‰ãƒƒãƒˆç©ã‚„ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒæœ€ã‚‚å¤§ãã„è¡¨ç¾ã‚’æŒã¤ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã«ä¸å¯æ¬ ã§ã‚ã‚‹ã€‚

# Applications ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

## Similar Tweets on Tweet Details page ãƒ„ã‚¤ãƒ¼ãƒˆè©³ç´°ãƒšãƒ¼ã‚¸ã§ã®é¡ä¼¼ãƒ„ã‚¤ãƒ¼ãƒˆ

For users who visit a Tweet via an email or a push notification, Twitter shows a module with other recommended Tweets, alongside replies.
ãƒ¡ãƒ¼ãƒ«ã‚„ãƒ—ãƒƒã‚·ãƒ¥é€šçŸ¥ã§ãƒ„ã‚¤ãƒ¼ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾ã—ã¦ã€Twitterã¯ä»–ã®ãŠã™ã™ã‚ãƒ„ã‚¤ãƒ¼ãƒˆã¨è¿”ä¿¡ã‚’ä¸¦ã¹ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
Prior to SimClusters, this module retrieved Tweets solely based on author similarity i.e.
SimClustersä»¥å‰ã¯ã€ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ä½œè€…ã®é¡ä¼¼æ€§ã ã‘ã«åŸºã¥ã„ã¦ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æ¤œç´¢ã—ã¦ã„ã¾ã—ãŸï¼ˆã¤ã¾ã‚Šã€ä½œè€…ã®é¡ä¼¼æ€§ã ã‘ã§ã€ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æ¤œç´¢ã—ã¦ã„ã¾ã—ãŸï¼‰ã€‚
Tweets written by users who share a lot of followers with the author of the main Tweet on the page.
ãƒšãƒ¼ã‚¸å†…ã®ãƒ¡ã‚¤ãƒ³ãƒ„ã‚¤ãƒ¼ãƒˆã®ä½œè€…ã¨å¤šãã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã‚’å…±æœ‰ã—ã¦ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ›¸ã„ãŸãƒ„ã‚¤ãƒ¼ãƒˆã€‚
We ran an online A/B test where we added similar Tweets from SimClusters i.e.
SimClustersã®é¡ä¼¼ãƒ„ã‚¤ãƒ¼ãƒˆã‚’è¿½åŠ ã—ãŸã‚ªãƒ³ãƒ©ã‚¤ãƒ³A/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã—ã¾ã—ãŸï¼ˆä¾‹ï¼‰ã€‚
we retrieved Tweets whose SimClusters representation has high cosine similarity with the representation of the main Tweet on the page.
ã¯ã€SimClustersè¡¨ç¾ãŒãã®ãƒšãƒ¼ã‚¸ã®ãƒ¡ã‚¤ãƒ³ãƒ„ã‚¤ãƒ¼ãƒˆã®è¡¨ç¾ã¨é«˜ã„ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’æŒã¤ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æ¤œç´¢ã—ã¾ã—ãŸã€‚
We found that the engagement rate on the resulting Tweets was 25% higher.4
ãã®çµæœã€ãƒ„ã‚¤ãƒ¼ãƒˆã«å¯¾ã™ã‚‹ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ãŒ25ï¼…é«˜ããªã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸ4ã€‚

Subsequently, we added a second candidate source for this product based on SimClusters â€“ retrieve Tweets whose SimClusters representation have high cosine similarity with the user influence representation of the author of the main Tweet on the page.
ãã®å¾Œã€SimClustersã«åŸºã¥ãã“ã®è£½å“ã®ç¬¬äºŒã®ã‚½ãƒ¼ã‚¹å€™è£œã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚SimClustersè¡¨ç¾ãŒã€ãƒšãƒ¼ã‚¸ä¸Šã®ãƒ¡ã‚¤ãƒ³ãƒ„ã‚¤ãƒ¼ãƒˆã®è‘—è€…ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å½±éŸ¿åŠ›è¡¨ç¾ã¨é«˜ã„ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼æ€§ã‚’æŒã¤ãƒ„ã‚¤ãƒ¼ãƒˆã‚’æ¤œç´¢ã—ã¾ã™ã€‚
Adding this source increases the coverage further, while the overall increase in engagement rate is a more modest but still impressive 7%.
ã“ã®ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ã‚«ãƒãƒ¼ç‡ã¯ã•ã‚‰ã«å‘ä¸Šã—ã€å…¨ä½“ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã®å‘ä¸Šã¯ã€ã‚ˆã‚Šæ§ãˆã‚ã§ã¯ã‚ã‚Šã¾ã™ãŒã€ãã‚Œã§ã‚‚7ï¼…ã¨ã„ã†ç´ æ™´ã‚‰ã—ã„çµæœã¨ãªã£ã¦ã„ã¾ã™ã€‚

## Tweet Recommendations in Home Page ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã§ãŠã™ã™ã‚ãƒ„ã‚¤ãƒ¼ãƒˆ

A userâ€™s Home feed on Twitter consists of both Tweets from users being directly followed as well as recommended Tweets from users not being followed (â€œOut of Network Tweetsâ€).
Twitterã®ãƒ›ãƒ¼ãƒ ãƒ•ã‚£ãƒ¼ãƒ‰ã¯ã€ç›´æ¥ãƒ•ã‚©ãƒ­ãƒ¼ã•ã‚Œã¦ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ„ã‚¤ãƒ¼ãƒˆã¨ã€ãƒ•ã‚©ãƒ­ãƒ¼ã•ã‚Œã¦ã„ãªã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãŠã™ã™ã‚ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆä»¥ä¸‹ã€Œãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¤–ãƒ„ã‚¤ãƒ¼ãƒˆã€ï¼‰ã®ä¸¡æ–¹ã‹ã‚‰æ§‹æˆã•ã‚Œã¾ã™ã€‚
Prior to SimClusters, the main algorithm for recommended Tweets was what is called â€œNetwork Activityâ€ - namely, use GraphJet [31] to identify which Tweets are being liked by the viewing userâ€™s followings (i.e.
SimClustersä»¥å‰ã¯ã€æ¨å¥¨ãƒ„ã‚¤ãƒ¼ãƒˆã®ä¸»ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€Œãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã€ã¨å‘¼ã°ã‚Œã‚‹ã‚‚ã®ã§ã—ãŸã€‚ã¤ã¾ã‚Šã€GraphJet [31]ã‚’ä½¿ç”¨ã—ã¦ã€é–²è¦§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ï¼ˆã¤ã¾ã‚Šã€ã€Œã„ã„ã­!
network).
ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯)ã€‚

Using SimClusters Tweet representations, we built two candidate sources to supplement Network Activity Tweets.
SimClustersã®ãƒ„ã‚¤ãƒ¼ãƒˆè¡¨ç¾ã‚’ä½¿ã£ã¦ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ„ã‚¤ãƒ¼ãƒˆã‚’è£œè¶³ã™ã‚‹2ã¤ã®ã‚½ãƒ¼ã‚¹å€™è£œã‚’æ§‹ç¯‰ã—ã¾ã—ãŸã€‚
The first candidate source identifies Tweets whose real-time representation has the highest dot-product with the viewing userâ€™s interest representation.
ç¬¬1ã®å€™è£œã‚½ãƒ¼ã‚¹ã¯ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¾ãŒé–²è¦§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èˆˆå‘³è¡¨ç¾ã¨ã®ãƒ‰ãƒƒãƒˆç©ãŒæœ€ã‚‚é«˜ã„ãƒ„ã‚¤ãƒ¼ãƒˆã‚’ç‰¹å®šã™ã‚‹ã€‚
The second candidate source is based on item-based collaborative filtering, and uses the same underlying implementation as the â€œSimilar Tweetsâ€ application described in Section 6.1 to identify Tweets similar to those Tweets which have been recently liked by the user.
2ã¤ç›®ã®å€™è£œã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ãƒ™ãƒ¼ã‚¹ã®å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«åŸºã¥ãã‚‚ã®ã§ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³6.1ã§èª¬æ˜ã—ãŸã€Œé¡ä¼¼ãƒ„ã‚¤ãƒ¼ãƒˆã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨åŒã˜åŸºæœ¬çš„ãªå®Ÿè£…ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ€è¿‘ã€Œã„ã„ã­ï¼ã€ã‚’æŠ¼ã—ãŸãƒ„ã‚¤ãƒ¼ãƒˆã¨é¡ä¼¼ã™ã‚‹ãƒ„ã‚¤ãƒ¼ãƒˆã‚’ç‰¹å®šã—ã¾ã™ã€‚
We ran an online A/B test by replacing existing candidates in production (in certain positions on Home) using the candidates from these two new candidate sources.
ã“ã®2ã¤ã®æ–°ã—ã„å€™è£œè€…ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®å€™è£œè€…ã‚’ã€æœ¬ç•ªã®æ—¢å­˜ã®å€™è£œè€…ï¼ˆHomeã®ç‰¹å®šã®ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼‰ã«ç½®ãæ›ãˆã¦ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§A/Bãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚
The experiment showed that the engagement rate of the new candidates is 33% higher than that for candidates generated by Network Activity, and shown in similar positions.
å®Ÿé¨“ã§ã¯ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã§ç”Ÿæˆã•ã‚ŒãŸå€™è£œè€…ã¨æ¯”è¼ƒã—ã¦ã€æ–°ã—ã„å€™è£œè€…ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ãŒ33%é«˜ãã€åŒã˜ã‚ˆã†ãªãƒã‚¸ã‚·ãƒ§ãƒ³ã§è¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚
The two candidate sources together were able to increase total weighted engagements on the platform by close to 1%, which is very large considering the maturity of this product and that recommended Tweets only account for a minority of the viewed content in Home pages.
ã“ã‚Œã¯ã€æœ¬è£½å“ã®æˆç†Ÿåº¦ã‚„ã€ãŠã™ã™ã‚ãƒ„ã‚¤ãƒ¼ãƒˆãŒãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã®é–²è¦§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å°‘æ•°æ´¾ã§ã‚ã‚‹ã“ã¨ã‚’è€ƒãˆã‚‹ã¨ã€éå¸¸ã«å¤§ããªåŠ¹æœã§ã™ã€‚

Apart from new candidates, we also use the user interest and Tweet representations to improve the ranking of candidates coming from all sources.
æ–°ã—ã„å€™è£œã¨ã¯åˆ¥ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èˆˆå‘³ã‚„ãƒ„ã‚¤ãƒ¼ãƒˆè¡¨ç¾ã‚’åˆ©ç”¨ã—ã¦ã€ã‚ã‚‰ã‚†ã‚‹ã‚½ãƒ¼ã‚¹ã‹ã‚‰æ¥ã‚‹å€™è£œã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’æ”¹å–„ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚
The user and item representations are used to enrich the set of existing user features, item features, as well as user-item interaction features in the input to an engagement prediction model.
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®è¡¨ç¾ã¯ã€ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ã«ãŠã„ã¦ã€æ—¢å­˜ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ç‰¹å¾´ã€ã‚¢ã‚¤ãƒ†ãƒ ç‰¹å¾´ã€ãŠã‚ˆã³ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ç›¸äº’ä½œç”¨ç‰¹å¾´ã®ã‚»ãƒƒãƒˆã‚’è±Šã‹ã«ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
A/B testing showed that the model trained with these features was able to increase engagement rate of recommended content by 4.7% relatively, which is a significant lift for a mature model.
A/Bãƒ†ã‚¹ãƒˆã§ã¯ã€ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã§å­¦ç¿’ã•ã›ãŸãƒ¢ãƒ‡ãƒ«ã¯ã€æ¨å¥¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã‚’4.7%ç›¸å¯¾çš„ã«é«˜ã‚ã‚‹ã“ã¨ãŒã§ãã€æˆç†Ÿã—ãŸãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã¯å¤§ããªãƒªãƒ•ãƒˆã‚¢ãƒƒãƒ—åŠ¹æœãŒã‚ã‚Šã¾ã—ãŸã€‚

## Ranking of Personalized Trends ##

Showing top trending content (e.g., Hashtags, Events, breaking news) is an important way to keep users informed about what is happening locally and globally.
ãƒˆãƒƒãƒ—ãƒˆãƒ¬ãƒ³ãƒ‰ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã€ã‚¤ãƒ™ãƒ³ãƒˆã€ãƒ‹ãƒ¥ãƒ¼ã‚¹é€Ÿå ±ãªã©ï¼‰ã‚’è¡¨ç¤ºã™ã‚‹ã“ã¨ã¯ã€åœ°åŸŸã‚„ä¸–ç•Œã§èµ·ã“ã£ã¦ã„ã‚‹ã“ã¨ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«çŸ¥ã‚‰ã›ã‚‹é‡è¦ãªæ–¹æ³•ã§ã™ã€‚
The implementation for Trends follows a two-stage process of Trends detection followed by ranking.
Trendsã®å®Ÿè£…ã¯ã€Trendsã®æ¤œå‡ºã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®2æ®µéšã‚’è¸ã‚“ã§ã„ã¾ã™ã€‚
Prior to SimClusters, the ranking of a Trend primarily depended on its volume and a small number of personalization features.
SimClustersä»¥å‰ã¯ã€ãƒˆãƒ¬ãƒ³ãƒ‰ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯ä¸»ã«ãã®ãƒœãƒªãƒ¥ãƒ¼ãƒ ã¨å°‘æ•°ã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºæ©Ÿèƒ½ã«ã‚ˆã£ã¦æ±ºå®šã•ã‚Œã¦ã„ã¾ã—ãŸã€‚
We used Trends SimClusters representations to score Trends for a given user by using the dot-product of the userâ€™s interest representation along with the real-time representation for a Trend.
ãƒˆãƒ¬ãƒ³ãƒ‰ã®SimClustersè¡¨ç¾ã‚’ä½¿ã£ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒè¡¨ç¾ã¨ãƒˆãƒ¬ãƒ³ãƒ‰ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¾ã®ãƒ‰ãƒƒãƒˆãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ä¸ãˆã‚‰ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ã‚¹ã‚³ã‚¢åŒ–ã—ã¾ã—ãŸã€‚
A/B testing revealed that using these scores led to a 8% increase in user engagement with the Trends themselves, as well as a bigger 12% increase in engagement on the landing page subsequent to a click.
A/Bãƒ†ã‚¹ãƒˆã§ã¯ã€ã“ã®ã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€Trendsè‡ªä½“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãŒ8ï¼…å¢—åŠ ã—ã€ã•ã‚‰ã«ã‚¯ãƒªãƒƒã‚¯å¾Œã®ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒšãƒ¼ã‚¸ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãŒ12ï¼…å¢—åŠ ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚
These improvements are large when compared against other experiments run on this product.
ã“ã‚Œã‚‰ã®æ”¹å–„ã¯ã€ã“ã®è£½å“ã§è¡Œã‚ã‚ŒãŸä»–ã®å®Ÿé¨“ã¨æ¯”è¼ƒã™ã‚‹ã¨ã€å¤§ããªã‚‚ã®ã§ã™ã€‚

## Topic Tweet Recommendations ãƒˆãƒ”ãƒƒã‚¯ ãƒ„ã‚¤ãƒ¼ãƒˆ ãŠã™ã™ã‚åº¦

Given a Topic in a pre-defined topic taxonomy such as â€œFashionâ€ or â€œMarvel Moviesâ€, how can we identify the best content about it? The original implementation here (before the product was launched publicly) primarily relied on custom text matching rules curated by human experts to identify topical Tweets.
ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ã€ã‚„ã€Œãƒãƒ¼ãƒ™ãƒ«æ˜ ç”»ã€ãªã©ã€ã‚ã‚‰ã‹ã˜ã‚å®šç¾©ã•ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯åˆ†é¡æ³•ã®ãƒˆãƒ”ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã€ãã®ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹æœ€é«˜ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç‰¹å®šã™ã‚‹ã«ã¯ã©ã†ã™ã‚Œã°ã‚ˆã„ã§ã—ã‚‡ã†ã‹ã€‚ã“ã“ã§ã®ã‚ªãƒªã‚¸ãƒŠãƒ«ã®å®Ÿè£…ï¼ˆè£½å“ãŒä¸€èˆ¬ã«ç™ºå£²ã•ã‚Œã‚‹å‰ï¼‰ã¯ã€ä¸»ã«äººé–“ã®å°‚é–€å®¶ãŒã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸã‚«ã‚¹ã‚¿ãƒ ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãƒ³ã‚°ãƒ«ãƒ¼ãƒ«ã«ä¾å­˜ã—ã¦ã€ãƒˆãƒ”ãƒƒã‚¯ãƒ„ã‚¤ãƒ¼ãƒˆã‚’è­˜åˆ¥ã—ã¦ã„ã¾ã—ãŸã€‚
Once we realized that this approach surfaced a number of false positives (primarily due to a Tweetâ€™s text incidentally matching the rules for a Topic), we tested a second implementation where we first identify those Tweets whose SimClusters representation has high cosine similarity with the representation of the query Topic, and then apply the textual matching rules.
ã“ã®æ–¹æ³•ã§ã¯ã€å¤šãã®èª¤æ¤œå‡ºï¼ˆä¸»ã«ãƒ„ã‚¤ãƒ¼ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆãŒãƒˆãƒ”ãƒƒã‚¯ã®ãƒ«ãƒ¼ãƒ«ã¨å¶ç„¶ä¸€è‡´ã™ã‚‹ã“ã¨ã«ã‚ˆã‚‹ï¼‰ãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã®ã§ã€2ç•ªç›®ã®å®Ÿè£…ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã—ãŸã€‚ã¾ãšã€SimClustersè¡¨ç¾ãŒã‚¯ã‚¨ãƒªãƒˆãƒ”ãƒƒã‚¯ã®è¡¨ç¾ã¨é«˜ã„ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’æŒã¤ãƒ„ã‚¤ãƒ¼ãƒˆã‚’ç‰¹å®šã—ã€æ¬¡ã«ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãƒ³ã‚°è¦å‰‡ã‚’é©ç”¨ã—ã¾ã—ãŸã€‚
Internal evaluation showed that the second approach returned much better results, therefore we launched this product publicly using this approach.
ç¤¾å†…ã§è©•ä¾¡ã—ãŸã¨ã“ã‚ã€2ç•ªç›®ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ–¹ãŒã¯ã‚‹ã‹ã«è‰¯ã„çµæœãŒå¾—ã‚‰ã‚ŒãŸãŸã‚ã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§æœ¬è£½å“ã‚’ä¸€èˆ¬ç™ºå£²ã—ã¾ã—ãŸã€‚
Since launch, this feature has received positive press externally as well as causing higher engagement with Tweets from the broader user base.
ã“ã®æ©Ÿèƒ½ã¯ã€ç™ºå£²ä»¥æ¥ã€å¤–éƒ¨ã§å¥½è©•ã‚’åšã—ã€ã‚ˆã‚Šå¤šãã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ãƒ„ã‚¤ãƒ¼ãƒˆã¸ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚’é«˜ã‚ã¦ã„ã¾ã™ã€‚

## Ranking Who To Follow Recommendations ãƒ•ã‚©ãƒ­ãƒ¼ã™ã¹ãäººãƒ©ãƒ³ã‚­ãƒ³ã‚° ãŠã™ã™ã‚

The candidates for Who To Follow recommendations are ranked using an engagement prediction model, to which we added new features based on the SimClusters representations of the viewing user and the candidate user.
Who To Followãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®å€™è£œã¯ã€ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚Œã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã«ã¯ã€é–²è¦§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨å€™è£œãƒ¦ãƒ¼ã‚¶ãƒ¼ã®SimClustersè¡¨ç¾ã«åŸºã¥ãæ–°ã—ã„ç‰¹å¾´ãŒåŠ ãˆã‚‰ã‚Œã¦ã„ã¾ã™ã€‚
In A/B tests, we observed an impressive increase of 7% in the follow rate by using these new features.
A/Bãƒ†ã‚¹ãƒˆã§ã¯ã€ã“ã‚Œã‚‰ã®æ–°æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒ•ã‚©ãƒ­ãƒ¼ç‡ãŒ7ï¼…å‘ä¸Šã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚

## Applications in progress ç¾åœ¨é€²è¡Œä¸­ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

### Notifications quality filter. é€šçŸ¥å“è³ªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€‚

A crucial task on Twitter is to protect users from getting abusive or spammy replies or mentions.
Twitterã®é‡è¦ãªã‚¿ã‚¹ã‚¯ã¯ã€ç½µå€’ã‚„ã‚¹ãƒ‘ãƒ çš„ãªãƒªãƒ—ãƒ©ã‚¤ã‚„ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚’å—ã‘ãªã„ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ä¿è­·ã™ã‚‹ã“ã¨ã§ã™ã€‚
We developed new SimClusters representations for users based on the userâ€“user block graph (i.e.
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚°ãƒ©ãƒ•ã«åŸºã¥ããƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãŸã‚ã®æ–°ã—ã„SimClustersè¡¨ç¾ã‚’é–‹ç™ºã—ãŸï¼ˆã™ãªã‚ã¡ã€‚
when one user blocks another), and used these representations as features to train a model for filtering out abusive and spammy replies.
ã‚’è¡¨ç¾ã—ã€ã“ã‚Œã‚‰ã®è¡¨ç¾ã‚’ç‰¹å¾´é‡ã¨ã—ã¦ã€ç½µå€’ã‚„ã‚¹ãƒ‘ãƒ ã®è¿”ä¿¡ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ã„ã¾ã™ã€‚
In offline tests, the model showed an impressive 4% lift in PR-AUC5 .
ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆã§ã¯ã€PR-AUC5 ãŒ 4ï¼…å‘ä¸Šã™ã‚‹ã¨ã„ã†ç´ æ™´ã‚‰ã—ã„çµæœã‚’ç¤ºã—ã¾ã—ãŸã€‚

### 6.6.2 Supervised embeddings from feature combinations. 6.6.2 ç‰¹å¾´ã®çµ„ã¿åˆã‚ã›ã‹ã‚‰æ•™å¸«ä»˜ãåŸ‹è¾¼ã‚’è¡Œã†ã€‚

While SimClusters representations mostly capture information from various engagement graphs, we are also experimenting approaches to combine it with other features about users or items (for example, follower counts or geo information).
SimClustersã®è¡¨ç¾ã¯ã€ä¸»ã«æ§˜ã€…ãªã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚°ãƒ©ãƒ•ã‹ã‚‰æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ãŒã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã«é–¢ã™ã‚‹ä»–ã®ç‰¹å¾´ï¼ˆä¾‹ãˆã°ã€ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°ã‚„ã‚¸ã‚ªæƒ…å ±ï¼‰ã¨çµ„ã¿åˆã‚ã›ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚‚è©¦ã—ã¦ã„ã¾ã™ã€‚
One approach where we are obtaining promising early results is to train a deep neural network on an ancillary prediction task (such as engagement prediction) where the input features are both the user and item SimClusters representations along with previously developed features for the user and item.
ç§ãŸã¡ãŒæœ‰æœ›ãªåˆæœŸçµæœã‚’å¾—ã¦ã„ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®1ã¤ã¯ã€è£œåŠ©çš„ãªäºˆæ¸¬ã‚¿ã‚¹ã‚¯ï¼ˆã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆäºˆæ¸¬ãªã©ï¼‰ã§ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è¨“ç·´ã™ã‚‹ã“ã¨ã§ã€å…¥åŠ›ç‰¹å¾´ã¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®SimClustersè¡¨ç¾ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ãŸã‚ã«ä»¥å‰ã«é–‹ç™ºã—ãŸç‰¹å¾´ã®ä¸¡æ–¹ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
By choosing the right architecture for this neural net, for example, the two-tower DNN model [36], we are able to learn dense embeddings separately for users and items.
ã“ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã«é©åˆ‡ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ä¾‹ãˆã°2å¡”å¼DNNãƒ¢ãƒ‡ãƒ«[36]ã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã«ã¤ã„ã¦åˆ¥ã€…ã«å¯†ãªåŸ‹ã‚è¾¼ã¿ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚

### 6.6.3 Real-time Event notifications. 6.6.3 ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¤ãƒ™ãƒ³ãƒˆé€šçŸ¥ã€‚

A major application at Twitter is to notify users who may be interested when a major news event happens.
Twitterã§ã®ä¸»ãªç”¨é€”ã¯ã€å¤§ããªãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒèµ·ã“ã£ãŸã¨ãã«ã€èˆˆå‘³ã‚’æŒã¡ãã†ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é€šçŸ¥ã™ã‚‹ã“ã¨ã§ã™ã€‚
Using the SimClusters representation of an Event (which is in turn derived by aggregating the representations of the human-curated Tweets about it), we can identify the communities of users who will be interested in it, and subsequently target users interested in them.
ã‚¤ãƒ™ãƒ³ãƒˆã®SimClustersè¡¨ç¾ï¼ˆã“ã‚Œã¯ã€ãã®ã‚¤ãƒ™ãƒ³ãƒˆã«é–¢ã™ã‚‹äººé–“ã®ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹ãƒ„ã‚¤ãƒ¼ãƒˆã®è¡¨ç¾ã‚’é›†ç´„ã™ã‚‹ã“ã¨ã§å¾—ã‚‰ã‚Œã‚‹ï¼‰ã‚’ä½¿ã£ã¦ã€ãã®ã‚¤ãƒ™ãƒ³ãƒˆã«èˆˆå‘³ã‚’æŒã¤ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’ç‰¹å®šã—ã€ãã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«èˆˆå‘³ã‚’æŒã¤ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
We are currently evaluating such an approach.
ç¾åœ¨ã€ãã®ã‚ˆã†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’è©•ä¾¡ã—ã¦ã„ã¾ã™ã€‚

# Related Work é–¢é€£ä½œå“

Traditionally, approaches to recommender systems are categorized as either neighborhood-based (which do not involve model-fitting), or model-based (which fit a model to the input data).
å¾“æ¥ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã‚’ä¼´ã‚ãªã„ãƒã‚¤ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã¨ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã«åˆ†é¡ã•ã‚Œã¦ã„ã¾ã™ã€‚

In our experience of building recommendations at Twitter, we find that neighborhood-based methods are easier to scale, more accurate, more interpretable, and also more flexible in terms of accommodating new users and/or items [9, 11, 12, 31].
Twitterã§ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã—ãŸçµŒé¨“ã‹ã‚‰ã€è¿‘éš£ãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã¯ã€ã‚¹ã‚±ãƒ¼ãƒ«ãŒç°¡å˜ã§ã€ã‚ˆã‚Šæ­£ç¢ºã§ã€ã‚ˆã‚Šè§£é‡ˆã—ã‚„ã™ãã€ã¾ãŸæ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã«å¯¾å¿œã™ã‚‹ç‚¹ã§ã€ã‚ˆã‚ŠæŸ”è»Ÿã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸ [9, 11, 12, 31] ã€‚
Recent research has also found that well-tuned neighborhood-based methods are not easy to beat in terms of accuracy [6].
ã¾ãŸã€æœ€è¿‘ã®ç ”ç©¶ã§ã¯ã€ã‚ˆãèª¿æ•´ã•ã‚ŒãŸè¿‘å‚é ˜åŸŸãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã¯ã€ç²¾åº¦ã®é¢ã§ç°¡å˜ã«ã¯å‹ã¦ãªã„ã“ã¨ãŒåˆ†ã‹ã£ã¦ã„ã¾ã™[6]ã€‚
However, neighborhoodbased approaches do not provide a general solution â€“ we needed to build and maintain separate systems to solve each recommendation sub-problems at Twitter in the past (see Section 1 for more discussion of our past work).
ã—ã‹ã—ã€ãƒã‚¤ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ä¸€èˆ¬çš„ãªè§£æ±ºç­–ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã¯ãªãã€ç§ãŸã¡ã¯éå»ã«Twitterã§ãã‚Œãã‚Œã®æ¨è–¦ã‚µãƒ–å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«åˆ¥ã€…ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ãƒ»ç¶­æŒã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã—ãŸï¼ˆéå»ã®ç ”ç©¶ã«ã¤ã„ã¦ã®è©³ç´°ã¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³1ã‚’å‚ç…§ã—ã¦ãã ã•ã„ï¼‰ã€‚

Model-based approaches, such as factorized models [18], graph embedding [10, 26] or VAE [22], fit separate parameters for each user or item.
å› æ•°åˆ†è§£ãƒ¢ãƒ‡ãƒ«[18]ã€ã‚°ãƒ©ãƒ•åŸ‹ã‚è¾¼ã¿[10, 26]ã€VAE[22]ãªã©ã®ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã«å¯¾ã—ã¦åˆ¥ã€…ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å½“ã¦ã¯ã‚ã¾ã™ã€‚
The number of model parameters that need to be learned in order to scale to a billion-user social network can easily approach 1012, necessitating unprecedentedly large systems for solving ML problems at that scale.
10å„„äººè¦æ¨¡ã®ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«å¯¾å¿œã™ã‚‹ãŸã‚ã«ã¯ã€å­¦ç¿’ã™ã¹ããƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ•°ãŒ1012å€‹ã«é”ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã€ãã®ã‚ˆã†ãªè¦æ¨¡ã®MLå•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã¯ã€ã“ã‚Œã¾ã§ã«ãªã„å¤§è¦æ¨¡ãªã‚·ã‚¹ãƒ†ãƒ ãŒå¿…è¦ã¨ãªã‚Šã¾ã™ã€‚
Hybrid models, such as Factorization Machine [27] and Deep Neural Networks (DNNs) [5] have been introduced to reduce the parameter space by utilizing the side information as prior knowledge for users and items.
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã®äº‹å‰çŸ¥è­˜ã¨ã—ã¦ã‚µã‚¤ãƒ‰æƒ…å ±ã‚’æ´»ç”¨ã—ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã‚’ç¸®å°ã™ã‚‹ãŸã‚ã«ã€å› æ•°åˆ†è§£ãƒã‚·ãƒ³ [27] ã‚„ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ (DNN) [5] ãªã©ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ãŒå°å…¥ã•ã‚Œã¦ã„ã¾ã™ã€‚
However, they require either well-defined feature vectors or pre-trained embeddings from auxiliary tasks as the input representation of users and items.
ã—ã‹ã—ã€ã“ã‚Œã‚‰ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã®å…¥åŠ›è¡¨ç¾ã¨ã—ã¦ã€ã‚ˆãå®šç¾©ã•ã‚ŒãŸç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‹ã€è£œåŠ©ã‚¿ã‚¹ã‚¯ã‹ã‚‰äº‹å‰ã«è¨“ç·´ã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿ã‚’å¿…è¦ã¨ã—ã¾ã™ã€‚
Graph Convolutional Networks (GCNs) [16, 37] can enrich pre-existing feature representations of the nodes by propagating the neighborhood information from the graph, without fitting model parameters for each node.
ã‚°ãƒ©ãƒ•ç•³ã¿è¾¼ã¿ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆGCNï¼‰[16, 37]ã¯ã€å„ãƒãƒ¼ãƒ‰ã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ã“ã¨ãªãã€ã‚°ãƒ©ãƒ•ã‹ã‚‰è¿‘å‚æƒ…å ±ã‚’ä¼æ’­ã™ã‚‹ã“ã¨ã§ã€ãƒãƒ¼ãƒ‰ã®æ—¢å­˜ã®ç‰¹å¾´è¡¨ç¾ã‚’è±Šã‹ã«ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
GCNs perform well in domains where the items have a good set of pre-existing features, e.g., where the items are images [37].
GCNã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ãŒç”»åƒã§ã‚ã‚‹å ´åˆãªã©ã€ã‚¢ã‚¤ãƒ†ãƒ ãŒæ—¢å­˜ã®ç‰¹å¾´ã®è‰¯ã„ã‚»ãƒƒãƒˆã‚’æŒã£ã¦ã„ã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã†ã¾ãæ©Ÿèƒ½ã—ã¾ã™[37]ã€‚
Such approaches work less well in the absence of useful content features and cannot deal with the short half life of items either.
ã“ã®ã‚ˆã†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€æœ‰ç”¨ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç‰¹å¾´ãŒãªã„å ´åˆã«ã¯ã†ã¾ãæ©Ÿèƒ½ã›ãšã€ã‚¢ã‚¤ãƒ†ãƒ ã®åŠæ¸›æœŸãŒçŸ­ã„å ´åˆã«ã‚‚å¯¾å¿œã§ããªã„ã€‚
We see SimClusters as an approach to scalably learn user and item representations which can be fed to hybrid models like DNNs [5] or GCNs [37].
SimClustersã¯ã€DNN [5]ã‚„GCN [37]ã®ã‚ˆã†ãªãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã«ä¾›çµ¦ã§ãã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®è¡¨ç¾ã‚’ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã«å­¦ç¿’ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚

Our problem definition bears some similarity to the cross-domain or heterogeneous recommender systems problem [2, 38], where one can use a joint objective function to simultaneously learn the representations of users and items across multiple domains [8, 39].
æˆ‘ã€…ã®å•é¡Œå®šç¾©ã¯ã€è¤‡æ•°ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã¾ãŸãŒã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®è¡¨ç¾ã‚’åŒæ™‚ã«å­¦ç¿’ã™ã‚‹ãŸã‚ã«å…±åŒç›®çš„é–¢æ•°ã‚’ä½¿ç”¨ã§ãã‚‹ã€ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³ã¾ãŸã¯ç•°ç¨®æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ å•é¡Œ [2, 38] ã«é¡ä¼¼ã—ã¦ã„ã‚‹ [8, 39]ã€‚
It is unclear how these methods can support our requirements for scale, handling dynamic items and graphs, and intepretability.
ã“ã‚Œã‚‰ã®æ–¹æ³•ã¯ã€ã‚¹ã‚±ãƒ¼ãƒ«ã€å‹•çš„ãªã‚¢ã‚¤ãƒ†ãƒ ã‚„ã‚°ãƒ©ãƒ•ã®æ‰±ã„ã€ã‚¤ãƒ³ãƒ†ãƒ—ãƒªã‚¿ãƒ“ãƒªãƒ†ã‚£ã¨ã„ã£ãŸæˆ‘ã€…ã®è¦æ±‚ã‚’ã©ã®ã‚ˆã†ã«ã‚µãƒãƒ¼ãƒˆã§ãã‚‹ã‹ã¯ä¸æ˜ã§ã‚ã‚‹ã€‚

# Conclusion çµè«–

We proposed a framework called SimClusters based on detecting bipartite communities from the user-user graph and use them as a representation space to solve many personalization and recommendation problems at scale.
æˆ‘ã€…ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚°ãƒ©ãƒ•ã‹ã‚‰äºŒéƒ¨ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’æ¤œå‡ºã—ã€ãã‚Œã‚’è¡¨ç¾ç©ºé–“ã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã“ã¨ã«åŸºã¥ãSimClustersã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€å¤šãã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã‚„æ¨è–¦å•é¡Œã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ã¦è§£æ±ºã™ã‚‹ã€‚
SimClusters uses a novel algorithm called Neighborhood-aware MH for solving the crucial problem of unipartite community detection with better scalability and accuracy.
SimClustersã§ã¯ã€ä¸€çµ„ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡ºã¨ã„ã†é‡è¦ãªå•é¡Œã‚’ã€ã‚ˆã‚Šå„ªã‚ŒãŸã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨ç²¾åº¦ã§è§£æ±ºã™ã‚‹ãŸã‚ã«ã€Neighborhood-aware MHã¨ã„ã†æ–°ã—ã„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ã¦ã„ã¾ã™ã€‚
We also presented several diverse deployed and in-progress applications where we use SimClusters representations to improve relevance at Twitter.
ã¾ãŸã€SimClustersè¡¨ç¾ã‚’ç”¨ã„ã¦Twitterã§ã®é–¢é€£æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€å¤šæ§˜ãªãƒ‡ãƒ—ãƒ­ã‚¤æ¸ˆã¿ãŠã‚ˆã³é€²è¡Œä¸­ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã„ãã¤ã‹ç´¹ä»‹ã—ã¾ã—ãŸã€‚

# Supplement: Further Evaluation ã‚µãƒ—ãƒªãƒ¡ãƒ³ãƒˆ ã•ã‚‰ãªã‚‹è©•ä¾¡

The code for Neighborhood-aware MH and an in-memory implementation of Stage 1 are open-sourced in https://github.com/ twitter/sbf.
Neighborhood-aware MHã®ã‚³ãƒ¼ãƒ‰ã¨Stage 1ã®ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªå®Ÿè£…ã¯ã€https://github.com/ twitter/sbfã§ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚

## Neighborhood-aware MH Empirical evaluation è¿‘å‚æ¢ç´¢å‹ MH çµŒé¨“å€¤è©•ä¾¡

### A.1.1 Comparison with RandomMH [33]. A.1.1 RandomMH [33]ã¨ã®æ¯”è¼ƒã€‚

We conducted a simple empirical evaluation in which we generated synthetic graphs with 100 nodes and varying number of communities, such that the probability of an edge between nodes inside the same community was large and the probability of an edge otherwise was small.
100ãƒãƒ¼ãƒ‰ã®åˆæˆã‚°ãƒ©ãƒ•ã‚’ä½œæˆã—ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®æ•°ã‚’å¤‰åŒ–ã•ã›ã€åŒã˜ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å†…ã®ãƒãƒ¼ãƒ‰é–“ã®ã‚¨ãƒƒã‚¸ã®ç¢ºç‡ãŒå¤§ããã€ãã‚Œä»¥å¤–ã®ã‚¨ãƒƒã‚¸ã®ç¢ºç‡ãŒå°ã•ããªã‚‹ã‚ˆã†ã«ã€ç°¡å˜ãªå®Ÿè¨¼è©•ä¾¡ã‚’è¡Œã„ã¾ã—ãŸã€‚
The approach from [33] which we label â€˜RandomMHâ€™, as well as our approach (â€˜Neighborhood-Awareâ€™) are implemented in the same code and use the same settings, except that the implementations for the proposal and the initialization functions are different.
RandomMHã€ã¨åä»˜ã‘ãŸ[33]ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã€æˆ‘ã€…ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆã€ŒNeighborhood-Awareã€ï¼‰ã¯ã€ææ¡ˆã¨åˆæœŸåŒ–é–¢æ•°ã®å®Ÿè£…ãŒç•°ãªã‚‹ã ã‘ã§ã€åŒã˜ã‚³ãƒ¼ãƒ‰ã§å®Ÿè£…ã•ã‚ŒåŒã˜è¨­å®šã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚
We compare both the approaches in terms of how many epochs they need to be to run to recover the synthetic communities, as well as the wall clock time (since the runtime for each epoch differs between the two approaches).
ä¸¡è€…ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ã€åˆæˆã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’å›å¾©ã™ã‚‹ãŸã‚ã«ä½•ã‚¨ãƒãƒƒã‚¯å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã¨ã„ã†ç‚¹ã¨ã€ã‚¦ã‚©ãƒ¼ãƒ«ã‚¯ãƒ­ãƒƒã‚¯æ™‚é–“ï¼ˆå„ã‚¨ãƒãƒƒã‚¯ã®å®Ÿè¡Œæ™‚é–“ãŒä¸¡è€…ã§ç•°ãªã‚‹ãŸã‚ï¼‰ã®ç‚¹ã§æ¯”è¼ƒã—ãŸã€‚
As can be seen from the results in Table 2, the number of epochs and time required when using RandomMH grows exponentially with increasing ğ‘˜, as expected.
è¡¨2ã®çµæœã‹ã‚‰ã‚ã‹ã‚‹ã‚ˆã†ã«ã€RandomMHã‚’ä½¿ç”¨ã—ãŸå ´åˆã®ã‚¨ãƒãƒƒã‚¯æ•°ã¨æ‰€è¦æ™‚é–“ã¯ã€äºˆæƒ³é€šã‚Šá‘˜ã®å¢—åŠ ã¨ã¨ã‚‚ã«æŒ‡æ•°é–¢æ•°çš„ã«æˆé•·ã™ã‚‹ã€‚
Neighborhood-aware MH on the other hand has no such problem with increasing ğ‘˜.
ä¸€æ–¹ã€Neighborhood-aware MHã¯ã€á‘˜ãŒå¢—åŠ ã—ã¦ã‚‚ãã®ã‚ˆã†ãªå•é¡Œã¯ãªã„ã€‚

### A.1.2 Comparison on real datasets. A.1.2 å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®æ¯”è¼ƒã€‚

We ran experiments on 8 real datasets (see Table 3) and compared Neighborhood-aware MH to the following algorithms from prior literature: (a) BigClam [34]: BigClam is interesting to compare to since there are many similarities, with the main difference being that itâ€™s optimized using gradient descent rather than randomized combinatorial optimization as in our case.
æˆ‘ã€…ã¯8ã¤ã®å®Ÿãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆè¡¨3å‚ç…§ï¼‰ã§å®Ÿé¨“ã‚’è¡Œã„ã€Neighborhood-aware MHã‚’ä»¥ä¸‹ã®å…ˆè¡Œæ–‡çŒ®ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨æ¯”è¼ƒã—ãŸï¼š (a) BigClam [34]ï¼š BigClam[34]ï¼šå¤šãã®é¡ä¼¼ç‚¹ãŒã‚ã‚‹ãŸã‚ã€æ¯”è¼ƒã™ã‚‹ã®ã¯èˆˆå‘³æ·±ã„ã§ã™ãŒã€ä¸»ãªé•ã„ã¯ã€æˆ‘ã€…ã®å ´åˆã®ã‚ˆã†ã«ãƒ©ãƒ³ãƒ€ãƒ ãªçµ„ã¿åˆã‚ã›æœ€é©åŒ–ã§ã¯ãªãã€å‹¾é…é™ä¸‹ã‚’ä½¿ç”¨ã—ã¦æœ€é©åŒ–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã§ã™ã€‚
We used the implementation in the SNAP package [21].
SNAPãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®å®Ÿè£…ã‚’ä½¿ç”¨ã—ãŸ[21]ã€‚
(b) Graclus [7]: Graclus optimizes weighted graph cuts without needing to compute eigenvectors, making it much faster than spectral algorithms without losing accuracy.6 Note that for all 8 of these datasets, the RandomMH algorithm proposed in [33] was not able to make any progress inside the allotted time (6 hours).
(b) Graclus [7]ï¼š Graclusã¯å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ãªãé‡ã¿ä»˜ãã‚°ãƒ©ãƒ•ã‚«ãƒƒãƒˆã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ï¼Œç²¾åº¦ã‚’è½ã¨ã™ã“ã¨ãªãã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«é«˜é€Ÿã«å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™6ï¼ãªãŠï¼Œã“ã‚Œã‚‰ã®8ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã™ã¹ã¦ã«ãŠã„ã¦ï¼Œ[33]ã§ææ¡ˆã—ãŸRandomMHã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯æ±ºã‚ã‚‰ã‚ŒãŸæ™‚é–“ï¼ˆ6æ™‚é–“ï¼‰å†…ã«é€²å±•ã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã§ã—ãŸï¼

We use two kinds of datasets: similarity graphs calculated for a subset of Twitter users in the way described in Section 3.1, as well as the 4 biggest undirected social networks we were able to find externally on the KONECT [19] collection.
3.1ç¯€ã§èª¬æ˜ã—ãŸæ–¹æ³•ã§Twitterãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦è¨ˆç®—ã•ã‚ŒãŸé¡ä¼¼ã‚°ãƒ©ãƒ•ã¨ã€KONECT [19] ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã§å¤–éƒ¨ã‹ã‚‰è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ããŸ4å¤§ç„¡å‘æ€§ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®2ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã€‚
While our method (Neighborhood-Aware MH) and Graclus both work with weighted graphs, BigClam does not, so we restrict ourselves to unweighted graphs.
æˆ‘ã€…ã®æ‰‹æ³•ï¼ˆNeighborhood-Aware MHï¼‰ã¨Graclusã¯å…±ã«é‡ã¿ä»˜ãã‚°ãƒ©ãƒ•ã‚’æ‰±ã†ãŒã€BigClamã¯ãã†ã§ã¯ãªã„ã®ã§ã€æˆ‘ã€…ã¯éé‡ã¿ä»˜ãã‚°ãƒ©ãƒ•ã«é™å®šã™ã‚‹ã€‚
For Neighborhood-aware MH, we run it with ğ‘™ = 1, i.e.
Neighborhood-aware MHã«ã¤ã„ã¦ã¯ã€á‘™ = 1ã§å®Ÿè¡Œã—ã¾ã™ã€ã™ãªã‚ã¡ã€‚
each node gets assigned to at most one community, to keep the comparison with Graclus fair.
Graclusã¨ã®æ¯”è¼ƒã‚’å…¬å¹³ã«ã™ã‚‹ãŸã‚ã€å„ãƒãƒ¼ãƒ‰ã¯æœ€å¤§1ã¤ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹ã€‚
ğ›¼ which can be used to trade precision with recall7 was set to 10, and ğ‘‡ , number of epochs, was set to 5.
ã‚’10ã«è¨­å®šã—ã€ã‚¨ãƒãƒƒã‚¯æ•°áµ„ã¯5ã¨ã—ãŸã€‚
All experiments were run on a 16-core machine with 256GB RAM.
ã™ã¹ã¦ã®å®Ÿé¨“ã¯ã€256GB RAMã‚’æ­è¼‰ã—ãŸ16ã‚³ã‚¢ã®ãƒã‚·ãƒ³ã§å®Ÿè¡Œã•ã‚Œã¾ã—ãŸã€‚

We evaluate all methods on Precision and Recall.
ã™ã¹ã¦ã®æ–¹æ³•ã‚’Precisionã¨Recallã§è©•ä¾¡ã—ã¾ã™ã€‚
A method is said to predict the existence of an edge (ğ‘¢, ğ‘£) if ğ‘¢ and ğ‘£ share at least one community per the output of the method.
ã‚ã‚‹æ–¹æ³•ã¯ã€ğ‘¢ã¨ğ‘£ãŒæ–¹æ³•ã®å‡ºåŠ›ã‚ãŸã‚Šå°‘ãªãã¨ã‚‚1ã¤ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’å…±æœ‰ã—ã¦ã„ã‚‹å ´åˆã€ã‚¨ãƒƒã‚¸ï¼ˆğ‘¢, 463ï¼‰ã®å­˜åœ¨ã‚’äºˆæ¸¬ã™ã‚‹ã¨è¨€ã†ã€‚
The Precision of a method is the proportion of actually existing predicted edges among all predicted edges for a method.
æ‰‹æ³•ã®ç²¾åº¦ã¯ã€ãã®æ‰‹æ³•ã§äºˆæ¸¬ã•ã‚ŒãŸã™ã¹ã¦ã®ã‚¨ãƒƒã‚¸ã®ã†ã¡ã€å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹äºˆæ¸¬ã‚¨ãƒƒã‚¸ã®å‰²åˆã§ã‚ã‚‹ã€‚
The Recall of a method is the proportion of correctly predicted edges (by that method) among all actually existing edges in the graph.
ã‚ã‚‹æ‰‹æ³•ã®Recallã¯ã€ã‚°ãƒ©ãƒ•ã«å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹ã™ã¹ã¦ã®è¾ºã®ã†ã¡ã€ãã®æ‰‹æ³•ã«ã‚ˆã£ã¦æ­£ã—ãäºˆæ¸¬ã•ã‚ŒãŸè¾ºã®å‰²åˆã§ã‚ã‚‹ã€‚
Given Precision and Recall, F1 is their harmonic mean.
Precisionã¨RecallãŒã‚ã‚‹ã¨ãã€F1ã¯ãã‚Œã‚‰ã®èª¿å’Œå¹³å‡ã§ã‚ã‚‹ã€‚
Note that Precision and Recall are not properties of a community by itself, but rather are properties of the entire output i.e.
ãªãŠã€Precisionã¨Recallã¯ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å˜ä½“ã®ç‰¹æ€§ã§ã¯ãªãã€å‡ºåŠ›å…¨ä½“ã®ç‰¹æ€§ã§ã‚ã‚‹ã€ã™ãªã‚ã¡
the (possibly overlapping) set of communities.
ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ¼ã®ï¼ˆé‡è¤‡ã™ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ï¼‰é›†åˆã§ã‚ã‚‹ã€‚
Note that our evaluation measures do not need any external groundtruth; they simply measure how well the community assignments are able to reconstruct the input graph.
ãªãŠã€æˆ‘ã€…ã®è©•ä¾¡æŒ‡æ¨™ã¯å¤–éƒ¨ã‹ã‚‰ã®çœŸå®Ÿã‚’å¿…è¦ã¨ã›ãšã€å˜ã«ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å‰²ã‚Šå½“ã¦ãŒå…¥åŠ›ã‚°ãƒ©ãƒ•ã‚’ã©ã‚Œã ã‘å†æ§‹æˆã§ãã‚‹ã‹ã‚’æ¸¬å®šã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã€‚

For all of the datasets, we generally tried to set ğ‘˜ â€“ the number of discovered communities â€“ so that the average size of a community is 100, because we see that having larger communities leads to significantly degraded Precision as unrelated pairs of nodes start to share at least one community.
ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®å¹³å‡ã‚µã‚¤ã‚ºãŒ100ã«ãªã‚‹ã‚ˆã†ã«ã€ç™ºè¦‹ã•ã‚ŒãŸã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®æ•°ã§ã‚ã‚‹á‘˜ã‚’è¨­å®šã—ã¾ã—ãŸã€‚
In the case of the Orkut and Livejournal datasets however, we used a smaller ğ‘˜ in order to get at least one of our baselines to run successfully.
ã—ã‹ã—ã€Orkutã¨Livejournalã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®å°‘ãªãã¨ã‚‚1ã¤ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‚ˆã†ã«ã€ã‚ˆã‚Šå°ã•ãªá‘˜ã‚’ä½¿ç”¨ã—ã¾ã—ãŸã€‚

For BigClam, we found that the default implementation was taking a very long time (more than 100Ã— the time for our method on our smallest dataset), so we made a modification to initialize using a random neighborhood (same as our method) instead of trying to identify the neighborhoods with the best conductance which was proving very expensive.
BigClamã«ã¤ã„ã¦ã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å®Ÿè£…ã§ã¯éå¸¸ã«æ™‚é–“ãŒã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸï¼ˆæœ€å°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æˆ‘ã€…ã®æ‰‹æ³•ã®100å€ä»¥ä¸Šã®æ™‚é–“ãŒã‹ã‹ã‚‹ï¼‰ã®ã§ã€éå¸¸ã«é«˜ä¾¡ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ãŸæœ€è‰¯ã®ã‚³ãƒ³ãƒ€ã‚¯ã‚¿ãƒ³ã‚¹ã®è¿‘éš£ã‚’è­˜åˆ¥ã—ã‚ˆã†ã¨ã™ã‚‹ã®ã§ã¯ãªãã€ãƒ©ãƒ³ãƒ€ãƒ ãªè¿‘éš£ï¼ˆæˆ‘ã€…ã®æ‰‹æ³•ã¨åŒã˜ï¼‰ã‚’ä½¿ç”¨ã—ã¦åˆæœŸåŒ–ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£ã—ã¾ã—ãŸã€‚
Despite this optimization, BigClam was unable to finish execution within 6 hours for our 3 biggest datasets.
ã“ã®æœ€é©åŒ–ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€BigClamã¯3ã¤ã®å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§6æ™‚é–“ä»¥å†…ã«å®Ÿè¡Œã‚’çµ‚äº†ã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚
For Actors and Petster, we found that BigClam finished execution successfully, but the results were completely unintelligible and seemed to have been affected by an unidentified bug.
Actorã¨Petsterã«ã¤ã„ã¦ã¯ã€BigClamã¯æ­£å¸¸ã«å®Ÿè¡Œã‚’çµ‚äº†ã—ãŸãŒã€çµæœã¯å…¨ãæ„å‘³ä¸æ˜ã§ã€æ­£ä½“ä¸æ˜ã®ãƒã‚°ã®å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹ã‚ˆã†ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚

As can be seen from the results in Table 3, our method is able to produce significantly more accurate results and is also much faster, typically 10x-100x faster.
è¡¨3ã®çµæœã‹ã‚‰ã‚ã‹ã‚‹ã‚ˆã†ã«ã€ç§ãŸã¡ã®æ–¹æ³•ã¯å¤§å¹…ã«ç²¾åº¦ã®é«˜ã„çµæœã‚’å‡ºã™ã“ã¨ãŒã§ãã€ã¾ãŸã€é€šå¸¸10å€ã‹ã‚‰100å€ã¨éå¸¸ã«é«˜é€Ÿã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚
Neighborhood-aware MH is fast because each epoch requires making a single pass over all the vertices and their adjacency lists and also because the overall approach is easy to parallelize.
è¿‘å‚æ¢ç´¢å‹MHãŒé«˜é€Ÿãªã®ã¯ã€å„ã‚¨ãƒãƒƒã‚¯ãŒã™ã¹ã¦ã®é ‚ç‚¹ã¨ãã®éš£æ¥ãƒªã‚¹ãƒˆã«å¯¾ã—ã¦1å›ã®ãƒ‘ã‚¹ã§æ¸ˆã‚€ãŸã‚ã§ã‚ã‚Šã€ã¾ãŸå…¨ä½“çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒä¸¦åˆ—åŒ–ã—ã‚„ã™ã„ãŸã‚ã§ã™ã€‚
Our approach is able to run inside 1.5 hours for a graph with 100M nodes and 5B edges (Top100M), while the largest graph either of our baselines is able to run on is at least an order of magnitude smaller.
æˆ‘ã€…ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€100Mã®ãƒãƒ¼ãƒ‰ã¨5Bã®ã‚¨ãƒƒã‚¸ã‚’æŒã¤ã‚°ãƒ©ãƒ•ï¼ˆTop100Mï¼‰ã«å¯¾ã—ã¦1.5æ™‚é–“ä»¥å†…ã«å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸãŒã€æˆ‘ã€…ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®ã„ãšã‚Œã‹ãŒå®Ÿè¡Œã§ãã‚‹æœ€å¤§ã®ã‚°ãƒ©ãƒ•ã¯ã€å°‘ãªãã¨ã‚‚1æ¡å°ã•ã„ã‚‚ã®ã§ã™ã€‚

## Bipartite Communities Empirical evaluation äºŒè€…é–“å…±åŒä½“ å®Ÿè¨¼è©•ä¾¡

A possible concern with our approach to discovering bipartite communities is whether breaking the problem up into 3 separate steps can result in a loss of accuracy, as compared to jointly learning the bipartite communities directly.
2ã¤ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’ç™ºè¦‹ã™ã‚‹æˆ‘ã€…ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§æ‡¸å¿µã•ã‚Œã‚‹ã®ã¯ã€å•é¡Œã‚’3ã¤ã®åˆ¥ã€…ã®ã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†ã‘ã‚‹ã“ã¨ã§ã€2ã¤ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’ç›´æ¥å…±åŒã§å­¦ç¿’ã™ã‚‹å ´åˆã¨æ¯”è¼ƒã—ã¦ã€ç²¾åº¦ãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã¨ã„ã†ã“ã¨ã§ã™ã€‚
To understand this empirically, we compare against NMF (Non-negative Matrix Factorization) â€“ recall that with both NMF and our approach, the end output is two low-dimensional sparse matrices.
ã“ã®ã“ã¨ã‚’çµŒé¨“çš„ã«ç†è§£ã™ã‚‹ãŸã‚ã«ã€NMFï¼ˆNon-negative Matrix Factorizationï¼‰ã¨æ¯”è¼ƒã—ã¾ã™ã€‚NMFã‚‚æˆ‘ã€…ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚‚ã€æœ€çµ‚å‡ºåŠ›ã¯2ã¤ã®ä½æ¬¡å…ƒã‚¹ãƒ‘ãƒ¼ã‚¹ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã§ã‚ã‚‹ã“ã¨ã‚’æ€ã„å‡ºã—ã¦ãã ã•ã„ã€‚
Specifically we use Scikit-Learnâ€™s implementation [3, 25] of alternating minimization using a Coordinate Descent solver, and with â€˜nndsvdâ€™ initialization, and with ğ¿1 penalty, where the ğ¿1 coefficient is adjusted to return results of comparable sparsity to our approach.
å…·ä½“çš„ã«ã¯ã€Scikit-Learnã®åº§æ¨™é™ä¸‹ã‚½ãƒ«ãƒãƒ¼ã«ã‚ˆã‚‹äº¤äº’æœ€å°åŒ–ã®å®Ÿè£… [3, 25] ã‚’ä½¿ç”¨ã—ã€åˆæœŸåŒ–ã¯ã€Œnndsvdã€ã€áµƒ1ãƒšãƒŠãƒ«ãƒ†ã‚£ã¯ã€æˆ‘ã€…ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨åŒç­‰ã®ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã‚’è¿”ã™ã‚ˆã†ã«áµƒ1ä¿‚æ•°ã‚’èª¿æ•´ã—ã¾ã™ã€‚
For our approach, we set various parameters as follows: for the similarity graph calculation in step 1, we only include edges with cosine similarity > 0.02; for Neighborhood-aware MH in step 2, we set ğ‘™ = 4, (i.e.
ã‚¹ãƒ†ãƒƒãƒ—1ã®é¡ä¼¼ã‚°ãƒ©ãƒ•è¨ˆç®—ã§ã¯ã€ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒ0.02ä»¥ä¸Šã®ã‚¨ãƒƒã‚¸ã®ã¿ã‚’å¯¾è±¡ã¨ã—ã€ã‚¹ãƒ†ãƒƒãƒ—2ã®ãƒã‚¤ãƒãƒ¼ãƒ•ãƒƒãƒ‰ã‚¢ã‚¦ã‚§ã‚¢MHã§ã¯ã€á‘™=4ã€ï¼ˆã™ãªã‚ã¡ã€"Neighborhood-aware MH"ï¼‰ã¨ã„ã†ã‚ˆã†ã«ã€æ§˜ã€…ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®šã—ã¾ã—ãŸã€‚
each rightnode can be assigned to at most 4 communities), ğ›¼ (see Eqn 1) to 10, and ğ‘‡ (max epochs) to 5; for calculating U in step 3, we assign a left-node to a community if and only if it is connected to at least 2 right-nodes that are assigned to that community.
å„å³ãƒãƒ¼ãƒ‰ã¯æœ€å¤§4ã¤ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹ï¼‰ã€Ç¼ï¼ˆå¼1å‚ç…§ï¼‰ï½10ã€â†ªL_1D447â†©ï¼ˆæœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°ï¼‰ï½5ã€‚ã‚¹ãƒ†ãƒƒãƒ—3ã®Uã®è¨ˆç®—ã§ã¯ã€å·¦ãƒãƒ¼ãƒ‰ã¯ã€ãã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸå³ãƒãƒ¼ãƒ‰ã®å°‘ãªãã¨ã‚‚2ã¤ã¨æ¥ç¶šã—ã¦ã„ã‚‹å ´åˆã«ã®ã¿ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å‰²ã‚Šå½“ã¦ã¾ã™ã€‚
All experiments were run on commodity servers with 8 cores and 24GB RAM.
ã™ã¹ã¦ã®å®Ÿé¨“ã¯ã€8ã‚³ã‚¢ã¨24GB RAMã‚’æ­è¼‰ã—ãŸã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£ã‚µãƒ¼ãƒãƒ¼ã§å®Ÿè¡Œã•ã‚Œã¾ã—ãŸã€‚
Note that this evaluation is purely to benchmark the accuracy of our approach; in terms of actual applicability, neither NMF nor other variants are practically feasible at our scale.
ãªãŠã€ã“ã®è©•ä¾¡ã¯ã€ç´”ç²‹ã«æˆ‘ã€…ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®ç²¾åº¦ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã‚ã‚Šã€å®Ÿéš›ã®é©ç”¨å¯èƒ½æ€§ã¨ã„ã†ç‚¹ã§ã¯ã€NMFã‚‚ä»–ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ã€æˆ‘ã€…ã®ã‚¹ã‚±ãƒ¼ãƒ«ã§ã¯ç¾å®Ÿçš„ã«å®Ÿç¾ä¸å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚

For evaluation, we use a combination of directed graphs and document-word occurrence graphs, and evaluate on the task of link prediction.
è©•ä¾¡ã«ã¯ã€æœ‰å‘ã‚°ãƒ©ãƒ•ã¨æ–‡æ›¸-å˜èªå‡ºç¾ã‚°ãƒ©ãƒ•ã®çµ„ã¿åˆã‚ã›ã‚’ç”¨ã„ã€ãƒªãƒ³ã‚¯äºˆæ¸¬ã¨ã„ã†ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã—ã¦ã„ã¾ã™ã€‚
We run both the approaches on 90% of the input dataset, and make a test set consisting of 10% of the held-out edges as well as the same number of randomly generated pairs of nodes which serve as negative examples in the test set.
ä¸¡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®90%ã§å®Ÿè¡Œã—ã€10%ã®ä¿ç•™ã•ã‚ŒãŸã‚¨ãƒƒã‚¸ã¨ã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§å¦å®šä¾‹ã¨ãªã‚‹åŒæ•°ã®ãƒ©ãƒ³ãƒ€ãƒ ã«ç”Ÿæˆã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã®ãƒšã‚¢ã‹ã‚‰ãªã‚‹ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹ã€‚
E.g., if a graph consists of 100ğ¾ edges, this results in a â€œtraining setâ€ of 90ğ¾ edges and test-set of 20ğ¾ edges (10ğ¾ positives and 10ğ¾ negatives).
ä¾‹ãˆã°ã€ã‚°ãƒ©ãƒ•ãŒ100_43å€‹ã®ã‚¨ãƒƒã‚¸ã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹å ´åˆã€90_43å€‹ã®ã‚¨ãƒƒã‚¸ã®ã€Œãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚»ãƒƒãƒˆã€ã¨20_43å€‹ã®ã‚¨ãƒƒã‚¸ã®ã€Œãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã€ï¼ˆ10_43å€‹ã®ãƒã‚¸ãƒ†ã‚£ãƒ–ã¨10_43å€‹ã®ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚
In order to predict whether an edge (ğ‘–, ğ‘—) exists, we use the cosine similarity of U(ğ‘–) and V(ğ‘—) as the predicted score for the existence of the edge.
ã‚¨ãƒƒã‚¸(ğ‘–, â†ªLl457)ãŒå­˜åœ¨ã™ã‚‹ã‹ã©ã†ã‹ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã«ã€U(ğ‘–)ã¨V(â†ªLl457)ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’ã‚¨ãƒƒã‚¸å­˜åœ¨ã®äºˆæ¸¬ã‚¹ã‚³ã‚¢ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚
(For both NMF and our approach, cosine similarity worked marginally better than dot product.) We evaluate the quality of these predicted scores in two ways - the first is we check the Correlation of the true label {0, 1} with the predicted score; and the second is to calculate the AUC (Area Under the ROC Curve).8
(NMFã¨æˆ‘ã€…ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®ä¸¡æ–¹ã«ãŠã„ã¦ã€ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã¯ãƒ‰ãƒƒãƒˆç©ã‚ˆã‚Šã‚‚ã‚ãšã‹ã«å„ªã‚Œã¦ã„ãŸï¼‰ã€‚1ã¤ç›®ã¯ã€çœŸã®ãƒ©ãƒ™ãƒ«{0, 1}ã¨äºˆæ¸¬ã‚¹ã‚³ã‚¢ã®ç›¸é–¢ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹æ–¹æ³•ã€2ã¤ç›®ã¯AUCï¼ˆArea Under the ROC Curveï¼‰ã‚’è¨ˆç®—ã™ã‚‹æ–¹æ³•ã§ã‚ã‚‹8ï¼

Details about the datasets as well as the results are in Table 4.
ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è©³ç´°ã¨çµæœã¯ã€è¡¨4ã«ç¤ºã™ã€‚
In terms of Correlation, our approach is consistently better across all datasets, while in terms of AUC, both the approaches are comparable.
ç›¸é–¢ã®é¢ã§ã¯ã€å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãŠã„ã¦æˆ‘ã€…ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ–¹ãŒä¸€è²«ã—ã¦å„ªã‚Œã¦ãŠã‚Šã€AUCã®é¢ã§ã¯ã€ä¸¡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯åŒç­‰ã§ã‚ã‚‹ã€‚
We also include the timing information, where our approach is generally a little faster than NMF.
ã¾ãŸã€ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±ã‚’å«ã‚ã‚‹ã¨ã€ä¸€èˆ¬çš„ã«NMFã‚ˆã‚Šå°‘ã—é€Ÿããªã‚‹ã€‚
However, note that the primary advantage of our approach is not that itâ€™s faster than NMF, but that itâ€™s more scalable, meaning that it is possible to extend to billionnode graphs and hundreds of thousands of latent dimensions while scaling NMF similarly is prohibitively costly.
ã¤ã¾ã‚Šã€10å„„ãƒãƒ¼ãƒ‰ã®ã‚°ãƒ©ãƒ•ã‚„æ•°åä¸‡å€‹ã®æ½œåœ¨æ¬¡å…ƒã«æ‹¡å¼µã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã‚ã‚‹ä¸€æ–¹ã€NMFã‚’åŒæ§˜ã«æ‹¡å¼µã™ã‚‹ã®ã¯æ³•å¤–ãªã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã¨ã„ã†ã“ã¨ã§ã™ã€‚
