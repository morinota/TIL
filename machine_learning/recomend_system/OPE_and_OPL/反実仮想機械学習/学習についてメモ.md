## 0章の教師あり学習の基礎

- 教師あり学習では、**同時分布 $p(x, y)$ に従う**特徴量(feature)と呼ばれる多次元確率変数 $x$ と、目的変数(outcome)と呼ばれる確率変数 $y$ の間の関係性を、データに基づいて明らかにしたり予測したりすることが目標。
- そのために、ある特徴量 $x$ が与えられた時に、それに対応する目的変数 $y$ を精度よく予測できる予測関数 $f$ を見つけ出すことを考える。
- より具体的には、次のように定義される期待リスク(expected risk)などによって予測関数 f の正確さを定量化し、それを最適化することを通じて、性格や予測関数$f$を得ることを考える。

### 期待リスク

$$
L(f) := E_{p(x,y)}[l(y, f(x))]
$$

ここで、$l(y, f(x))$ は、予測誤差(yとf(x)の乖離度合い)を評価するための損失関数(loss function)。
期待リスクを最小化する予測関数を、最適な予測関数とよび、$f^* := \argmin_{f} L(f)$ と表記する。

最もよく用いられる損失関数 $l$ の一つに、二乗誤差(squared loss) $l(a,b) = (a - b)^2$ がある。この場合の期待リスクは、次のように表される。

$$
L(f) := E_{p(x,y)}[(y - f(x))^2]
$$

この二乗誤差に基づく期待リスクを変形していく。
まず2乗の展開を行うと...

$$
= E_{p(x,y)}[y^2 - 2yf(x) + f(x)^2]
$$

続いて、「追加の項を足したり引いたりして、都合のいい形に変形できるようにする」テクニックを使うと...

$$
= E_{p(x,y)}[
    % 元々の式
    y^2 - 2yf(x) + f(x)^2
    % テクニックとして追加した項
    + 2yE_{p(y'|x)}[y'] - 2yE_{p(y'|x)}[y'] % 足し引き0
    + 2E_{p(y'|x)}[y'^2] - 2E_{p(y'|x)}[y'^2] % 足し引き0
]
$$

- 実は、上記の足し引きは**分散分解(バイアス・バリアンス分解)につながる有名なテクニック**らしい
  - 具体的には、$E[(y - f(x))^2] = E[(y - E[y|x])^2] + E[(E[y|x] - f(x))^2]$ みたいな式で、誤差を「真の条件付き期待値からのブレ」と「モデルが真の条件付き期待値からズレてる分」に分解して考える、っていう**お決まりの流れ**があるらしい!!

続いて、いい感じに項を並び替えた上で、期待値の線形性を使って分解すると...

$$
= E_{p(x,y)}[y^2 - 2y E_{p(y'|x)}[y'] + (E_{p(y'|x)}[y'])^2]
\\
+ E_{p(x,y)}[(E_{p(y'|x)}[y'])^2 - 2yf(x) + f(x)^2]
\\
+ E_{p(x,y)}[2yE_{p(y'|x)}[y'] - 2(E_{p(y'|x)}[y'])^2]
$$

続いて、「同時分布に関する期待値」を、「条件付き期待値の期待値」に落とし込むテクニックを使って...

- ここで使ってるテクニック
  - 「同時分布の期待値 = まずはxの期待値、続いてyの条件付き期待値をとる」性質を使ってる...! $E_{p(x,y)}[hoge] = E_{p(x)}[E_{p(y|x)}[hoge]]$ みたいな感じで、「同時分布の期待値」を「条件付き期待値の期待値」に落とし込むテクニックが使われてる...!

$$
% 各項について、同時分布に関する期待値が、「条件付き期待値の期待値」という二重の期待値に変形される
= E_{p(x)}[E_{p(y|x)}[y^2 - 2y E_{p(y'|x)}[y'] + (E_{p(y'|x)}[y'])^2]]
\\
+ E_{p(x)}[E_{p(y|x)}[(E_{p(y'|x)}[y'])^2 - 2yf(x) + f(x)^2]]
\\
+ E_{p(x)}[E_{p(y|x)}[2yE_{p(y'|x)}[y'] - 2(E_{p(y'|x)}[y'])^2]]
$$

続いて、各項の期待値の中身を整理していくと...

$$
= E_{p(x)}[E_{p(y|x)}[(y - E_{p(y'|x)}[y'])^2]] % 期待値の中身を因数分解
\\
+ E_{p(x)}[(E_{p(y|x)}[y'])^2 - 2E_{p(y|x)}[y]f(x) + f(x)^2] % 期待値の線形性を使って、条件付き期待値を展開
\\
+ E_{p(x)}[2(E_{p(y|x)}[y])^2 - 2(E_{p(y|x)}[y'])^2] % 期待値の線形性を使って、条件付き期待値を展開
$$

- ここでやってること
  - 第1項: 期待値の中身を因数分解して、**条件付き分散の定義式**の形に! $Var_{p(y|x)}[y] = E_{p(y|x)}[(y - E_{p(y|x)}[y])^2]$
  - 第2項: 期待値の線形性を使って、条件付き期待値を展開。(第2.2項以外はyにとって定数になるのでスッキリするのか...!:thinking:)
    - ちなみに $E_{p(y|x)}[(E_{p(y|x)}[y'])^2] = (E_{p(y|x)}[y'])^2$ になる点に注意!!**理由を簡単に説明すると、E[定数] = 定数 だから**
      - 中身の $E_{p(y'|x)}[y']$ は、「特徴量xを固定された時の、目的変数yの期待値」のこと。**これはxについての関数になり、yの分布に依存しない定数**である!
      - 定数を二乗しても当然定数！
      - よって、$E_{p(y|x)}[定数] = 定数$ になる!
    - 最終的にこの項は「条件付き期待値 - 予測関数」の二乗に落ち着く!
  - 第3項: 期待値の線形性を使って、条件付き期待値を展開。
    - ちなみに $E_{p(y|x)}[2yE_{p(y'|x)}[y']] = 2(E_{p(y|x)}[y])^2$ になる点に注意!!
      - 期待値の線形性 ($E_{p(x)}[Ax] = A E_{p(x)}[x]$) を使って、$E_{p(y'|x)}[y']$ を定数とみなすと上記の結果になる!!:thinking:
    - ちなみに $E_{p(y|x)}[2(E_{p(y'|x)}[y'])^2] = 2(E_{p(y|x)}[y'])^2$ になるのは、前述と同様に $E[定数] = 定数$ なので!!
    - 最終的に、この項は打ち消されて0になる!!

最後に...

$$
= E_{p(x)}[Var_{p(y|x)}[y]] % xで条件付けたyの条件付き分散
\\
+ E_{p(x)}[(E_{p(y|x)}[y] - f(x))^2] % 予測関数f(x)のバイアス
$$

となり、最終的に期待リスク $L(f)$ は、以下の2つの要素に分解されることがわかる。
(期待リスクの分散の式、完全に理解した!!:thinking:)

1. $E_{p(x)}[Var_{p(y|x)}[y]]$ : 「目的変数 $y$ の条件付き分布 $p(y|x)$ に関する分散(の期待値)」。これは、特徴量xが与えられた時の目的変数yのばらつき度合いであり、**目的変数yの予測における、特徴量xの質・有用さ**を定量化したもの。
2. $E_{p(x)}[(E_{p(y|x)}[y] - f(x))^2]$ : 「予測関数 $f(x)$ と、目的変数の条件付き期待値 $E_{p(y|x)}[y]$ の二乗誤差(の期待値)」。これは、**予測関数f(x)の予測精度**を表す。

期待リスクの要素分解からわかること:

- 期待リスクの1つ目の要素を最小化するには、**より良い（同じ$x$を持つデータの$y$のばらつきが小さい）特徴量 $x$ を構成することが求められる**。
- **期待リスクの1つ目の要素は、予測関数 $f$ に非依存である**。つまり、特徴量 $x$ がひとたび定義されてしまえば、予測関数 $f$ の最適化をいくら頑張ったとしても、この1つ目の要素を小さくすることはできない。
- （損失関数 $l$ が二乗誤差のときの）最適な予測関数は $f^*(x) = E_{p(y|x)}[y]$ であり、この時の期待リスクは $L(f^*) = E_{p(x)}[Var_{p(y|x)}[y]]$ になる。

#### 推薦方策の性能についても、期待リスクの要素分解、みたいな考えを定式化したいメモ

### しかし実は、期待リスクは未知である

仮に真の同時分布 $p(x, y)$ がわかっているのならば、最適な予測関数 $f^*$ はちょっとした計算で明らかになるため、教師あり学習の問題は完璧に解けてしまう。

しかし現実には、**同時分布 $p(x,y)$ は未知の情報**である。

代わりに教師あり学習では、予測関数 $f$ を最適化するための情報としてトレーニングデータと呼ばれるデータセットが与えられる。
トレーニングデータは、同時分布 $p(x,y)$ から独立に同分布に(i.i.d.)サンプリングされたデータであり、特徴量 $x$ と目的変数 $y$ のn個の観測の組であり、$D = {(x_i, y_i)}_{i=1}^{n}$ と表記される

理想的には期待リスク $L(f)$ を最適化することで最適な予測関数 $f^*$ を得たいが、真の同時分布 $p(x,y)$ が未知であるため計算できない。
その代わりにトレーニングデータ $D$ に基づいて、**期待リスクを推定する推定量 $\hat{L}(f;D)$ を構築した上で、この推定量を(仕方なく)最小化する**ことで、より良い予測関数 $\hat{f}^*$ を得る (学習する)、という手順に落ち着く。
