# ランキングにおけるオフ方策評価についてメモ

- 1章にて、オフ方策評価の基本的な考え方や手法を学んだ。しかし実際の現場では、**より複雑な問題設定が必要なケース**が多々ある。
  - 代表的なものの一つが、**複数の行動を同時に選択したり並び替えたりする、いわゆるランキング問題**。
- ランキング問題では...
  - **行動空間が組み合わせ爆発的に増加**するため、1章の推定量をそのまま適用することは難しい。
- 本章では、ランキング問題において正確なオフ方策評価を行うための主流なアイデアとして、ユーザ行動に仮定をおくことで問題の厳密性と解きやすさのバランスを制御するアプローチと、それがもたらす重要なバイアス・バリアンストレードオフについて学ぶ。

## 2.1 ランキング問題の定式化

- 推薦や検索などのランキング問題 = ユーザの属性情報や行動履歴などによって構成される特徴量に基づいて、アイテムのランキングを選択し提示する**意思決定の問題**、として捉えることができる。

ランキングに関する意思決定最適化問題の定式化

- まず...
  - 特徴量ベクトル $x \in \mathbb{R}^d$
  - 商品やニュース記事などの個々のアイテム $a \in \mathcal{A}$
- アイテム集合 $\mathcal{A}$ に属する**アイテムを並び替えることで構成されるランキングをベクトル $\mathbf{a} := (a_1, a_2, \ldots, a_K) \in \prod(A)$ で表す**。
  - 注意!: この定式化ではランキング長さ $K := |A|$ と置いている。実務ではもっと小さい値になることもあるので、必要に応じて $\prod(A)$ の部分は変わるはず...!:thinking:
- また、**あるランキング $\mathbf{a}$ を提示した結果として観測される報酬を、同じくベクトル $\mathbf{r} := (r_1, r_2, \ldots, r_K) \in \mathbb{R}^K$ で表す**。
  - 各要素 $\mathbf{r}(k)$ は、k番目に提示されたアイテムで観測される報酬を表す(ex. クリック有無、視聴有無など...!)
- ランキング方策 $\pi: \mathcal{X} \to \Delta(\prod(A))$ を、ランキング集合 $\prod(A)$ 上の条件付き確率分布として定義する。
  - つまり、$\pi(\mathbf{a} | x)$ は、ある特徴量ベクトル $x$ が与えられたときに、特定のランキング $\mathbf{a}$ を選択する確率を意味する。

定式化された問題設定に基づくと、ランキング方策 $\pi$ による一連の意思決定プロセスは以下のようになる。
(添え字 $i$ はログデータの識別子)

- まず、未知の確率分布 $p(x)$ に従うユーザ情報などの特徴量 $x_i$ を観測する。（ここは1章と同じ！）
- 次に、観測した特徴量 $x$ に基づき、ランキング方策 $\pi(\mathbf{a} | x)$ が特定のランキング $\mathbf{a}_i$ を選択する。
- 最後に、特徴量 $x_i$ とランキング $\mathbf{a}_i$ に依存して、報酬ベクトル $\mathbf{r}_i$ が未知の確率分布 $p(\mathbf{r} | x, \mathbf{a})$ に従い観測される。

また、ランキング方策 $\pi$ の性能を次のように定義する:

$$
V(\pi) := E_{p(x) \pi(\mathbf{a} | x) p(\mathbf{r} | x, \mathbf{a})} [ \sum_{k=1}^K \alpha_k \mathbf{r}(k) ]
\\
= E_{p(x) \pi(\mathbf{a} | x)} [ \sum_{k=1}^K \alpha_k q_k(x, \mathbf{a}) ]
\tag{2.1}
$$

- ここで、
  - $q_k(x, \mathbf{a}) := E_{p(\mathbf{r} | x, \mathbf{a})} [ \mathbf{r}(k) ]$ は、特徴量 $x$ とランキング $\mathbf{a}$ が与えられた時にk番目のポジションで発生する報酬 $r(k)$ の期待値を表し、**ポジションレベルでの期待報酬関数 (position-level expected reward function)** と呼ぶ。(うんうん、わかる...!:thinking:)
  - また、$\alpha_k$ は、分析者によって事前に定義される k 番目のポジションの重要度を表すハイパーパラメータ。
- ランキング方策の性能 $V(\pi)$ は、その方策を環境に実装した際に得られる**ポジションごとの報酬の重み付き和の期待値**で定義されるのが通例らしい。
  - まあ我々が最適化したい報酬の定義によっても異なるだろうけど、だいたいこの定義で一般化できるのかも...!:thinking:

(メモ)ポジションの重要度ハイパーパラメータ $\alpha_k$ は、**既存のランキング指標を一般化したもの**としても理解できる...!:thinking:

- 前提として、分析者が自由に設定できる! (別に有名なランキング指標を知ってなくてもOK...!:)
- ex.) 
  - $\alpha_k = \mathbb{I}[k <= K] / K$ と定義すると... $V(\pi)$ は**有名なランキング指標 Precision@K に一致**する！
  - $\alpha_k = \mathbb{I}[k <= K]/ \log_{2}(k+1)$ と定義すると... $V(\pi)$ は**NDCG@K に一致**する！

## ランキング問題のオフ方策評価

- ランキング問題におけるオフ方策評価の目的:
  - すでに実装されているランキング方策 $\pi_0$ (データ収集方策)によって収集されたログデータのみを用いて、$\pi_0$ とは異なる新しいランキング方策 $\pi$ (評価方策) の性能を推定する、という統計的推定問題。

ここでログデータ $D$ は、次の独立同一分布から抽出されると考える。

$$
D := {(x_i, \mathbf{a}_i, \mathbf{r}_i)}_{i=1}^n \sim p(D) = \prod_{i=1}^n p(x_i) \pi_0(\mathbf{a}_i | x_i) p(\mathbf{r}_i | x_i, \mathbf{a}_i)
\tag{2.2}
$$

OPE推定量の正確さは、例えば以下の平均二乗誤差 (MSE) により定量化できる。

$$
MSE[\hat{V}(\pi;D)] := E_{p(D)} [ (V(\pi) - \hat{V}(\pi;D))^2 ]
$$

## ランキングにおけるIPS推定量とその問題点

IPS推定量は、全く同じ発想に基づき、次のようにしてランキングの設定に容易に拡張できる。

$$
\hat{V}_{IPS}(\pi;D) := \frac{1}{n} \sum_{i=1}^n \frac{\pi(\mathbf{a}_i | x_i)}{\pi_0(\mathbf{a}_i | x_i)} \sum_{k=1}^K \alpha_k \mathbf{r}_i(k)
\\
= \frac{1}{n} \sum_{i=1}^n w(x_i, \mathbf{a}_i) \sum_{k=1}^K \alpha_k \mathbf{r}_i(k)
\tag{2.4}
$$

- ここで、
  - 重み $w(x, \mathbf{a}) := \pi(\mathbf{a} | x) / \pi_0(\mathbf{a} | x)$ は、評価方策 $\pi$ とデータ収集方策 $\pi_0$ による行動選択確率の比であり、**ランキングレベルの重要度重み（ranking-level importance weight）**と呼ぶ。
  - またちなみに、$\hat{V}_{IPS}^{(k)}(\pi;D) := \frac{1}{n} \sum_{i=1}^n w(x_i, \mathbf{a}_i) \mathbf{r}_i(k)$ により、k番目のポジションにおける期待報酬に対するIPS推定量を表すことがある
    - この場合、$V_{IPS}(\pi;D) = \sum_{k=1}^K \alpha_k \hat{V}_{IPS}^{(k)}(\pi;D)$ と表記できる。

ランキングにおけるIPS推定量の問題点

- IPS推定量のバイアスとバリアンスの式を計算するとわかること:
  - 共通サポート仮定を満たせば、不偏推定できる。
  - データ数 $n$ が増えるにつれて、MSEも単調に減少していく。
- しかし残念なことに、**ランキングの問題においてIPS推定量はほとんど使い物にならない**、という悲しい事実が知られている。
  - その理由は、IPS推定量のバリアンスやMSEの式に現れる重要度重み $w(x, \mathbf{a})$ がとても厄介な現象を引き起こすから。
  - より具体的には...
    - **ユニークなアイテムの数 $|A|$ が増えるにつれ、ランキングの数 $|\prod(A)|$ は組合せ爆発的に増加していくため、ランキングレベルの重要度重み $w(x, \mathbf{a})$ がとてつもなく巨大な値をとってしまう可能性がある**。
      - ->IPS推定量のバリアンスやMSEの式には、重要度重みのバリアンスが含まれるため、これは大きな問題となる。
- 擬似データで実験してみると...
  - ランキングの長さ $K$ が大きくなるにつれ、IPS推定量の推定誤差が急激に悪化していく。

ランキング問題においてもIPS推定量は確かに不偏推定量ではあるが、ランキングの数 $|\prod(A)|$ が往々にして天文学的な値になってしまうため、バリアンスが使い物にならないくらいに大きくなってしまう、という欠点がある。
よって、**ランキングの設定に特化した推定量を開発する必要がある**...!

## ランキングにおけるDM推定量やDR推定量と、その問題点

- ISP推定量のバリアンスが問題ならば、DM推定量やDR推定量を使えば良いのでは??
  - -> IPS推定量とは正反対の特徴を持つDM推定量や、バイアスを発生させることなくバリアンスを改善できるDR推定量の使用を検討しよう、というアイデアは至極当然。

DM推定量をランキングの設定へ拡張すると...

$$
\hat{V}_{DM}(\pi;D, \hat{q}) := \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K \alpha_k \hat{q}_k(x_i, \pi) = \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K \alpha_k \sum_{\mathbf{a} \in \prod(A)} \pi(\mathbf{a} | x_i) \hat{q}_k(x_i, \mathbf{a})
\tag{2.7}
$$

- ここで、
  - $\hat{q}_k(x, \mathbf{a})$ は、ポジションレベルの期待報酬関数 $q_k(x, \mathbf{a})$ に対する推定モデル。
  - $\hat{q}_k(x, \pi)$ は、**期待報酬関数に対する推定モデル $\hat{q}_k(x, \mathbf{a})$ のランキング方策 $\pi$ に関する期待値**を表す。

同様に、DR推定量をランキングの設定へ拡張すると...

$$
\hat{V}_{DR}(\pi;D, \hat{q}) := \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K \alpha_k \left( \hat{q}_k(x_i, \pi) + w(x_i, \mathbf{a}_i)(\mathbf{r}_i(k) - \hat{q}_k(x_i, \mathbf{a}_i)) \right)
\tag{2.8}
$$


- ここで注目すべきは、DM推定量とDR推定量の両方で登場する $\hat{q}_k(x, \pi)$ という「期待報酬関数に対する推定モデルの、ランキング方策 $\pi$ に関する期待値」という項。
  - -> これはすなわち、**ニューラルネットなどで構築される期待報酬関数の推定モデル $\hat{q}_k(x, \mathbf{a})$ による推論を、全てのランキングの数 $|\prod(A)|$ に対して行う必要がある**ことを意味する...!

よって、ランキングの問題に対してDM推定量やDR推定量を定義することは可能なものの、**期待報酬関数の推定モデル $\hat{q}_k(x, \mathbf{a})$ の計算コストの観点から実用的ではない**。
この観点から、**IPS推定量をベースにそれに工夫を加えることで改善を図っていくアプローチが、ランキングにおけるオフ方策評価の研究の主流**になっている。

## ユーザ行動に関する仮定を駆使したIPS推定量の改善

### IIPS（Independent IPS）推定量

- その名の通り、**ポジションレベルの期待報酬関数 $q_k(x, \mathbf{a})$ に独立性を仮定することで、IPS推定量のバリアンスの大幅な改善を狙った推定量**。
- 次の**独立モデル(independent model)**と呼ばれる、ユーザ行動or期待報酬関数 $q_k(x, \mathbf{a})$ に関する仮定を活用する。
- 仮定: 全ての $x \in \mathcal{X}$ および $k \in [K]$ 、$\mathbf{a} \in \prod(A)$ について、以下が成り立つとき、ポジションレベルの期待報酬関数 $q_k(x, \mathbf{a})$ は**独立性**を持つという。

$$
E_{p(\mathbf{r}(k) | x, \mathbf{a})} [\mathbf{r}(k)] = E_{p(\mathbf{r}(k) | x, \mathbf{a}(k))} [\mathbf{r}(k)] 
\\
\forall x \in \mathcal{X}, k \in [K], \mathbf{a} \in \prod(A)
\tag{2.9}
$$

- この仮定の意味合い・解釈:
  - **あるランキング $\mathbf{a}$ の k番目のポジションで発生する報酬が、そのポジションに提示された単一のアイテム $a(k)$ にのみ依存して決まること**。
  - (つまり、各ユーザは、推薦されたランキングの各アイテムを独立に評価した上で、クリックしたり購入したりという報酬を発生させる。ランキング内の**アイテム間の相互作用を完全に無視する**、という仮定...!:thinking:)
    - まあ問題設定によっては、アイテム間の相互作用を無視しちゃってもいい気もする:thinking:

もちろん「同じアイテムでも、一緒に推薦されたアイテムに応じてクリック確率などが変化するかも」と想定するのが**より厳密で現実的**ではある。しかし、それを全て考慮しようとすると、**定式化はより厳密になる一方で解かなくてはならない問題が複雑化**する。結果として巨大なバリアンスが発生してしまう。
IIPS推定量のように、**ある程度現実性は諦めつつも問題を解くことができるレベルに簡略化できる、という意味で、独立モデルなどのユーザ行動・期待報酬関数に関する仮定は、ランキングにおけるオフ方策評価でとても有用とされている**。

- どんな場合に、ポジションレベルの期待報酬関数が独立性を持つと言えそう??
  - ex.) 真の期待報酬関数が $q_k(x, \mathbf{a}) = \theta(k) \cdot v(x, a(k))$ という構造を持っている状況。
    - ここで
      - $\theta(k)$ は、ランキング中のk番目のポジションがユーザに閲覧される確率。
      - $v(x, a(k))$ は、特徴量 $x$ を持つユーザがアイテム $a(k)$ に持っている興味度合い。
    - 上記の構造を言い換えると...
      - **ユーザがあるk番目のポジションを閲覧し、かつそのポジションに提示されたアイテム $\mathbf{a}(k)$ が興味と合致してた場合に報酬が発生する**状況、を考えている。
      - (ちなみにこれは、情報検索(information retrieval)の分野でよく用いられる、position-based model と呼ばれる、クリックが発生する構造に関する仮定。これは独立性を有するモデルの一つ...!:thinking:)
    - この構造はある程度納得感がありそうだし、独立性を満たしている...!:thinking:

このユーザ行動・期待報酬関数に関する独立性を活用して、IPS推定量を改善した方法が、**IIPS（Independent IPS）推定量**であり、以下で定義される。

$$
\hat{V}_{IIPS}(\pi;D) := \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K \frac{\pi(\mathbf{a}(k) | x_i, k)}{\pi_0(\mathbf{a}(k) | x_i, k)} \alpha_k \mathbf{r}_i(k)
\\
= \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K w_{k}(x_i, \mathbf{a}_i(k)) \alpha_k \mathbf{r}_i(k)
\tag{2.11}
$$

- ここで、
  - $\pi(\mathbf{a}(k) | x, k)$ は、あるアイテム $a \in \mathcal{A}$ が任意のランキングの k 番目のポジションに提示される周辺確率。
    - (なお**計算時には、各ランキングの選択確率を、各アイテム・ポジション毎の周辺確率に変換することになる...!**)
  - $w_{k}(x, \mathbf{a}) := \pi(\mathbf{a}(k) | x, k) / \pi_0(\mathbf{a}(k) | x, k)$ は、**ポジションレベルの重要度重み（position-level importance weight）**。
  - またちなみに...
    - $\hat{V}_{IIPS}^{(k)}(\pi;D) := \frac{1}{n} \sum_{i=1}^n w_{k}(x_i, \mathbf{a}_i(k)) \mathbf{r}_i(k)$ により、k番目のポジションにおける期待報酬に対するIIPS推定量を表すことがある
    - この場合、方策の性能に対するIIPS推定量は $V_{IIPS}(\pi;D) = \sum_{k=1}^K \alpha_k \hat{V}_{IIPS}^{(k)}(\pi;D)$ とも表記できる。

- IIPS推定量のポイント: IPS推定量で用いられていた**ランキングレベルの重要度重みではなく、各アイテムがそれぞれのポジションに提示される周辺確率に基づくポジションレベルの重要度重み**が用いられている点!

独立性が成り立つ場合、IIPS推定量は不偏推定量となり、かつIPS推定量よりもはるかに小さなバリアンスを持つことが知られている。(open bandit pipelineにも実装されてる...!:thinking:)

一方で当然、**独立性が成り立っていない状況ではIIPS推定量も何らかの困難を抱える**はず。
特に独立性は、**ランキング中のアイテム間の相互作用を全て無視するとても強い仮定**なので、この仮定が成り立たない時の不利益もきっちり理解しておく必要がある。

- バイアスを計算していくと...IIPS推定量は、IPS推定量よりも大幅に小さいバリアンスを持つ一方で、独立性が成り立たないユーザの割合の増加に伴って、非常に大きなバイアスが発生してしまう。
  - 仮定が満たされないことで発生するバイアスが、バリアンス減少効果よりも大きいときには、IPS推定量よりも更に大きな誤差を生じる可能性がある。
- よって、**ユーザ行動が単純な場合に備えてIIPS推定量を武器の一つとして持っておくことは有用だが、それだけではより複雑で現実的な状況には対応できないかもしれない**。

### RIPS（Reward-interaction IPS）推定量

- 背景
  - ランキング問題においてIPS推定量は巨大なバリアンスを発生してしまう。一方でIIPS推定量は、期待報酬関数の独立性の仮定が成り立たない場合には大きなバイアスを発生させてしまう。
  - -> 独立性の仮定が成り立たない状況でもバイアスの発生を抑えつつ、バリアんすの減少効果を同時に得ることができる推定量があれば...!:thinking:
  - -> 次に提案されたのが、**RIPS（Reward-interaction IPS）推定量**。

期待報酬関数に関する独立性よりも弱い（より現実的な）**カスケードモデル(cascade model)**と呼ばれる仮定に基づく。

- 仮定: 全ての $x \in \mathcal{X}$ および $k \in [K]$ 、$\mathbf{a} \in \prod(A)$ について、以下が成り立つとき、ポジションレベルの期待報酬関数 $q_k(x, \mathbf{a})$ は**カスケード性**を持つという。

$$
E_{p(\mathbf{r}(k) | x, \mathbf{a})} [\mathbf{r}(k)] = E_{p(\mathbf{r}(k) | x, \mathbf{a}(1:k))} [\mathbf{r}(k)]
\tag{2.17}
$$

- ここで
  - $\mathbf{a}(1:k)$ は、ランキング $\mathbf{a}$ において1番目からk番目までに提示されたアイテムの集合。
- この仮定の意味合い・解釈:
  - **あるランキング $\mathbf{a}$ のk番目のポジションで発生する期待報酬が、そのポジションよりも上位に提示されたアイテム $\mathbf{a}(1:k)$ のみに依存して決まる**こと。
    - i.e. 各ユーザがランキング上位のアイテムから順に吟味し、所望のアイテムを見つけた時に報酬が発生する、という想定。
    - **IIPS推定量の独立性の仮定と比べると、かなり現実的な想定**と言える...!

例えばどんな場合に、ポジションレベルの期待報酬関数 $q_k(x, \mathbf{a})$ がカスケード性を持つと言えそう??
真の期待報酬関数が次のような構造を持っている状況:

$$
q_k(x, \mathbf{a}) = \begin{cases}
  v(x, \mathbf{a}(k)) & (k = 1) \\
  v(x, \mathbf{a}(k)) \prod_{j=1}^{k-1} (1 - v(x, \mathbf{a}(j))) & (k > 1)
\end{cases}
\tag{2.18}
$$

- ここで
  - $v(x, \mathbf{a}(k))$ は、特徴量 $x$ を持つユーザがアイテム $\mathbf{a}(k)$ に持っている興味度合い。
- すなわち上式は、k番目のポジションに提示されたアイテムに対する興味度合いが大きく、またより上位に提示されたアイテム $a(1:k-1)$ に対する興味度合いが小さい場合に、k番目のポジションの期待報酬が大きくなる構造をしている。

このカスケード性の仮定に基づいて提案されたのが、**RIPS（Reward-interaction IPS）推定量**であり、以下で定義される。

$$
\hat{V}_{RIPS}(\pi;D) := \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K \frac{\pi(\mathbf{a}(1:k) | x_i)}{\pi_0(\mathbf{a}(1:k) | x_i)} \alpha_k \mathbf{r}_i(k)
= \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K w_{1:k}(x_i, \mathbf{a}_i) \alpha_k \mathbf{r}_i(k)
\tag{2.19}
$$

- ここで
  - $\pi(\mathbf{a}(1:k) | x) := \sum_{\mathbf{a}' \in \prod(A)} \mathbb{I}[\mathbf{a}'(1:k) = \mathbf{a}(1:k)] \pi(\mathbf{a}' | x)$ は、上位k番目までのアイテムの組がそれぞれ所定のポジションに提示される周辺確率。
  - $w_{1:k}(x, \mathbf{a})$ は、**トップkに関する重要度重み**(top-k importance weight)と呼ばれる（上位k番目のポジションまでの行動選択確率の比を考えていることから）。

RIPS推定量のポイントは、**IPS推定量で用いられていたランキングレベルの重要度重みではなく、トップkに関する重要度重み**が用いられている点。

- ランキング問題における...
  - IPS推定量 -> ランキングレベルの重要度重み
  - IIPS推定量 -> ポジションレベルの重要度重み
  - RIPS推定量 -> トップkに関する重要度重み

RIPS推定量は、カスケード性の仮定が成り立つ場合には不偏推定量であり、かつIPS推定量よりも小さなバリアンスを持つことが知られている（IIPS推定量よりもバリアンスは大きい）。

### AIPS（Adaptive IPS）推定量

- 前述のIIPS(Independent IPS)推定量やRIPS(Reward-interaction IPS)推定量では、ユーザ行動あるいは機体報酬関数に関する仮定を駆使することで、ランキング問題に対応する推定量を提案してきた。
- しかし**IIPS推定量とRIPS推定量が暗黙のうちにおいてしまっている重大な仮定**がある...!
  - -> **全てのデータ（ユーザ）に対して全く同じユーザ行動を仮定してしまっている**こと！
  - 直感的にも、このような大雑把なモデリングは、バイアスとバリアンスの両面から明らかに適切ではない。
- 例: 独立性を持つユーザAと、カスケード性を持つユーザBが混在する状況を考える。
  - -> IIPS推定量を用いる場合...**ユーザBについては独立性の仮定が成り立たない -> バイアスが発生する可能性**。
  - -> RIPs推定量を用いる場合...全てのユーザがカスケード性かそれよりも単純な独立性を持っている。->バイアスが発生しない。しかし、**独立性を持っているユーザAに対して過剰に重要度重みをかけてしまっているので、不必要なバリアンスが発生**。

よって、**異なる行動モデルを有するユーザが混在する、より現実的な状況では、ユーザごとに適用する仮定および重要度重みの種類を切り替えることが、バイアスとバリアんすの両面で理想的**のはず。
各ユーザが従う行動モデルに対して、適応的(adaptive)に重要度重みの種類を切り替えることで、より正確なオフ方策評価を目指した推定量が**AIPS（Adaptive IPS）推定量**である。

AIPS推定量を定義するために、**ユーザ毎の行動モデルの違いを考慮できるように、データ生成過程を以下のように拡張**する。

$$
D := {(x_i, \mathbf{a}_i, \mathbf{c}_i, \mathbf{r}_i)}_{i=1}^n \sim p(D) = \prod_{i=1}^n p(x_i) \pi_0(\mathbf{a}_i | x_i) p(\mathbf{c}_i | x_i) p(\mathbf{r}_i | x_i, \mathbf{a}_i)
\tag{2.23}
$$

- ここで...
  - $\mathbf{c}_i \sim p(\mathbf{c} | x_i)$ は、**ユーザ $i$ が従う行動モデルを表しており、次のような行列形式**をしている。

$$
% K * Kのbinary行列
\mathbf{c} = \begin{pmatrix}
  c_{1,1} & \cdots & c_{1,k'} & \cdots & c_{1,K} \\
  \vdots & \ddots & \vdots & \ddots & \vdots \\
  c_{k,1} & \cdots & c_{k,k'} & \cdots & c_{k,K} \\
  \vdots & \ddots & \vdots & \ddots & \vdots \\
  c_{K,1} & \cdots & c_{K,k'} & \cdots & c_{K,K}
\end{pmatrix}
\in \{0, 1\}^{K \times K}
\tag{2.24}
$$

- ここで...
  - **行列の(k,k')の要素 $c_{k,k'}$ は、k番目のポジションにおける報酬 $\mathbf{r}(k)$ が、k'番目のポジションに提示された行動 $\mathbf{a}(k')$ に依存するか否かを表す2値変数**。
    - IIPS推定量で扱った独立モデル(=独立性の仮定を満たす行動モデル)も、RIPS推定量で扱ったカスケードモデル(=カスケード性の仮定を満たす行動モデル)も、このユーザ行動モデルの行列形式で表現できる。

ちなみに、独立モデルをユーザ行動モデルの行列形式で表現すると...

$$
% 独立モデルの場合は、対角成分のみ1で他は0(=単位行列!)
\mathbf{c}_{independent} = \begin{pmatrix}
  1 & 0 & \cdots & 0 \\
  0 & 1 & \cdots & 0 \\
  \vdots & \vdots & \ddots & \vdots \\
  0 & 0 & \cdots & 1
\end{pmatrix}
$$

ちなみにちなみに、カスケードモデルをユーザ行動モデルの行列形式で表現すると...

$$
% カスケードモデルの場合は、左下三角成分が1で他は0(=下三角行列!)
\mathbf{c}_{cascade} = \begin{pmatrix}
  1 & 0 & \cdots & 0 \\
  1 & 1 & \cdots & 0 \\
  \vdots & \vdots & \ddots & \vdots \\
  1 & 1 & \cdots & 1
\end{pmatrix}
$$

このように、**ユーザ行動モデルの行列形式を用いることで、独立モデルやカスケードモデルを含むあらゆるユーザ行動モデルを自在に表現できる**。

また、ユーザ行動モデルの行列形式の定義に基づいて、、あるモデル $\mathbf{c}$ が観測された時のポジションレベルの期待報酬関数 $q_k(x, \mathbf{a})$ を、次のように簡略化できる。


$$
q_k(x, \mathbf{a}) =  E_{p(\mathbf{r}(k) | x, \mathbf{a})} [\mathbf{r}(k)] = E_{p(\mathbf{r}(k) | x, \Phi_{k}(\mathbf{a}, \mathbf{c}))} [\mathbf{r}(k)] = q_k(x, \Phi_{k}(\mathbf{a}, \mathbf{c}))
\tag{2.27}
$$

- ここで...
  - $\Phi_{k}(\mathbf{a}, \mathbf{c}) := \{a_{l} \in A, l \in [K] | c_{k,l} = 1 \}$ は、**k番目のポジションの報酬に影響を与えるアイテムの集合であり、これはユーザ行動モデル $\mathbf{c}$ に依存して決まる**。
  - ex)
    - 独立モデルの場合: $\Phi_{k}(\mathbf{a}, \mathbf{c}_{independent}) = \{ a(k) \}$ になるので、式(2.27)は独立モデルによる期待報酬関数の簡略化(2.9)と一致する。
    - カスケードモデルの場合: $\Phi_{k}(\mathbf{a}, \mathbf{c}_{cascade}) = a(1:k)$
  - （まあ単に**これまでの独立モデルやカスケードモデルによる定式化を一般化してるだけ**...!）

これでAIPS推定量を定義する準備が整った...!AIPS(Adaptive IPS)推定量は、次のように定義される。

$$
\hat{V}_{AIPS}(\pi;D) := \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K \frac{\pi(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)}{\pi_0(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)} \alpha_k \mathbf{r}_i(k)
\\
= \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K w_{k}(x_i, \Phi_{k}(\mathbf{a}_i, \mathbf{c}_i)) \alpha_k \mathbf{r}_i(k)
\tag{2.28}
$$

- ここで...
  - $\pi(\Phi_{k}(\mathbf{a}, \mathbf{c}) | x) := \sum_{\mathbf{a}' \in \prod(A)} \pi(\mathbf{a}' | x) \mathbb{I}[\Phi_{k}(\mathbf{a}', \mathbf{c}) = \Phi_{k}(\mathbf{a}, \mathbf{c})]$ は、$\Phi_{k}(\mathbf{a}, \mathbf{c})$ で表されるアイテム集合が、それぞれ所定のポジションに提示される周辺確率。
  - $w_{k}(x, \Phi_{k}(\mathbf{a}, \mathbf{c}))$ は、評価方策とデータ収集方策による**適応的重要度重み(adaptive importance weight)**。

- 少々複雑な定義に見えるが、各ポジションの報酬に影響を与えるアイテム集合 $\Phi_{k}(\mathbf{a}, \mathbf{c})$ に絞って重要度重みを定義している部分が、唯一の相違点!
- AIPS推定量で特に重要なのは、**重要度重みがデータ $i$ ごとに変化する**こと！これが**適応的**重要度重みと呼ばれる所以！
  - ex.
    - あるユーザが独立モデルに従う場合...適応的重要度重みは、ポジションレベルの重要度重みに変換される!
    - またあるユーザがカスケードモデルに従う場合...適応的重要度重みは、トップkに関する重要度重みに変換される!
  - このように、**重要度重みの賢い切り替えを行なってくれるのが、AIPSの定義に登場する$\Phi_{k}(\mathbf{a}, \mathbf{c})$ の役割**!

さてここで疑問点！**AIPS推定量が現実的には未知であるはずの真の行動モデル $\mathbf{c}$ を用いて定義されている**が、これはどうやって実現するのか...??
実際のところ、真の行動モデルは観測できないので、なんらかの方法で代替する必要がある。
AIPS推定量の提案論文では、AIPS推定量のMSEが最小化されるように、行動モデルの推定モデルを学習する方法が提案されている。

#### ちなみに: AIPS推定量のログデータDに関する期待値の導出

AIPS推定量の期待値を導出するために、まずAIPS推定量の定義を再掲する。

$$
\hat{V}_{AIPS}(\pi;D) := \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K \frac{\pi(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)}{\pi_0(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)} \alpha_k \mathbf{r}_i(k)
\\
= \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K w_{k}(x_i, \Phi_{k}(\mathbf{a}_i, \mathbf{c}_i)) \alpha_k \mathbf{r}_i(k)
$$

ここで、$D := {(x_i, \mathbf{a}_i, \mathbf{c}_i, \mathbf{r}_i)}_{i=1}^n \sim p(D) = \prod_{i=1}^n p(x_i) \pi_0(\mathbf{a}_i | x_i) p(\mathbf{c}_i | x_i) p(\mathbf{r}_i | x_i, \mathbf{a}_i)$ であることを考慮する。

AIPS推定量の期待値を計算するために、まず各項の期待値を計算する。

$$
E[\hat{V}_{AIPS}(\pi;D)] = E\left[\frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K w_{k}(x_i, \Phi_{k}(\mathbf{a}_i, \mathbf{c}_i)) \alpha_k \mathbf{r}_i(k)\right]
$$

独立同一分布に従うため、期待値の線形性を利用して次のように書ける。

$$
E[\hat{V}_{AIPS}(\pi;D)] = \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K E\left[w_{k}(x_i, \Phi_{k}(\mathbf{a}_i, \mathbf{c}_i)) \alpha_k \mathbf{r}_i(k)\right]
$$

さらに、各項の期待値を計算する。

$$
E\left[w_{k}(x_i, \Phi_{k}(\mathbf{a}_i, \mathbf{c}_i)) \alpha_k \mathbf{r}_i(k)\right] = \alpha_k E\left[w_{k}(x_i, \Phi_{k}(\mathbf{a}_i, \mathbf{c}_i)) \mathbf{r}_i(k)\right]
$$

ここで、$w_{k}(x_i, \Phi_{k}(\mathbf{a}_i, \mathbf{c}_i)) = \frac{\pi(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)}{\pi_0(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)}$ であることを考慮する。

$$
E\left[\frac{\pi(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)}{\pi_0(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)} \mathbf{r}_i(k)\right]
$$

ここで、$\mathbf{r}_i(k)$ は $p(\mathbf{r}_i(k) | x_i, \mathbf{a}_i)$ に従うため、次のように書ける。

$$
E\left[\frac{\pi(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)}{\pi_0(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)} \mathbf{r}_i(k)\right] = E\left[\frac{\pi(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)}{\pi_0(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)} E[\mathbf{r}_i(k) | x_i, \mathbf{a}_i]\right]
$$

さらに、$E[\mathbf{r}_i(k) | x_i, \mathbf{a}_i] = q_k(x_i, \mathbf{a}_i)$ であることを考慮する。

$$
E\left[\frac{\pi(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)}{\pi_0(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)} q_k(x_i, \mathbf{a}_i)\right]
$$

ここで、$q_k(x_i, \mathbf{a}_i)$ は $\mathbf{a}_i$ に依存するため、次のように書ける。

$$
E\left[\frac{\pi(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)}{\pi_0(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)} q_k(x_i, \mathbf{a}_i)\right] = E\left[\frac{\pi(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)}{\pi_0(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)}\right] E[q_k(x_i, \mathbf{a}_i)]
$$

ここで、$E\left[\frac{\pi(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)}{\pi_0(\Phi_{k}(\mathbf{a}_i, \mathbf{c}_i) | x_i)}\right] = 1$ であることを考慮する。

$$
E[q_k(x_i, \mathbf{a}_i)]
$$

したがって、AIPS推定量の期待値は次のようになる。

$$
E[\hat{V}_{AIPS}(\pi;D)] = \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K \alpha_k E[q_k(x_i, \mathbf{a}_i)]
$$

これにより、AIPS推定量の期待値が導出された。
ちなみにこの定義は、ランキング方策 $\pi$ の性能の定義と一致するので、AIPS推定量はランキング方策の性能を推定するための不偏推定量であることがわかる。
