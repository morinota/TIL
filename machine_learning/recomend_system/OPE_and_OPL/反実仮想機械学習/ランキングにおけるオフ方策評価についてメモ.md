# ランキングにおけるオフ方策評価についてメモ

- 1章にて、オフ方策評価の基本的な考え方や手法を学んだ。しかし実際の現場では、**より複雑な問題設定が必要なケース**が多々ある。
  - 代表的なものの一つが、**複数の行動を同時に選択したり並び替えたりする、いわゆるランキング問題**。
- ランキング問題では...
  - **行動空間が組み合わせ爆発的に増加**するため、1章の推定量をそのまま適用することは難しい。
- 本章では、ランキング問題において正確なオフ方策評価を行うための主流なアイデアとして、ユーザ行動に仮定をおくことで問題の厳密性と解きやすさのバランスを制御するアプローチと、それがもたらす重要なバイアス・バリアンストレードオフについて学ぶ。

## 2.1 ランキング問題の定式化

- 推薦や検索などのランキング問題 = ユーザの属性情報や行動履歴などによって構成される特徴量に基づいて、アイテムのランキングを選択し提示する**意思決定の問題**、として捉えることができる。

ランキングに関する意思決定最適化問題の定式化

- まず...
  - 特徴量ベクトル $x \in \mathbb{R}^d$
  - 商品やニュース記事などの個々のアイテム $a \in \mathcal{A}$
- アイテム集合 $\mathcal{A}$ に属する**アイテムを並び替えることで構成されるランキングをベクトル $\mathbf{a} := (a_1, a_2, \ldots, a_K) \in \prod(A)$ で表す**。
  - 注意!: この定式化ではランキング長さ $K := |A|$ と置いている。実務ではもっと小さい値になることもあるので、必要に応じて $\prod(A)$ の部分は変わるはず...!:thinking:
- また、**あるランキング $\mathbf{a}$ を提示した結果として観測される報酬を、同じくベクトル $\mathbf{r} := (r_1, r_2, \ldots, r_K) \in \mathbb{R}^K$ で表す**。
  - 各要素 $\mathbf{r}(k)$ は、k番目に提示されたアイテムで観測される報酬を表す(ex. クリック有無、視聴有無など...!)
- ランキング方策 $\pi: \mathcal{X} \to \Delta(\prod(A))$ を、ランキング集合 $\prod(A)$ 上の条件付き確率分布として定義する。
  - つまり、$\pi(\mathbf{a} | x)$ は、ある特徴量ベクトル $x$ が与えられたときに、特定のランキング $\mathbf{a}$ を選択する確率を意味する。

定式化された問題設定に基づくと、ランキング方策 $\pi$ による一連の意思決定プロセスは以下のようになる。
(添え字 $i$ はログデータの識別子)

- まず、未知の確率分布 $p(x)$ に従うユーザ情報などの特徴量 $x_i$ を観測する。（ここは1章と同じ！）
- 次に、観測した特徴量 $x$ に基づき、ランキング方策 $\pi(\mathbf{a} | x)$ が特定のランキング $\mathbf{a}_i$ を選択する。
- 最後に、特徴量 $x_i$ とランキング $\mathbf{a}_i$ に依存して、報酬ベクトル $\mathbf{r}_i$ が未知の確率分布 $p(\mathbf{r} | x, \mathbf{a})$ に従い観測される。

また、ランキング方策 $\pi$ の性能を次のように定義する:

$$
V(\pi) := E_{p(x) \pi(\mathbf{a} | x) p(\mathbf{r} | x, \mathbf{a})} [ \sum_{k=1}^K \alpha_k \mathbf{r}(k) ]
\\
= E_{p(x) \pi(\mathbf{a} | x)} [ \sum_{k=1}^K \alpha_k q_k(x, \mathbf{a}) ]
\tag{2.1}
$$

- ここで、
  - $q_k(x, \mathbf{a}) := E_{p(\mathbf{r} | x, \mathbf{a})} [ \mathbf{r}(k) ]$ は、特徴量 $x$ とランキング $\mathbf{a}$ が与えられた時にk番目のポジションで発生する報酬 $r(k)$ の期待値を表し、**ポジションレベルでの期待報酬関数 (position-level expected reward function)** と呼ぶ。(うんうん、わかる...!:thinking:)
  - また、$\alpha_k$ は、分析者によって事前に定義される k 番目のポジションの重要度を表すハイパーパラメータ。
- ランキング方策の性能 $V(\pi)$ は、その方策を環境に実装した際に得られる**ポジションごとの報酬の重み付き和の期待値**で定義されるのが通例らしい。
  - まあ我々が最適化したい報酬の定義によっても異なるだろうけど、だいたいこの定義で一般化できるのかも...!:thinking:

(メモ)ポジションの重要度ハイパーパラメータ $\alpha_k$ は、**既存のランキング指標を一般化したもの**としても理解できる...!:thinking:

- 前提として、分析者が自由に設定できる! (別に有名なランキング指標を知ってなくてもOK...!:)
- ex.) 
  - $\alpha_k = \mathbb{I}[k <= K] / K$ と定義すると... $V(\pi)$ は**有名なランキング指標 Precision@K に一致**する！
  - $\alpha_k = \mathbb{I}[k <= K]/ \log_{2}(k+1)$ と定義すると... $V(\pi)$ は**NDCG@K に一致**する！

## ランキング問題のオフ方策評価

- ランキング問題におけるオフ方策評価の目的:
  - すでに実装されているランキング方策 $\pi_0$ (データ収集方策)によって収集されたログデータのみを用いて、$\pi_0$ とは異なる新しいランキング方策 $\pi$ (評価方策) の性能を推定する、という統計的推定問題。

ここでログデータ $D$ は、次の独立同一分布から抽出されると考える。

$$
D := {(x_i, \mathbf{a}_i, \mathbf{r}_i)}_{i=1}^n \sim p(D) = \prod_{i=1}^n p(x_i) \pi_0(\mathbf{a}_i | x_i) p(\mathbf{r}_i | x_i, \mathbf{a}_i)
\tag{2.2}
$$

OPE推定量の正確さは、例えば以下の平均二乗誤差 (MSE) により定量化できる。

$$
MSE[\hat{V}(\pi;D)] := E_{p(D)} [ (V(\pi) - \hat{V}(\pi;D))^2 ]
$$

## ランキングにおけるIPS推定量とその問題点

IPS推定量は、全く同じ発想に基づき、次のようにしてランキングの設定に容易に拡張できる。

$$
\hat{V}_{IPS}(\pi;D) := \frac{1}{n} \sum_{i=1}^n \frac{\pi(\mathbf{a}_i | x_i)}{\pi_0(\mathbf{a}_i | x_i)} \sum_{k=1}^K \alpha_k \mathbf{r}_i(k)
\\
= \frac{1}{n} \sum_{i=1}^n w(x_i, \mathbf{a}_i) \sum_{k=1}^K \alpha_k \mathbf{r}_i(k)
\tag{2.4}
$$

- ここで、
  - 重み $w(x, \mathbf{a}) := \pi(\mathbf{a} | x) / \pi_0(\mathbf{a} | x)$ は、評価方策 $\pi$ とデータ収集方策 $\pi_0$ による行動選択確率の比であり、**ランキングレベルの重要度重み（ranking-level importance weight）**と呼ぶ。
  - またちなみに、$\hat{V}_{IPS}^{(k)}(\pi;D) := \frac{1}{n} \sum_{i=1}^n w(x_i, \mathbf{a}_i) \mathbf{r}_i(k)$ により、k番目のポジションにおける期待報酬に対するIPS推定量を表すことがある
    - この場合、$V_{IPS}(\pi;D) = \sum_{k=1}^K \alpha_k \hat{V}_{IPS}^{(k)}(\pi;D)$ と表記できる。

ランキングにおけるIPS推定量の問題点

- IPS推定量のバイアスとバリアンスの式を計算するとわかること:
  - 共通サポート仮定を満たせば、不偏推定できる。
  - データ数 $n$ が増えるにつれて、MSEも単調に減少していく。
- しかし残念なことに、**ランキングの問題においてIPS推定量はほとんど使い物にならない**、という悲しい事実が知られている。
  - その理由は、IPS推定量のバリアンスやMSEの式に現れる重要度重み $w(x, \mathbf{a})$ がとても厄介な現象を引き起こすから。
  - より具体的には...
    - **ユニークなアイテムの数 $|A|$ が増えるにつれ、ランキングの数 $|\prod(A)|$ は組合せ爆発的に増加していくため、ランキングレベルの重要度重み $w(x, \mathbf{a})$ がとてつもなく巨大な値をとってしまう可能性がある**。
      - ->IPS推定量のバリアンスやMSEの式には、重要度重みのバリアンスが含まれるため、これは大きな問題となる。
- 擬似データで実験してみると...
  - ランキングの長さ $K$ が大きくなるにつれ、IPS推定量の推定誤差が急激に悪化していく。

ランキング問題においてもIPS推定量は確かに不偏推定量ではあるが、ランキングの数 $|\prod(A)|$ が往々にして天文学的な値になってしまうため、バリアンスが使い物にならないくらいに大きくなってしまう、という欠点がある。
よって、**ランキングの設定に特化した推定量を開発する必要がある**...!

## ランキングにおけるDM推定量やDR推定量と、その問題点

- ISP推定量のバリアンスが問題ならば、DM推定量やDR推定量を使えば良いのでは??
  - -> IPS推定量とは正反対の特徴を持つDM推定量や、バイアスを発生させることなくバリアンスを改善できるDR推定量の使用を検討しよう、というアイデアは至極当然。

DM推定量をランキングの設定へ拡張すると...

$$
\hat{V}_{DM}(\pi;D, \hat{q}) := \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K \alpha_k \hat{q}_k(x_i, \pi) = \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K \alpha_k \sum_{\mathbf{a} \in \prod(A)} \pi(\mathbf{a} | x_i) \hat{q}_k(x_i, \mathbf{a})
\tag{2.7}
$$

- ここで、
  - $\hat{q}_k(x, \mathbf{a})$ は、ポジションレベルの期待報酬関数 $q_k(x, \mathbf{a})$ に対する推定モデル。
  - $\hat{q}_k(x, \pi)$ は、**期待報酬関数に対する推定モデル $\hat{q}_k(x, \mathbf{a})$ のランキング方策 $\pi$ に関する期待値**を表す。

同様に、DR推定量をランキングの設定へ拡張すると...

$$
\hat{V}_{DR}(\pi;D, \hat{q}) := \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K \alpha_k \left( \hat{q}_k(x_i, \pi) + w(x_i, \mathbf{a}_i)(\mathbf{r}_i(k) - \hat{q}_k(x_i, \mathbf{a}_i)) \right)
\tag{2.8}
$$


- ここで注目すべきは、DM推定量とDR推定量の両方で登場する $\hat{q}_k(x, \pi)$ という「期待報酬関数に対する推定モデルの、ランキング方策 $\pi$ に関する期待値」という項。
  - -> これはすなわち、**ニューラルネットなどで構築される期待報酬関数の推定モデル $\hat{q}_k(x, \mathbf{a})$ による推論を、全てのランキングの数 $|\prod(A)|$ に対して行う必要がある**ことを意味する...!

よって、ランキングの問題に対してDM推定量やDR推定量を定義することは可能なものの、**期待報酬関数の推定モデル $\hat{q}_k(x, \mathbf{a})$ の計算コストの観点から実用的ではない**。
この観点から、**IPS推定量をベースにそれに工夫を加えることで改善を図っていくアプローチが、ランキングにおけるオフ方策評価の研究の主流**になっている。

## ユーザ行動に関する仮定を駆使したIPS推定量の改善

### IIPS（Independent IPS）推定量

- その名の通り、**ポジションレベルの期待報酬関数 $q_k(x, \mathbf{a})$ に独立性を仮定することで、IPS推定量のバリアンスの大幅な改善を狙った推定量**。
- 次の**独立モデル(independent model)**と呼ばれる、ユーザ行動or期待報酬関数 $q_k(x, \mathbf{a})$ に関する仮定を活用する。
- 仮定: 全ての $x \in \mathcal{X}$ および $k \in [K]$ 、$\mathbf{a} \in \prod(A)$ について、以下が成り立つとき、ポジションレベルの期待報酬関数 $q_k(x, \mathbf{a})$ は**独立性**を持つという。

$$
E_{p(\mathbf{r}(k) | x, \mathbf{a})} [\mathbf{r}(k)] = E_{p(\mathbf{r}(k) | x, \mathbf{a}(k))} [\mathbf{r}(k)] 
\\
\forall x \in \mathcal{X}, k \in [K], \mathbf{a} \in \prod(A)
\tag{2.9}
$$

- この仮定の意味合い・解釈:
  - **あるランキング $\mathbf{a}$ の k番目のポジションで発生する報酬が、そのポジションに提示された単一のアイテム $a(k)$ にのみ依存して決まること**。
  - (つまり、各ユーザは、推薦されたランキングの各アイテムを独立に評価した上で、クリックしたり購入したりという報酬を発生させる。ランキング内の**アイテム間の相互作用を完全に無視する**、という仮定...!:thinking:)
    - まあ問題設定によっては、アイテム間の相互作用を無視しちゃってもいい気もする:thinking:

もちろん「同じアイテムでも、一緒に推薦されたアイテムに応じてクリック確率などが変化するかも」と想定するのが**より厳密で現実的**ではある。しかし、それを全て考慮しようとすると、**定式化はより厳密になる一方で解かなくてはならない問題が複雑化**する。結果として巨大なバリアンスが発生してしまう。
IIPS推定量のように、**ある程度現実性は諦めつつも問題を解くことができるレベルに簡略化できる、という意味で、独立モデルなどのユーザ行動・期待報酬関数に関する仮定は、ランキングにおけるオフ方策評価でとても有用とされている**。

- どんな場合に、ポジションレベルの期待報酬関数が独立性を持つと言えそう??
  - ex.) 真の期待報酬関数が $q_k(x, \mathbf{a}) = \theta(k) \cdot v(x, a(k))$ という構造を持っている状況。
    - ここで
      - $\theta(k)$ は、ランキング中のk番目のポジションがユーザに閲覧される確率。
      - $v(x, a(k))$ は、特徴量 $x$ を持つユーザがアイテム $a(k)$ に持っている興味度合い。
    - 上記の構造を言い換えると...
      - **ユーザがあるk番目のポジションを閲覧し、かつそのポジションに提示されたアイテム $\mathbf{a}(k)$ が興味と合致してた場合に報酬が発生する**状況、を考えている。
      - (ちなみにこれは、情報検索(information retrieval)の分野でよく用いられる、position-based model と呼ばれる、クリックが発生する構造に関する仮定。これは独立性を有するモデルの一つ...!:thinking:)
    - この構造はある程度納得感がありそうだし、独立性を満たしている...!:thinking:

このユーザ行動・期待報酬関数に関する独立性を活用して、IPS推定量を改善した方法が、**IIPS（Independent IPS）推定量**であり、以下で定義される。

$$
\hat{V}_{IIPS}(\pi;D) := \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K \frac{\pi(\mathbf{a}(k) | x_i, k)}{\pi_0(\mathbf{a}(k) | x_i, k)} \alpha_k \mathbf{r}_i(k)
\\
= \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K w_{k}(x_i, \mathbf{a}_i(k)) \alpha_k \mathbf{r}_i(k)
\tag{2.11}
$$

- ここで、
  - $\pi(\mathbf{a}(k) | x, k)$ は、あるアイテム $a \in \mathcal{A}$ が任意のランキングの k 番目のポジションに提示される周辺確率。
    - (なお**計算時には、各ランキングの選択確率を、各アイテム・ポジション毎の周辺確率に変換することになる...!**)
  - $w_{k}(x, \mathbf{a}) := \pi(\mathbf{a}(k) | x, k) / \pi_0(\mathbf{a}(k) | x, k)$ は、**ポジションレベルの重要度重み（position-level importance weight）**。
  - またちなみに...
    - $\hat{V}_{IIPS}^{(k)}(\pi;D) := \frac{1}{n} \sum_{i=1}^n w_{k}(x_i, \mathbf{a}_i(k)) \mathbf{r}_i(k)$ により、k番目のポジションにおける期待報酬に対するIIPS推定量を表すことがある
    - この場合、方策の性能に対するIIPS推定量は $V_{IIPS}(\pi;D) = \sum_{k=1}^K \alpha_k \hat{V}_{IIPS}^{(k)}(\pi;D)$ とも表記できる。

- IIPS推定量のポイント: IPS推定量で用いられていた**ランキングレベルの重要度重みではなく、各アイテムがそれぞれのポジションに提示される周辺確率に基づくポジションレベルの重要度重み**が用いられている点!

独立性が成り立つ場合、IIPS推定量は不偏推定量となり、かつIPS推定量よりもはるかに小さなバリアンスを持つことが知られている。(open bandit pipelineにも実装されてる...!:thinking:)

一方で当然、**独立性が成り立っていない状況ではIIPS推定量も何らかの困難を抱える**はず。
特に独立性は、**ランキング中のアイテム間の相互作用を全て無視するとても強い仮定**なので、この仮定が成り立たない時の不利益もきっちり理解しておく必要がある。

- バイアスを計算していくと...IIPS推定量は、IPS推定量よりも大幅に小さいバリアンスを持つ一方で、独立性が成り立たないユーザの割合の増加に伴って、非常に大きなバイアスが発生してしまう。
  - 仮定が満たされないことで発生するバイアスが、バリアンス減少効果よりも大きいときには、IPS推定量よりも更に大きな誤差を生じる可能性がある。
- よって、**ユーザ行動が単純な場合に備えてIIPS推定量を武器の一つとして持っておくことは有用だが、それだけではより複雑で現実的な状況には対応できないかもしれない**。

### RIPS（Reward-interaction IPS）推定量

- 背景
  - ランキング問題においてIPS推定量は巨大なバリアンスを発生してしまう。一方でIIPS推定量は、期待報酬関数の独立性の仮定が成り立たない場合には大きなバイアスを発生させてしまう。
  - -> 独立性の仮定が成り立たない状況でもバイアスの発生を抑えつつ、バリアんすの減少効果を同時に得ることができる推定量があれば...!:thinking:
  - -> 次に提案されたのが、**RIPS（Reward-interaction IPS）推定量**。

期待報酬関数に関する独立性よりも弱い（より現実的な）**カスケードモデル(cascade model)**と呼ばれる仮定に基づく。

- 仮定: 全ての $x \in \mathcal{X}$ および $k \in [K]$ 、$\mathbf{a} \in \prod(A)$ について、以下が成り立つとき、ポジションレベルの期待報酬関数 $q_k(x, \mathbf{a})$ は**カスケード性**を持つという。

$$
E_{p(\mathbf{r}(k) | x, \mathbf{a})} [\mathbf{r}(k)] = E_{p(\mathbf{r}(k) | x, \mathbf{a}(1:k))} [\mathbf{r}(k)]
\tag{2.17}
$$

- ここで
  - $\mathbf{a}(1:k)$ は、ランキング $\mathbf{a}$ において1番目からk番目までに提示されたアイテムの集合。
- この仮定の意味合い・解釈:
  - **あるランキング $\mathbf{a}$ のk番目のポジションで発生する期待報酬が、そのポジションよりも上位に提示されたアイテム $\mathbf{a}(1:k)$ のみに依存して決まる**こと。
    - i.e. 各ユーザがランキング上位のアイテムから順に吟味し、所望のアイテムを見つけた時に報酬が発生する、という想定。
    - **IIPS推定量の独立性の仮定と比べると、かなり現実的な想定**と言える...!

例えばどんな場合に、ポジションレベルの期待報酬関数 $q_k(x, \mathbf{a})$ がカスケード性を持つと言えそう??
真の期待報酬関数が次のような構造を持っている状況:

$$
q_k(x, \mathbf{a}) = \begin{cases}
  v(x, \mathbf{a}(k)) & (k = 1) \\
  v(x, \mathbf{a}(k)) \prod_{j=1}^{k-1} (1 - v(x, \mathbf{a}(j))) & (k > 1)
\end{cases}
\tag{2.18}
$$

- ここで
  - $v(x, \mathbf{a}(k))$ は、特徴量 $x$ を持つユーザがアイテム $\mathbf{a}(k)$ に持っている興味度合い。
- すなわち上式は、k番目のポジションに提示されたアイテムに対する興味度合いが大きく、またより上位に提示されたアイテム $a(1:k-1)$ に対する興味度合いが小さい場合に、k番目のポジションの期待報酬が大きくなる構造をしている。

このカスケード性の仮定に基づいて提案されたのが、**RIPS（Reward-interaction IPS）推定量**であり、以下で定義される。

$$
\hat{V}_{RIPS}(\pi;D) := \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K \frac{\pi(\mathbf{a}(1:k) | x_i)}{\pi_0(\mathbf{a}(1:k) | x_i)} \alpha_k \mathbf{r}_i(k)
= \frac{1}{n} \sum_{i=1}^n \sum_{k=1}^K w_{1:k}(x_i, \mathbf{a}_i) \alpha_k \mathbf{r}_i(k)
\tag{2.19}
$$

- ここで
  - $\pi(\mathbf{a}(1:k) | x) := \sum_{\mathbf{a}' \in \prod(A)} \mathbb{I}[\mathbf{a}'(1:k) = \mathbf{a}(1:k)] \pi(\mathbf{a}' | x)$ は、上位k番目までのアイテムの組がそれぞれ所定のポジションに提示される周辺確率。
  - $w_{1:k}(x, \mathbf{a})$ は、**トップkに関する重要度重み**(top-k importance weight)と呼ばれる（上位k番目のポジションまでの行動選択確率の比を考えていることから）。

RIPS推定量のポイントは、**IPS推定量で用いられていたランキングレベルの重要度重みではなく、トップkに関する重要度重み**が用いられている点。

- ランキング問題における...
  - IPS推定量 -> ランキングレベルの重要度重み
  - IIPS推定量 -> ポジションレベルの重要度重み
  - RIPS推定量 -> トップkに関する重要度重み

RIPS推定量は、カスケード性の仮定が成り立つ場合には不偏推定量であり、かつIPS推定量よりも小さなバリアンスを持つことが知られている（IIPS推定量よりもバリアンスは大きい）。

### AIPS（Adaptive IPS）推定量
