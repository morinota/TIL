## 0.1. link ãƒªãƒ³ã‚¯

- https://arxiv.org/abs/2305.06566 https://arxiv.org/abs/2305.06566

## 0.2. title ã‚¿ã‚¤ãƒˆãƒ«

A First Look at LLM-Powered Generative News Recommendation
LLMã«ã‚ˆã‚‹ç”Ÿæˆçš„ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã®åˆè¦‹

## 0.3. abstract æŠ„éŒ²

Personalized news recommendation systems have become essential tools for users to navigate the vast amount of online news content, yet existing news recommenders face significant challenges such as the cold-start problem, user profile modeling, and news content understanding.
ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè†¨å¤§ãªã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒŠãƒ“ã‚²ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã«ä¸å¯æ¬ ãªãƒ„ãƒ¼ãƒ«ã¨ãªã£ã¦ã„ã‚‹ãŒã€æ—¢å­˜ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆå•é¡Œã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç†è§£ãªã©ã€å¤§ããªèª²é¡Œã«ç›´é¢ã—ã¦ã„ã‚‹ã€‚
Previous works have typically followed an inflexible routine to address a particular challenge through model design, but are limited in their ability to understand news content and capture user interests.
ã“ã‚Œã¾ã§ã®ç ”ç©¶ã¯ã€ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆã‚’é€šã˜ã¦ç‰¹å®šã®èª²é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®æŸ”è»Ÿæ€§ã«æ¬ ã‘ã‚‹ãƒ«ãƒ¼ãƒãƒ³ã«å¾“ã†ã®ãŒä¸€èˆ¬çš„ã§ã‚ã£ãŸãŒã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å†…å®¹ã‚’ç†è§£ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒã‚’æ‰ãˆã‚‹èƒ½åŠ›ã«ã¯é™ç•ŒãŒã‚ã£ãŸã€‚
In this paper, we introduce GENRE, an LLM-powered generative news recommendation framework, which leverages pretrained semantic knowledge from large language models to enrich news data.
æœ¬ç¨¿ã§ã¯ã€**LLMã‚’æ´»ç”¨ã—ãŸç”Ÿæˆçš„ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹GENRE**ã‚’ç´¹ä»‹ã™ã‚‹ã€‚GENREã¯ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰äº‹å‰ã«å­¦ç¿’ã•ã‚ŒãŸæ„å‘³çŸ¥è­˜ã‚’æ´»ç”¨ã—ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å……å®Ÿã•ã›ã‚‹.
Our aim is to provide a flexible and unified solution for news recommendation by moving from model design to prompt design.
ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã«ç§»è¡Œã™ã‚‹ã“ã¨ã§ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã®ãŸã‚ã®æŸ”è»Ÿã§çµ±ä¸€ã•ã‚ŒãŸã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚
We showcase the use of GENRE for personalized news generation, user profiling, and news summarization.
ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ç”Ÿæˆã€ãƒ¦ãƒ¼ã‚¶ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦ç´„ã«GENREã‚’ä½¿ç”¨ã—ãŸä¾‹ã‚’ç´¹ä»‹ã™ã‚‹ã€‚
Extensive experiments with various popular recommendation models demonstrate the effectiveness of GENRE.
æ§˜ã€…ãªä¸€èˆ¬çš„ãªæ¨è–¦ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸåºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€GENREã®æœ‰åŠ¹æ€§ãŒå®Ÿè¨¼ã•ã‚Œã¦ã„ã‚‹ã€‚
We will publish our code and data for other researchers to reproduce our work.
æˆ‘ã€…ã¯ã€ä»–ã®ç ”ç©¶è€…ãŒæˆ‘ã€…ã®ç ”ç©¶ã‚’å†ç¾ã§ãã‚‹ã‚ˆã†ã«ã€ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã™ã‚‹ã€‚

# 1. Introduction ã¯ã˜ã‚ã«

Online news platforms, such as Google News, play a vital role in disseminating information worldwide.
ã‚°ãƒ¼ã‚°ãƒ«ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚ˆã†ãªã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¯ã€ä¸–ç•Œä¸­ã«æƒ…å ±ã‚’ç™ºä¿¡ã™ã‚‹ä¸Šã§é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ã„ã‚‹ã€‚
However, the sheer volume of articles available on these platforms can be overwhelming for users.
ã—ã‹ã—ã€ã“ã‚Œã‚‰ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§åˆ©ç”¨å¯èƒ½ãªè¨˜äº‹ã®è†¨å¤§ãªé‡ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’åœ§å€’ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
Hence, news recommender systems have become an essential component, guiding users navigate through a vast amount of content and pinpointing articles that align with their interests.
ãã‚Œã‚†ãˆã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã¯ã€è†¨å¤§ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ä¸­ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ãƒŠãƒ“ã‚²ãƒ¼ãƒˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èˆˆå‘³ã«æ²¿ã£ãŸè¨˜äº‹ã‚’ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆã§ç´¹ä»‹ã™ã‚‹ã€ä¸å¯æ¬ ãªè¦ç´ ã¨ãªã£ã¦ã„ã‚‹ã€‚
Nonetheless, present news recommendation systems face several major challenges.
ãã‚Œã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€ç¾åœ¨ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã¯ã„ãã¤ã‹ã®å¤§ããªèª²é¡Œã«ç›´é¢ã—ã¦ã„ã‚‹ã€‚
One such challenge is the well-known cold-start problem, a scenario where many long-tail or new users have limited browsing history, making it difficult to accurately model and understand their interests.
ã“ã®ã‚ˆã†ãªèª²é¡Œã®ã²ã¨ã¤ãŒã€ã‚ˆãçŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆå•é¡Œã§ã‚ã‚‹ã€‚ãƒ­ãƒ³ã‚°ãƒ†ãƒ¼ãƒ«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¤šãã¯é–²è¦§å±¥æ­´ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹ãŸã‚ã€å½¼ã‚‰ã®èˆˆå‘³ã‚’æ­£ç¢ºã«ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¦ç†è§£ã™ã‚‹ã“ã¨ãŒé›£ã—ã„ã¨ã„ã†ã‚·ãƒŠãƒªã‚ªã§ã‚ã‚‹ã€‚
User profile modeling poses another challenge, since user profiles consist of highly condensed information, such as geographic location or topics of interest, which are frequently withheld from datasets due to privacy concerns.
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€åœ°ç†çš„ãªä½ç½®ã‚„é–¢å¿ƒã®ã‚ã‚‹ãƒˆãƒ”ãƒƒã‚¯ãªã©ã€éå¸¸ã«å‡ç¸®ã•ã‚ŒãŸæƒ…å ±ã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã®å•é¡Œã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œãªã„ã“ã¨ãŒå¤šã„ã€‚
Additionally, there is the unique challenge of news content understanding in the field of news recommendation.
ã•ã‚‰ã«ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã®åˆ†é‡ã§ã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹å†…å®¹ã®ç†è§£ã¨ã„ã†ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªèª²é¡ŒãŒã‚ã‚‹ã€‚
Due to limited and unaligned text information in news datasets, it can be challenging for models to capture the deeper semantics of news articles.
ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã¯é™ã‚‰ã‚Œã¦ãŠã‚Šã€æ•´åˆæ€§ãŒã¨ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ãŒãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®æ·±ã„æ„å‘³ã‚’æ‰ãˆã‚‹ã“ã¨ã¯å›°é›£ã§ã‚ã‚‹ã€‚
For instance, in an article (in the MIND [48] dataset) with the title â€œHereâ€™s Exactly When To Cook Every Dish For Thanksgiving Dinnerâ€, the main idea may be â€œguidanceâ€ or â€œinstructionsâ€ rather than the specific terms mentioned in the title.
ä¾‹ãˆã°ã€ã€ŒHere's Exactly When To Cook Every Dish For Thanksgiving Dinnerã€ã¨ã„ã†ã‚¿ã‚¤ãƒˆãƒ«ã®è¨˜äº‹ï¼ˆMIND [48]ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ï¼‰ã§ã¯ã€ã‚¿ã‚¤ãƒˆãƒ«ã§è¨€åŠã•ã‚Œã¦ã„ã‚‹ç‰¹å®šã®ç”¨èªã§ã¯ãªãã€ã€Œã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã€ã‚„ã€ŒæŒ‡ç¤ºã€ãŒä¸»ãªã‚¢ã‚¤ãƒ‡ã‚¢ã‹ã‚‚ã—ã‚Œãªã„ã€‚
However, accurately identifying key concepts or themes in news articles can be challenging, which in turn affects the ability of news recommender systems to provide personalized recommendations to users.
ã—ã‹ã—ã€**ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ä¸­ã®ä¸»è¦ãªæ¦‚å¿µã‚„ãƒ†ãƒ¼ãƒã‚’æ­£ç¢ºã«ç‰¹å®šã™ã‚‹ã“ã¨**ã¯å›°é›£ã§ã‚ã‚Šã€ãã‚Œã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸæ¨è–¦ã‚’æä¾›ã™ã‚‹èƒ½åŠ›ã«å½±éŸ¿ã™ã‚‹ã€‚
Previous works [19, 41, 45] have proposed various recommendation models to tackle the aforementioned challenges.
å…ˆè¡Œç ”ç©¶[19, 41, 45]ã§ã¯ã€å‰è¿°ã®èª²é¡Œã«å–ã‚Šçµ„ã‚€ãŸã‚ã«æ§˜ã€…ãªæ¨è–¦ãƒ¢ãƒ‡ãƒ«ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚
However, due to the limited data and knowledge available in the training dataset, these models are limited in their ability to understand news content and capture user interests.
ã—ã‹ã—ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚„çŸ¥è­˜ã«ã¯é™ã‚ŠãŒã‚ã‚‹ãŸã‚ã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å†…å®¹ã‚’ç†è§£ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒã‚’æŠŠæ¡ã™ã‚‹èƒ½åŠ›ã«é™ç•ŒãŒã‚ã‚‹ã€‚
Although some methods [37] have attempted to incorporate external sources, such as knowledge graphs, their performance is often constrained by the size of the knowledge graphs.
ã„ãã¤ã‹ã®æ‰‹æ³•[37]ã¯ã€çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®ã‚ˆã†ãªå¤–éƒ¨ã‚½ãƒ¼ã‚¹ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã‚’è©¦ã¿ã¦ã„ã‚‹ãŒã€ãã®æ€§èƒ½ã¯çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®ã‚µã‚¤ã‚ºã«ã‚ˆã£ã¦åˆ¶ç´„ã‚’å—ã‘ã‚‹ã“ã¨ãŒå¤šã„ã€‚

LLM-powered generative news recommendation: a novel perspective.
LLMã‚’åˆ©ç”¨ã—ãŸç”Ÿæˆçš„ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ï¼šæ–°ã—ã„è¦–ç‚¹ã€‚
The advancement of large language models (LLMs), such as ChatGPT2 or LLaMA [32], has revolutionized the field of natural language processing.
ChatGPT2ã‚„LLaMA [32]ã®ã‚ˆã†ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®é€²æ­©ã¯ã€è‡ªç„¶è¨€èªå‡¦ç†ã®åˆ†é‡ã«é©å‘½ã‚’ã‚‚ãŸã‚‰ã—ãŸã€‚
The exceptional language modeling capability of LLMs enables them to understand complex patterns and relationships in language.
LLMã®å“è¶Šã—ãŸè¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°èƒ½åŠ›ã«ã‚ˆã‚Šã€è¨€èªã®è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„é–¢ä¿‚ã‚’ç†è§£ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
As powerful few-shot learners, they can quickly learn the distribution of news data and incorporate relevant contextual information to improve their understanding of the data.
å¼·åŠ›ãªæ•°ç™ºå­¦ç¿’è€…ã¨ã—ã¦ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒã‚’ç´ æ—©ãå­¦ç¿’ã—ã€é–¢é€£ã™ã‚‹æ–‡è„ˆæƒ…å ±ã‚’å–ã‚Šå…¥ã‚Œã¦ãƒ‡ãƒ¼ã‚¿ã®ç†è§£ã‚’æ·±ã‚ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
This makes LLMs a suitable tool for addressing the challenges of news recommendation systems, including the cold-start problem, user profile modeling, and news content understanding.
ã“ã®ãŸã‚LLMã¯ã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆå•é¡Œã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹å†…å®¹ã®ç†è§£ãªã©ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®èª²é¡Œã«å–ã‚Šçµ„ã‚€ã®ã«é©ã—ãŸãƒ„ãƒ¼ãƒ«ã¨ãªã£ã¦ã„ã‚‹ã€‚

In this work, we introduce a novel perspective for news recommendation by using LLMs to generate informative knowledge and news data such as synthetic news content tailored to cold-start users, user profiles, and refined news titles, which can be utilized to enhance the original dataset and tackle the aforementioned challenges.
æœ¬ç ”ç©¶ã§ã¯ã€LLMã‚’ç”¨ã„ã¦ã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆãƒ¦ãƒ¼ã‚¶ã«åˆã‚ã›ãŸåˆæˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã€æ´—ç·´ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ãªã©ã€æœ‰ç›ŠãªçŸ¥è­˜ã¨ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€**ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‹¡å¼µ**ã—ã€å‰è¿°ã®èª²é¡Œã«å–ã‚Šçµ„ã‚€ãŸã‚ã«åˆ©ç”¨ã§ãã‚‹ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã®ãŸã‚ã®æ–°ã—ã„è¦–ç‚¹ã‚’ç´¹ä»‹ã™ã‚‹ã€‚

Figure 1 illustrates our proposed LLM-powered GEnerative News REcommendation (GENRE) framework.
å›³1ã¯ã€æˆ‘ã€…ãŒææ¡ˆã™ã‚‹LLMã‚’åˆ©ç”¨ã—ãŸ**GEnerative News REcommendationï¼ˆGENREï¼‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
The main idea is to utilize the available news data, such as the title, abstract, and category of each news article, to construct prompts or guidelines, which can then be fed into an LLM for producing informative news information.
ä¸»ãªã‚¢ã‚¤ãƒ‡ã‚¢ã¯ã€å„ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã€æŠ„éŒ²ã€ã‚«ãƒ†ã‚´ãƒªãªã©ã®åˆ©ç”¨å¯èƒ½ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã—ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã€ãã‚Œã‚’LLMã«å…¥åŠ›ã—ã¦æœ‰ç›Šãªãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’ä½œæˆã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
Due to its extensive pretrained semantic knowledge, the LLM can comprehend the underlying distribution of news data, even with very limited information provided in the original dataset, and generate enriched news data and information.
LLMã¯ã€äº‹å‰ã«è¨“ç·´ã•ã‚ŒãŸåºƒç¯„ãªæ„å‘³çš„çŸ¥è­˜ã«ã‚ˆã‚Šã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æä¾›ã•ã‚Œã‚‹æƒ…å ±ãŒéå¸¸ã«é™ã‚‰ã‚Œã¦ã„ã¦ã‚‚ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®æ ¹æœ¬çš„ãªåˆ†å¸ƒã‚’ç†è§£ã—ã€å……å®Ÿã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã¨æƒ…å ±ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
These generated news data and information can be integrated back into the original dataset for the next round of knowledge generation in an iterative fashion, or utilized to train downstream news recommendation models.
ã“ã‚Œã‚‰ã®ç”Ÿæˆã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚„æƒ…å ±ã¯ã€æ¬¡ã®çŸ¥è­˜ç”Ÿæˆã®ãŸã‚ã«å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ç¹°ã‚Šè¿”ã—çµ±åˆã—ãŸã‚Šã€ä¸‹æµã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«åˆ©ç”¨ã—ãŸã‚Šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
In this study, we explore GENRE for 1) personalized news generation, 2) user profiling, and 3) news summarization, to address the three challenges mentioned above.
æœ¬ç ”ç©¶ã§ã¯ã€ä¸Šè¨˜ã®3ã¤ã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€1ï¼‰ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ç”Ÿæˆã€2ï¼‰ãƒ¦ãƒ¼ã‚¶ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã€3ï¼‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦ç´„ã®ãŸã‚ã®GENREã‚’æ¢æ±‚ã™ã‚‹ã€‚
To validate the effectiveness of our proposed GENRE framework, we perform comprehensive experiments on IM-MIND [50], a multimodal news recommendation dataset derived from MIND [48].
ææ¡ˆã™ã‚‹GENREãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«ã€MIND [48]ã‹ã‚‰æ´¾ç”Ÿã—ãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹IM-MIND [50]ã‚’ç”¨ã„ã¦åŒ…æ‹¬çš„ãªå®Ÿé¨“ã‚’è¡Œã£ãŸã€‚
We employ GPT-3.5 as the LLM and collect the generated data through API calls.
**LLMã¨ã—ã¦GPT-3.5ã‚’æ¡ç”¨ã—ã€APIã‚³ãƒ¼ãƒ«ã«ã‚ˆã£ã¦ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚’åé›†**ã™ã‚‹ã€‚(ãŠé‡‘ãŸãã•ã‚“ã‹ã‹ã‚Šãã†...!)
Our evaluation involves four matching-based news recommendation models and four ranking-based CTR models, all of which are typical and widely used in industrial recommender systems.
æˆ‘ã€…ã®è©•ä¾¡ã§ã¯ã€4ã¤ã®ãƒãƒƒãƒãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã¨4ã¤ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®CTRãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸã€‚
We observe that GENRE improves the performance of the base models significantly.
æˆ‘ã€…ã¯ã€**GENREãŒãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹**ã“ã¨ã‚’ç¢ºèªã—ãŸã€‚
To summarize, our contributions are listed as follows:
è¦ç´„ã™ã‚‹ã¨ã€æˆ‘ã€…ã®è²¢çŒ®ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã‚ã‚‹ï¼š

- To our knowledge, this work is the first attempt to exploit LLMs for generative news recommendation. æˆ‘ã€…ã®çŸ¥ã‚‹é™ã‚Šã€ã“ã®ç ”ç©¶ã¯LLMã‚’ç”Ÿæˆçš„ãªãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã«åˆ©ç”¨ã™ã‚‹æœ€åˆã®è©¦ã¿ã§ã‚ã‚‹ã€‚

- We propose GENRE, an LLM-based generative news recommendation framework. Compared to traditional methods that require designing individual models for different tasks, GENRE offers a flexible and unified solution by introducing pretrained semantic knowledge to the training data through prompt design. æˆ‘ã€…ã¯ã€LLMãƒ™ãƒ¼ã‚¹ã®ç”Ÿæˆçš„ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹GENREã‚’ææ¡ˆã™ã‚‹ã€‚ ã‚¿ã‚¹ã‚¯ã”ã¨ã«å€‹åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨­è¨ˆã™ã‚‹å¿…è¦ãŒã‚ã‚‹å¾“æ¥ã®æ‰‹æ³•ã«æ¯”ã¹ã€GENREã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã‚’é€šã˜ã¦è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«äº‹å‰è¨“ç·´ã•ã‚ŒãŸæ„å‘³çŸ¥è­˜ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€æŸ”è»Ÿã‹ã¤çµ±ä¸€çš„ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã™ã‚‹ã€‚

- We demonstrate the effectiveness of GENRE through extensive experimentation and evaluation on three tasks: 1) personalized news generation, 2) user profiling, and 3) news summarization. GENREã®æœ‰åŠ¹æ€§ã‚’ã€3ã¤ã®ã‚¿ã‚¹ã‚¯ã«é–¢ã™ã‚‹åºƒç¯„ãªå®Ÿé¨“ã¨è©•ä¾¡ã‚’é€šã˜ã¦å®Ÿè¨¼ã™ã‚‹ï¼š 1ï¼‰ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ç”Ÿæˆã€2ï¼‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã€3ï¼‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦ç´„ã§ã‚ã‚‹ã€‚

# 2. Preliminaries å‰å“¨æˆ¦

## 2.1. Notations and Problem Statement

Before delving into the details of our proposed method, we first introduce basic notations and formally define the news recommendation task.
ææ¡ˆæ‰‹æ³•ã®è©³ç´°ã«å…¥ã‚‹å‰ã«ã€ã¾ãšåŸºæœ¬çš„ãªè¨˜æ³•ã‚’ç´¹ä»‹ã—ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚¿ã‚¹ã‚¯ã‚’æ­£å¼ã«å®šç¾©ã™ã‚‹ã€‚
Let N be a set of news articles, where each news ğ‘› âˆˆ N is represented by a multi-modal feature set including the title, category, and cover image.
$N$ ã‚’ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®é›†åˆã¨ã—ã€å„ãƒ‹ãƒ¥ãƒ¼ã‚¹ $n \in N$ ã¯ã‚¿ã‚¤ãƒˆãƒ«ã€ã‚«ãƒ†ã‚´ãƒªã€ã‚«ãƒãƒ¼ç”»åƒã‚’å«ã‚€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç‰¹å¾´é‡ã‚»ãƒƒãƒˆã§è¡¨ã•ã‚Œã‚‹.
Let U be a set of users, where each user ğ‘¢ âˆˆ U has a history of reading news articles â„ (ğ‘¢) .
$U$ ã‚’ãƒ¦ãƒ¼ã‚¶é›†åˆã¨ã—ã€å„ãƒ¦ãƒ¼ã‚¶ $u \in U$ ã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’èª­ã‚“ã å±¥æ­´ $h (u)$ ã‚’æŒã¤.
Let D be a set of click data, where each click ğ‘‘ âˆˆ D is a tuple (ğ‘¢, ğ‘›, ğ‘¦) indicating whether user ğ‘¢ clicked on news article ğ‘› with label ğ‘¦ âˆˆ {0, 1}.
å„ã‚¯ãƒªãƒƒã‚¯ $d \in D$ ã¯ã€ãƒ©ãƒ™ãƒ« $y \in {0, 1}$ ã‚’æŒã¤ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ $n$ ã‚’ãƒ¦ãƒ¼ã‚¶ $u$ ãŒã‚¯ãƒªãƒƒã‚¯ã—ãŸã‹ã©ã†ã‹ã‚’ç¤ºã™ã‚¿ãƒ—ãƒ« $(u, n, y)$ ã§ã‚ã‚‹ã€‚
The task of the news recommendation is to infer the userâ€™s interest in a candidate news article.
ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã®ã‚¿ã‚¹ã‚¯ã¯ã€**å€™è£œã¨ãªã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«å¯¾ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ã®interestã‚’æ¨æ¸¬ã™ã‚‹ã“ã¨**ã§ã‚ã‚‹ã€‚

## 2.2. General News Recommendation Model ä¸€èˆ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ãƒ¢ãƒ‡ãƒ«

A news recommendation model generally involves three modules: a news encoder, a user encoder, and an interaction module.
ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã«ã¯ä¸€èˆ¬çš„ã«ã€**ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®3ã¤ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**ãŒå«ã¾ã‚Œã‚‹ã€‚
The news encoder, as depicted in Figure 2, is designed to encode the multimodal features of each news article into a unified ğ‘‘-dimension news vector vğ‘›.
å›³2ã«ç¤ºã™ã‚ˆã†ã«ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ã€å„ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªç‰¹å¾´ã‚’çµ±ä¸€ã•ã‚ŒãŸ $d$ æ¬¡å…ƒã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ™ã‚¯ãƒˆãƒ« $v_n$ ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã‚‹.
The user encoder, as shown in Figure 3a, is designed on the top of the news encoder, generating a unified ğ‘‘-dimension user vector vğ‘¢ from the sequence of browsed news vectors.
å›³3aã«ç¤ºã™ã‚ˆã†ã«ã€**ãƒ¦ãƒ¼ã‚¶ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®ä¸Šã«è¨­è¨ˆ(ã¯ã„ã¯ã„ç¢ºã‹ã«...åŸºæœ¬çš„ã«ã¯ãã†)**ã•ã‚Œã¦ãŠã‚Šã€é–²è¦§ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒ™ã‚¯ãƒˆãƒ«åˆ—ã‹ã‚‰çµ±ä¸€ã•ã‚ŒãŸ $d$ æ¬¡å…ƒã®ãƒ¦ãƒ¼ã‚¶ãƒ™ã‚¯ãƒˆãƒ« $v_u$ ã‚’ç”Ÿæˆã™ã‚‹ã€‚
Finally, the interaction modules in ranking models (such as DCN [39]) and matching models (such as NAML [43]) have some differences.
æœ€å¾Œã«ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«(DCN [39]ãªã©)ã¨ãƒãƒƒãƒãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«(NAML [43]ãªã©)ã®ç›¸äº’ä½œç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã¯ã„ãã¤ã‹ã®é•ã„ãŒã‚ã‚‹.
For ranking models, the click-through probability is directly calculated based on the candidate news vector vğ‘ and the user vector vğ‘¢, which is a regression problem.
ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€ã‚¯ãƒªãƒƒã‚¯ã‚¹ãƒ«ãƒ¼ç¢ºç‡ã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹å€™è£œãƒ™ã‚¯ãƒˆãƒ«$v_c$ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ™ã‚¯ãƒˆãƒ« $v_u$ ã«åŸºã¥ã„ã¦ç›´æ¥è¨ˆç®—ã•ã‚Œã‚‹ãŒã€ã“ã‚Œã¯å›å¸°å•é¡Œã§ã‚ã‚‹.
In contrast, for matching models, the interaction module needs to identify the positive sample that best matches the user vector vğ‘¢ among multiple candidate news vectors Vğ‘ = [v (1) ğ‘ , ..., v (ğ‘˜+1) ğ‘ ] where ğ‘˜ is the number of negative samples, which is a classification problem.
å¯¾ç…§çš„ã«ã€ãƒãƒƒãƒãƒ³ã‚°ãƒ»ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€ç›¸äº’ä½œç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€è¤‡æ•°ã®å€™è£œãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ãƒ™ã‚¯ãƒˆãƒ« $V_{c} = [v(1)_c, \cdots, v(k+1)_c]$ (kã¯ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ»ã‚µãƒ³ãƒ—ãƒ«ã®æ•°)ã®ä¸­ã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ãƒ»ãƒ™ã‚¯ãƒˆãƒ« $v_u$ ã«æœ€ã‚‚ãƒãƒƒãƒã™ã‚‹ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ã‚µãƒ³ãƒ—ãƒ«ã‚’ç‰¹å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€ã“ã‚Œã¯åˆ†é¡å•é¡Œã§ã‚ã‚‹.
(æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªmatching modelãŒã€ãƒ™ã‚¯ãƒˆãƒ«é–“ã®é¡ä¼¼åº¦ã§ç‰¹å®šã™ã‚‹æ–¹æ³•ãªã®ã‹ãª.)

The design of the news encoder, user encoder, and interaction module varies across different news recommendation models.
ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã€ãƒ¦ãƒ¼ã‚¶ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®è¨­è¨ˆã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ç•°ãªã‚‹.

# 3. Proprsed Framework: GENRE ã‚¸ãƒ£ãƒ³ãƒ«

## 3.1. Overview æ¦‚è¦

Figure 1 illustrate the our proposed GENRE framework for LLMpowered generative news recommendation, which consists of the following four steps.1) Prompting: create prompts or instructions to harness the capability of a LLM for data generation for diverse objectives.2) Generating: the LLM generates new knowledge and data based on the designed prompts.3) Updating: use the LLMgenerated data to update the current data for the next round of prompting and generation, which is optional.4) Training: leverage the LLM-generated data to train news recommendation models.
å›³1ã¯ã€LLMã‚’æ´»ç”¨ã—ãŸç”Ÿæˆçš„ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã®ãŸã‚ã®GENREãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ææ¡ˆã§ã‚ã‚Šã€ä»¥ä¸‹ã®4ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹ã€‚

- 1ï¼‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ï¼šå¤šæ§˜ãªç›®çš„ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ãŸã‚ã«LLMã®èƒ½åŠ›ã‚’æ´»ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„æŒ‡ç¤ºã‚’ä½œæˆã™ã‚‹ã€‚
- 2ï¼‰ã‚¸ã‚§ãƒãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼šLLMã¯è¨­è¨ˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸºã¥ã„ã¦æ–°ã—ã„çŸ¥è­˜ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã€‚
- 3ï¼‰ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼šLLMãŒç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€æ¬¡ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã¨ç”Ÿæˆã®ãƒ©ã‚¦ãƒ³ãƒ‰ã®ãŸã‚ã«ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã€‚

Prompt design forms the foundation of GENRE, and the iterative generation and updating mechanism allows for an expansive and complex design space.
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»ãƒ‡ã‚¶ã‚¤ãƒ³ã¯GENREã®åŸºç¤ã‚’å½¢æˆã—ã€åå¾©çš„ãªç”Ÿæˆã¨æ›´æ–°ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒåºƒå¤§ã§è¤‡é›‘ãªãƒ‡ã‚¶ã‚¤ãƒ³ç©ºé–“ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚
In the following, we show examples of prompts designed under GENRE for news summarization, user profile modeling, and personalized news generation.
ä»¥ä¸‹ã§ã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦ç´„ã€ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã€ãŠã‚ˆã³ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ç”Ÿæˆã®ãŸã‚ã«GENREã®ä¸‹ã§è¨­è¨ˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¾‹ã‚’ç¤ºã™ã€‚

## 3.2. LLM as News Summarizer ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦ç´„ã¨ã—ã¦ã®LLM

Large language models are capable of summarizing news content into concise phrases or sentences, due to their training on vast amounts of natural language data and summarization tasks.
å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€è†¨å¤§ãªé‡ã®è‡ªç„¶è¨€èªãƒ‡ãƒ¼ã‚¿ã¨è¦ç´„ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹å­¦ç¿’ã«ã‚ˆã‚Šã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç°¡æ½”ãªãƒ•ãƒ¬ãƒ¼ã‚ºã‚„ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã«è¦ç´„ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
Moreover, large language models possess remarkable skills in comprehending text, allowing them to identify noun entities like the names of individuals and locations.
ã•ã‚‰ã«ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ç†è§£ã™ã‚‹ä¸Šã§å“è¶Šã—ãŸã‚¹ã‚­ãƒ«ã‚’æŒã£ã¦ãŠã‚Šã€å€‹äººåã‚„å ´æ‰€ã®ã‚ˆã†ãªåè©ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’è­˜åˆ¥ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
These entities may have appeared infrequently in the original dataset, making it challenging to learn their representations.
ã“ã‚Œã‚‰ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¯ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯å‡ºç¾é »åº¦ãŒä½ãã€ãã®è¡¨ç¾ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒå›°é›£ã§ã‚ã‚‹ã€‚
However, large language models can associate them more effectively with knowledge learned during pre-training.
ã—ã‹ã—ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€äº‹å‰å­¦ç¿’ã§å­¦ã‚“ã çŸ¥è­˜ã‚’ã‚ˆã‚ŠåŠ¹æœçš„ã«é–¢é€£ä»˜ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚

Therefore, we design a prompt for news title enhancement, as shown in Figure 4a.
ãã“ã§ã€å›³4aã«ç¤ºã™ã‚ˆã†ã«ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å¼·èª¿ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ‡ã‚¶ã‚¤ãƒ³ã™ã‚‹ã€‚
By providing the news title, abstract, and category as input, the large language model produces a more informative news title as output.
ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒˆãƒ«ã€ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’å…¥åŠ›ã¨ã—ã¦æä¾›ã™ã‚‹ã“ã¨ã§ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã‚ˆã‚Šæƒ…å ±é‡ã®å¤šã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å‡ºåŠ›ã¨ã—ã¦ç”Ÿæˆã™ã‚‹ã€‚
As shown by the provided sample, the enhanced title not only summarizes the news information but also highlights the main topic of the news â€“ â€œguideâ€, which is missing from the original title.
æä¾›ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ã§ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€å¼·åŒ–ã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«ã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’è¦ç´„ã™ã‚‹ã ã‘ã§ãªãã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã§ã‚ã‚‹ã€Œã‚¬ã‚¤ãƒ‰ã€ã‚’å¼·èª¿ã—ã¦ã„ã‚‹ã€‚

During the training of the recommendation model, the enhanced news title will replace the original title and be used as one of the input features, together with other multi-modal features, for the news encoder (Figure 2).
æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ä¸­ã€**å¼·åŒ–ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ã¯å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«ã«ç½®ãæ›ãˆã‚‰ã‚Œ**ã€ä»–ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç‰¹å¾´ã¨ã¨ã‚‚ã«ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®å…¥åŠ›ç‰¹å¾´ã®1ã¤ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã‚‹ï¼ˆå›³2ï¼‰ã€‚
The green news vectors in Figure 3b represent the news vectors with the enhanced titles.
å›³3bã®ç·‘è‰²ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ãƒ™ã‚¯ãƒˆãƒ«ã¯ã€ã‚¿ã‚¤ãƒˆãƒ«ãŒå¼·èª¿ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ãƒ™ã‚¯ãƒˆãƒ«ã§ã‚ã‚‹ã€‚

## 3.3. LLM as User Profiler ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ã¨ã—ã¦ã®LLM

The user profile generally refers to their preferences and characteristics, such as age, gender, topics of interest, and geographic location.
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã¯ä¸€èˆ¬çš„ã«ã€å¹´é½¢ã€æ€§åˆ¥ã€èˆˆå‘³ã®ã‚ã‚‹è©±é¡Œã€åœ°ç†çš„ãªå ´æ‰€ãªã©ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å—œå¥½ã‚„ç‰¹å¾´ã‚’æŒ‡ã™ã€‚
These explicit preferences often serve as important features for click-through rate (CTR) recommendation models.
ã“ã®ã‚ˆã†ãªæ˜ç¤ºçš„ãªå—œå¥½ã¯ã€ã‚¯ãƒªãƒƒã‚¯ã‚¹ãƒ«ãƒ¼ç‡ï¼ˆCTRï¼‰æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã®é‡è¦ãªç‰¹å¾´ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã“ã¨ãŒå¤šã„ã€‚
However, these information are usually not provided in the anonymized dataset for training recommendation models, due to privacy policies.
ã—ã‹ã—ã€æ¨è–¦ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã®åŒ¿ååŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã®ãŸã‚ã€ã“ã‚Œã‚‰ã®æƒ…å ±ã¯é€šå¸¸æä¾›ã•ã‚Œãªã„ã€‚
Large language models are capable of understanding a userâ€™s reading history through their ability to model long sequences, enabling them to analyze and create an outline of the userâ€™s profile.
å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€**é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹èƒ½åŠ›**ã‚’é€šã˜ã¦ã€ãƒ¦ãƒ¼ã‚¶ã®èª­æ›¸å±¥æ­´ã‚’ç†è§£ã™ã‚‹ã“ã¨ãŒã§ãã€ãƒ¦ãƒ¼ã‚¶ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€æ¦‚è¦ã‚’ä½œæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
Hence, we design a prompt for user profiles modeling, as depicted in Figure 4b.
ãã“ã§ã€å›³4bã«ç¤ºã™ã‚ˆã†ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ‡ã‚¶ã‚¤ãƒ³ã™ã‚‹ã€‚
Given a userâ€™s reading history, the large language model produces a user profile that includes his/her interested topics and regions.
**ãƒ¦ãƒ¼ã‚¶ã®èª­æ›¸å±¥æ­´ãŒä¸ãˆã‚‰ã‚Œã‚‹ã¨ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€ãã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒèˆˆå‘³ã‚’æŒã£ã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚„åœ°åŸŸã‚’å«ã‚€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ**ã™ã‚‹ã€‚
In this example, the LLM infers that the user may be interested in the region of Florida, based on the word â€œMiamiâ€ in the news.
ã“ã®ä¾‹ã§ã¯ã€LLMã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ä¸­ã®ã€Œãƒã‚¤ã‚¢ãƒŸã€ã¨ã„ã†å˜èªã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ•ãƒ­ãƒªãƒ€ã¨ã„ã†åœ°åŸŸã«èˆˆå‘³ãŒã‚ã‚‹ã®ã§ã¯ãªã„ã‹ã¨æ¨æ¸¬ã™ã‚‹ã€‚
Although â€œMiamiâ€ may have a low occurrence in the dataset, â€œFloridaâ€ is more frequently represented and therefore more likely to be connected to other news or users for collaborative filtering.
ãƒã‚¤ã‚¢ãƒŸã€ã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯å‡ºç¾ç‡ãŒä½ã„ã‹ã‚‚ã—ã‚Œãªã„ãŒã€ã€Œãƒ•ãƒ­ãƒªãƒ€ã€ã¯ã‚ˆã‚Šé »ç¹ã«å‡ºç¾ã™ã‚‹ãŸã‚ã€å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®ãŸã‚ã«ä»–ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨çµã³ä»˜ã‘ã‚‰ã‚Œã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã€‚
The summarized user profile will be fed into an interest fusion module which produces a interest vector vğ‘– (the pink vector in Figure 3c), defined by
è¦ç´„ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¤ãƒ³ã‚¿ãƒ¬ã‚¹ãƒˆãƒ»ãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ä¾›çµ¦ã•ã‚Œã€ã‚¤ãƒ³ã‚¿ãƒ¬ã‚¹ãƒˆãƒ»ãƒ™ã‚¯ãƒˆãƒ«vğ‘–ï¼ˆå›³3cã®ãƒ”ãƒ³ã‚¯ã®ãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã‚’ç”Ÿæˆã™ã‚‹ã€‚

$$
\tag{1}
$$

where POOL is the average pooling operation, Etopics and Eregions are the embedding matrices of the interested topics and regions, and [; ] is the vector concatenation operation.
ã“ã“ã§ã€POOLã¯å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°æ¼”ç®—ã€Etopicsã¨Eregionsã¯é–¢å¿ƒã®ã‚ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã¨åœ°åŸŸã®åŸ‹ã‚è¾¼ã¿è¡Œåˆ—ã€[; ]ã¯ãƒ™ã‚¯ãƒˆãƒ«é€£çµæ¼”ç®—ã§ã‚ã‚‹ã€‚
The interest vector vğ‘– will be combined with the user vector vğ‘¢ (the blue vector in Figure 3c) learned by the user encoder to form the interest-aware user vector vğ‘–ğ‘¢ (the purple vector in Figure 3c) as follows:
é–¢å¿ƒãƒ™ã‚¯ãƒˆãƒ«vğ‘–ã¯ã€ãƒ¦ãƒ¼ã‚¶ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŒå­¦ç¿’ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ™ã‚¯ãƒˆãƒ«v_46ï¼ˆå›³3cã®é’ãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã¨çµåˆã•ã‚Œã€ä»¥ä¸‹ã®ã‚ˆã†ã«é–¢å¿ƒå¯¾å¿œãƒ¦ãƒ¼ã‚¶ãƒ™ã‚¯ãƒˆãƒ«vğ‘–á‘¢ï¼ˆå›³3cã®ç´«ãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã‚’å½¢æˆã™ã‚‹ï¼š

$$

\tag{2}
\tag{2}ã‚¿ã‚°


$$

where MLP is a multi-layer perceptron with ReLU activation.

## 3.4. LLM as Personalized News Generator

The cold-start problem, which is well-known for its difficulties, occurs when new users3 have limited interaction data, making it difficult for the user encoder to capture their characteristics and ultimately weakening its ability to model warm users 4 . Recent studies [7, 33] have shown that LLMs possess exceptional capabilities to learn from few examples. Hence, we propose to use an LLM to model the distribution of user-interested news given very limited user historical data. Specifically, we use it as a personalized news generator to generate synthetic news that may be of interest to new users, enhancing their historical interactions and allowing the user encoder to learn effective user representations. The prompt displayed in Figure 4c serves as a guide for the personalized news generator, allowing the LLM to create synthetic news pieces tailored to the userâ€™s interests. The generated news pieces (indicated by the yellow news vectors in Figure 3d) are incorporated into the user historical sequence, which will be encoded and fed to the user encoder to generate the user vector.

## 3.5. Chain-based Generation

While we have shown several examples of â€œone-pass generationâ€ (Figure 4) under our GENRE framework, it is worth noting that the design space of GENRE is vast and of a high-order complexity. As illustrated by the diagram in Figure 1, GENRE enables iterative generation and updating. The data generated by the LLM can be leveraged to enhance the quality of current data, which can subsequently be utilized in the next round of generation and prompting in an iterative fashion. We refer to this type of generation as â€œchainbased generationâ€, in contrast to â€œone-pass generationâ€. We design a chain-based personalized news generator by combining the one-pass user profiler and personalized news generator. As illustrated in Figure 5, we first use the LLM to generate the interested topics and regions of a user, which are then combined with the user history news list to prompt the LLM to generate synthetic news pieces. The user profile helps the LLM to engage in chain thinking, resulting in synthetic news that better matches the userâ€™s interests than the one-pass generator. The prompt for the chain-based generator is provided in the supplementary materials.

## 3.6. Downstream Training

Our GENRE framework can be applied with any news recommendation model. Existing news recommendation models mainly include matching-based models such as NAML [43], LSTUR [1], NRMS [45], and PLMNR [46], and ranking-based deep CTR models, such as BST [4], DCN [39], PNN [26], and DIN [55]. Since ranking-based models directly calculate the click-through rate, they place greater emphasis on the design of multiple feature interactions, compared to the relatively straightforward design of the news encoder and user encoder (Table 2). These models are trained with the binary cross-entropy loss defined as:

$$

\tag{3}
\tag{3}ã‚¿ã‚°


$$

where ğ‘§ is the batch size, ğ‘¦ğ‘– is the label of the ğ‘–-th sample (can be 0 or 1), and ğ‘¦Ë†ğ‘– is the predicted probability of the ğ‘–-th sample. In contrast, matching-based models concentrate on capturing semantic information from news features and user interests. Therefore, they prioritize the design of news encoder and user encoder and use a relatively simple interaction module (Table 2). These models are trained using the cross-entropy loss:

$$

\tag{4}
\4}ã‚¿ã‚°
$$
