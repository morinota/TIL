# STAR: A Simple Training-free Approach for Recommendations using Large Language Models

## abstract

Recent progress in large language models (LLMs) offers promising new approaches for recommendation system (RecSys) tasks. While the current state-of-the-art methods rely on fine-tuning LLMs to achieve optimal results, this process is costly and introduces significant engineering complexities. Conversely, methods that bypass fine-tuning and use LLMs directly are less resource-intensive but often fail to fully capture both semantic and collaborative information, resulting in sub-optimal performance compared to their fine-tuned counterparts. In this paper, we propose a Simple Training-free Approach for Recommendation (STAR), a framework that utilizes LLMs and can be applied to various recommendation tasks without the need for fine-tuning. Our approach involves a retrieval stage that uses semantic embeddings from LLMs combined with collaborative user information to retrieve candidate items. We then apply an LLM for pairwise ranking to enhance next-item prediction. Experimental results on the Amazon Review dataset show competitive performance for next item prediction, even with our retrieval stage alone. Our full method achieves Hits@10 performance of +23.8% on Beauty, +37.5% on Toys and Games, and -1.8% on Sports and Outdoors relative to the best supervised models. This framework offers an effective alternative to traditional supervised models, highlighting the potential of LLMs in recommendation systems without extensive training or custom architectures.

## Introduction

Personalized recommendation systems have become indispensable tools for enhancing user experiences and driving engagement across a wide range of online platforms. Recent advances in large language models (LLMs) present new opportunities for addressing recommendation tasks (brown2020language,; team2023gemini,; lin2023can,; zhao2023recommender,; li2023large,; chen2024large,; tsai-etal-2024-leveraging,; wu2024survey,). Current strategies primarily involve utilizing LLMs as either feature encoders (sun2019bert4rec,; Ding2022,; hou2022towards,; hou2023learning,; singh2023better,; yuan2023go,; harte2023leveraging,; gong2023unified,; li2023text,; liu2024once,; li2024enhancing,; ren2024representation,; rajput2024recommender,; zheng2024adapting,; sheng2024language,; hu2024enhancing,) or as scoring and ranking functions (wang2023zero,; wang2023drdt,; hou2024large,; wang-etal-2024-recmind,; xu2024prompting,; zhao2024let,; liang2024taxonomy,). When LLMs are employed as feature encoders, there is potential for transfer learning and cross-domain generalization by initializing embedding layers with LLM embeddings, although this approach requires extensive training. On the other hand, using LLMs for scoring and ranking demonstrates the ability to leverage their reasoning capabilities to address recommendation tasks. However, these models still lag behind the performance of fine-tuned models due to a lack of collaborative knowledge.

Figure 1.Retrieval pipeline uses scoring rules that combine semantic and collaborative information with temporal, weight, and rating factors to score unseen items without requiring any fine-tuning.

The primary motivation of this work is to develop a general framework that serves as a generalist across multiple recommendation domains. We demonstrate that recent advancements in LLMs align with this vision, effectively functioning as generalists without requiring any domain-specific fine-tuning. Based on our findings, we present a Simple Training-free Approach for Recommendation (STAR) framework using LLMs. The STAR framework involves two stages: Retrieval and Ranking. The Retrieval stage scores new items using a combination of semantic similarity and collaborative commonality to the items in a user’s history. Here, we utilize LLM-based embeddings to determine semantic similarity. Additionally, a temporal factor gives priority to user’s recent interactions, and a rating factor aligns with user preferences to rank items within a specific set (See Figure 1 and Section 3.2). The Ranking stage leverages the reasoning capabilities of LLMs to adjust the rankings of the initially retrieved candidates. Specifically, we assess various LLM-based ranking approaches, including point-wise, pair-wise, and list-wise methods, while also determining the key information needed for the LLM to better understand user preferences and make accurate predictions (Section 3.3). Our experimental evaluation shows competitive performance across a diverse range of recommendation datasets, all without the need for supervised training or the development of custom-designed architectures.

We present extensive experimental results on the Amazon Review dataset (mcauley2015image,; he2016ups,). Our findings are as follow: (1) Our retrieval pipeline, comprised of both semantic relationship and collaborative information, demonstrates competitive results compared to a wide range of fine-tuned methods. LLM embeddings allow for an effective method to calculate semantic similarity; (2) We show that pair-wise ranking further improves upon our retrieval performance, while point-wise and list-wise methods struggle to achieve similar improvements; and (3) We illustrate that collaborative information is a critical component that adds additional benefits to the semantic information throughout our system, in both the retrieval and ranking stages.

## Related Work

### LLM as a Feature Encoder for RecSys

Recommendation systems typically leverage feature encoders to transform item and user profiles into suitable representations for model training. Traditionally, ID-based systems relied on one-hot encoding for structured features (zhou2018deep,; wang2021dcn,). However, recent advancements in LLMs have enabled the utilization of text encoders to capture rich semantic information from item metadata and user profiles (reimers2019sentence,; cer-etal-2018-universal,; ni2021sentence,; lee2024gecko,) To further optimize these representations for specific applications, researchers have explored several approaches: (1) mapping continuous LLM embeddings into discrete tokens using vector quantization and training a subsequent generative model (hou2023learning,; singh2023better,; rajput2024recommender,; zheng2024adapting,); (2) training sequential models by initializing the embedding layer with LLM embeddings (sun2019bert4rec,; yuan2023go,; hu2024enhancing,); and (3) training models to directly compute the relevance between item and user embeddings (i.e., embeddings of user selected items) (Ding2022,; hou2022towards,; gong2023unified,; li2023text,; liu2024once,; li2024enhancing,; ren2024representation,; sheng2024language,). While optimizing representations can improve recommendation performance, this often comes at the cost of increased training expenses and reduced generalizability. In this work, we demonstrate that LLM embeddings can be directly used as effective item representations, yielding strong results in sequential recommendation tasks without requiring extensive optimization. This finding aligns with those of (harte2023leveraging,), but differs by usage of novel scoring rules that incorporates collaborative and temporal information.

### LLM as a Scoring and Ranking function for RecSys

Recent studies show that LLMs can recommend items by understanding user preferences or past interactions in natural language. This is achieved through generative selection prompting, where the model ranks and selects top recommended items from a set of candidates (wang2023zero,; wang2023drdt,; hou2024large,; wang-etal-2024-recmind,; xu2024prompting,; zhao2024let,; liang2024taxonomy,). However, these studies show that LLMs alone are less effective than models fine-tuned on user-item interaction data, which leverage collaborative knowledge. To bridge the gap between collaborative knowledge and the semantic understanding of LLMs, recent efforts have focused on fine-tuning the models with interaction data, though this approach is also costly (geng2022recommendation,; zhang2023recommendation,; bao2023tallrec,; xu2024openp5,; tan2024idgenrec,; kim2024large,).

### LLM as a Ranker for Information Retrieval

Ranking using LLMs has been widely adopted in document retrieval (zhu2023large,; wang2024large,). Recent studies indicate that LLMs surpass traditional supervised cross-encoders in zero-shot passage ranking. Three prompting approaches have emerged: (1) point-wise: LLMs directly evaluate relevance using numerical scores or binary judgments (liang2022holistic,; zhuang2023beyond,), but this method struggles with capturing the relative importance of passages; (2) pair-wise: LLMs express preferences between item pairs, which is effective but inefficient due to the high number of calls required (qin-etal-2024-large,); (3) list-wise: LLMs compare multiple passages simultaneously (sun2023chatgpt,), but performance heavily relies on the model’s semantic prior and reasoning capabilities (qin-etal-2024-large,). In this paper, we investigate the potential of LLM ranking for recommendation tasks, which are subjective in nature, unlike the deterministic nature of document retrieval.

## STAR: Smart Training-free Approach

Figure 2.STAR Framework overview. We use the semantic relationship scores in R S and the collaborative relationship scores in R C to score the items in the user history compared to new items to recommend. The final score for one new item is a weighted average from the semantic relationship and collaborative relationship scores, with additional weights from the user’s ratings r and a temporal decay λ < 1 which prioritize recent interactions. The top scoring retrieved items are sent to the LLM Ranking, where we can use point-wise, pair-wise, or list-wise ranking approaches to further improve upon the scoring of recommended items.

This section initially outlines the problem formulation (Section 3.1). Subsequently, we detail the proposed retrieval (Section 3.2) and ranking pipelines (Section 3.3).

### Sequential Recommendation

Figure 2.STAR Framework overview. We use the semantic relationship scores in R S and the collaborative relationship scores in R C to score the items in the user history compared to new items to recommend. The final score for one new item is a weighted average from the semantic relationship and collaborative relationship scores, with additional weights from the user’s ratings r and a temporal decay λ < 1 which prioritize recent interactions. The top scoring retrieved items are sent to the LLM Ranking, where we can use point-wise, pair-wise, or list-wise ranking approaches to further improve upon the scoring of recommended items.

### Retrieval Pipeline

The retrieval pipeline aims to assign a score to an unseen item x ∈ I given the sequence S u . To achieve this, we build two scoring components: one that focuses on the semantic relationship between items and another that focuses on the collaborative relationship.

#### Semantic Relationship

Understanding how similar a candidate item is to the items in a user’s interaction history s i ∈ S u is key to accurately gauging how well candidate items align with user preferences. Here we leverage LLM embedding models, where we pass in custom text prompts representing items and collect embedding vectors of dimension d e . We construct a prompt based on the item information and metadata, including the title, description, category, brand, sales ranking, and price. We omit metadata fields like Item ID and URL, as those fields contain strings that can contain spurious lexical similarity (e.g., IDs: “000012”, “000013’ or URLs: “<https://abc.com/uxrl”>, “<https://abc.com/uxrb”>) and can reduce the uniformity of the embedding space and make it difficult to distinguish between semantically different items (See Appendix A.1 for the full prompt). We collect embeddings for each item i ∈ I , resulting in E ∈ ℝ n × d e , where n is number of items in I . The semantic relationship between two items ( i a , i b ) is then calculated using the cosine similarity between their embeddings E i a , E i b ∈ E . This measure provides a numerical representation of how closely related the items are in semantic space. For our experiments, we precompute the entire semantic relationship matrix R S ∈ ℝ n × n . For many domains, this is a practical solution. However, if | I | is very large, Approximate Nearest Neighbor methods (guo2020accelerating,; sun2024soar,) are efficient approaches to maintain quality and reduce computation.

#### Collaborative Relationship

Collaborative relationship. Semantic similarity between a candidate item and items in a user’s interaction history is a helpful cue for assessing the similarity of items based on the item information. However, this alone does not fully capture the engagement interactions of items by multiple users. To better understand the collaborative relationship, we consider how frequently different combinations of items are interacted with by users. These shared interaction patterns can provide strong indicators of how likely the candidate item is to resonate with a broader audience with similar preferences. For each item i ∈ I , we derive an interaction array that represents user interactions, forming a set of sparse user-item interaction arrays C ∈ ℝ n × m , where m is number of users in U . The collaborative relationship between two items ( i a , i b ) is then computed by using the cosine similarity between their sparse arrays C i a , C i b ∈ C , capturing the normalized co-occurrence of the items. To streamline the process, we pre-compute and store these values in a collaborative relationship matrix R C ∈ ℝ n × n , which is typically very sparse.

#### Scoring rules

The score for an unseen item x ∈ I is calculated by averaging both the semantic and collaborative relationships between items in S u = { s 1 , s 2 , … , s n } as follows:

where R S x ⁢ j and R C x ⁢ j represent the semantic and collaborative relationships between the unseen item x and item s j ∈ S u , respectively. In this equation, r j is the rating given by user u to item s j , and λ t j is an exponential decay function applied to the temporal order t j of s j in the sequence S u . Here, t j is set to 1 for the most recent item in S u and increments by 1 up to n for the oldest item. The framework, illustrated in Figure 2, outputs the top k items in descending order based on their scores.

### Ranking Pipeline

Figure 3.Prompt overview for the ranking pipeline. The prompt includes history items, candidate items, and instructions for the ranking strategy. Each item is represented by metadata, along with additional details such as popularity and co-occurrence, formatted in JSON. Full prompt is available in Appendix A.2.

After retrieving the top k items, denoted as I k , from the initial retrieval process, a LLM is employed to further rank these items to enhance the overall ranking quality. The items in I k are already ordered based on scores from the retrieval framework, which reflect semantic, collaborative, and temporal information. We intentionally incorporate this initial order into the ranking process to enhance both efficiency and effectiveness. This framework then leverages the capabilities of the LLM to better capture user preference, complex relationships and contextual relevance among the items.

#### Rank schema

We present three main strategies for ranking: (1) Point-wise evaluates each item x ∈ I k independently, based on the user sequence S u , to determine how likely it is that user u will interact with item x . If two items receive the same score, their rank follows the initial order from I k ; (2) Pair-wise evaluates the preference between two items x i , x j ∈ I k based on the user sequence S u . We adopt a sliding window approach, starting from the items with the lowest retrieval score at the bottom of the list (qin-etal-2024-large,). The LLM compares and swaps adjacent pairs, while iteratively stepping the comparison window one element at a time. (3) List-wise evaluates the preference among multiple items x i , … , x i + w ∈ I k based on the user sequence S u . This method also uses a sliding window approach, with a window size w and a stride d to move the window across the list, refining the ranking as it passes (sun2023chatgpt,). In this setup, pair-wise is a special case of list-wise with w = 2 and d = 1 .

#### Item information

We represent the metadata (e.g., Item ID, title, category, etc.) for each item in the user sequence s j ∈ S u and each candidate item to be ranked x ∈ I k as JSON format in the input prompt. Additionally, we incorporate two more types of information that can help the reasoning capabilities of the LLM: (1) Popularity is calculated as the number of users who have interacted with the item x , simply by counting the occurrences in the training data. This popularity value is then included in the prompt for both the items in the user sequence s j ∈ S u and the candidate item to be ranked x ∈ I k as “Number of users who bought this item: ###”; (2) Co-occurrence is calculated as the number of users who have interacted with both item x and item s j ∈ S u . The resulting value is then included for candidate items x ∈ I k as “Number of users who bought both this item and item s j : ###”.

## Experimental Setup

### Datasets

### Dataset Construction and Evaluation Metrics

### Compared Methods

### Implementation Details

## Experimental Results

### Retrieval Pipeline

#### Q1. How do semantic and collaborative information affect predictions?

#### Q2. How does the number of user history items l and recency factor λ affect predictions?

#### Q3. Does incorporating more user feedback improve results?

## Conclusion

In this paper, we introduced a Simple Training-free Approach for Recommendation (STAR) that uses the power of large language models (LLMs) to create a generalist framework applicable across multiple recommendation domains. Our method comprises two key stages: a retrieval phase and a ranking phase. In the retrieval stage, we combine semantic embeddings from LLMs with collaborative user information to effectively select candidate items. In the ranking stage, we apply LLMs to enhance next-item prediction and refine the recommendations. Experimental results on a large-scale Amazon review dataset demonstrate that our retrieval method alone outperforms most supervised models. By employing LLMs in the ranking stage, we achieve further improvements. Importantly, our study highlights that incorporating collaborative information is critical in both stages to maximize performance. Our findings reveal that LLMs can effectively function as generalists in recommendation tasks without requiring any domain-specific fine-tuning. This opens up exciting possibilities for developing versatile and efficient recommendation systems that are readily adaptable across diverse domains.

## Limitations & Future Work

The STAR framework presents an effective alternative to traditional supervised models, showcasing the potential of LLMs in recommendation systems without the need for extensive training or custom architectures. However, several limitations remain, which also indicate directions for future improvement:

### Importance of item modality and enriched item meta-data

The STAR framework’s ability to capture semantic relationships between items relies significantly on the presence of rich item text meta-data. Without such meta-data and with only user-item interaction data available, the framework’s semantic relationship component will be less effective. To maximize the use of semantic relationships between items, future work should explore incorporating additional modalities, such as visual or audio data, to generate more comprehensive semantic representations of items, fully utilizing all the available information.

### Improving Retrieval Simplicity and Scalability

Although our work demonstrates the effectiveness of a general training-free framework, the current method requires different choices for parameters. In future work, we will explore ways to either reduce the number of parameters choices or select values more easily. In our current implementation, we compute the full set of item-item comparisons for both the semantic and collaborative information. This computation is infeasible if the item set is too large. In future work, we will run experiments to measure how effective approximate nearest neighbor methods are at reducing computation and maintaining retrieval quality.

### Beyond LLM ranking

The importance of our work highlights that high quality results can be achieved without additional fine-tuning. However, in the current method, our STAR ranking pipeline utilizes costly LLM calls that would result in high latency. This may be a suitable solution to use in offline scenarios, but would be prohibitive to serve large-scale and real-time user traffic. Future work needs to explore how we can improve efficiency, such as using a mix of pair-wise and list-wise ranking. Our work shows a promising first step to creating high quality, training-free, and general recommendation systems.
