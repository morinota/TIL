# Recommenders with a Mission: Assessing Diversity in News Recommendations

published date: March 2021,
authors: Sanne Vrijenhoek , Mesut Kaya , Nadia Metoui , Judith Möller , Daan Odijk , Natali Helberger
url(paper): https://dl.acm.org/doi/10.1145/3406522.3446019
(勉強会発表者: morinota)

---

## どんなもの?

- 推薦結果の"精度"のみを考慮した推薦システムは、ユーザが以前に見たものと似たものを不当に宣伝し、ユーザを「同じものをもっと」というフィードバックループに閉じ込め得る。そのため**beyond-accuracy指標**として"多様性"の研究が進んでいる。
- 一般的な推薦システムにおける"多様性"は、シンプルに推薦アイテム間の距離指標として表される事が多い。ニュース推薦における"多様性"を検討する上では、それでは不十分でしょ！(というか、目指すべき点はそれではないでしょ!)って話だった。
- 本論文は、コンピュータサイエンスにおける"多様性"と、メディアや民主主義の規範的な意味としての"多様性"のギャップを埋める事を目的とした研究.
- 規範的概念としての"多様性"を、異なるニュース推薦デザインの評価や比較に使用可能な5つのmetricsのセットに落とし込む取り組み.
- 

## 先行研究と比べて何がすごい？

コンピュータサイエンスの文献では、beyond-accuracyの evaluation metrics を概念化する様々な試みがなされているが、**これらの指標は推薦システムという広い分野に対して構築されているため、ニュースという文脈に限らず**、音楽、映画、ウェブ検索クエリ等にも適用可能.
一般的な推薦システムにおける"多様性"は、**シンプルに推薦アイテム間の距離指標**として表される事が多い。ニュース推薦における"多様性"を検討する上では、それでは不十分でしょ！(というか、目指すべき点はそれではないでしょ!)って話だった。
また、Loecherbachら[31]が示すように、メディア法、基本権法、民主主義理論、メディア研究/コミュニケーション科学の文献における**多様性の規範的理解**に根拠がなく、言及もしない.

## 技術や手法の肝は？

### 4種類のメディアモデル(メディアの民主的役割)

ニュース推薦における多様性を評価するためのより定量的な指標を定義する前に、まず**多様性の概念的な説明**を行う.
欧州評議会の定義に従えば、**多様性はそれ自体が目的ではなく、使命(mission)を持った概念**であり、多様性の概念は**民主主義のアプローチの違い**によって異なる場合がある.

本論文の内容はHelberger[19]が開発した**レコメンデーションにおける多様性の概念**に基づいている。
Helberger[19]は**多様なレコメンデーションはどうあるべきか**という規範的な理解と、**多様な露出がユーザに与える影響とは何か**という、より実証的な概念を組み合わせている.
民主主義には多くの理論があるが、Helbergerの論文では、**メディアの民主的役割**について語る際に最もよく使われる**4つの理論(メディアモデル?)**に焦点をあてている:

- Liberal model(自由主義モデル)
- Participatory model(参加主義モデル)
- Deliberative model(熟議主義モデル)
- Critical model(批判主義モデル)

各メディアモデルに優劣はない.
**どのモデルに従うかは、メディア企業自身が、そのmissionに従い、民主主義社会で果たしたい役割に応じて決めるべき**こと.

- Liberal model(自由主義モデル):
  - 自由主義的な民主主義のモデルは、自己啓発と自律的な意思決定を促進する.
  - ニュース推薦において重視すべき基準:
    - ユーザが選択した分野での専門性を高めること.
    - コンテンツもスタイルも、**ユーザの好みに合わせてカスタマイズされる**事.
- Participatory model(参加主義モデル)
  - 参加型民主主義のモデルは、人々が社会で積極的な役割を果たすことができるようにすることを目的としている.
  - ニュース推薦において重視すべき基準:
    - **異なるユーザが必ずしも同じ記事を見る必要はないが、同じトピックを見ることは必要**.
    - 記事のcomplexity(複雑さ)は、ユーザの好みや能力に合わせて調整されるべき.
- Deliberative model(熟議主義モデル)
  - 社会におけるさまざまな意見や価値観を提示し、共通の合意を得ること、あるいは異なる価値観に合意することを目的としている.
  - ニュース推薦において重視すべき基準:
    - 現在、**社会的な議論の中心となっているトピックに焦点を当てる.**
    - そのトピックの中で、**複数の声や意見を提示すること**.
- Critical model(批判主義モデル)
  - 普段は聞くことのできない声や意見に、プラットフォームを提供することを目的としている.
  - ニュース推薦において重視すべき基準:
    - **限界集落(=アウトサイダー的な少数派?)からの意見の重視**

### 5種類のdiversity metrics

4種類のメディアモデルによって、"目指すべき多様性"の価値と意味合いが異なる.
それがまた**推薦システムに対する異なる多様性の期待に変換される**.
本論文では民主主義理論に基づき、既存の情報検索metricsを応用して、各メディアモデルが推薦システムに期待する事から直接的に導かれる**5つの多様性に関わるmetrics**を提案している：

- Calibration
- Fragmentation
- Activation
- Representation
- Alternative Voices

各metricについて、その概念や民主主義理論との関連性をまとめる. なお、すべてのmetricsがすべてのメディアモデルに関連するわけではない.
(ただ、まだvalidなmetricsとしては不完全であり、今後改善が必要とのこと. たぶんdistance metricsの性質を満たすべき、みたいな話とか...!)

#### 変数定義

metricsを説明する前に、複数のmetricsに関連する以下の変数を定義する：

- $p$: 推薦システムが選択することができる記事のリストで、"pool"とも呼ばれる.
- $q$: 推薦セットに含まれる記事の順序不同のリスト(=推薦結果のrank-awareではないver.)
- $Q$: 推薦セットに含まれる記事の順序付きリスト(=推薦結果のrank-aware ver.)
- $r$: ユーザのreading historyにある記事のリスト.

#### Calibration:

出力された推薦結果がユーザの好みをどの程度反映しているかを示すmetric.
スコア0は完璧なCalibrationを意味し、スコアが高いほどユーザの好みとの乖離が大きいことを意味する.

従来のレコメンダーシステムの文献ではよく知られたmetricsであり、ニュース領域ではトピック、映画領域ではジャンルといった**カテゴリー情報の分布において、"現在ユーザに推薦されているもの"と"過去にユーザーが消費したもの"との差**を測定することで算出される.
本論文ではCalibrationの概念をトピックやジャンルの枠を超えて拡張し、**記事のスタイル(=writing style, 文体の事??)や複雑さ(complexity)**等も含めて、ユーザの興味や嗜好に合わせたニュース推薦を評価する事を提案する.
ex) **政治には詳しいが、医療にはあまり詳しくないというようなユーザの場合**、前者の場合はより複雑な記事を、後者の場合はより単純な記事を受け取りたいと考えるかもしれない.

このmetricは、「Liberal」「Participatory」モデルの推薦システムにおいて最も重要.

- Liberal model の目的はユーザの特殊化を促進することであり、トピックの文脈ではCalibrationスコアは0に近くなるべき.
- Participatory modelは個人よりも共通の利益を優先するモデルなので、異なるユーザで共通のトピックを推薦する事を考慮すると、トピック文脈のCalibrationは乖離するべき.
- またどちらのモデルも、特に Participatory model では、**記事の複雑さという点でユーザのニーズに合わせたコンテンツを受け取る必要があり**、この文脈では、0に近いCalibrationスコアを目指すべき.(このtopicはcomplexity高く、このtopicはcomplexity低く、みたいな文脈で、ユーザの好みと推薦結果を類似させるべき、という話.)

Steck [47]では、2つの確率分布間のKullback-Leibler divergenceをCalibration metricとして、以下のように使用している：

$$
Calibration_{r, q} = \text{KL Divergence}(r(c|u), q(c|u))
\\
\sum_{c} r(c|u) log \frac{r(c|u)}{\tilde{q}(c|u)}
$$

#### Fragmentation:

このmetricは、**異なるユーザに表示されるnews推薦結果間の重複の度合い**を示す.
Fragmentationのスコアが0であれば、ユーザ同士が完全に重なっていることを示し、スコアが1であれば、全く重なっていないことを示す.

Fragmentationとは、具体的には、ユーザ間で推薦されるnews story chain(同じ問題や出来事を異なる視点、書き方、時点から記述した記事の集合)[38]の違いを比較するもので、**違いが小さいほど、ユーザは社会における同じ出来事や問題をより認識しており、共同課題を語ることができる**としている.
複数のユーザに表示されるnews story chain が大きく異なると、**公共圏がよりfragment(細分化)される**ため、Fragmentationと呼ばれるようになった.

Participatory型とDeliberative型の両モデルとも、共通の公共圏を好むため、Fragmentation のスコアはゼロに近くなるべきである.
一方で、**Liberal型は、ユーザの興味ある分野への特化を促進するため、Fragmentationスコアが高くなる**.
最後に、社会全体の力の不均衡に注目することに重点を置く Critical 型は、Fragmentation のスコアを低く設定する.

news story の特定は、手動によるアノテーションや教師なし学習のアプローチで自動的に行う取り組みがされている.
story が特定されると、Fragmentationスコアは、すべてのユーザ間の推薦セット間の平均距離の総和として定義することができる.
本論文では、Rank Biased Overlapをベースとしたアプローチを採用. (**2022年の論文では、全てJS Divergenceに統一されている**.)

$$
Fragmentation_{Q_1, Q_2} = 1 - RBO(Q_1, Q_2, s) = 1 -  (1 - s) \sum_{d=1}^{\infty}s^{d-1} A_{d}
$$

ここで、$Q_1$と$Q_2$はユーザ1と2に発行された2つの推薦結果を示す.
Rank-Biased Overlapは0と1の間のスコアで、0は2つのリストが完全に不連続、1は完全に重なることを示す.
表現されるスコアはFragmentation指標で表現しようとするものと意味的に逆なので、1 - Rank-Biased Overlapを計算してFragmentationスコアを求める.
最後に、各ユーザのFragmentationスコアを他のユーザーと平均して、Aggregate Fragmentation scoreを算出する.

#### Activation:

Activationは、発行された推薦結果が、**ユーザの行動を喚起するものであるかどうか**を表すmetric.
**スコアが1に近いほど活性化するコンテンツが多く、-1に近いほど中立的なコンテンツが多い**ことを表している.

記事の書き方は、読み手に何らかの影響を与える可能性がある.
**公平な記事であれば、異なる視点への理解を深めることができ、感情的な記事であれば、行動を起こすきっかけとなる**.
Activation metricは、記事中に表現された感情の強さを測定することで、これを把握することを目的としている.

Activationの指標は、4種類のメディアモデルのうち3種類で関連している.

- Deliberativeモデルは、共通のコンセンサスと議論を目指すため、**Activationスコアが低い公平な記事を一定程度目立たせる**ことになる.
- Participatoryモデルは、共通の利益と理解を促進し、ユーザが市民としての役割を果たし、必要に応じて行動できるようにすることを目的としている. 活性化する成分があることが望ましいが、極端なものはない.
- 一方でCriticalモデルでは、現状を打破するためのemotionalで挑発的なコンテンツがより多く存在する事を望む. この場合Activation値は高い値であるべき.

推薦システムのActivationスコアは以下のように計算される.

$$
Activation(p, q) = (|polarity(q)| - |polarity(p)|) / 2
$$

ここで、$p$はプールにあるすべての利用可能な記事の集合を示し、$q$ は推薦結果にあるものを示す.
両 記事集合とも、各記事のpolarity(中立か、positive/negativeの感情に依っているか?)の絶対値の平均をとり、これをActivationの近似値として使用する.
Activationは-1 ~ 1の範囲にmappingされる.(**2022年の論文では、全てJS Divergenceに統一されている...!**)
ゼロより低い値は、推薦システムが、データプールで利用可能だったよりも活性化するコンテンツが少なく、より中立的な記事を優先して表示することを示す.
ゼロより高い値は、その逆で、推薦結果セットには、プールで利用可能なものよりも多くの活性化コンテンツが含まれていることを示す.

#### Representation:

このmetricは、発行された推薦結果が、**異なる意見や視点のバランスを保ち、ある意見が他の意見より不当に多く、あるいは少なくなっていないかどうか**を表すもの.
**ゼロに近いほどバランスが取れていることを示し**、一方で、スコアが高いほどアンバランスにある意見が優遇されているを示す.

Representationは、**より直感的な多様性の解釈の一つ**.
このmetricでは、誰が言っている記事なのかよりも、**何が言われている記事なのか**が重要. (前者は最後の"Alternative Voices" metricが担う.)

各メディアモデルとの関連:

- Participatoryモデルは、"the real political world"を反映することを目的としている. したがって、**社会に存在する力関係をニュース推薦にも反映し**、より優勢な意見ほどRepresentationでのシェアが大きくなるはず.
- Deliberativeモデルは、一つの意見が他の意見よりも優勢になることなく、**すべての意見を平等に俯瞰すること**を目的としている. Representationスコアは0に近づくべき.
- クリティカルモデルは、パワーバランスを変えることに大きな重点を置いており、**代表的でない意見にプラットフォームを与えることで、逆の視点を促進する**ことでそれを実現する. よってRepresentationスコアは大きくなるべき.

Representation、そして次のAlternative Voicesを算出する為には、**ニュースで言及された意見と意見保有者を正確かつ完全に特定すること**に強く依存している.
Representationスコアの算出には、再びKL Divergenceを使用する.(2022年の論文では、全てJS Divergenceに置き換わっている.)
今回は推薦結果と利用可能なデータプールの意見カテゴリ分布を使用する：

$$
Representation_{p, q} = \text{KL Divergence}(p(o), q(o))
$$

#### Alternative Voices:

このmetricは、**少数派または周縁化されたグループの人々の相対的な存在感を測定**するもの.

Representationが視点の明確な内容（What）に主眼を置いているのに対し、**Alternative Voicesは、その視点を持つ人物（Who）に関心があり**、特にその人物や組織が、主流メディアで十分に表現されない可能性の高い**少数派や疎外されたグループの一人であるかどうか**を重視する.

具体的に何をもってマイノリティとするかは、かなり曖昧な定義.
テキストデータからマイノリティの特定の特性を検出することを目的とした研究は数多くあるらしい...??
このテーマは、一般的に「**(algorithmic) Fairness**」と呼ばれ、**データ駆動型のコンピュータシステムにおける偏見や差別に対抗することを目的とした活発な研究分野**、とのこと.

メディアモデルとの関連:

- 当然ながら、Criticalモデルにおいて最も大きな意味を持つ.

機械学習システムにおける「公平性」をめぐる議論では、さまざまな定義がなされている.
Alternative Voicesの運用については、Burkeら[5]の式10を本論文では適用した：

$$
AlternativeVoices = \frac{q^{+} / p^{+}}{q^{-} / p^{-}}
$$

ここで、$q^{+}$は推薦結果における保護されている団体の記事数を示し、一方、$p^{+}$ は利用可能なアイテムプールにおける保護されている団体の記事数を示している.
$q^{-}$ と $p^{-}$ はそれぞれ、推薦結果とアイテムプールにおける、保護されていない団体の記事数を示す.
このmetricは、保護されたグループと保護されていないグループの人々の間のバランスが完全にとれている場合に1になる.
値が1より大きいと、保護されていないグループの記事が推薦セットに多く登場し、1より小さいと逆にあまり登場しない事を意味する.

## どうやって有効だと検証した?

特に実験等はなし.
各種metricsが https://github.com/svrijenhoek/dart/ にて実装されているとのこと.

## 議論はある？

- ランキング順序の考慮をmetricsに組み込む必要がある.
- データセットのbiasの考慮.

## 次に読むべき論文は？

- metrics関連: オフラインmetricsを組み合わせて、オンラインパフォーマンスの予測モデルを生成する試み [Predicting Online Performance of News Recommender Systems Through Richer Evaluation Metrics](https://dl.acm.org/doi/10.1145/2792838.2800184)

## お気持ち実装

今回はなしです...!
