## 0.1. link

- [pdf](https://arxiv.org/pdf/2209.13520.pdf) pdf](https:

## 0.2. title ã‚¿ã‚¤ãƒˆãƒ«

RADio â€“ Rank-Aware Divergence Metrics to Measure Normative Diversity in News Recommendations
RADio - ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã«ãŠã‘ã‚‹è¦ç¯„çš„å¤šæ§˜æ€§ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã®ãƒ©ãƒ³ã‚¯èªè­˜å‹ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹

## 0.3. abstract ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ

In traditional recommender system literature, diversity is often seen as the opposite of similarity, and typically defined as the distance between identified topics, categories or word models.
å¾“æ¥ã®æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®æ–‡çŒ®ã§ã¯ã€**å¤šæ§˜æ€§ã¯é¡ä¼¼æ€§ã®åå¯¾ã¨è¦‹ãªã•ã‚Œã‚‹**ã“ã¨ãŒå¤šãã€ä¸€èˆ¬ã«è­˜åˆ¥ã•ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯ã€ã‚«ãƒ†ã‚´ãƒªã€ã¾ãŸã¯å˜èªãƒ¢ãƒ‡ãƒ«é–“ã®è·é›¢ã¨ã—ã¦å®šç¾©ã•ã‚Œã‚‹.
However, this is not expressive of the social scienceâ€™s interpretation of diversity, which accounts for a news organizationâ€™s norms and values and which we here refer to as normative diversity.
ã—ã‹ã—ã€ã“ã‚Œã¯ã€**å ±é“æ©Ÿé–¢ã®è¦ç¯„ã‚„ä¾¡å€¤è¦³ã‚’è€ƒæ…®ã—ãŸç¤¾ä¼šç§‘å­¦çš„ãªå¤šæ§˜æ€§ã®è§£é‡ˆã‚’è¡¨ç¾ã—ã¦ãŠã‚‰ãš**ã€ã“ã“ã§ã¯**è¦ç¯„çš„å¤šæ§˜æ€§**ã¨å‘¼ã¶ã“ã¨ã«ã™ã‚‹.
We introduce RADio, a versatile metrics framework to evaluate recommendations according to these normative goals.
æˆ‘ã€…ã¯ã€ã“ã‚Œã‚‰ã®è¦ç¯„çš„ãªç›®æ¨™ã«å¾“ã£ã¦æ¨è–¦ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ±ç”¨çš„ãªãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹**RADio**ã‚’ç´¹ä»‹ã™ã‚‹.
RADio introduces a rank-aware Jensen Shannon (JS) divergence.
RADioã¯ãƒ©ãƒ³ã‚¯ã‚’è€ƒæ…®ã—ãŸã‚¸ã‚§ãƒ³ã‚»ãƒ³ãƒ»ã‚·ãƒ£ãƒãƒ³ï¼ˆJSï¼‰ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’å°å…¥ã—ã¦ã„ã‚‹.
This combination accounts for (i) a userâ€™s decreasing propensity to observe items further down a list and (ii) full distributional shifts as opposed to point estimates.
ã“ã®çµ„ã¿åˆã‚ã›ã¯ã€(i)ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒªã‚¹ãƒˆã®ã•ã‚‰ã«ä¸‹ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’è¦³å¯Ÿã™ã‚‹å‚¾å‘ãŒæ¸›å°‘ã™ã‚‹ã“ã¨ã€(ii)ç‚¹æ¨å®šã§ã¯ãªãã€å®Œå…¨ãªåˆ†å¸ƒã‚·ãƒ•ãƒˆã‚’èª¬æ˜ã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹.
We evaluate RADioâ€™s ability to reflect five normative concepts in news recommendations on the Microsoft News Dataset and six (neural) recommendation algorithms, with the help of our metadata enrichment pipeline.
æˆ‘ã€…ã¯ã€**Microsoft News Dataset**ã¨6ã¤ã®æ¨è–¦ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ï¼‰ã«ãŠã„ã¦ã€**RADioãŒ5ã¤ã®è¦ç¯„çš„æ¦‚å¿µã‚’ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã«åæ˜ ã™ã‚‹èƒ½åŠ›**ã‚’ã€æˆ‘ã€…ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¼·åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åŠ©ã‘ã«ã‚ˆã£ã¦è©•ä¾¡ã—ãŸ.
We find that RADio provides insightful estimates that can potentially be used to inform news recommender system design.
ãã®çµæœã€**RADioã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆã«åˆ©ç”¨ã§ãã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹**ã€æ´å¯Ÿã«æº€ã¡ãŸæ¨å®šå€¤ã‚’æä¾›ã™ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸ.

# 1. Introduction ã¯ã˜ã‚ã«

For centuries, the interplay between journalists and news editors has shaped how news items are created and how they are shown to their readers [82].
ä½•ä¸–ç´€ã«ã‚‚ã‚ãŸã£ã¦ã€ã‚¸ãƒ£ãƒ¼ãƒŠãƒªã‚¹ãƒˆã¨ãƒ‹ãƒ¥ãƒ¼ã‚¹ç·¨é›†è€…ã®é–“ã®ç›¸äº’ä½œç”¨ã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¢ã‚¤ãƒ†ãƒ ãŒã©ã®ã‚ˆã†ã«ä½œæˆã•ã‚Œã€ãã‚Œã‚‰ãŒã©ã®ã‚ˆã†ã«èª­è€…ã«ç¤ºã•ã‚Œã‚‹ã‹ã‚’å½¢ä½œã£ã¦ããŸ[82].
With the digitization of society, much has changed: while before, people would typically limit themselves to reading one type of newspaper, they now have a wealth of information available to them at the click of a button [63] â€“ more than anyone could possibly be expected to read or make sense of.
ç¤¾ä¼šã®ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–ã«ä¼´ã„ã€å¤šãã®ã“ã¨ãŒå¤‰åŒ–ã—ãŸ. ä»¥å‰ã¯ã€äººã€…ã¯é€šå¸¸ã€1ç¨®é¡ã®æ–°èã‚’èª­ã‚€ã“ã¨ã«é™å®šã—ã¦ã„ãŸãŒã€ä»Šã§ã¯ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã ã‘ã§åˆ©ç”¨ã§ãã‚‹è±Šå¯Œãªæƒ…å ± [63]ã‚’æ‰‹ã«å…¥ã‚Œã‚‹ã“ã¨ãŒã§ãã€èª°ã‚‚ãŒèª­ã¿ã€ç†è§£ã™ã‚‹ã“ã¨ã‚’æœŸå¾…ã§ãã‚‹é‡ã‚’è¶…ãˆã¦ã„ã‚‹.
News recommender systems can filter the enormous amount of information available to just those news items that are in some way interesting or relevant to their users [8, 52].
ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã¯ã€åˆ©ç”¨å¯èƒ½ãªè†¨å¤§ãªæƒ…å ±ã‚’ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã¨ã£ã¦ä½•ã‚‰ã‹ã®å½¢ã§èˆˆå‘³æ·±ã„ã€ã‚ã‚‹ã„ã¯é–¢é€£æ€§ã®ã‚ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¢ã‚¤ãƒ†ãƒ ã ã‘ã«çµã‚Šè¾¼ã‚€ã“ã¨ãŒã§ãã‚‹[8, 52].
The use of news recommender systems is widespread, not just for personalized news recommendations, but also to automatically populate the front page of a news website [53], or present the reader of a particular news article with other articles about the same topic, but from a different perspective [54].
ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã¯ï¼Œãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¨è–¦ã™ã‚‹ã ã‘ã§ãªãï¼Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®ãƒ•ãƒ­ãƒ³ãƒˆãƒšãƒ¼ã‚¸ã‚’è‡ªå‹•çš„ã«ç”Ÿæˆã—ãŸã‚Š [53]ï¼Œç‰¹å®šã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®èª­è€…ã«åŒã˜ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹ä»–ã®è¨˜äº‹ã‚’ç•°ãªã‚‹è¦–ç‚¹ã‹ã‚‰æç¤ºã—ãŸã‚Š [54]ã™ã‚‹ãŸã‚ã«åºƒãåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ï¼
The use of news recommender systems has a wide range of benefits.
ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®åˆ©ç”¨ã«ã¯ã€ã•ã¾ã–ã¾ãªåˆ©ç‚¹ãŒã‚ã‚‹.
They can increase engagement [55] and help raise informed citizens [28].
**engagementã‚’é«˜ã‚ã‚‹(?)**ã“ã¨ãŒã§ã [55]ã€æƒ…å ±é€šã®å¸‚æ°‘ã‚’è‚²ã¦ã‚‹ã®ã«å½¹ç«‹ã¤ [28].
A news recommender system may broaden the horizons of their users by presenting diverse recommendations, including items different from what they are used to or expect seeing.
**ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹æ…£ã‚Œã¦ã„ã‚‹ã‚‚ã®ã€ã‚ã‚‹ã„ã¯æœŸå¾…ã—ã¦ã„ã‚‹ã‚‚ã®ã¨ã¯ç•°ãªã‚‹ã‚‚ã®ã‚’å«ã‚€å¤šæ§˜ãªæ¨è–¦ã‚’æç¤ºã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦–é‡ã‚’åºƒã’ã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã‚‚ã—ã‚Œãªã„**.
They could even foster tolerance and understanding [29, 66], and counter so-called filter bubbles or echo chambers [52, 58].
ã•ã‚‰ã«ã€**å¯›å®¹ã•ã¨ç†è§£ã‚’è‚²ã¿** [29ã€66]ã€ã„ã‚ã‚†ã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒãƒ–ãƒ«ã‚„ã‚¨ã‚³ãƒ¼ãƒã‚§ãƒ³ãƒãƒ¼ã«å¯¾æŠ—ã§ãã‚‹ã‹ã‚‚ã—ã‚Œãªã„ [52ã€58].

To realize the potential benefits of news recommender systems, much attention has been given to generating recommendations that reflect the userâ€™s interests and preferences [39].
**ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®æ½œåœ¨çš„ãªåˆ©ç‚¹ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«**ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èˆˆå‘³ã‚„å—œå¥½ã‚’åæ˜ ã—ãŸæ¨è–¦æ–‡ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã«æ³¨ç›®ãŒé›†ã¾ã£ã¦ã„ã‚‹[39].
However, with news recommenders taking over the role of human editors in news selection, they are becoming gatekeepers in what news is shown to audiences and have thus a democratic role to play in society.
ã—ã‹ã—ï¼Œãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã¯ï¼Œãƒ‹ãƒ¥ãƒ¼ã‚¹é¸æŠã«ãŠã‘ã‚‹äººé–“ã®ç·¨é›†è€…ã®å½¹å‰²ã‚’å¼•ãç¶™ãï¼Œã©ã®ã‚ˆã†ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦–è´è€…ã«ç¤ºã•ã‚Œã‚‹ã‹ã®ã‚²ãƒ¼ãƒˆã‚­ãƒ¼ãƒ‘ãƒ¼ã¨ãªã‚Šã¤ã¤ã‚ã‚Šï¼Œç¤¾ä¼šçš„ã«æ°‘ä¸»çš„ãªå½¹å‰²ã‚’æ‹…ã£ã¦ã„ã‚‹ï¼
As such, their evaluation has different requirements than those of other types of recommender systems [4, 5, 72, 75].
ãã®ãŸã‚ï¼Œ**ãã®è©•ä¾¡ã¯ä»–ã®ã‚¿ã‚¤ãƒ—ã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ç•°ãªã‚‹è¦ä»¶ã‚’æŒã¤** [4, 5, 72, 75].
Recent controversies have shown that merely optimizing for click-through rates and engagement may promote sensationalist content [68], and is particularly conducive to the spread of misinformation.1
**æœ€è¿‘ã®è«–äº‰ã§ã¯ã€click-throughç‡ã‚„engagementã‚’æœ€é©åŒ–ã™ã‚‹ã ã‘ã§ã¯ã€ã‚»ãƒ³ã‚»ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åŠ©é•·ã—ã‹ã­ãš[68]ã€ç‰¹ã«èª¤å ±ã®æ‹¡æ•£ã‚’åŠ©é•·ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹**.
This observation is not limited to the academic literature â€“ an increasing number of media organizations, both public service and commercial, have acknowledged the difficulties in translating their editorial norms into concrete metrics that can inform recommender system design [9, 32].
ã“ã®è¦³å¯Ÿã¯ã€å­¦è¡“çš„ãªæ–‡çŒ®ã«é™ã£ãŸã“ã¨ã§ã¯ãªãã€å…¬å…±ã‚µãƒ¼ãƒ“ã‚¹ã‚„å•†æ¥­ã®ä¸¡æ–¹ã®ãƒ¡ãƒ‡ã‚£ã‚¢çµ„ç¹”ãŒã€ç·¨é›†è¦ç¯„ã‚’ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆã«å½¹ç«‹ã¤å…·ä½“çš„ãªæŒ‡æ¨™ã«å¤‰æ›ã™ã‚‹ã“ã¨ã®é›£ã—ã•ã‚’èªã‚ã¦ã„ã¾ã™ [9ã€32].
News recommender systems exist in a complex space consisting of many different areas and disciplines, each with their own goals and challenges; think of balancing diversity and accuracy [57], nudging [50] or even identifying user preferences [6, 49] and biases [74].
ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã¯ã€å¤šæ§˜æ€§ã¨æ­£ç¢ºã•ã®ãƒãƒ©ãƒ³ã‚¹ [57]ã€ãƒŠãƒƒã‚¸ãƒ³ã‚° [50]ã€ã‚ã‚‹ã„ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ [6, 49]ã‚„ãƒã‚¤ã‚¢ã‚¹ [74]ã®ç‰¹å®šãªã©ã€å¤šãã®ç•°ãªã‚‹åˆ†é‡ã‚„é ˜åŸŸã‹ã‚‰ãªã‚‹è¤‡é›‘ãªç©ºé–“ã«å­˜åœ¨ã—ã€ãã‚Œãã‚ŒãŒç‹¬è‡ªã®ã‚´ãƒ¼ãƒ«ã¨èª²é¡Œã‚’æŠ±ãˆã¦ã„ã‚‹.
In this paper, we focus on the process of translating normative theory (i.e., what it means for a recommendation to be diverse) into metrics that are usable and understandable for both technical and editorial purposes.
ã“ã®è«–æ–‡ã§ã¯ã€è¦ç¯„çš„ãªç†è«–ï¼ˆã™ãªã‚ã¡ã€æ¨è–¦ãŒå¤šæ§˜ã§ã‚ã‚‹ã“ã¨ã®æ„å‘³ï¼‰ã‚’ã€æŠ€è¡“çš„ãŠã‚ˆã³ç·¨é›†çš„ãªç›®çš„ã®ãŸã‚ã«ä½¿ç”¨å¯èƒ½ã§ç†è§£ã—ã‚„ã™ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«å¤‰æ›ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹.
We build on the work of Helberger [33], who provides a theoretical foundation for conceptualizing diversity, and of Vrijenhoek et al. [71], who propose a new set of metrics (DART) that reflect this theory.
æˆ‘ã€…ã¯ã€å¤šæ§˜æ€§ã‚’æ¦‚å¿µåŒ–ã™ã‚‹ãŸã‚ã®ç†è«–çš„åŸºç¤ã‚’æä¾›ã—ãŸHelberger [33]ã®ä»•äº‹ã¨ã€ã“ã®ç†è«–ã‚’åæ˜ ã—ãŸæ–°ã—ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆDARTï¼‰ã®ã‚»ãƒƒãƒˆã‚’ææ¡ˆã—ãŸVrijenhoekã‚‰[71]ã®ä»•äº‹ã‚’åŸºç¤ã¨ã—ã¦ã„ã‚‹.
The DART metrics represent a first step towards a normative interpretation of diversity in news recommendations.
DARTãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã«ãŠã‘ã‚‹å¤šæ§˜æ€§ã®è¦ç¯„çš„è§£é‡ˆã¸ã®ç¬¬ä¸€æ­©ã¨ãªã‚‹ã‚‚ã®ã§ã‚ã‚‹.
We identify a number of possible shortcomings in these metrics: there could be more consideration for the theory of metrics and distance functions, generalizability to other normative concepts, unification under one framework, and rankawareness.
æˆ‘ã€…ã¯ã€ã“ã‚Œã‚‰ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ¬ ç‚¹ã¨ã—ã¦ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ç†è«–ã‚„è·é›¢é–¢æ•°ã¸ã®é…æ…®ã€ä»–ã®è¦ç¯„çš„æ¦‚å¿µã¸ã®ä¸€èˆ¬åŒ–ã€ä¸€ã¤ã®æ çµ„ã¿ã®ä¸‹ã§ã®çµ±ä¸€ã€ãƒ©ãƒ³ã‚¯èªè­˜ãªã©ãŒè€ƒãˆã‚‰ã‚Œã‚‹ã“ã¨ã‚’æŒ™ã’ã¦ã„ã‚‹.
In this paper, we focus on the mathematical aspects of a rank-aware metric, versatile to different normative concepts and as such addressing these shortcomings.
ã“ã®è«–æ–‡ã§ã¯ã€ãƒ©ãƒ³ã‚¯èªè­˜ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®æ•°å­¦çš„å´é¢ã«ç„¦ç‚¹ã‚’å½“ã¦ã€ç•°ãªã‚‹è¦ç¯„æ¦‚å¿µã«æ±ç”¨æ€§ãŒã‚ã‚Šã€ãã®çµæœã€ã“ã‚Œã‚‰ã®æ¬ ç‚¹ã«å¯¾å‡¦ã—ã¦ã„ã‚‹.
We refer to our framework as the Rank-Aware Divergence metrIcs to measure nOrmative diversity (RADio).
æˆ‘ã€…ã¯ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’**Rank-Aware Divergence metrIcs to measure nOrmative diversity (RADio)**ã¨å‘¼ã‚“ã§ã„ã‚‹.

Our contribution consists of a diversity metric that is (i) versatile to any normative concept and expressed as the divergence between two (discrete) distributions; (ii) rank-aware, taking into account the position of an item in a recommendation set; and (iii) mathematically grounded in distributional divergence statistics.
æˆ‘ã€…ã®è²¢çŒ®ã¯ã€(i)ã‚ã‚‰ã‚†ã‚‹è¦ç¯„çš„æ¦‚å¿µã«æ±ç”¨æ€§ãŒã‚ã‚Šã€2ã¤ã®ï¼ˆé›¢æ•£ï¼‰åˆ†å¸ƒé–“ã®ç™ºæ•£ã¨ã—ã¦è¡¨ç¾ã•ã‚Œã€(ii)æ¨è–¦ã‚»ãƒƒãƒˆå†…ã®é …ç›®ã®ä½ç½®ã‚’è€ƒæ…®ã—ã€ãƒ©ãƒ³ã‚¯ã‚’æ„è­˜ã—ã€(iii)åˆ†å¸ƒç™ºæ•£çµ±è¨ˆã«æ•°å­¦çš„æ ¹æ‹ ã‚’æŒã¤å¤šæ§˜æ€§ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹.
We demonstrate the effectiveness of this formulation of the metrics by defining a natural language processing (NLP) metadata enrichment pipeline (e.g., sentiment analysis, named entity recognition) and running it against the MIND dataset [80].
æˆ‘ã€…ã¯ã€è‡ªç„¶è¨€èªå‡¦ç†ï¼ˆNLPï¼‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ãƒªãƒƒãƒãƒ¡ãƒ³ãƒˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆä¾‹ï¼šæ„Ÿæƒ…åˆ†æã€åå‰ä»˜ãå®Ÿä½“èªè­˜ï¼‰ã‚’å®šç¾©ã—ã€MINDãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ[80]ã«å¯¾ã—ã¦ãã‚Œã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€ã“ã®å®šå¼åŒ–ã®æœ‰åŠ¹æ€§ã‚’å®Ÿè¨¼ã—ã¦ã„ã‚‹.
Figure 1 illustrates the operationalization.
å›³1ã¯ãã®é‹ç”¨ã‚’èª¬æ˜ã™ã‚‹ã‚‚ã®.
The pipeline and the code produced for metadata enrichment and metric computation are available online.2 The goal of RADio is not to serve as thresholds or strict guidelines for â€œdiverse recommendations,â€ but to provide developers of recommender systems with the tools to evaluate their systems on normative principles.
**RADioã®ç›®çš„**ã¯ã€ã€Œå¤šæ§˜ãªæ¨è–¦ã€ã®ãŸã‚ã®é–¾å€¤ã‚„å³æ ¼ãªã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã“ã¨ã§ã¯ãªãã€**æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºè€…ã«è¦ç¯„çš„ãªåŸå‰‡ã«åŸºã¥ã„ã¦ã‚·ã‚¹ãƒ†ãƒ ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã‚’æä¾›ã™ã‚‹ã“ã¨**ã§ã‚ã‚‹.

# 2. Related Work é–¢é€£ä½œå“

We first highlight recent work on the formal mathematical work on diversity in news recommendation, before citing related work on the normative aspect of diversity.
ã¾ãšã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã«ãŠã‘ã‚‹å¤šæ§˜æ€§ã«é–¢ã™ã‚‹å½¢å¼çš„ãªæ•°å­¦çš„ä½œæ¥­ã«é–¢ã™ã‚‹æœ€è¿‘ã®ç ”ç©¶ã‚’ç´¹ä»‹ã—ã€ãã®å¾Œã€å¤šæ§˜æ€§ã®è¦ç¯„çš„å´é¢ã«é–¢ã™ã‚‹é–¢é€£ç ”ç©¶ã‚’å¼•ç”¨ã™ã‚‹.
Finally we describe the gap that exists between descriptive and normative diversity.3
æœ€å¾Œã«ã€è¨˜è¿°çš„ãªå¤šæ§˜æ€§ã¨è¦ç¯„çš„ãªå¤šæ§˜æ€§ã®é–“ã«å­˜åœ¨ã™ã‚‹ã‚®ãƒ£ãƒƒãƒ—ã«ã¤ã„ã¦è¿°ã¹ã‚‹.

## 2.1. Descriptive (General-Purpose) Diversity Descriptive (æ±ç”¨) å¤šæ§˜æ€§

Diversity is a central concept in Information Retrieval literature [17, 62], albeit with a different interpretation than the normative diversity described in the previous section.
å¤šæ§˜æ€§ã¯ã€å‰ç¯€ã§èª¬æ˜ã—ãŸè¦ç¯„çš„ãªå¤šæ§˜æ€§ã¨ã¯ç•°ãªã‚‹è§£é‡ˆã§ã¯ã‚ã‚‹ãŒã€æƒ…å ±æ¤œç´¢ã®æ–‡çŒ®[17, 62]ã§ã¯ä¸­å¿ƒçš„ãªæ¦‚å¿µã§ã‚ã‚‹.
During the development of news recommender systems, there is currently a large focus on the predictive power of an algorithm.
ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã§ã¯ã€**ç¾åœ¨ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®äºˆæ¸¬åŠ›ã«å¤§ããªç„¦ç‚¹ãŒå½“ã¦ã‚‰ã‚Œã¦ã„ã‚‹**.
However, this may unduly promote content similar to what a user has interacted with before, and lock them in loops of â€œmore of the same.â€
ã—ã‹ã—ã€ã“ã‚Œã§ã¯ã€**ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒéå»ã«æ¥ã—ãŸã“ã¨ã®ã‚ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨é¡ä¼¼ã—ãŸã‚‚ã®ã‚’ä¸å½“ã«ä¿ƒé€²ã—ã€"more of the same "ã®ãƒ«ãƒ¼ãƒ—ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’é–‰ã˜è¾¼ã‚ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚‹**.
To tackle this, â€œdiversityâ€ is introduced, which is typically defined as the â€œopposite of similarityâ€ [11].
ã“ã‚Œã«å–ã‚Šçµ„ã‚€ãŸã‚ã«ï¼Œ"**diversity**"ãŒå°å…¥ã•ã‚Œã‚‹ï¼ã“ã‚Œã¯ï¼Œå…¸å‹çš„ã«ã¯"opposite of similarity"ã¨å®šç¾©ã•ã‚Œã‚‹[11]ï¼
Its goal is to prevent users from being shown the same type of items in their recommendations list and is often expressed as intra-list-diversity (ILD) [11, 13, 19, 23, 24, 38, 48, 70]: mean pairwise dissimilarity between recommended item lists.
ãã®ç›®çš„ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¨è–¦ãƒªã‚¹ãƒˆã§åŒã˜ç¨®é¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’è¡¨ç¤ºã•ã‚Œã‚‹ã®ã‚’é˜²ãã“ã¨ã§ã‚ã‚Šã€ã—ã°ã—ã° **intra-list-diversity (ILD)** [11, 13, 19, 23, 24, 38, 48, 70]: æ¨è–¦ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆé–“ã®å¹³å‡ãƒšã‚¢ãƒ¯ã‚¤ã‚ºéé¡ä¼¼åº¦ã¨ã—ã¦è¡¨ç¾ã•ã‚Œã‚‹.
ILD requires the specification of a distance function between lists, and thus leaves it up to interpretation as to what it means for two lists to be distant.
**ILDã¯ãƒªã‚¹ãƒˆé–“ã®è·é›¢é–¢æ•°ã‚’æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚‹(=2ã¤ã®ã‚¢ã‚¤ãƒ†ãƒ é–“ã®è·é›¢ã‚’ä½•ã‚‰ã‹ã®æ–¹æ³•ã§å®šé‡åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚‹?)**ãŸã‚ã€2ã¤ã®ãƒªã‚¹ãƒˆãŒé›¢ã‚Œã¦ã„ã‚‹ã“ã¨ã®æ„å‘³ã«ã¤ã„ã¦ã¯è§£é‡ˆæ¬¡ç¬¬ã¨ãªã‚‹.
In theory, it could still be interpreted with a metric that accounts for the presence of different sources or viewpoints [25].
ç†è«–çš„ã«ã¯ï¼Œç•°ãªã‚‹æƒ…å ±æºã‚„è¦–ç‚¹ã®å­˜åœ¨ã‚’è€ƒæ…®ã—ãŸæŒ‡æ¨™ã§è§£é‡ˆã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã‚ã‚‹[25]ï¼
However, in practice, diversity is most often implemented as a descriptive distance metric such as cosine similarity between two bag-of-words models or word embeddings [43, 48].
ã—ã‹ã—ã€å®Ÿéš›ã«ã¯2ã¤ã®bag-of-wordsãƒ¢ãƒ‡ãƒ«ã‚„å˜èªåŸ‹ã‚è¾¼ã¿ã®cosine similarityã®ã‚ˆã†ãªè¨˜è¿°çš„ãªè·é›¢æŒ‡æ¨™ã¨ã—ã¦å®Ÿè£…ã•ã‚Œã‚‹ã“ã¨ãŒã»ã¨ã‚“ã©ã§ã‚ã‚‹[43, 48].

Other popular â€œbeyond-accuracyâ€ metrics related to diversity are novelty (how different is this item from what the user has seen in the past), serendipity (is the user positively surprised by this item), and coverage (what percentage of articles are recommended to at least one user).
å¤šæ§˜æ€§ã«é–¢é€£ã™ã‚‹ä»–ã®äººæ°—ã®ã‚ã‚‹ **"beyond-accuracy(ç²¾åº¦ã‚’è¶…ãˆãŸ)"ãƒ¡ãƒˆãƒªã‚¯ã‚¹** ã¯ã€ä»¥ä¸‹ãŒã‚ã‚‹.

- **novelty(æ–°è¦æ€§)**ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒéå»ã«è¦‹ãŸã‚‚ã®ã¨ã“ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒã©ã‚Œã ã‘é•ã†ã‹).
- **serendipity**ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã“ã®ã‚¢ã‚¤ãƒ†ãƒ ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ã«é©šã„ãŸã‹).
- **coverage**ï¼ˆå°‘ãªãã¨ã‚‚1äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ¨è–¦ã•ã‚ŒãŸè¨˜äº‹ã®å‰²åˆï¼‰.

These metrics can be taken into account at different points in the machine learning pipeline [43, 81].
ã“ã‚Œã‚‰ã®æŒ‡æ¨™ã¯ã€**æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ç•°ãªã‚‹ãƒã‚¤ãƒ³ãƒˆã§è€ƒæ…®(??)**ã™ã‚‹ã“ã¨ãŒã§ãã‚‹.

One can optimize for these descriptive notions of diversity (i) before training, by clustering users based on their profile diversity with JS divergence [27], (ii) directly at training time (e.g., for learning-to-rank [10, 13, 70], collaborative filtering [60], graphs [30, 59] or bandits [21, 84]), (iii) by re-ranking a recommendation set and balance diversity vs. relevance [16] or popularity vs. relevance [15], and (iv) by defining a post-recommendation metric to measure diversity for each recommendation set or at user-level (e.g., the generalist-specialist score [2, 73]).
ã“ã®ã‚ˆã†ãªå¤šæ§˜æ€§ã®æ¦‚å¿µã¯ï¼Œå­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ãŠã„ã¦ä»¥ä¸‹ã®**ï¼”ã¤ã®æ™‚ç‚¹**ã§å¯¾å¿œã™ã‚‹äº‹ãŒå¯èƒ½ã§ã‚ã‚‹.

- (i)å­¦ç¿’å‰ã«ï¼ŒJS divergence [27]ã‚’ç”¨ã„ã¦ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤šæ§˜æ€§ã«åŸºã¥ã„ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ï¼Œ
- (ii)å­¦ç¿’æ™‚ã«ç›´æ¥æœ€é©åŒ–ã§ãã‚‹ï¼ˆä¾‹ï¼šlearning-to-rank [10, 13, 70], collaborative filter [60], graph [30, 59] or bandits [21, 84]ï¼ã¾ãŸã€
- (iii) æ¨è–¦ã‚»ãƒƒãƒˆã®å†ãƒ©ãƒ³ã‚¯ä»˜ã‘ã‚’è¡Œã„ã€å¤šæ§˜æ€§ã¨é–¢é€£æ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’ã¨ã‚‹ [16]ã€ã‚ã‚‹ã„ã¯äººæ°—ã¨é–¢é€£æ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’ã¨ã‚‹ [15] ã€
- (iv) æ¨è–¦å¾Œã®æŒ‡æ¨™ã‚’å®šç¾©ã—ã€æ¨è–¦ã‚»ãƒƒãƒˆã”ã¨ã‚ã‚‹ã„ã¯ãƒ¦ãƒ¼ã‚¶å˜ä½ã§å¤šæ§˜æ€§ã‚’æ¸¬ã‚‹ï¼ˆä¾‹ï¼šä¸€èˆ¬ä¸»ç¾©-å°‚é–€ä¸»ç¾©ã‚¹ã‚³ã‚¢ [2, 73]ï¼‰

With any of these four methods, a trade-off must be made between the relevance of a recommendation issued to users and the level of descriptive diversity, though there have also been studies indicating that increasing diversity does not necessarily need to negatively affect relevance [48].
ã“ã®4ã¤ã®æ–¹æ³•ã®ã„ãšã‚Œã«ãŠã„ã¦ã‚‚ã€ãƒ¦ãƒ¼ã‚¶ã«æç¤ºã™ã‚‹æ¨è–¦æ–‡ã®é–¢é€£æ€§ã¨descriptive diversity ã®ãƒ¬ãƒ™ãƒ«ã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®é–¢ä¿‚ã«ã‚ã‚‹ãŒã€**å¤šæ§˜æ€§ã‚’é«˜ã‚ã‚‹ã“ã¨ãŒå¿…ãšã—ã‚‚é–¢é€£æ€§ã«æ‚ªå½±éŸ¿ã‚’ä¸ãˆã‚‹å¿…è¦ã¯ãªã„**ã“ã¨ã‚’ç¤ºã™ç ”ç©¶ã‚‚ã‚ã‚‹[48]ã€‚
Nevertheless, this encouraged recent efforts in training neural-based recommenders that explicitly make a trade-off between accuracy and diversity [61].
ã—ã‹ã—ã€è¿‘å¹´ã§ã¯ã€**å¤šæ§˜æ€§ã¨ç²¾åº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ˜ç¤ºçš„ã«è¡Œã†**ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ»ãƒ™ãƒ¼ã‚¹ãƒ»ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹[61].
Also recently, there have been studies that differentiate between diversity needs of users [83].
ã¾ãŸã€æœ€è¿‘ã§ã¯ã€ãƒ¦ãƒ¼ã‚¶ã®å¤šæ§˜æ€§ãƒ‹ãƒ¼ã‚ºã‚’åŒºåˆ¥ã™ã‚‹ç ”ç©¶ã‚‚è¡Œã‚ã‚Œã¦ã„ã‚‹[83].

## 2.2. Normative Diversity Normative Diversity (è¦ç¯„çš„å¤šæ§˜æ€§)

Diversity is extensively discussed as a normative concept in literature, and has a role in many different areas of science [46, 65], spanning from ecological diversity to diversity as a proxy for fairness in machine learning systems [51].
å¤šæ§˜æ€§ã¯è¦ç¯„çš„ãªæ¦‚å¿µã¨ã—ã¦æ–‡çŒ®ã§åºƒãè­°è«–ã•ã‚Œã¦ãŠã‚Šã€ç”Ÿæ…‹ç³»ã®å¤šæ§˜æ€§ã‹ã‚‰æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹å…¬å¹³æ€§ã®ä»£ç†ã¨ã—ã¦ã®å¤šæ§˜æ€§[51]ã¾ã§ã€ç§‘å­¦ã®å¤šãã®ç•°ãªã‚‹åˆ†é‡ã§å½¹å‰²ã‚’æ‹…ã£ã¦ã„ã‚‹[46, 65].
While these interpretations of diversity are often related, they do not fully cover the nuances of a diverse news recommender system, the work on which stems from democratic theory and the role of media in society.
ã“ã‚Œã‚‰ã®å¤šæ§˜æ€§ã®è§£é‡ˆã¯ã—ã°ã—ã°é–¢é€£ã—ã¦ã„ã‚‹ãŒï¼Œæ°‘ä¸»ä¸»ç¾©ç†è«–ã‚„ç¤¾ä¼šã«ãŠã‘ã‚‹ãƒ¡ãƒ‡ã‚£ã‚¢ã®å½¹å‰²ã«ç”±æ¥ã™ã‚‹ï¼Œå¤šæ§˜ãªãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’å®Œå…¨ã«ã‚«ãƒãƒ¼ã™ã‚‹ã‚‚ã®ã§ã¯ãªã„.
Following Helberger [33], we define a normatively diverse news recommendation as one that succeeds in informing the user and supports them in fulfilling their role in democratic society.
Helberger [33]ã«å¾“ã„ã€æˆ‘ã€…ã¯**è¦ç¯„çš„ã«å¤šæ§˜ãªãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚’ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æƒ…å ±ã‚’æä¾›ã™ã‚‹ã“ã¨ã«æˆåŠŸã—ã€æ°‘ä¸»ä¸»ç¾©ç¤¾ä¼šã«ãŠã‘ã‚‹å½¹å‰²ã‚’æœãŸã™ã“ã¨ã‚’æ”¯æ´ã™ã‚‹ã‚‚ã®**ã¨å®šç¾©ã™ã‚‹.
Out of the many theoretical models that exist in literature, Helberger [33] describes four different models from the normative framework of democracy, each with a different view on what it means to properly inform citizens:
æ–‡çŒ®ã«å­˜åœ¨ã™ã‚‹å¤šãã®ç†è«–ãƒ¢ãƒ‡ãƒ«ã®ã†ã¡ã€Helberger [33]ã¯ã€æ°‘ä¸»ä¸»ç¾©ã®è¦ç¯„çš„æ çµ„ã¿ã‹ã‚‰**4ã¤ã®ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«**ã‚’èª¬æ˜ã—ã€ãã‚Œãã‚Œã€å¸‚æ°‘ã«é©åˆ‡ã«æƒ…å ±ã‚’æä¾›ã™ã‚‹ã“ã¨ã®æ„å‘³ã«ã¤ã„ã¦ç•°ãªã‚‹è¦‹è§£ã‚’ç¤ºã—ã¦ã„ã‚‹.

- the Liberal model, which aims to enable personal development and autonomy,
- è‡ªç”±ä¸»ç¾©ãƒ¢ãƒ‡ãƒ«ï¼šå€‹äººã®æˆé•·ã¨è‡ªå¾‹ã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ã€
- the Participatory model, which aims to enable users to fulfill their role as active citizens in a democratic society,
- å‚åŠ å‹ãƒ¢ãƒ‡ãƒ«ï¼šæ°‘ä¸»ä¸»ç¾©ç¤¾ä¼šã«ãŠã‘ã‚‹ç©æ¥µçš„ãªå¸‚æ°‘ã¨ã—ã¦ã®å½¹å‰²ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœãŸã›ã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã€
- the Deliberative model, which aims to foster discussion and debate by equally presenting different viewpoints and opinions in a rational and neutral way, and
- å¯©è­°å‹ãƒ¢ãƒ‡ãƒ«ï¼šç•°ãªã‚‹è¦–ç‚¹ã‚„æ„è¦‹ã‚’åˆç†çš„ã‹ã¤ä¸­ç«‹çš„ã«å¹³ç­‰ã«æç¤ºã—ã€è­°è«–ã‚„è¨è«–ã‚’ä¿ƒã™ã“ã¨ã€
- the Critical model, which aims to challenge the status quo and to inspire the readers to take action against existing injustices in society.
- æ‰¹åˆ¤ãƒ¢ãƒ‡ãƒ«ï¼šç¾çŠ¶ã«æŒ‘æˆ¦ã—ã€ç¤¾ä¼šã®æ—¢å­˜ã®ä¸å…¬å¹³ã«å¯¾ã—ã¦è¡Œå‹•ã‚’èµ·ã“ã™ã‚ˆã†ã«èª­è€…ã‚’é¼“èˆã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚

For more details regarding the different models, and what a recommender system following each of these models would look like, we refer to Helberger [33].
å„ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°ã‚„ã€**å„ãƒ¢ãƒ‡ãƒ«ã«å¾“ã£ãŸæ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ãŒã©ã®ã‚ˆã†ãªã‚‚ã®ã‹**ã«ã¤ã„ã¦ã¯ã€Helberger [33]ã‚’å‚ç…§ã—ã¦ãã ã•ã„.
Which model is followed is a decision that needs to be made by the media organization itself, and should be in line with their norms and values.
**ã©ã®ãƒ¢ãƒ‡ãƒ«ã«å¾“ã†ã‹ã¯ã€å ±é“æ©Ÿé–¢è‡ªèº«ãŒæ±ºå®šã™ã¹ãã“ã¨**ã§ã‚ã‚Šã€ãã®è¦ç¯„ã‚„ä¾¡å€¤è¦³ã«æ²¿ã£ãŸã‚‚ã®ã§ã‚ã‚‹ã¹ãã§ã‚ã‚‹.

Based on these models, the DART metrics [71] take a first step towards normative diversity for recommender systems and reflect the nuances of the different democratic models described above:
ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ã¦ã€**DART Metrics** [71] ã¯æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®ãŸã‚ã®è¦ç¯„çš„ãªå¤šæ§˜æ€§ã¸ã®ç¬¬ä¸€æ­©ã‚’è¸ã¿å‡ºã—ã€ä¸Šè¿°ã—ãŸç•°ãªã‚‹æ°‘ä¸»ä¸»ç¾©ãƒ¢ãƒ‡ãƒ«ã®ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’åæ˜ ã•ã›ãŸã‚‚ã®ã§ã‚ã‚‹:

- Calibration
- Fragmentation
- Activation
- Representation
- Alternative Voices.

Table 1 provides an overview of the DART metrics and their expected value ranges for the different models, and will be further elaborated later in the paper.
è¡¨1ã¯ã€DART Metricsã®æ¦‚è¦ã¨ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹æœŸå¾…å€¤ã®ç¯„å›²ã‚’ç¤ºã—ã¦ãŠã‚Šã€ã“ã®è«–æ–‡ã®å¾ŒåŠã§ã•ã‚‰ã«è©³ã—ãèª¬æ˜ã™ã‚‹äºˆå®šã§ã‚ã‚‹.

## 2.3. The Gap Between Normative and Descriptive Diversity

The descriptive diversity metrics described in Section 2.1 are generalpurpose and meant to be applicable in all domains of recommendation.
ã‚»ã‚¯ã‚·ãƒ§ãƒ³2.1ã§èª¬æ˜ã—ãŸ **descriptive diversity metrics ã¯æ±ç”¨çš„ã§ã‚ã‚Šã€ã™ã¹ã¦ã®æ¨è–¦ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«é©ç”¨ã§ãã‚‹**ã“ã¨ã‚’æ„å›³ã—ã¦ã„ã‚‹.
However, in their simplicity a large gap can be observed between this interpretation of diversity and the social sciencesâ€™ perspective on media diversity that is detailed in Section 2.2.
ã—ã‹ã—ã€**ãã®å˜ç´”ã•ã‚†ãˆã«ã€ã“ã®å¤šæ§˜æ€§ã®è§£é‡ˆã¨ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³2.2ã§è©³è¿°ã™ã‚‹ãƒ¡ãƒ‡ã‚£ã‚¢ã®å¤šæ§˜æ€§ã«é–¢ã™ã‚‹ç¤¾ä¼šç§‘å­¦ã®è¦³ç‚¹ã¨ã®é–“ã«å¤§ããªã‚®ãƒ£ãƒƒãƒ—ãŒè¦‹ã‚‰ã‚Œã‚‹**.
In their comprehensive work on the implementation of media diversity across different domains, Loecherbach et al. [46] note that there is â€œlittle to no overlap between concepts and operationalizations (of diversity) used in the different fields interested in media diversity.â€
Loecherbachã‚‰[46]ã¯ã€ç•°ãªã‚‹é ˜åŸŸã«ã‚ãŸã‚‹ãƒ¡ãƒ‡ã‚£ã‚¢ã®å¤šæ§˜æ€§ã®å®Ÿç¾ã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªç ”ç©¶ã®ä¸­ã§ã€"ãƒ¡ãƒ‡ã‚£ã‚¢ã®å¤šæ§˜æ€§ã«é–¢å¿ƒã‚’æŒã¤ç•°ãªã‚‹åˆ†é‡ã§ä½¿ç”¨ã•ã‚Œã‚‹ï¼ˆå¤šæ§˜æ€§ã®ï¼‰æ¦‚å¿µã¨é‹ç”¨ã®é–“ã«ã¯ã»ã¨ã‚“ã©é‡è¤‡ãŒãªã„"ã“ã¨ã‚’æŒ‡æ‘˜ã—ã¦ã„ã‚‹.
As such, a recommendation that would score high on diversity according to traditional information retrieval-based metrics [17, 62], may not be considered to be diverse according to the criteria maintained by newsroom editors.
ãã®ãŸã‚ã€å¾“æ¥ã®æƒ…å ±æ¤œç´¢ã«åŸºã¥ãè©•ä¾¡åŸºæº–[17, 62]ã§ã¯å¤šæ§˜æ€§ã§é«˜å¾—ç‚¹ã‚’å¾—ã‚‰ã‚Œã‚‹æ¨è–¦æ–‡ã‚‚ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ«ãƒ¼ãƒ ã®ç·¨é›†è€…ãŒä¿æŒã™ã‚‹åŸºæº–ã§ã¯å¤šæ§˜æ€§ãŒã‚ã‚‹ã¨ã¯è¦‹ãªã•ã‚Œãªã„å¯èƒ½æ€§ãŒã‚ã‚‹. (i.e. **diversityã®è©•ä¾¡æ–¹æ³•ãŒã¾ã¡ã¾ã¡ã ã£ã¦è©±!**)
Both Loecherbach et al. [46] and Bernstein et al. [7] call for truly interdisciplinary research in bridging this gap, where Bernstein et al. [7] argue for close collaboration between academia and industry and the foundation of joint labs.
Loecherbachã‚‰[46]ã¨Bernsteinã‚‰[7]ã¯ã€ã“ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã«çœŸã«å­¦éš›çš„ãªç ”ç©¶ã‚’æ±‚ã‚ã¦ãŠã‚Šã€Bernsteinã‚‰[7]ã¯ã€å­¦è¡“ç•Œã¨ç”£æ¥­ç•Œã®å¯†æ¥ãªå”åŠ›ã¨å…±åŒãƒ©ãƒœã®å‰µè¨­ã‚’ä¸»å¼µã—ã¦ã„ã‚‹.
This work is a step in that direction, as we provide a versatile and mathematically grounded **rank-aware metric** that can be used by practitioners to monitor their normative goals.
ã“ã®ç ”ç©¶ã¯ãã®æ–¹å‘ã¸ã®ä¸€æ­©ã§ã‚ã‚Šã€æˆ‘ã€…ã¯ã€**å®Ÿå‹™å®¶ãŒè¦ç¯„çš„ç›®æ¨™ã‚’ç›£è¦–ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã§ãã‚‹ã€æ±ç”¨çš„ã§æ•°å­¦çš„æ ¹æ‹ ã®ã‚ã‚‹ rank-aware metric**ã‚’æä¾›ã™ã‚‹ã‹ã‚‰ã§ã‚ã‚‹.

# 3. Operationalizing Normative Diversity for News Recommendation ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã®ãŸã‚ã®è¦ç¯„çš„å¤šæ§˜æ€§ã®é‹ç”¨

With our RADio framework, we further refine the DART metrics that were defined by Vrijenhoek et al. [71] in order to resolve a number of the shortcomings of the metricsâ€™ initial formalizations.
RADioãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã¯ã€Vrijenhoekã‚‰[71]ãŒå®šç¾©ã—ãŸ**DARTãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ã•ã‚‰ã«æ”¹è‰¯**ã—ã€metricsã®åˆæœŸå½¢å¼åŒ–ã®æ¬ ç‚¹ã‚’ã„ãã¤ã‹è§£æ±ºã—ã¦ã„ã‚‹.
In their current form, each of the metrics has different value ranges; for example, Activation has a value range [âˆ’1, 1], where a higher score indicates a higher degree of activating content, and Calibration has a range of [0, âˆ], where a lower score indicates a better Calibration.
ä¾‹ãˆã°ã€Activationã¯[-1, 1]ã®å€¤åŸŸã‚’æŒã¡ã€ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã»ã©æ´»æ€§åŒ–ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç¨‹åº¦ãŒé«˜ã„ã“ã¨ã‚’ç¤ºã—ã€Calibrationã¯[0, âˆ]ã®ç¯„å›²ã‚’æŒã£ã¦ãŠã‚Šã€ã‚¹ã‚³ã‚¢ãŒä½ã„ã»ã©CalibrationãŒè‰¯ã„ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹.
These different value ranges reduce the interpretability of the metrics, making them harder to explain and as such less likely to be adopted by news editors.
ã“ã‚Œã‚‰ã®ç•°ãªã‚‹å€¤åŸŸã¯ã€metricsã®è§£é‡ˆå¯èƒ½æ€§ã‚’ä½ä¸‹ã•ã›ã€èª¬æ˜ãŒé›£ã—ããªã‚Šã€ãã®çµæœã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ç·¨é›†è€…ãŒæ¡ç”¨ã™ã‚‹å¯èƒ½æ€§ãŒä½ããªã‚‹.
Furthermore, the proposed metrics do not take the position of an article in a recommendation into account.
ã•ã‚‰ã«ã€ææ¡ˆã•ã‚ŒãŸmetricsã¯ã€**ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹è¨˜äº‹ã®ä½ç½®ã‚’è€ƒæ…®ã«å…¥ã‚Œã¦ã„ãªã„**.
News recommendations are ranked lists of articles that are typically presented to users in such a way that the likelihood of a recommended article to be considered by the user decreases further down the ranking.
ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦æ–‡ã¯é€šå¸¸ã€æ¨è–¦ã•ã‚ŒãŸè¨˜äº‹ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦èª­ã¾ã‚Œã‚‹å¯èƒ½æ€§ãŒãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®ä¸‹æ–¹ã«è¡Œãã»ã©ä½ããªã‚‹ã‚ˆã†ã«ãƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚ŒãŸãƒªã‚¹ãƒˆã§ã‚ã‚‹.
As such, in the evaluation of the diversity of the recommender system we should also account for the position of an article in the recommendation ranking, rather than considering the set as a whole (e.g. ILD).
ãã®ãŸã‚ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®å¤šæ§˜æ€§ã‚’è©•ä¾¡ã™ã‚‹éš›ã«ã¯ã€é›†åˆå…¨ä½“ï¼ˆILDãªã©ï¼‰ã‚’è€ƒæ…®ã™ã‚‹ã®ã§ã¯ãªãã€**ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«ãŠã‘ã‚‹è¨˜äº‹ã®ä½ç½®**ã‚‚è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚‹.

Thus, the two major challenges that we seek to address are that (i) scores should be comparable between the metrics and across recommendation systems, and (ii) scoring of both unranked and ranked sets of recommendations should be possible.
ã“ã®ã‚ˆã†ã«ã€æˆ‘ã€…ã¯ä»¥ä¸‹ã®äºŒã¤ã®å¤§ããªèª²é¡Œã‚’è§£æ±ºã—ã‚ˆã†ã¨ã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹.

- (i) metricsé–“ãŠã‚ˆã³æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ é–“ã§ã‚¹ã‚³ã‚¢ãŒæ¯”è¼ƒå¯èƒ½ã§ã‚ã‚‹ã“ã¨
- (ii) ãƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚Œã¦ã„ãªã„æ¨è–¦ã‚»ãƒƒãƒˆã¨ãƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚ŒãŸæ¨è–¦ã‚»ãƒƒãƒˆã®ä¸¡æ–¹ã®ã‚¹ã‚³ã‚¢ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨.

In this section, we first detail these requirements (Section 3.1), then describe how we reformulate the metrics to each use the same divergence-based approach (Section 3.2).
æœ¬ç¯€ã§ã¯ã€ã¾ãšã“ã‚Œã‚‰ã®è¦æ±‚ã‚’è©³è¿°ã—ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ 3.1ï¼‰ã€æ¬¡ã«metricã‚’ã©ã®ã‚ˆã†ã«å†å®šå¼åŒ–ã—ã€ãã‚Œãã‚ŒãŒåŒã˜divergence ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç”¨ã„ã‚‹ã‹ã‚’èª¬æ˜ã™ã‚‹ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ 3.2ï¼‰ï¼
We then add the rank-aware aspect to the metrics (Section 3.3), before applying them to the five concrete DART metrics (Section 3.4).
ãã—ã¦ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«ãƒ©ãƒ³ã‚¯ã‚’æ„è­˜ã—ãŸå´é¢ã‚’è¿½åŠ ã—ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³3.3ï¼‰ã€ãã‚Œã‚‰ã‚’5ã¤ã®å…·ä½“çš„ãªDARTãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«é©ç”¨ã™ã‚‹ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³3.4ï¼‰.

## 3.1. Requirements å¿…è¦æ¡ä»¶

We first enunciate the classical definition of a distance metric, before specifying three desirable metric criteria for news recommendations.
ã¾ãšã€**distance metric** ã®å¤å…¸çš„ãªå®šç¾©ã‚’æ˜ã‚‰ã‹ã«ã—ãŸå¾Œã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã«æœ›ã¾ã—ã„3ã¤ã®metricã®åŸºæº–ã‚’è¦å®šã™ã‚‹.
Take a set $X$ of random variables and $x, y,z \in X$, then a metric $D$ is a proper distance measure if $D(x,y) = 0 <=> x =y, D(x,y) = D(y,x)$ and $D(x,y) \leq D(x,z) + D(z,y)$.
ç¢ºç‡å¤‰æ•°ã®é›†åˆ$X$ã‚’ã¨ã‚Šã€$x, y,z \in X$ã¨ã™ã‚‹ã¨ã€$D(x,y)=0 <=> x = y, D(x,y) = D(y,x)$ ã‹ã¤ $D(x,y) \leq D(x,z) + D(z,y)$ ãªã‚‰distance measureãŒé©åˆ‡ã§ã‚ã‚‹ã¨è¨€ãˆã‚‹.

These are respectively the axioms of identity, symmetry and triangle inequality, that express intuitions about concepts of distance [56].
ã“ã‚Œã‚‰ã¯ãã‚Œãã‚Œã€distanceã®æ¦‚å¿µã«é–¢ã™ã‚‹ç›´è¦³ã‚’è¡¨ã™ã€åŒä¸€æ€§(identity)ã€å¯¾ç§°æ€§(symmetry)ã€ä¸‰è§’å½¢ã®ä¸ç­‰å¼(triangle inequality)ã¨ã„ã†å…¬ç†ã§ã‚ã‚‹[56].

We add that our distance measure should (i) be bounded by [0; 1], for comparisons of different recommendation algorithms (ii) be unified, so as to fairly consider different diversity aspects (as opposed to e.g. using weighted averages or maxima in [18]) and (iii) allow for discrete rank-based distribution sets, to fit the ranked recommendation setting.
ã¾ãŸã€[18]ã§ã®åŠ é‡å¹³å‡ã‚„æœ€å¤§å€¤ã¨ã¯å¯¾ç…§çš„ã«ã€(i)ç•°ãªã‚‹æ¨è–¦ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ¯”è¼ƒã®ãŸã‚ã«ã€[0; 1]ã§å¢ƒç•Œã•ã‚Œã€(ii)ç•°ãªã‚‹å¤šæ§˜æ€§ã®å´é¢ã‚’å…¬æ­£ã«è€ƒæ…®ã™ã‚‹ãŸã‚ã«çµ±ä¸€ã•ã‚Œã€(iii) ãƒ©ãƒ³ã‚¯ä»˜ãã®æ¨è–¦è¨­å®šã«åˆã†ã‚ˆã†ã«ã€é›¢æ•£ãƒ©ãƒ³ã‚¯ãƒ™ãƒ¼ã‚¹ã®åˆ†å¸ƒã‚»ãƒƒãƒˆã‚’å¯èƒ½ã«ã™ã‚‹ã¹ãã§ã‚ã‚‹ã“ã¨ã‚’ä»˜ã‘åŠ ãˆã‚‹.

## 3.2. f-Divergence â™ª f-ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹

We model the task of measuring diversity as a comparison between probability distributions: the difference in distribution between the issued recommendations (ğ‘„) and its context (ğ‘ƒ).
**diversity ã‚’æ¸¬å®šã™ã‚‹ä½œæ¥­ã¯ã€ç¢ºç‡åˆ†å¸ƒã®æ¯”è¼ƒã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã•ã‚Œã‚‹**.
ã¤ã¾ã‚Šã€ç™ºè¡Œã•ã‚ŒãŸæ¨è–¦(Q)ã¨ãã®context(P)ã®é–“ã®åˆ†å¸ƒã®é•ã„ã§ã‚ã‚‹.
Each diversity metric prescribes its own ğ‘„ and ğ‘ƒ.
å„ãƒ€ã‚¤ãƒãƒ¼ã‚·ãƒ†ã‚£æŒ‡æ¨™ã¯ç‹¬è‡ªã® Qã¨ P ã‚’è¦å®šã™ã‚‹.
The elements in the distribution ğ‘„ can be recommendation items (cf. Calibrated Recommendations [64]), but can also be higher-level concepts, such as distributions of topics and viewpoints.
åˆ†å¸ƒQã®è¦ç´ ã¯æ¨è–¦ã‚¢ã‚¤ãƒ†ãƒ ï¼ˆcf. Calibrated Recommendations [64]ï¼‰ã§ã‚ã‚‹å ´åˆã‚‚ã‚ã‚‹ãŒã€ãƒˆãƒ”ãƒƒã‚¯ã‚„è¦–ç‚¹ã®åˆ†å¸ƒãªã©ã€ã‚ˆã‚Šé«˜ã„ãƒ¬ãƒ™ãƒ«ã®æ¦‚å¿µã§ã‚ã‚‹å ´åˆã‚‚ã‚ã‚‹.
The context ğ‘ƒ may refer to either the overall supply of available items, the user profile, such as the reading history or explicitly stated preferences, or the recommendations that were issued to other users (see Figure 1).
context P ã¯ã€åˆ©ç”¨å¯èƒ½ãªã‚¢ã‚¤ãƒ†ãƒ ã®å…¨ä½“çš„ãªä¾›çµ¦é‡ã€èª­æ›¸å±¥æ­´ã‚„æ˜ç¤ºçš„ãªå¥½ã¿ãªã©ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã€ä»–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç™ºè¡Œã•ã‚ŒãŸæ¨è–¦æ–‡ã®ã„ãšã‚Œã‹ã‚’å‚ç…§ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ï¼ˆå›³1å‚ç…§ï¼‰.
Intuitively, when ğ‘ƒ is linked to the same user as ğ‘„, we measure within user diversity (e.g., towards preventing getting locked in â€œfilter bubblesâ€).
ç›´æ„Ÿçš„ã«ã¯ã€PãŒ Q ã¨åŒã˜ãƒ¦ãƒ¼ã‚¶ã«ãƒªãƒ³ã‚¯ã•ã‚Œã¦ã„ã‚‹å ´åˆã€ãƒ¦ãƒ¼ã‚¶å†…ã®å¤šæ§˜æ€§ã‚’æ¸¬å®šã™ã‚‹ï¼ˆä¾‹ãˆã°ã€ã€Œãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒãƒ–ãƒ«ã€ã«é–‰ã˜è¾¼ã‚ã‚‰ã‚Œã‚‹ã®ã‚’é˜²ããŸã‚ã«ï¼‰.
When ğ‘ƒ is linked to another user than ğ‘„, we measure diversity across users (e.g., monitoring diversity of viewpoints represented across personalized homepages).
PãŒ Q ä»¥å¤–ã®ãƒ¦ãƒ¼ã‚¶ã«ãƒªãƒ³ã‚¯ã•ã‚Œã¦ã„ã‚‹å ´åˆã€ãƒ¦ãƒ¼ã‚¶é–“ã®å¤šæ§˜æ€§ã‚’æ¸¬å®šã™ã‚‹ï¼ˆä¾‹ãˆã°ã€å€‹äººåŒ–ã•ã‚ŒãŸãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã§è¡¨ç¾ã•ã‚Œã‚‹è¦–ç‚¹ã®å¤šæ§˜æ€§ã‚’ç›£è¦–ã™ã‚‹ï¼‰.
In the following, we formalize the role of ğ‘ƒ and ğ‘„ in two different metric settings, starting with the simple and common KL divergence metric, before presenting its refinement (JensenShannon divergence) as our preferred metric.
ä»¥ä¸‹ã§ã¯ã€P ã¨ Q ã®å½¹å‰²ã‚’ã€å˜ç´”ã§ä¸€èˆ¬çš„ãªKL divergence metric ã‹ã‚‰å§‹ã‚ã¦ã€ãã®æ”¹è‰¯ç‰ˆï¼ˆJensenShannonãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ï¼‰ã‚’æˆ‘ã€…ã®å¥½ã¾ã—ã„ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨ã—ã¦æç¤ºã™ã‚‹2ç¨®é¡ã®metricè¨­å®šã«ãŠã„ã¦æ­£å¼ã«èª¬æ˜ã™ã‚‹.

### 3.2.1. Kullback-Leibler Divergence.

The concept of relative entropy or KL (Kullbackâ€“Leibler) divergence [42] between two probability mass functions P and Q (here, a recommendation and its context) is defined as:
2ã¤ã®ç¢ºç‡è³ªé‡é–¢æ•° Pã¨ Qï¼ˆã“ã“ã§ã¯recommendation ã¨ ãã®contextï¼‰ã®é–“ã®ç›¸å¯¾entropyã¾ãŸã¯KLï¼ˆKullback-Leiblerï¼‰ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ï¼»42ï¼½ã®æ¦‚å¿µã¯æ¬¡ã®ã‚ˆã†ã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹:

$$
D_{KL}(P, Q) = - \sum_{x\in X}{P(x)\log_{2}{Q(x)}}
+ \sum_{x\in X}{P(x)\log_{2}{P(x)}}
\tag{1}
$$

Often also expressed as $D_{KL}(ğ‘ƒ, ğ‘„) = ğ»(ğ‘ƒ, ğ‘„)âˆ’ğ»(ğ‘ƒ)$, with $ğ»(ğ‘ƒ, ğ‘„)$ the cross entropy of ğ‘ƒ and ğ‘„, and $ğ»(ğ‘ƒ)$ the entropy of P.
ã—ã°ã—ã°ã€$D_{KL}(ğ‘„) = H(P,Q) - H(P)$ã¨ã‚‚è¡¨ã•ã‚Œã€$H(P,Q)$ã¯Pã¨Qã¨ã®ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã€$H(P)$ã¯Pã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã§ã‚ã‚‹ã¨ã™ã‚‹.
Both cross entropy and KL divergence can be thought of as measurements of how far the probability distribution ğ‘„ is from the reference probability distribution ğ‘ƒ.
ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã¨KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¯ã¨ã‚‚ã«ã€**ç¢ºç‡åˆ†å¸ƒ Q ãŒå‚ç…§ç¢ºç‡åˆ†å¸ƒP ã‹ã‚‰ã©ã‚Œã ã‘é›¢ã‚Œã¦ã„ã‚‹ã‹**ã‚’æ¸¬å®šã™ã‚‹ã‚‚ã®ã¨è€ƒãˆã‚‹ã“ã¨ãŒã§ãã‚‹.
When $P = Q$, $D_{KL}(P, Q) = D_{KL}(P, P) = 0$, that identity property is not guaranteed by cross entropy alone.
P = Q$ã®ã¨ãã€$D*{KL}(P, Q) = D*{KL}(P, P) = 0$ã¨ãªã‚Šã€ãã®åŒä¸€æ€§ã¯ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã ã‘ã§ã¯ä¿è¨¼ã•ã‚Œãªã„.
This is the main reason to prefer KL divergence over cross entropy.
ã“ã‚ŒãŒ**ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚ˆã‚Šã‚‚KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’å¥½ã‚€ä¸»ãªç†ç”±**ã§ã‚ã‚‹.
Though KL Divergence satisfies the identity requirement, the symmetry and triangle inequality are not fulfilled.
KL Divergence ã¯identityã®è¦ä»¶ã‚’æº€ãŸã™ãŒã€symmetryã¨triangle inequality ã¯æº€ãŸã•ãªã„.
This can be resolved by further refining KL Divergence.
ã“ã‚Œã¯ã€KL Divergenceã‚’ã•ã‚‰ã«æ´—ç·´ã•ã›ã‚‹ã“ã¨ã§è§£æ±ºã™ã‚‹ã“ã¨ãŒã§ãã‚‹.

### 3.2.2. Jensenâ€“Shannon Divergence.

A succession of steps from KL divergence lead to Jensen-Shannon (JS) divergence.
KL divergence ã‹ã‚‰æ®µéšã‚’çµŒã¦ã€**Jensen-Shannon (JS) divergence** ã«è‡³ã‚‹.
KL divergence was first turned symmetric [37] and then upper bounded [45], to lead to...
KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¯ã¾ãšå¯¾ç§°åŒ–ã•ã‚Œ[37]ã€æ¬¡ã«ä¸Šç•ŒåŒ–ã•ã‚Œ[45]ã€æ¬¡ã®ã‚ˆã†ã«å°ã‹ã‚Œã‚‹ã‚ˆã†ã«ãªã£ãŸ...

$$
D_{JS}(P, Q) = - \sum_{x\in X}\frac{P(x)+Q(x)}{2} \log_{2}{\frac{P(x)+Q(x)}{2}}
\\
+ \frac{1}{2} \sum_{x\in X}{P(x)\log_{2}{P(x)}}
+ \frac{1}{2} \sum_{x\in X}{Q(x)\log_{2}{Q(x)}}
\tag{2}
$$

When the base 2 logarithm is used, the JS divergence bounds are $0 \leq D_{JS}(P, Q) \leq 1$.
åŸºåº•2å¯¾æ•°ã‚’ç”¨ã„ãŸå ´åˆã€JS divergenceã®å¢ƒç•Œã¯ $0 \leq D_{JS}(P, Q) \leq 1$ã¨ãªã‚‹.
Additionally, Endres and Schindelin [26] show that $\sqrt{ğ·_{JS}}$ is a proper distance which fulfills the identity, symmetry and the triangle inequality properties.
ã¾ãŸEndres and Schindelin [26]ã¯ã€$\sqrt{D_{JS}}$ãŒidentityã€symmetryã€triangle inequality ã®æ€§è³ªã‚’æº€ãŸã™é©åˆ‡ãªdistance(=distance metric?)ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹.
When we refer to $ğ·_{JS}$ or $JS$ divergence below, we therefore implicitly refer to the square root of the JS formulation with log base 2.
ä»¥ä¸‹ã€$D_{JS}$ã¾ãŸã¯ JS Divergence ã¨è¡¨è¨˜ã™ã‚‹å ´åˆã€**log base 2**ã®JSå®šå¼åŒ–ã®å¹³æ–¹æ ¹ã‚’æš—é»™ã«æŒ‡ã™ã“ã¨ã«ãªã‚‹.
Liese and Vajda [44] defined f-Divergence[$D_f$]: a generic formulation of several divergence metrics.
Liese and Vajda [44]ã¯**f-Divergence**[$D_f$]ã‚’å®šç¾©ã—ãŸï¼š**ã„ãã¤ã‹ã® divergence metricsã®ä¸€èˆ¬çš„ãªå®šå¼åŒ–**ã§ã‚ã‚‹.
Among them are the JS and KL divergences.
Further along the text, we use $D_f$ as a shorthand notation for KL and JS divergences.
ãã®ä¸­ã«ã¯ã€JS divergence ã¨KL divergence ãŒã‚ã‚‹. ã•ã‚‰ã«æœ¬æ–‡ã§ã¯ã€**KL divergence ã¨JS divergence ã®ç•¥è¨˜æ³•ã¨ã—ã¦$D_f$ã‚’ç”¨ã„ã‚‹**.
$D_f$ in discrete form is...
é›¢æ•£å½¢å¼ã®$D_f$ã¯...

$$
D_f(P,Q) = \sum_{x}{Q(x)f(\frac{P(x)}{Q(x)})}
\tag{3}
$$

where $f_{KL}(t) = t \log{t}$ and $f_{JS}(t) = \frac{1}{2}[(t+1)\log{\frac{2}{t+1}} +t \log{t}]$.
ã“ã“ã§ã€$f_{KL}(t) = t \log{t}$, $f_{JS}(t) = \frac{1}{2}[(t+1)\log{frac{2}{t+1}} +t \log{t}]$ ã¨ã™ã‚‹.

To avoid misspecified metrics [64], we write $\bar{P}$ and $\bar{Q}$:
metricsã®æŒ‡å®šãƒŸã‚¹ã‚’é¿ã‘ã‚‹ãŸã‚[64]ã€$bar{P}$, $bar{Q}$ã¨è¡¨è¨˜ã™ã‚‹.

$$
\bar{Q}(x) = (1 - a)Q(x) + a P(x), \\
\bar{P}(x) = (1 - a)P(x) + a Q(x),
\tag{4}
$$

where a is a small number close to zero.
ã“ã“ã§ã€aã¯ã‚¼ãƒ­ã«è¿‘ã„å°ã•ãªæ•°ã§ã‚ã‚‹.
$\bar{P}$ prevents artificially setting $D_f$ to zero when a category (e.g., a news topic) is represented in Q and not in P.
Qã§è¡¨ç¾ã•ã‚Œã€Pã§è¡¨ç¾ã•ã‚Œãªã„ã‚«ãƒ†ã‚´ãƒªï¼ˆä¾‹ãˆã°ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ”ãƒƒã‚¯ï¼‰ãŒã‚ã‚‹å ´åˆã€$D_f$ã‚’äººç‚ºçš„ã«ã‚¼ãƒ­ã«ã™ã‚‹ã“ã¨ã‚’é˜²ããŸã‚ã«$bar{P}$ãŒä½¿ç”¨ã•ã‚Œã‚‹.
In the opposite case (when a category is represented in ğ‘ƒ and not in ğ‘„), $\bar{Q}$ avoids zero divisions.
é€†ã®å ´åˆ(ã‚ã‚‹ã‚«ãƒ†ã‚´ãƒªãŒğ‘ƒã§è¡¨ã•ã‚Œã€ğ‘„ã§è¡¨ã•ã‚Œãªã„å ´åˆ)ã€$bar{Q}$ã¯ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
In order for the entire probabilistic distributions $\bar{P}$ and $\bar{Q}$ to remain proper statistical distributions, we normalize them to ensure $\sum_{x}\bar{P}(x) = \sum_{x}\bar{Q}(x) = 1$.
ç¢ºç‡åˆ†å¸ƒå…¨ä½“ $bar{P}$ ã¨ $tar{Q}$ ãŒé©åˆ‡ãªçµ±è¨ˆåˆ†å¸ƒã§ã‚ã‚Šç¶šã‘ã‚‹ãŸã‚ã«ã€$Î˜sum_{x} Î˜bar{P}(x) = \sum_{x} Î˜bar{Q}(x) = 1$ã¨ãªã‚‹ã‚ˆã†ã«æ­£è¦åŒ–ã—ã¾ã™ã€‚
To avoid notation congestion, ğ‘ƒ and ğ‘„ will implicitly refer to $\bar{P}$ and $\bar{Q}$, in the following sections.
è¡¨è¨˜ã®æ··é›‘ã‚’é¿ã‘ã‚‹ãŸã‚ã€ä»¥ä¸‹ã®ç¯€ã§ã¯ã€ğ‘ƒã¨ğ‘„ã¯æš—é»™ã«$Î˜bar{P}$ã¨$Î˜bar{Q}$ã‚’æŒ‡ã™ã“ã¨ã«ã™ã‚‹ã€‚

## 3.3. Rank-Aware f-Divergence Metrics é †ä½è€ƒæ…®å‹ f-ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹

Our ranked recommendation setting (characteristic (iii) above) motivates a further reformulation of our f-Divergence metric.
ãƒ©ãƒ³ã‚¯ä»˜ã‘æ¨è–¦ã®è¨­å®šï¼ˆä¸Šè¨˜ã®ç‰¹æ€§(iii)ï¼‰ã¯f-Divergenceãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ›´ãªã‚‹å†å®šå¼åŒ–ã‚’å‹•æ©Ÿã¥ã‘ã‚‹ã€‚
It is well entrenched in Learning To Rank (LTR) literature [67, 85], and by extension in conventional descriptive diversity metrics [13] that a user is a lot less likely to see items further down a recommended ranked list (i.e., diminishing inspection probabilities).
Learning To Rank (LTR) ã®æ–‡çŒ® [67, 85]ã€ã²ã„ã¦ã¯å¾“æ¥ã®è¨˜è¿°çš„å¤šæ§˜æ€§æŒ‡æ¨™ [13]ã§ã¯ã€ãƒ¦ãƒ¼ã‚¶ãŒæ¨å¥¨ãƒ©ãƒ³ã‚¯ãƒªã‚¹ãƒˆã®ã•ã‚‰ã«ä¸‹ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’è¦‹ã‚‹å¯èƒ½æ€§ã¯ã‹ãªã‚Šä½ã„ï¼ˆã™ãªã‚ã¡ã€æ¤œæŸ»ç¢ºç‡ãŒé€“æ¸›ã™ã‚‹ï¼‰ã¨ã„ã†ã“ã¨ãŒã‚ˆãç†è§£ã•ã‚Œã¦ã„ã¾ã™ã€‚
Note that the ranking oftentimes reflects relevance to the user, but it is not always the case for news (e.g., editorial layout of a news homepage).
ã¾ãŸï¼Œãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯ã—ã°ã—ã°ãƒ¦ãƒ¼ã‚¶ã¨ã®é–¢é€£æ€§ã‚’åæ˜ ã™ã‚‹ãŒï¼Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å ´åˆã¯å¿…ãšã—ã‚‚ãã†ã§ã¯ãªã„ï¼ˆä¾‹ãˆã°ï¼Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã®ç·¨é›†ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰ã“ã¨ã«æ³¨æ„ã•ã‚ŒãŸã„ï¼
We extend our metrics with an optional discount factor for ğ‘ƒ and ğ‘„ to weigh down the importance of results lower in the ranked recommendation list.
æˆ‘ã€…ã¯ã€ãƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚ŒãŸæ¨è–¦ãƒªã‚¹ãƒˆã§ä¸‹ä½ã®çµæœã®é‡è¦æ€§ã‚’é‡ã¿ä»˜ã‘ã™ã‚‹ãŸã‚ã«ã€áµ„ã¨áµ„ã«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å‰²å¼•ä¿‚æ•°ã‚’ä»˜ã‘ã¦æˆ‘ã€…ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’æ‹¡å¼µã—ã¾ã™ã€‚
The ranking relevancy metrics Mean Reciprocal Rank (MRR) and Normalized Discounted Cumulative Gain (NDCG) are popular rank-aware metrics for LTR [14, 36], in particular for news recommendation [80].
ãƒ©ãƒ³ã‚­ãƒ³ã‚°é–¢é€£æ€§æŒ‡æ¨™ã§ã‚ã‚‹Mean Reciprocal Rank (MRR) ã¨ Normalized Discounted Cumulative Gain (NDCG) ã¯ï¼ŒLTR [14, 36]ï¼Œç‰¹ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ [80] ã§ã‚ˆãç”¨ã„ã‚‰ã‚Œã‚‹ãƒ©ãƒ³ã‚¯è€ƒæ…®å‹æŒ‡æ¨™ã§ã‚ã‚‹ï¼
In line with the LTR literature, we first define the discrete probability distribution of a ranked recommendation set $ğ‘„^âˆ—$ , given each item ğ‘– in the recommendation list ğ‘…:
LTRã®æ–‡çŒ®ã«æ²¿ã£ã¦ã€ã¾ãšã€æ¨è–¦ãƒªã‚¹ãƒˆğ‘…ã®å„é …ç›®ğ‘–ã‚’ä¸ãˆã¦ã€ãƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚ŒãŸæ¨è–¦ã‚»ãƒƒãƒˆ$áµ„^âˆ—$ã®é›¢æ•£ç¢ºç‡åˆ†å¸ƒã‚’å®šç¾©ã™ã‚‹ã€‚

$$
\tag{5}
$$

where $ğ‘¤_{ğ‘…ğ‘–}$ , the weight of a rank for item ğ‘–, can be different depending on the discount form.
ã“ã“ã§ã€é …ç›®ğ‘–ã®ãƒ©ãƒ³ã‚¯ã®é‡ã¿$ğ‘¤_{Ç”ğ‘–}$ã¯å‰²å¼•å½¢å¼ã«ã‚ˆã£ã¦ç•°ãªã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚
For MMR, $ğ‘¤_{ğ‘…ğ‘–} = \frac{1}{Ri}$ , for NDCG, $ğ‘¤_{ğ‘…ğ‘–} =  \frac{1}{\log_2{Ri+1}}$ When $ğ‘¤_{ğ‘…ğ‘–} = 1$, $ğ‘„^âˆ—$ is not discounted (i.e., $ğ‘„^âˆ— = ğ‘„$).
MMRã®å ´åˆã€$ğ‘¤ğ‘–} = \frac{1}{Ri}$ ã€NDCGã®å ´åˆã€$ğ‘¤ğ‘–} = \frac{1}{log_2{Ri+1}$ $ğ‘…ğ‘–} = 1$ æ™‚ã€$áµ„^âˆ—$ã¯å‰²å¼•ã‹ã‚Œãªã„ï¼ˆã™ãªã‚ã¡$áµ„^âˆ— = ğ‘„$ï¼‰ã€‚

In news recommendation, the sparsity bias plays a predominant role: users will interact with a small fraction of a large item collection, such as scrollable news recommendation websites [40].
ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã§ã¯ï¼Œã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ãƒã‚¤ã‚¢ã‚¹ãŒæ”¯é…çš„ãªå½¹å‰²ã‚’æœãŸã™ï¼ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ[40]ã®ã‚ˆã†ã«ï¼Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å¤§ããªã‚¢ã‚¤ãƒ†ãƒ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ã”ãä¸€éƒ¨ã¨ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã™ã‚‹ï¼
We thus opt for weighing based on MRR rather than NDCG, because it applies a heavier discount along the ranking than NDCG.
ãã®ãŸã‚ï¼ŒNDCGã‚ˆã‚Šã‚‚MRRã«åŸºã¥ãé‡ã¿ä»˜ã‘ã‚’é¸æŠã™ã‚‹ã€‚ã“ã‚Œã¯ï¼ŒNDCGã‚ˆã‚Šã‚‚ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«æ²¿ã£ã¦ã‚ˆã‚Šé‡ã„å‰²å¼•ã‚’é©ç”¨ã™ã‚‹ãŸã‚ã§ã‚ã‚‹ã€‚
Note that the latter is said to be more suited for query-related rankings, where the user has a particular information need related to a query and thus higher propensity to scroll down a page [14].
å¾Œè€…ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¯ã‚¨ãƒªã«é–¢é€£ã—ãŸç‰¹å®šã®æƒ…å ±ãƒ‹ãƒ¼ã‚ºã‚’æŒã£ã¦ãŠã‚Šã€ã—ãŸãŒã£ã¦ãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã™ã‚‹å‚¾å‘ãŒã‚ˆã‚Šé«˜ã„ã€ã‚¯ã‚¨ãƒªé–¢é€£ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«é©ã—ã¦ã„ã‚‹ã¨è¨€ã‚ã‚Œã¦ã„ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„[14]ã€‚

The context distribution ğ‘ƒ is discounted in the same manner, when it is a ranked recommendation list.
ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†å¸ƒ áµ„ ã¯ã€ãƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚ŒãŸæ¨è–¦ãƒªã‚¹ãƒˆã§ã‚ã‚‹å ´åˆã€åŒã˜ã‚ˆã†ã«å‰²ã‚Šå¼•ã‹ã‚Œã‚‹ã€‚
When ğ‘ƒ is a userâ€™s reading history (see Figure 1), the discount on ğ‘ƒ increases with time: articles read recently are weighted higher than articles read longer ago.
ğ‘ƒãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èª­æ›¸å±¥æ­´ã®å ´åˆï¼ˆå›³1å‚ç…§ï¼‰ã€ğ‘ƒã®å‰²å¼•ç‡ã¯æ™‚é–“ã¨å…±ã«å¢—åŠ ã™ã‚‹ï¼šæœ€è¿‘èª­ã‚“ã è¨˜äº‹ã¯ã€ã‚ˆã‚Šæ˜”ã«èª­ã‚“ã è¨˜äº‹ã‚ˆã‚Šé«˜ãè©•ä¾¡ã•ã‚Œã‚‹ã€‚
There are situations when rank-awareness is not applicable, for example when ğ‘ƒ is the entire pool of available articles.5 With rankaware $ğ‘„^âˆ—$ and optionally rank-aware $ğ‘ƒ^âˆ—$ , we formulate RADio, our rank-aware f-Divergence metric:
ãƒ©ãƒ³ã‚¯ã‚’è€ƒæ…®ã—ãŸ$áµ„^âˆ—$ã¨ä»»æ„ã§ãƒ©ãƒ³ã‚¯ã‚’è€ƒæ…®ã—ãŸ$ğ‘ƒ^âˆ—$ã§ã€ãƒ©ãƒ³ã‚¯ã‚’è€ƒæ…®ã—ãŸf-Divergenceãƒ¡ãƒˆãƒªãƒƒã‚¯ã§ã‚ã‚‹RADioã‚’å®šå¼åŒ–ã™ã‚‹ã€‚

$$
\tag{6}
$$

$ğ‘„^âˆ—(ğ‘¥)$ and $ğ‘ƒ^âˆ—(ğ‘¥)$ accommodate for multiple situations: for example, $ğ‘„^âˆ—(ğ‘
ğ‘…)$ is the rank-aware distribution of news categories ğ‘ over the recommendation set ğ‘…. In the following, we specify $ğ‘ƒ^âˆ—(ğ‘¥

## 3.4. Normative Diversity metrics as Rank-Aware f-Divergences é †ä½ã‚’è€ƒæ…®ã—ãŸf-Divergencesã¨ã—ã¦ã®è¦ç¯„çš„ãªå¤šæ§˜æ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹

In this section, we describe the RADio formalization of the general f-Divergence formulation above to the five DART metrics.
ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€ä¸Šè¨˜ã®ä¸€èˆ¬çš„ãªf-Divergenceã®å®šå¼åŒ–ã‚’5ã¤ã®DARTãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«RADioã§å®šå¼åŒ–ã—ãŸã‚‚ã®ã«ã¤ã„ã¦èª¬æ˜ã™ã‚‹ã€‚
We leave the exact implementation of the metrics in practice for a particular open news recommendation dataset to the next section.
ç‰¹å®šã®ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹å®Ÿéš›ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ­£ç¢ºãªå®Ÿè£…ã¯æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«è­²ã‚Šã¾ã™ã€‚
More formally, we define the following global parameters:
ã‚ˆã‚Šæ­£å¼ã«ã¯ã€ä»¥ä¸‹ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ã™ã‚‹ã€‚

- ğ‘†: The list of news articles the recommender system could make its selection from, also referred to as the â€œsupply.â€ ğ‘†: ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ãŒé¸æŠã—ã†ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ãƒªã‚¹ãƒˆã§ã€"ä¾›çµ¦ "ã¨ã‚‚å‘¼ã°ã‚Œã‚‹ã€‚

- ğ‘…: The ranked list of articles in the recommendation set. ğ‘…: æ¨è–¦ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã‚‹è¨˜äº‹ã®ãƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚ŒãŸãƒªã‚¹ãƒˆã€‚

- ğ»: The list of articles in a userâ€™s reading history, ranked by recency. ğ»: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èª­æ›¸å±¥æ­´ã«ã‚ã‚‹è¨˜äº‹ã®ãƒªã‚¹ãƒˆã§ã€æ–°ç€é †ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

$ğ‘…_{i}^u \in {1, 2, 3, \cdots}$ refers to the rank of an item ğ‘– in a ranked list of recommendations for user ğ‘¢.
ğ‘…\_{i}^u \in {1, 2, 3, \cdots}$ ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ğ‘¢ã«å¯¾ã™ã‚‹æ¨å¥¨ãƒªã‚¹ãƒˆã«ãŠã‘ã‚‹ã‚¢ã‚¤ãƒ†ãƒ  ğ‘–ã®ãƒ©ãƒ³ã‚¯ã‚’æ„å‘³ã™ã‚‹ã€‚
In this work, metrics are defined for a specific user at a certain point in time, therefore ğ‘… implicitly refers to $ğ‘…^ğ‘¢$, unless stated otherwise.
ã“ã®ä½œæ¥­ã§ã¯ã€ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¯ã‚ã‚‹æ™‚ç‚¹ã®ç‰¹å®šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾ã—ã¦å®šç¾©ã•ã‚Œã‚‹ãŸã‚ã€ç‰¹ã«æ–­ã‚‰ãªã„é™ã‚Šã€ğ‘…ã¯æš—é»™çš„ã«$ğ‘¢$ã‚’æ„å‘³ã™ã‚‹ã€‚
While this section contains some contextualization of the DART metrics [71], the original paper contains further normative justifications.
ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯DARTãƒ¡ãƒˆãƒªã‚¯ã‚¹[71]ã®æ–‡è„ˆã‚’å«ã‚“ã§ã„ã¾ã™ãŒã€å…ƒã®è«–æ–‡ã¯ã•ã‚‰ã«è¦ç¯„çš„ãªæ­£å½“æ€§ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚

### 3.4.1. Calibration. ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã¾ã™ã€‚

(Equation 7) measures to what extent the recommendations are tailored to a userâ€™s preferences. The userâ€™s preferences are deduced from their reading history (ğ»). Calibration can have two aspects: the divergence of the recommended articlesâ€™ categories and complexity. The former is expected to be extracted from news metadata and thus categorical by nature, the latter is a binned (categorical) probabilistic measure extracted via a language model. As such, we compare $ğ‘ƒ^âˆ—(ğ‘
ğ»)$, the rank-aware distribution of categories or complexity score bins ğ‘ over the usersâ€™ reading history, and $ğ‘„^âˆ—(ğ‘

### 3.4.2. Fragmentation. ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³

(Equation 8) reflects to what extent we can speak of a common public sphere, or whether the users exist in their own bubble. We measure Fragmentation as the divergence between every pair of usersâ€™ recommendations. Here we consider$ ğ‘ƒ^âˆ—(ğ‘’
ğ‘…^ğ‘¢)$ as the rank-aware distribution of news events ğ‘’ over the recommendations ğ‘… for user ğ‘¢, and $ğ‘„^âˆ—(ğ‘’

### 3.4.3. Activation. ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³

(Equation 9) Most off-the-shelf sentiment analysis tools analyze a text, and return a value (0, 1] when the text expresses a positive emotion, a value [âˆ’1, 0) when the expressed sentiment is negative, and 0 if it is completely neutral. The more extreme the value, the stronger the expressed sentiment is. As proposed in [71], we use an articleâ€™s absolute sentiment score as an approximation to determine the height of the emotion and therefore the level of Activation expressed in a single article. This then yields a continuous value between 0 and 1. $ğ‘ƒ(ğ‘˜
ğ‘†)$ denotes the distribution of (binned) article Activation score ğ‘˜ within the pool of items that were available at that point (ğ‘†). $ğ‘„^âˆ—(ğ‘˜

### 3.4.4. Representation. è¡¨ç¾

(Equation 10) aims to approximate a notion of viewpoint diversity (e.g. mentions of political topics or political parties), where the viewpoints are expressed categorically. Here ğ‘ refers to the presence of a particular viewpoint, and $ğ‘ƒ(ğ‘
ğ‘†)$ is the distribution of these viewpoints within the overall pool of articles, while $ğ‘„^âˆ—(ğ‘

### 3.4.5. Alternative Voices. ã‚ªãƒ«ã‚¿ãƒŠãƒ†ã‚£ãƒ–ãƒ»ãƒ´ã‚©ã‚¤ã‚¹

(Equation 11) is related to the Representation metric in the sense that it also aims to reflect an aspect of viewpoint diversity.
(å¼11ï¼‰ã¯ã€è¦–ç‚¹ã®å¤šæ§˜æ€§ã®ä¸€é¢ã‚’åæ˜ ã•ã›ã‚‹ã¨ã„ã†æ„å‘³ã§ã€RepresentationæŒ‡æ¨™ã¨é–¢é€£ã—ã¦ã„ã‚‹ã€‚
Rather than focusing on the content of the viewpoint, it focuses on the viewpoint holder, and specifically whether they belong to a â€œprotected groupâ€ or not.
ã“ã‚Œã¯ã€è¦–ç‚¹ã®å†…å®¹ã§ã¯ãªãã€è¦–ç‚¹ã®æŒã¡ä¸»ã€ç‰¹ã«ã€Œä¿è­·ã•ã‚ŒãŸé›†å›£ã€ã«å±ã—ã¦ã„ã‚‹ã‹å¦ã‹ã«ç€ç›®ã—ãŸã‚‚ã®ã§ã‚ã‚‹ã€‚
Examples of such protected
ä¿è­·ã•ã‚ŒãŸé›†å›£ã®ä¾‹

$$
\tag{11}
$$

# 4. Experimental Setup å®Ÿé¨“ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

TUP In order to demonstrate RADioâ€™s potential effectiveness, we developed an NLP pipeline to retrieve input features to the metrics in Section 3.4 and ran them on a public dataset.
TUP RADioã®æ½œåœ¨çš„ãªæœ‰åŠ¹æ€§ã‚’å®Ÿè¨¼ã™ã‚‹ãŸã‚ã«ã€æˆ‘ã€…ã¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³3.4ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¸ã®å…¥åŠ›ç‰¹å¾´ã‚’å–å¾—ã™ã‚‹NLPãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é–‹ç™ºã—ã€å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å®Ÿè¡Œã—ãŸã€‚
It should be noted that this pipeline is an imperfect approximation, and that each metric individually would benefit from more sophisticated methods.
ã“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ä¸å®Œå…¨ãªè¿‘ä¼¼ã§ã‚ã‚Šã€å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯å€‹ã€…ã«ã€ã‚ˆã‚Šæ´—ç·´ã•ã‚ŒãŸæ‰‹æ³•ã‹ã‚‰åˆ©ç›Šã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã«ç•™æ„ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
The MIND dataset [80] contains the interactions of 1 million randomly sampled and anonymized users with the news items on MSN News between October 12 and November 22 2019.
MINDãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ[80]ã«ã¯ã€2019å¹´10æœˆ12æ—¥ã‹ã‚‰11æœˆ22æ—¥ã®é–“ã«MSNãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹é …ç›®ã¨ã€ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒåŒ¿ååŒ–ã•ã‚ŒãŸ100ä¸‡äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
Each interaction contains an impression log, listing which articles were presented to the user, which were clicked on and the userâ€™s reading history.
å„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã«ã¯ã€ã©ã®è¨˜äº‹ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æç¤ºã•ã‚Œã€ã©ã‚ŒãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã‹ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èª­æ›¸å±¥æ­´ã‚’ãƒªã‚¹ãƒˆåŒ–ã—ãŸã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
The MIND dataset was published accompanied by a performance comparison on news recommender algorithms trained on this dataset,8 including news-specific neural recommendation methods NPA [78], NAML [77], LSTUR [1] and NRMS [79].
MINDãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å­¦ç¿’ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«é–¢ã™ã‚‹æ€§èƒ½æ¯”è¼ƒ8ã‚’ä¼´ã£ã¦å…¬é–‹ã•ã‚Œã€ãã®ä¸­ã«ã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹å°‚ç”¨ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æ¨è–¦æ‰‹æ³•NPA [78]ã€NAML [77]ã€LSTUR [1] ãŠã‚ˆã³NRMS [79]ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
It was shown that these algorithms outperform general-purpose ones [80] or common collaborative filtering models (such as alternating least squares (ALS)), in particular due to the short lifespan of news items [31].
ã“ã‚Œã‚‰ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ï¼Œç‰¹ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¢ã‚¤ãƒ†ãƒ ã®å¯¿å‘½ãŒçŸ­ã„ã“ã¨ã‹ã‚‰ï¼Œæ±ç”¨çš„ãªã‚‚ã® [80] ã‚„ä¸€èˆ¬çš„ãªå”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ï¼ˆäº¤äº’æœ€å°äºŒä¹—æ³• (ALS) ãªã©ï¼‰ã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ [31]ï¼ã¾ãŸï¼Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¢ã‚¤ãƒ†ãƒ ã®å¯¿å‘½ãŒçŸ­ã„ã“ã¨ã‹ã‚‰ï¼Œã“ã‚Œã‚‰ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ï¼Œä¸€èˆ¬çš„ãªã‚‚ã®ã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ï¼
These algorithms are trained on the impression logs in order to predict which items the users are most likely to click on.
ã“ã‚Œã‚‰ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€ãƒ¦ãƒ¼ã‚¶ãŒã©ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã‹ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã«ã€ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ»ãƒ­ã‚°ã«å¯¾ã—ã¦å­¦ç¿’ã•ã‚Œã¾ã™ã€‚
For the purpose of this paper we will evaluate these neural recommendation methods with the RADio framework (on the DART metrics) and compare their performance with two naive baseline methods, based on a reasonable set of candidates (the original impression log): a random selection, and a selection of the most popular items, where the popularity of the item is approximated by the number of recorded clicks in the dataset.
ã“ã®è«–æ–‡ã§ã¯ã€RADioãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã“ã‚Œã‚‰ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ»ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ‰‹æ³•ã‚’è©•ä¾¡ã—ï¼ˆDARTãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§ï¼‰ã€å¦¥å½“ãªå€™è£œã®é›†åˆï¼ˆå…ƒã®ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ï¼‰ã«åŸºã¥ã2ã¤ã®ãƒŠã‚¤ãƒ¼ãƒ–ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã¨ãã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¯”è¼ƒã—ã¾ã™ï¼šãƒ©ãƒ³ãƒ€ãƒ é¸æŠã¨ã€ã‚¢ã‚¤ãƒ†ãƒ ã®äººæ°—åº¦ãŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨˜éŒ²ã•ã‚ŒãŸã‚¯ãƒªãƒƒã‚¯æ•°ã§è¿‘ä¼¼ã•ã‚Œã‚‹æœ€ã‚‚äººæ°—ã®ã‚ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã‚’é¸æŠã™ã‚‹æ–¹æ³•ã§ã™ã€‚

Since RADio computes the average of all {ğ‘ƒ, ğ‘„} pairs, we retrieve confidence intervals over paired distances too, as illustrated in the sensitivity analyses below.
RADioã¯ã™ã¹ã¦ã®{u_1D443}ã®ãƒšã‚¢ã®å¹³å‡ã‚’è¨ˆç®—ã™ã‚‹ã®ã§ã€ä»¥ä¸‹ã®æ„Ÿåº¦åˆ†æã§ç¤ºã•ã‚Œã‚‹ã‚ˆã†ã«ã€æˆ‘ã€…ã¯ãƒšã‚¢ã®è·é›¢ã«å¯¾ã™ã‚‹ä¿¡é ¼åŒºé–“ã‚‚å–å¾—ã—ã¾ã™ã€‚
In a traditional model evaluation setting, it would be desirable to generate confidence intervals via different model seeds or cross-validation splits.
ä¼çµ±çš„ãªãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®è¨­å®šã§ã¯ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚·ãƒ¼ãƒ‰ã¾ãŸã¯ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ†å‰²ã«ã‚ˆã£ã¦ä¿¡é ¼åŒºé–“ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒæœ›ã¾ã—ã„ã¨æ€ã‚ã‚Œã‚‹ã€‚
We refrain from doing this for our metric evaluation as this would introduce a multidimensional confidence interval (e.g., over {ğ‘ƒ, ğ‘„} pairs and over model seeds).
ã“ã‚Œã¯å¤šæ¬¡å…ƒä¿¡é ¼åŒºé–“ï¼ˆä¾‹ãˆã°ã€{u, ğ‘ƒã®ãƒšã‚¢ã¨ãƒ¢ãƒ‡ãƒ«ã‚·ãƒ¼ãƒ‰ä»¥ä¸Šï¼‰ã‚’å°å…¥ã™ã‚‹ã®ã§ã€æˆ‘ã€…ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯è©•ä¾¡ã®ãŸã‚ã«ã“ã‚Œã‚’è¡Œã†ã“ã¨ã‚’æ§ãˆã‚‹ã€‚ï¼‰
We scrape articles via the URLs provided in the MIND dataset.
MINDãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æä¾›ã•ã‚Œã‚‹URLã‚’ä»‹ã—ã¦è¨˜äº‹ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹ã€‚
Each articleâ€™s metadata is enriched with five methods:
å„è¨˜äº‹ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¯5ã¤ã®ãƒ¡ã‚½ãƒƒãƒ‰ã§ã‚¨ãƒ³ãƒªãƒƒãƒã•ã‚Œã¦ã„ã‚‹ã€‚

(1) Complexity analysis:
(1)è¤‡é›‘ã•åˆ†æã€‚
Each item is assigned a complexity score based on the Flesch-Kincaid reading ease test [41], implemented in the Python module py-readability-metrics [20].
å„é …ç›®ã¯Pythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«py-readability-metrics [20]ã§å®Ÿè£…ã•ã‚ŒãŸFlesch-Kincaid read ease test [41]ã«åŸºã¥ã„ã¦è¤‡é›‘ã•ã®ã‚¹ã‚³ã‚¢ã‚’å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹ã€‚
Complexity is then discretized into bins, to accommodate for the discrete form of $ğ·^*_f$.
ãã®å¾Œã€$ğ·^*_f$ã®é›¢æ•£å½¢å¼ã‚’è€ƒæ…®ã—ã€è¤‡é›‘åº¦ã‚’ãƒ“ãƒ³ã«é›¢æ•£åŒ–ã™ã‚‹ã€‚

(2) Story clustering:
(2) ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
The individual news items are clustered into so-called news story chains, which means that stories about the same event will be grouped together.
å€‹ã€…ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹é …ç›®ã¯ã„ã‚ã‚†ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒã‚§ãƒ¼ãƒ³ã«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã•ã‚Œã‚‹ã€‚ã¤ã¾ã‚Šã€åŒã˜å‡ºæ¥äº‹ã«é–¢ã™ã‚‹ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã¯ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚‹ã€‚
This way, we add a level of analysis between individual news items and higher level categories (see Section 3.4).
ã“ã®ã‚ˆã†ã«ã—ã¦ï¼Œå€‹ã€…ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹é …ç›®ã¨ä¸Šä½ã‚«ãƒ†ã‚´ãƒªã¨ã®é–“ã«åˆ†æãƒ¬ãƒ™ãƒ«ã‚’è¿½åŠ ã™ã‚‹ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³3.4å‚ç…§ï¼‰ï¼
We use a TF-IDF based unsupervised clustering algorithm based on cosine similarity and a three days moving window, following the setup of Trilling and van Hoof [69].
æˆ‘ã€…ã¯Trilling and van Hoof [69]ã®è¨­å®šã«å¾“ã£ã¦ã€ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã¨3æ—¥é–“ã®ç§»å‹•çª“ã«åŸºã¥ã„ã¦ã€TF-IDFãƒ™ãƒ¼ã‚¹ã®æ•™å¸«ãªã—ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚

(3) Sentiment analysis:
(3) ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æã€‚
Using the textBlob open source NLP library we assign each article a sentiment polarity score [47].
ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®NLPãƒ©ã‚¤ãƒ–ãƒ©ãƒªtextBlobã‚’ä½¿ç”¨ã—ã¦ã€å„è¨˜äº‹ã«ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆæ¥µæ€§ã‚¹ã‚³ã‚¢[47]ã‚’å‰²ã‚Šå½“ã¦ã¾ã™ã€‚
Our focus is on the relative neutrality of articles, we thus take the absolute value of the negative
æˆ‘ã€…ã¯è¨˜äº‹ã®ç›¸å¯¾çš„ãªä¸­ç«‹æ€§ã«ç€ç›®ã—ã¦ã„ã‚‹ãŸã‚ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ãªè¨˜äº‹ã®çµ¶å¯¾å€¤ã‚’å–ã‚‹ã€‚

(4) Named entity recognition:
(4)åå‰ä»˜ãå®Ÿä½“ã®èªè­˜
Using spaCy, we identify the people, organizations and locations mentioned in the text [34], and count their frequency.
spaCyã‚’ç”¨ã„ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹äººç‰©ã€çµ„ç¹”ã€å ´æ‰€ã‚’ç‰¹å®šã—[34]ã€ãã®é »åº¦ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ã€‚

(5) Named entity augmentation:
(5ï¼‰åå‰ä»˜ãã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®å¢—å¼·ã€‚
For the entities identified in the text in the previous step, we attempt to link them to their Wikidata9 entry through fuzzy name matching, to figure out if they are politicians, or in the case of organizations, political parties.10
å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç‰¹å®šã•ã‚ŒãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«ã¤ã„ã¦ã€ãƒ•ã‚¡ã‚¸ãƒ¼åç…§åˆã«ã‚ˆã‚Šã€ãã®ã‚¨ãƒ³ãƒ†ã‚£ ãƒ†ã‚£ã‚’ Wikidata9 ã®ã‚¨ãƒ³ãƒˆãƒªã«ãƒªãƒ³ã‚¯ã—ã€ãã‚Œã‚‰ãŒæ”¿æ²»å®¶ã‹ã©ã†ã‹ã€çµ„ç¹”ã®å ´åˆã¯æ”¿å…šã‹ã©ã†ã‹ã‚’åˆ¤ æ–­ã—ã‚ˆã†ã¨ã™ã‚‹10ã€‚

We implement RADio with the pipeline above.
ä¸Šè¨˜ã®ã‚ˆã†ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§RADioã‚’å®Ÿè£…ã—ã¾ã™ã€‚
Table 2 links the numbered list above with the DART metrics.
è¡¨2ã¯ã€ä¸Šè¨˜ã®ç•ªå·ä»˜ããƒªã‚¹ãƒˆã¨DARTãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒªãƒ³ã‚¯ã•ã›ãŸã‚‚ã®ã§ã™ã€‚
It provides an overview of the different metrics and their respective context distribution ğ‘ƒ over normative concepts.
ã“ã‚Œã¯ã€ç•°ãªã‚‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ã€è¦ç¯„çš„ãªæ¦‚å¿µã«å¯¾ã™ã‚‹ãã‚Œãã‚Œã®æ–‡è„ˆåˆ†å¸ƒáµ„ã®æ¦‚è¦ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã€‚
The code for this implementation is available online.11
ã“ã®å®Ÿè£…ã®ã‚³ãƒ¼ãƒ‰ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§å…¥æ‰‹å¯èƒ½ã§ã‚ã‚‹11ã€‚

We evaluate the outcome of our RADio framework for different recommender strategies (LSTUR, NAML, NPA, NRMS, most popular and random), with both KL Divergence and Jensen-Shannon as divergence metrics, with and without discounting for the position in the recommendation and at different ranking cutoffs.
æˆ‘ã€…ã¯ã€ç•°ãªã‚‹æ¨è–¦æˆ¦ç•¥ï¼ˆLSTURã€NAMLã€NPAã€NRMSã€æœ€ã‚‚äººæ°—ã®ã‚ã‚‹ã€ãƒ©ãƒ³ãƒ€ãƒ ï¼‰ã«å¯¾ã—ã¦ã€KL Divergenceã¨Jensen-Shannonã®ä¸¡æ–¹ã‚’ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ã—ã¦ã€æ¨è–¦ã«ãŠã‘ã‚‹ä½ç½®ã«å¯¾ã™ã‚‹å‰²å¼•ã®æœ‰ç„¡ã€ç•°ãªã‚‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚«ãƒƒãƒˆã‚ªãƒ•ã§RADioãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®çµæœã‚’è©•ä¾¡ã—ãŸã€‚

# 5. Results çµæœ

Having described our methodology and experimental setup around the operationalization of DART metrics, we analyze the results of the experiments on MIND.
DARTãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®é‹ç”¨ã«ã¾ã¤ã‚ã‚‹æˆ‘ã€…ã®æ–¹æ³•è«–ã¨å®Ÿé¨“ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’èª¬æ˜ã—ãŸå¾Œã€MINDã§ã®å®Ÿé¨“çµæœã‚’åˆ†æã™ã‚‹ã€‚
We separate descriptive analysis of the results in Section 5 from the interpretation of normative interpretation of the metrics in Section 6.
ã‚»ã‚¯ã‚·ãƒ§ãƒ³5ã§ã®çµæœã®è¨˜è¿°çš„åˆ†æã¨ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³6ã§ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¦ç¯„çš„ãªè§£é‡ˆã‚’åˆ†ã‘ã¦èª¬æ˜ã—ã¾ã™ã€‚
We choose to implement RADio with rank-awareness and JS divergence with a rank cutoff @N (the entire ranking list) as our default.
æˆ‘ã€…ã¯ã€ãƒ©ãƒ³ã‚¯ã‚’æ„è­˜ã—ãŸRADioã®å®Ÿè£…ã¨ã€ãƒ©ãƒ³ã‚¯ã‚«ãƒƒãƒˆã‚ªãƒ•@Nï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒªã‚¹ãƒˆå…¨ä½“ï¼‰ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ãŸJSãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’é¸æŠã—ã¾ã—ãŸã€‚
After commenting on the overall results, we further motivate that choice with a sensitivity analysis to different hyperparameters.
å…¨ä½“çš„ãªçµæœã«ã¤ã„ã¦ã‚³ãƒ¡ãƒ³ãƒˆã—ãŸå¾Œã€ç•°ãªã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ„Ÿåº¦åˆ†æã‚’è¡Œã„ã€ã“ã®é¸æŠã®å‹•æ©Ÿä»˜ã‘ã‚’ã•ã‚‰ã«è¡Œã†ã€‚
We alter the divergence metric (KL or JS), rank-awareness (with and without a discount) and ranking cutoffs ($@n, with ğ‘› = 1, 2, 5, 10, 20, ğ‘$) for the different recommender models.
æˆ‘ã€…ã¯ã€ç•°ãªã‚‹ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦ã€ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ãƒ¡ãƒˆãƒªãƒƒã‚¯ï¼ˆKLã¾ãŸã¯JSï¼‰ã€ãƒ©ãƒ³ã‚¯èªè­˜ï¼ˆå‰²å¼•ã‚ã‚Šãƒ»ãªã—ï¼‰ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚«ãƒƒãƒˆã‚ªãƒ•ï¼ˆ$@nã€ğ‘› = 1, 2, 5, 10, 20, ğ‘$ï¼‰ã‚’å¤‰æ›´ã—ãŸã€‚

Table 3 displays results for RADio with rank-aware JS divergence.12 Higher values imply higher divergence scores, but whether high or low divergence is desired depends on the goal of the recommender system, which we will further elaborate in Section 6.
è¡¨ 3 ã¯ã€RADIO ãŒãƒ©ãƒ³ã‚¯ã‚’æ„è­˜ã—ãŸ JS ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’è¡Œã£ãŸçµæœã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚12 å€¤ãŒé«˜ã„ã»ã©ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã“ã¨ã‚’æ„å‘³ã™ã‚‹ãŒã€ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ãŒé«˜ã„ã‹ä½ã„ã‹ã¯ã€æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®ç›®æ¨™ã«ä¾å­˜ã™ã‚‹ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ 6 ã§ã•ã‚‰ã«è©³ã—ãèª¬æ˜ã™ã‚‹ï¼‰ã€‚
The random recommender scores highest on divergence for all metrics and is also one of the least relevant by definition (see NDCG score).
ãƒ©ãƒ³ãƒ€ãƒ ãƒ»ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã¯ã™ã¹ã¦ã®æŒ‡æ¨™ã§ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ ã®ã‚¹ã‚³ã‚¢ãŒæœ€ã‚‚é«˜ãã€ã¾ãŸå®šç¾©ä¸Šæœ€ã‚‚é–¢é€£æ€§ã®ä½ã„ãƒ¬ã‚³ãƒ¡ãƒ³ ãƒ€ãƒ¼ã§ã‚ã‚‹ï¼ˆNDCG ã‚¹ã‚³ã‚¢å‚ç…§ï¼‰ã€‚
Most popular and random have comparable NDCG results.
æœ€ã‚‚äººæ°—ã®ã‚ã‚‹ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã¨ãƒ©ãƒ³ãƒ€ãƒ ã® NDCG ã‚¹ã‚³ã‚¢ã¯åŒç¨‹åº¦ã§ã‚ã‚‹ã€‚
Popularity scores for the articles are derived from the clicks recorded in the MIND interaction logs, and many articles have zero or only one click recorded.
è¨˜äº‹ã®äººæ°—åº¦ã‚¹ã‚³ã‚¢ã¯MINDã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã«è¨˜éŒ²ã•ã‚ŒãŸã‚¯ãƒªãƒƒã‚¯æ•°ã‹ã‚‰å°ã‹ã‚Œã€å¤šãã®è¨˜äº‹ã¯ã‚¼ãƒ­ã‹1ã‚¯ãƒªãƒƒã‚¯ã—ã‹è¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚
When the candidate list contains exclusively articles with a similar number of clicks this forces the most popular recommender to a random choice, which explains the artificial similarity between most popular and random in terms of the NDCG score.
å€™è£œãƒªã‚¹ãƒˆã«åŒç¨‹åº¦ã®ã‚¯ãƒªãƒƒã‚¯æ•°ã®è¨˜äº‹ã—ã‹å«ã¾ã‚Œã¦ã„ãªã„å ´åˆã€æœ€ã‚‚äººæ°—ã®ã‚ã‚‹ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã¯ãƒ©ãƒ³ãƒ€ãƒ ãªé¸æŠã‚’ä½™å„€ãªãã•ã‚Œã‚‹ãŸã‚ã€NDCGã‚¹ã‚³ã‚¢ã®è¦³ç‚¹ã‹ã‚‰è¦‹ã‚‹ã¨ã€æœ€ã‚‚äººæ°—ã®ã‚ã‚‹ã‚‚ã®ã¨ãƒ©ãƒ³ãƒ€ãƒ ãªã‚‚ã®ã®é–“ã«äººå·¥çš„ãªé¡ä¼¼æ€§ãŒã‚ã‚‹ã“ã¨ã‚’èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚
Between the neural recommenders, most scores for LSTUR, NPA, NRMS and NAML are in lower ranges.
ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã®ã†ã¡ã€LSTURã€NPAã€NRMSã€NAMLã®ã‚¹ã‚³ã‚¢ã¯ã»ã¨ã‚“ã©ãŒä½ã„ç¯„å›²ã«ã‚ã‚‹ã€‚
Note that they produce similar recommendations (see NDCG values and Wu et al. [80]).
ã“ã‚Œã‚‰ã¯é¡ä¼¼ã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã«æ³¨æ„ã™ã‚‹ï¼ˆNDCGå€¤ãŠã‚ˆã³Wuã‚‰[80]ã‚’å‚ç…§ï¼‰ã€‚
Some notable differences can be observed when comparing these neural methods to the baselines.
ã“ã‚Œã‚‰ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨æ¯”è¼ƒã™ã‚‹ã¨ã€ã„ãã¤ã‹ã®é¡•è‘—ãªé•ã„ãŒè¦³å¯Ÿã•ã‚Œã‚‹ã€‚
For example, we see that the neural recommenders are more Calibrated to the items present in peopleâ€™s reading history, though the most popular baseline performs marginally better in terms of Calibration of complexity.
ä¾‹ãˆã°ã€æœ€ã‚‚äººæ°—ã®ã‚ã‚‹ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¯è¤‡é›‘ã•ã®Calibrationã¨ã„ã†ç‚¹ã§ã¯ã‚ãšã‹ã«å„ªã‚Œã¦ã„ã‚‹ãŒã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ»ãƒªã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã¯äººã€…ã®èª­æ›¸å±¥æ­´ã«å­˜åœ¨ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã«å¯¾ã—ã¦ã‚ˆã‚ŠCalibrationã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚
In the following, we further analyse the entire distribution of individual recommendation list divergences and test the sensitivity of RADio to different settings.
ä»¥ä¸‹ã§ã¯ã€ã•ã‚‰ã«å€‹ã€…ã®æ¨è–¦ãƒªã‚¹ãƒˆã®ç™ºæ•£ã®åˆ†å¸ƒå…¨ä½“ã‚’åˆ†æã—ã€ç•°ãªã‚‹è¨­å®šã«å¯¾ã™ã‚‹RADioã®æ„Ÿåº¦ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
Boxplots for all metrics and all recommender strategies are available in the online repository, where we highlight the importance of rank-awareness.
ã™ã¹ã¦ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨ã™ã¹ã¦ã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼æˆ¦ç•¥ã®ç®±ã²ã’å›³ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒªãƒã‚¸ãƒˆãƒªã§å…¥æ‰‹å¯èƒ½ã§ã‚ã‚Šã€ãƒ©ãƒ³ã‚¯æ„è­˜ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚

## 5.1. Sensitivityto the Divergence Metric â™ª ç™ºæ•£ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¸ã®æ„Ÿåº¦

JS divergence is our preferred implementation of universal diversity metrics.
JSãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¯æˆ‘ã€…ãŒæ¨å¥¨ã™ã‚‹æ™®éçš„å¤šæ§˜æ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å®Ÿè£…ã§ã‚ã‚‹ã€‚
It is a proper distance metric and bounded between 0 and 1 (see Section 3.2).
ã“ã‚Œã¯é©åˆ‡ãªè·é›¢æŒ‡æ¨™ã§ã‚ã‚Šã€0ã¨1ã®é–“ã§å¢ƒç•ŒãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³3.2å‚ç…§ï¼‰ã€‚
Figure 2 substantiates that claim empirically, visualizing the sensitivity of RADio to the two described f-Divergence metrics:
å›³2ã¯ãã®ä¸»å¼µã‚’å®Ÿè¨¼çš„ã«ç¤ºã—ã¦ãŠã‚Šã€2ã¤ã®fãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«å¯¾ã™ã‚‹RADioã®æ„Ÿåº¦ã‚’å¯è¦–åŒ–ã—ãŸã‚‚ã®ã§ã‚ã‚‹ã€‚
KL and JS Divergence.
KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¨JSãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã§ã™ã€‚
Clear differences can be observed in the distributions; KL divergence is skewed towards lower divergence, while JS divergence yields a more centered distribution of values.
KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¯ä½ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã«åã‚Šã€JSãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¯ã‚ˆã‚Šä¸­å¿ƒçš„ãªåˆ†å¸ƒã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
Additionally, JS divergence applies more contrast between the neural recommender systems and the naive recommendation methods and especially the random baseline.
ã•ã‚‰ã«ã€JSãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã¨ãƒŠã‚¤ãƒ¼ãƒ–æ¨è–¦æ‰‹æ³•ã€ç‰¹ã«ãƒ©ãƒ³ãƒ€ãƒ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®é–“ã«ã€ã‚ˆã‚Šå¤šãã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’é©ç”¨ã—ã¦ã„ã¾ã™ã€‚
Due to the large sample in MIND, the random baseline is an approximation of a diverse recommendation set, given the candidate articles.
MINDã§ã¯ã‚µãƒ³ãƒ—ãƒ«ãŒå¤šã„ãŸã‚ã€ãƒ©ãƒ³ãƒ€ãƒ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¯å€™è£œè¨˜äº‹ãŒã‚ã‚Œã°ã€å¤šæ§˜ãªæ¨è–¦ã‚»ãƒƒãƒˆã®è¿‘ä¼¼ã¨ãªã‚‹ã€‚
In certain cases KL introduces consequential skew in the distribution of individual ğ‘ƒ,ğ‘„ comparison pairs across recommendation models; this does not occur to that extent with JS.
KLã¯æ¨è–¦ãƒ¢ãƒ‡ãƒ«é–“ã§å€‹ã€…ã®áµ„,áµ„æ¯”è¼ƒãƒšã‚¢ã®åˆ†å¸ƒã«çµæœçš„ã«æ­ªã¿ã‚’ã‚‚ãŸã‚‰ã™å ´åˆãŒã‚ã‚‹ãŒã€JSã§ã¯ãã®ã‚ˆã†ãªã“ã¨ã¯ãªã„ã€‚
Although KL Divergence is a well-known metric that can be found in many applications and is simpler to express mathematically, we found the JS divergence to be a better fit both theoretically and empirically.
KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã¯å¤šãã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§è¦‹ã‚‰ã‚Œã‚‹æœ‰åãªæŒ‡æ¨™ã§ã‚ã‚Šã€æ•°å­¦çš„ã«è¡¨ç¾ã™ã‚‹ã®ã‚‚ç°¡å˜ã§ã‚ã‚‹ãŒã€æˆ‘ã€…ã¯JSãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ãŒç†è«–çš„ã«ã‚‚çµŒé¨“çš„ã«ã‚‚ã‚ˆã‚Šé©åˆã—ã¦ã„ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ãŸã€‚

## 5.2. Sensitivity to Rank-awareness ãƒ©ãƒ³ã‚¯èªè­˜ã¸ã®æ„Ÿåº¦

In the original formulation of DART metrics [71], rank-awareness was not considered for most of the defined metrics.
DARTãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã‚ªãƒªã‚¸ãƒŠãƒ«ã®å®šå¼åŒ–[71]ã§ã¯ã€å®šç¾©ã•ã‚ŒãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã»ã¨ã‚“ã©ã«ã¤ã„ã¦ã€ãƒ©ãƒ³ã‚¯ã‚’æ„è­˜ã—ã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚
In our formalization, rank-awareness is the default.
æˆ‘ã€…ã®å®šå¼åŒ–ã§ã¯ã€ãƒ©ãƒ³ã‚¯ã‚¢ã‚¦ã‚§ã‚¢ãƒã‚¹ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã‚ã‚‹ã€‚
In Figure 3, we visualize the effect of removing the rank-awareness (in blue) on Fragmentation and compare to the original rank-aware Fragmentation (in orange).
å›³3ã§ã¯ã€Fragmentationã«ãŠã‘ã‚‹ãƒ©ãƒ³ã‚¯è€ƒæ…®ã®å‰Šé™¤ã®åŠ¹æœï¼ˆé’ï¼‰ã¨ã€å…ƒã®ãƒ©ãƒ³ã‚¯è€ƒæ…®Fragmentationï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ï¼‰ã®æ¯”è¼ƒã‚’å¯è¦–åŒ–ã—ã¦ã„ã¾ã™ã€‚
Rank-awareness allows for better differentiation between methods:
ãƒ©ãƒ³ã‚¯ã‚’æ„è­˜ã™ã‚‹ã“ã¨ã§ã€æ‰‹æ³•é–“ã®åŒºåˆ¥ãŒã‚ˆã‚Šæ˜ç¢ºã«ãªã‚‹ã€‚
LSTUR and â€œmost popularâ€ seem to be similarly distributed without a rank discount.
LSTURã¨ "æœ€ã‚‚äººæ°—ã®ã‚ã‚‹ "æ‰‹æ³•ã¯ã€ãƒ©ãƒ³ã‚¯å‰²å¼•ã‚’è¡Œã‚ãªãã¦ã‚‚åŒã˜ã‚ˆã†ã«åˆ†å¸ƒã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚
Introducing rank-awareness shifts LSTUR towards a larger divergence, whereas â€œmost popularâ€ remains largely the same.
ãƒ©ãƒ³ã‚¯ã‚’æ„è­˜ã™ã‚‹ã“ã¨ã§ã€LSTURã¯ã‚ˆã‚Šå¤§ããªä¹–é›¢ã«ã‚·ãƒ•ãƒˆã™ã‚‹ãŒã€"ä¸€ç•ªäººæ°— "ã¯ã»ã¨ã‚“ã©å¤‰ã‚ã‚‰ãªã„ã€‚

## 5.3. Sensitivity @n æ„Ÿæ€§@n

One could also consider adding a cut-off point where only the top ğ‘› recommendations are considered for evaluation, the results of which are shown in Figure 4.
ã¾ãŸã€ä¸Šä½ğ‘›å€‹ã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ã¿ã‚’è©•ä¾¡å¯¾è±¡ã¨ã™ã‚‹ã‚«ãƒƒãƒˆã‚ªãƒ•ãƒã‚¤ãƒ³ãƒˆã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã‚‚è€ƒãˆã‚‰ã‚Œã‚‹ãŒã€ãã®çµæœã¯å›³4ã«ç¤ºã™ã¨ãŠã‚Šã§ã‚ã‚‹ã€‚
The figure shows that the effect of rank-awareness becomes stronger with a higher cut-off point, and causes the divergence score to stabilize after roughly 10 recommendations.
ã“ã®å›³ã‹ã‚‰ã€ãƒ©ãƒ³ã‚¯æ„è­˜ã®åŠ¹æœã¯ã‚«ãƒƒãƒˆã‚ªãƒ•ãƒã‚¤ãƒ³ãƒˆãŒé«˜ã„ã»ã©å¼·ããªã‚Šã€ãŠã‚ˆã10å€‹ã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§ä¹–é›¢ã‚¹ã‚³ã‚¢ãŒå®‰å®šã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚
This is because our MMR rank-awareness strongly discounts values further down the ranking.
ã“ã‚Œã¯ã€MMRã®ãƒ©ãƒ³ã‚¯æ„è­˜ãŒãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®ã•ã‚‰ã«ä¸‹ä½ã®å€¤ã‚’å¼·ãå‰²ã‚Šå¼•ããŸã‚ã§ã‚ã‚‹ã€‚
@20 and @N (no cutoff) are similar for all metrics because MIND rarely contains more than 20 recommendation candidates.
20ã¨@Nï¼ˆã‚«ãƒƒãƒˆã‚ªãƒ•ãªã—ï¼‰ã¯ã€MINDãŒ20ä»¥ä¸Šã®æ¨è–¦å€™è£œã‚’å«ã‚€ã“ã¨ã¯ã»ã¨ã‚“ã©ãªã„ãŸã‚ã€ã™ã¹ã¦ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§åŒæ§˜ãªçµæœãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚
Note that when calculating the divergence score for Activation, Representation or Alternative Voices without rank-awareness and without cutoff point, there is no divergence to be reported as recommendation and target distribution are identical in these cases.13
ãªãŠã€ãƒ©ãƒ³ã‚¯ã‚’æ„è­˜ã›ãšã€ã‚«ãƒƒãƒˆã‚ªãƒ•ãƒã‚¤ãƒ³ãƒˆã‚’è¨­ã‘ãšã€Activationã€Representationã€Alternative Voicesã®ç™ºæ•£ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ãŸå ´åˆã€æ¨è–¦ã¨ç›®æ¨™åˆ†å¸ƒãŒåŒä¸€ã§ã‚ã‚‹ãŸã‚ã€å ±å‘Šã•ã‚Œã‚‹ç™ºæ•£ã¯ãªã„13ã€‚

## 5.4. Normative Evaluation #è¦ç¯„çš„è©•ä¾¡

By comparing divergence scores across different recommender strategies, we can draw conclusions on the way they influence exposure of news to users.
ç•°ãªã‚‹ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼æˆ¦ç•¥ã®ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚¹ã‚³ã‚¢ã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®éœ²å‡ºã«å½±éŸ¿ã‚’ä¸ãˆã‚‹æ–¹æ³•ã«ã¤ã„ã¦çµè«–ã‚’å°ãå‡ºã™ã“ã¨ãŒã§ãã‚‹ã€‚
This is especially the case when comparing neural methods to the random recommender, which should reflect the characteristics of the overall pool of data.
ã“ã‚Œã¯ç‰¹ã«ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æ‰‹æ³•ã‚’ãƒ©ãƒ³ãƒ€ãƒ ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã¨æ¯”è¼ƒã™ã‚‹å ´åˆã«é¡•è‘—ã§ã‚ã‚Šã€ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¼ãƒ«å…¨ä½“ã®ç‰¹æ€§ã‚’åæ˜ ã™ã‚‹ã¯ãšã§ã‚ã‚‹ã€‚
Combining this with DARTâ€™s different theoretical models of democracy (summarized in Table 1), one can make informed decisions on which recommender system is better suited to oneâ€™s normative stance than others.
ã“ã‚Œã‚’DARTã®æ°‘ä¸»ä¸»ç¾©ã«é–¢ã™ã‚‹ã•ã¾ã–ã¾ãªç†è«–ãƒ¢ãƒ‡ãƒ«ï¼ˆè¡¨1ã«ã¾ã¨ã‚ãŸï¼‰ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ã©ã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ãŒä»–ã‚ˆã‚Šã‚‚è‡ªåˆ†ã®è¦ç¯„çš„ã‚¹ã‚¿ãƒ³ã‚¹ã«é©ã—ã¦ã„ã‚‹ã‹ã€æƒ…å ±ã«åŸºã¥ã„ãŸåˆ¤æ–­ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
Imagine, for example, a public service media organization that aims to reflect Participatory norms and values in their recommendations.
ä¾‹ãˆã°ã€å‚åŠ å‹è¦ç¯„ã¨ä¾¡å€¤ã‚’ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«åæ˜ ã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™å…¬å…±ã‚µãƒ¼ãƒ“ã‚¹ãƒ¡ãƒ‡ã‚£ã‚¢æ©Ÿé–¢ã‚’æƒ³åƒã—ã¦ãã ã•ã„ã€‚
The Participatory model prescribes low Fragmentation and low Activation, which is shown in the scores of the neural recommenders.
Participatoryãƒ¢ãƒ‡ãƒ«ã¯ä½Fragmentationã¨ä½Activationã‚’è¦å®šã—ã€ãã‚Œã¯ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ»ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã®ã‚¹ã‚³ã‚¢ã«ç¤ºã•ã‚Œã¾ã™ã€‚
This would indicate that those models are more suitable for this organizationâ€™s goals.
ã“ã‚Œã¯ã€ãã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ãŒã“ã®çµ„ç¹”ã®ç›®æ¨™ã«ã‚ˆã‚Šé©ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ã‚‚ã®ã ã‚ã†ã€‚
In comparison, imagine a large media organization that wants to dedicate a small section of their website to Critical principles, consisting of one element with recommendations called â€œA different perspective.â€
ã“ã‚Œã¨æ¯”è¼ƒã—ã¦ã€ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®å°ã•ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’Criticalã®åŸå‰‡ã«å……ã¦ãŸã„ã¨è€ƒãˆã¦ã„ã‚‹å¤§è¦æ¨¡ãªãƒ¡ãƒ‡ã‚£ã‚¢çµ„ç¹”ã‚’æƒ³åƒã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"A different perspective "ã¨ã„ã†ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æŒã¤1ã¤ã®è¦ç´ ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚
The Critical model calls for a high divergence score in both Representation and Alternative Voices.
Critical ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€Representation ã¨ Alternative Voices ã®ä¸¡æ–¹ã§é«˜ã„ç™ºæ•£ã‚¹ã‚³ã‚¢ã‚’è¦æ±‚ã—ã¦ã„ã¾ã™ã€‚
Given that the random recommender scores best according to these principles, the neural recommenders would not be very suitable for this goal.
ã“ã‚Œã‚‰ã®åŸå‰‡ã«å¾“ã£ã¦ãƒ©ãƒ³ãƒ€ãƒ ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ãŒæœ€ã‚‚è‰¯ã„ã‚¹ã‚³ã‚¢ã‚’å‡ºã™ã“ã¨ã‚’è€ƒãˆã‚‹ã¨ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã¯ã“ã®ç›®æ¨™ã«ã¯ã‚ã¾ã‚Šé©ã•ãªã„ã§ã—ã‚‡ã†ã€‚
Nevertheless, the conclusion that a random recommender is suitable for Critical norms and values is moot.
ã¨ã¯ã„ãˆã€ãƒ©ãƒ³ãƒ€ãƒ ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ãŒCriticalãªè¦ç¯„ã‚„ä¾¡å€¤è¦³ã«é©ã—ã¦ã„ã‚‹ã¨ã„ã†çµè«–ã¯ãƒ ãƒªã§ã™ã€‚
Additional steps should be taken to further improve upon these scores: recommendation algorithm developers could tweak the trade-off between different target values in the recommendation, or even explicitly optimize on these metrics.
ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é–‹ç™ºè€…ã¯ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹ç•°ãªã‚‹ç›®æ¨™å€¤é–“ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å¾®èª¿æ•´ã—ãŸã‚Šã€ã‚ã‚‹ã„ã¯ã“ã‚Œã‚‰ã®æŒ‡æ¨™ã‚’æ˜ç¤ºçš„ã«æœ€é©åŒ–ã—ãŸã‚Šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã ã‚ã†ã€‚

# 6. Discussion ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³

Choosing an f-Divergence score as the base for our metrics allows us to construct a single base formalization with a clear interpretation amongst all metrics; when the value is 0, the distribution between the recommendations and the chosen context is identical.
f-Divergenceã‚¹ã‚³ã‚¢ã‚’æ¸¬å®šåŸºæº–ã®ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦é¸æŠã™ã‚‹ã“ã¨ã§ã€ã™ã¹ã¦ã®æ¸¬å®šåŸºæº–ã®é–“ã§æ˜ç¢ºãªè§£é‡ˆã‚’æŒã¤å˜ä¸€ã®ãƒ™ãƒ¼ã‚¹å½¢å¼ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚å€¤ãŒ0ã®å ´åˆã€æ¨å¥¨ã¨é¸æŠã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé–“ã®åˆ†å¸ƒã¯åŒä¸€ã¨ãªã‚Šã¾ã™ã€‚
The larger the measurements, the larger the divergence is.
æ¸¬å®šå€¤ãŒå¤§ãããªã‚Œã°ãªã‚‹ã»ã©ã€ä¹–é›¢ã¯å¤§ãããªã‚Šã¾ã™ã€‚
However, it also comes with a number of limitations.
ã—ã‹ã—ã€ã“ã‚Œã«ã¯ã„ãã¤ã‹ã®åˆ¶ç´„ã‚‚ã‚ã‚‹ã€‚
For one, f-Divergence does not take the relations between categorical values into account, and the ordering of the categorical values in the input vector is arbitrary.
ã²ã¨ã¤ã¯ã€f-Divergenceã¯ã‚«ãƒ†ã‚´ãƒªå€¤é–“ã®é–¢ä¿‚ã‚’è€ƒæ…®ã—ã¦ãŠã‚‰ãšã€å…¥åŠ›ãƒ™ã‚¯ãƒˆãƒ«ã«ãŠã‘ã‚‹ã‚«ãƒ†ã‚´ãƒªå€¤ã®é †åºã¯ä»»æ„ã§ã‚ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
For example, two left-wing political parties in the Representation metric may be more similar than an extremely left-wing and an extremely right-wing party, but this is currently not taken into account.
ä¾‹ãˆã°ã€Representation ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®2ã¤ã®å·¦ç¿¼æ”¿å…šã¯ã€æ¥µç«¯ãªå·¦ç¿¼æ”¿å…šã¨æ¥µç«¯ãªå³ç¿¼æ”¿å…šã‚ˆã‚Šã‚‚é¡ä¼¼ã—ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒã€ç¾çŠ¶ã§ã¯ã“ã®ç‚¹ã¯è€ƒæ…®ã•ã‚Œã¦ã„ãªã„ã€‚
Related to this, in order to make continuous values suitable for our general discrete definition of f-Divergence, they need to be discretized into arbitrarily defined bins.
ã“ã‚Œã«é–¢é€£ã—ã¦ã€é€£ç¶šå€¤ã‚’æˆ‘ã€…ã®ä¸€èˆ¬çš„ãªf-Divergenceã®é›¢æ•£çš„å®šç¾©ã«é©åˆã•ã›ã‚‹ãŸã‚ã«ã¯ã€ãã‚Œã‚‰ã‚’ä»»æ„ã«å®šç¾©ã•ã‚ŒãŸãƒ“ãƒ³ã«é›¢æ•£åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
This means that two very similar values may end up in different binsFuture work may propose a different approach for calculating divergence between continuous variables.
ã“ã®ã“ã¨ã¯ã€éå¸¸ã«ä¼¼ãŸ2ã¤ã®å€¤ãŒç•°ãªã‚‹ãƒ“ãƒ³ã«å…¥ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’æ„å‘³ã™ã‚‹ã€‚å°†æ¥çš„ã«ã¯ã€é€£ç¶šå¤‰æ•°é–“ã®ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
Regarding the data enrichment pipeline, we identify a number of enhancement points.
ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ãƒªãƒƒãƒãƒ¡ãƒ³ãƒˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ã¤ã„ã¦ã¯ã€ã„ãã¤ã‹ã®å¼·åŒ–ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚
While some metrics, such as topic Calibration, work with simple data on news topics that is often directly available in a dataset, other metrics require a more sophisticated data enrichment pipeline.
ãƒˆãƒ”ãƒƒã‚¯ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãªã©ã®ã„ãã¤ã‹ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯ã€ã—ã°ã—ã°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ç›´æ¥åˆ©ç”¨å¯èƒ½ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹å˜ç´”ãªãƒ‡ãƒ¼ã‚¿ã§å‹•ä½œã™ã‚‹ãŒã€ä»–ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯ã‚ˆã‚Šæ´—ç·´ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ãƒªãƒƒãƒãƒ¡ãƒ³ãƒˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å¿…è¦ã¨ã™ã‚‹ã€‚
The differences in these approaches appear in the results: the metrics with more trivial metadata retrieval setups show clear and distinct patterns for different recommender algorithms, but this is not the case for the more complicated ones.
ã“ã‚Œã‚‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®é•ã„ã¯çµæœã«ã‚‚ç¾ã‚Œã¦ã„ã‚‹ã€‚ã‚ˆã‚Šäº›ç´°ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ¤œç´¢è¨­å®šã‚’ç”¨ã„ãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯ã€ç•°ãªã‚‹ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«å¯¾ã—ã¦æ˜ç¢ºã§ç•°ãªã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã™ãŒã€ã‚ˆã‚Šè¤‡é›‘ãªã‚‚ã®ã«ã¤ã„ã¦ã¯ãã†ã§ã¯ãªã„ã€‚
Furthermore, it is not possible to determine the quality of the pipeline, as we do not have a ground truth for evaluation.
ã•ã‚‰ã«ã€è©•ä¾¡ã®ãŸã‚ã®ã‚°ãƒ©ãƒ³ãƒ‰ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ã‚’æŒã£ã¦ã„ãªã„ãŸã‚ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å“è³ªã‚’æ±ºå®šã™ã‚‹ã“ã¨ã¯ã§ããªã„ã€‚
For future work, we suggest to take the base formalizations as constructed in this paper as a starting point, and work to improve the extraction of the relevant parameters for metrics such as Representation, Alternative Voices and Activation.
ä»Šå¾Œã®èª²é¡Œã¨ã—ã¦ã¯ã€æœ¬è«–æ–‡ã§æ§‹ç¯‰ã—ãŸåŸºæœ¬çš„ãªå½¢å¼åŒ–ã‚’å‡ºç™ºç‚¹ã¨ã—ã¦ã€Representationã€Alternative Voicesã€Activationã¨ã„ã£ãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«é–¢é€£ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æŠ½å‡ºã‚’æ”¹å–„ã™ã‚‹ä½œæ¥­ã‚’è¡Œã†ã“ã¨ã‚’ææ¡ˆã™ã‚‹ã€‚
Especially for the first two, there is already a large body of work that can facilitate this process [3, 22].
ç‰¹ã«ã€æœ€åˆã®2ã¤ã«ã¤ã„ã¦ã¯ã€ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã®å¤§è¦æ¨¡ãªä½œæ¥­ãŒã™ã§ã«å­˜åœ¨ã—ã¾ã™[3, 22]ã€‚
Human evaluation, including the input from editorial teams, would then be a promising way to evaluate these three normative metrics, similar to the work in the context of language generation bias [18].
ç·¨é›†ãƒãƒ¼ãƒ ã‹ã‚‰ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã‚’å«ã‚€äººé–“ã«ã‚ˆã‚‹è©•ä¾¡ã¯ã€è¨€èªç”Ÿæˆãƒã‚¤ã‚¢ã‚¹ã®æ–‡è„ˆã«ãŠã‘ã‚‹ä½œæ¥­ã¨åŒæ§˜ã«ã€ã“ã‚Œã‚‰3ã¤ã®è¦ç¯„çš„ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è©•ä¾¡ã™ã‚‹æœ‰æœ›ãªæ–¹æ³•ã¨ãªã‚‹ã§ã—ã‚‡ã†[18]ã€‚
Additionally, more insight needs to be gained on the influence of the choice of dataset.
ã•ã‚‰ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®é¸æŠã®å½±éŸ¿ã«ã¤ã„ã¦ã€ã‚ˆã‚Šå¤šãã®æ´å¯Ÿã‚’å¾—ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
The MIND dataset contains a significant amount of so-called soft news, including articles on lifestyle, sport and entertainment, whereas the DART metrics are mostly applicable to hard news.
MINDãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯ã€ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚¹ãƒãƒ¼ãƒ„ã€ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ¡ãƒ³ãƒˆã«é–¢ã™ã‚‹è¨˜äº‹ãªã©ã€ã„ã‚ã‚†ã‚‹ã‚½ãƒ•ãƒˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå¤§é‡ã«å«ã¾ã‚Œã¦ã„ã¾ã™ãŒã€DARTãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯ãƒãƒ¼ãƒ‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ã»ã¨ã‚“ã©é©ç”¨ã•ã‚Œã¾ã™ã€‚
The influence of the chosen dataset needs to be investigated in more detail, which can then lead to more informed decision-making on the trade-off between diversity and click-through rate, and what can reasonably be expected of a news recommender system.
ãã®çµæœã€å¤šæ§˜æ€§ã¨ã‚¯ãƒªãƒƒã‚¯ã‚¹ãƒ«ãƒ¼ç‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚„ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã«æœŸå¾…ã•ã‚Œã‚‹åˆç†æ€§ã«ã¤ã„ã¦ã€ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’å¾—ãŸä¸Šã§ã®æ„æ€æ±ºå®šã«ã¤ãªãŒã‚‹ã§ã—ã‚‡ã†ã€‚

# 7. Conclusion çµè«–

In this paper we have made a first attempt at constructing and implementing new evaluation criteria for news recommender systems, with a foundation in normative theory.
æœ¬è«–æ–‡ã§ã¯ã€è¦ç¯„ç†è«–ã‚’åŸºç¤ã¨ã—ãŸã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®æ–°ã—ã„è©•ä¾¡åŸºæº–ã®æ§‹ç¯‰ã¨å®Ÿè£…ã‚’åˆã‚ã¦è©¦ã¿ãŸã€‚
Based on the DART metrics, first theoretically conceptualized in earlier work, we propose to look at diversity as a divergence score, observing differences between the issued recommendations and a metric-specific target distribution.
å…ˆè¡Œç ”ç©¶ã§åˆã‚ã¦ç†è«–çš„ã«æ¦‚å¿µåŒ–ã•ã‚ŒãŸDARTãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€ç™ºè¡Œã•ã‚ŒãŸæ¨è–¦æ–‡ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹å›ºæœ‰ã®ç›®æ¨™åˆ†å¸ƒã¨ã®å·®ç•°ã‚’è¦³å¯Ÿã—ã€ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚¹ã‚³ã‚¢ã¨ã—ã¦å¤šæ§˜æ€§ã‚’è¦‹ã‚‹ã“ã¨ã‚’ææ¡ˆã™ã‚‹ã€‚
We proposed RADio, a unified rank-aware f-Divergence metric framework that is mathematically grounded and that fits several possible use cases within the original DART metrics and we hope beyond in future work.
ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯æ•°å­¦çš„ãªæ ¹æ‹ ãŒã‚ã‚Šã€å…ƒã®DARTãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã„ãã¤ã‹ã®å¯èƒ½ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«é©åˆã—ã€å°†æ¥ã®ç ”ç©¶ã«ãŠã„ã¦ãã‚Œã‚’è¶…ãˆã‚‹ã“ã¨ã‚’æœŸå¾…ã—ã¦ã„ã‚‹ã€‚
We showed that JS divergence was preferred over other divergence metrics.
æˆ‘ã€…ã¯ã€JSãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ãŒä»–ã®ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚ˆã‚Šã‚‚å¥½ã¾ã—ã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚
At first mathematically, as JS is a proper distance metric, and empirically, via a sensitivity analysis to different cutoff, rank-awareness and divergence metric regimes.
ã¾ãšæ•°å­¦çš„ã«ã€JSã¯é©åˆ‡ãªè·é›¢æŒ‡æ¨™ã§ã‚ã‚‹ã“ã¨ã€ãã—ã¦çµŒé¨“çš„ã«ã€ç•°ãªã‚‹ã‚«ãƒƒãƒˆã‚ªãƒ•ã€ãƒ©ãƒ³ã‚¯èªè­˜ã€ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹æŒ‡æ¨™ã®ãƒ¬ã‚¸ãƒ¼ãƒ ã«å¯¾ã™ã‚‹æ„Ÿåº¦åˆ†æã‚’é€šã˜ã¦ã€JSãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ãŒä»–ã®ãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚ˆã‚Šã‚‚å¥½ã¾ã—ã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚
When our approach is adopted in practice, it enables the evaluation of news recommender systems on normative principles beyond user relevance.
æˆ‘ã€…ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå®Ÿéš›ã«æ¡ç”¨ã•ã‚ŒãŸå ´åˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®é–¢é€£æ€§ã‚’è¶…ãˆãŸè¦ç¯„çš„ãªåŸå‰‡ã«åŸºã¥ã„ã¦ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã¨ãªã‚‹ã€‚
Finally, we wish to emphasize that the metrics proposed are meant to supplement standard recommender system evaluation metrics, in the same way that current beyond-accuracy metrics do.
æœ€å¾Œã«ã€ææ¡ˆã™ã‚‹è©•ä¾¡æŒ‡æ¨™ã¯ã€ç¾åœ¨ã®ç²¾åº¦ã‚’è¶…ãˆãŸè©•ä¾¡æŒ‡æ¨™ãŒãã†ã§ã‚ã‚‹ã‚ˆã†ã«ã€æ¨™æº–çš„ãªæ¨è–¦ã‚·ã‚¹ãƒ†ãƒ è©•ä¾¡æŒ‡æ¨™ã‚’è£œå®Œã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã“ã¨ã‚’å¼·èª¿ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚
Most importantly, they are meant to bridge the gap between different disciplines involved in the process of news recommendation and to support more informed discussion between them.
ã¾ãŸã€æœ€ã‚‚é‡è¦ãªã“ã¨ã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã®ãƒ—ãƒ­ã‚»ã‚¹ã«é–¢ã‚ã‚‹æ§˜ã€…ãªåˆ†é‡ã®é–“ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã€ã‚ˆã‚Šå¤šãã®æƒ…å ±ã«åŸºã¥ã„ãŸè­°è«–ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
We hope for future research to foster interdisciplinary teams, leveraging each fieldsâ€™ unique skills and specialties.
ä»Šå¾Œã®ç ”ç©¶ã§ã¯ã€å„åˆ†é‡ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚¹ã‚­ãƒ«ã‚„å°‚é–€æ€§ã‚’ç”Ÿã‹ã—ãŸå­¦éš›çš„ãªãƒãƒ¼ãƒ ã‚’è‚²æˆã™ã‚‹ã“ã¨ã‚’æœŸå¾…ã—ã¦ã„ã‚‹ã€‚
