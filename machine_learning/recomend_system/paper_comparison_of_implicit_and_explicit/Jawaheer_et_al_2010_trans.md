## 0.1. link 0.1. リンク

https:
httpsを使用しています。

## 0.2. authors 0.2.

## 0.3. title 0.3. タイトル

Comparison of implicit and explicit feedback from an online music recommendation service
オンライン音楽推薦サービスからの暗黙的フィードバックと明示的フィードバックの比較

## 0.4. abstract 0.4. 抽象的

Explicit and implicit feedback exhibits different characteristics of users' preferences with both pros and cons.
明示的なフィードバックと暗黙的なフィードバックは、ユーザーの嗜好について異なる特徴を示し、長所と短所の両方を持つ。
However, a combination of these two types of feedback provides another paradigm for recommender systems (RS).
しかし、この2つのタイプのフィードバックを組み合わせることで、推薦システム（Recommender System: RS）に別のパラダイムを提供することができる。
Their combination in a user preference model presents a number of challenges but can also overcome the problems associated with each other.
ユーザ嗜好モデルにおけるこれらの組み合わせは、多くの課題をもたらすが、互いに関連する問題を克服することも可能である。
In order to build an effective RS on combination of both types of feedback, we need to have comparative data allowing an understanding of the computation of user preferences.
両者の組み合わせによる効果的なRSを構築するためには、ユーザ嗜好の計算を理解するための比較データが必要である。
In this paper, we provide an overview of the differentiating characteristics of explicit and implicit feedback using datasets mined from Last.fm, an online music station and recommender service.
本論文では、オンラインミュージックステーションおよびレコメンダーサービスであるLast.fmから収集したデータセットを用いて、明示的および暗示的フィードバックの差異特性について概観する。
The datasets consisted of explicit positive feedback (by loving tracks) and implicit feedback which is inherently positive (the number of times a track is played).
データセットは、明示的なポジティブフィードバック（トラックを愛することによる）と、本質的にポジティブである暗黙的なフィードバック（トラックが再生された回数）で構成されている。
Rather than relying on just one type of feedback, we present techniques for extracting user preferences from both.
我々は、一方のフィードバックだけに頼るのではなく、両方のフィードバックからユーザの嗜好を抽出する技術を提示する。
In order to compare and contrast the performances of these techniques, we carried out experiments using the Taste recommender system engine and the Last.fm datasets.
これらの手法の性能を比較検討するために、Taste推薦システムエンジンとLast.fmデータセットを用いた実験を行った。
Our results show that implicit and explicit positive feedback complements each other, with similar performances despite their different characteristics.
その結果、暗黙的なポジティブフィードバックと明示的なポジティブフィードバックは互いに補完し合い、異なる特性を持ちながらも同様の性能を示すことがわかった。

# 1. Introduction and Motivation 1. 導入と動機

All recommender systems (RS) require a model of the users’ interests in order to function.
すべてのレコメンダーシステム（RS）が機能するためには、ユーザーの興味関心に関するモデルが必要である。
A common approach to building such a user preference model is through eliciting feedback from the user, either explicitly or implicitly.
このようなユーザーの嗜好モデルを構築するための一般的なアプローチは、ユーザーから明示的または暗黙的にフィードバックを引き出すことである。
Explicit feedback, such as rating scales, provides users with a mechanism to unequivocally express their interests in items.
評価尺度のような明示的なフィードバックは、ユーザーがアイテムに対する興味を明確に表現する仕組みを提供するものである。
On the other hand, implicit feedback is generated by the RS itself, through inferences it makes about the user’s behaviour.
一方、暗黙のフィードバックは、RS自身がユーザーの行動を推論することで生成される。
What constitutes implicit feedback depends on the application domain:
何が暗黙のフィードバックを構成するかは、アプリケーションのドメインに依存する。
Typically, it will be one or multiple observable and measurable parameters that arise out of the user’s interactions with the RS.
典型的には、ユーザーのRSとの相互作用から生じる1つまたは複数の観察可能で測定可能なパラメータとなります。
Most of the research in RS has focussed on using one or the other type of feedback; only few have combined these two heterogeneous feedbacks.
RSの研究のほとんどは、どちらか一方のタイプのフィードバックの使用に焦点をあてています。

In this paper, we present an overview of the differentiating characteristics of explicit feedback provided by the user in relation to implicit feedback gathered by a music recommendation service, namely, Last.fm1 - an online radio station and music recommender service that recommends tracks to users based on their listening habits.
本稿では、音楽推薦サービスであるLast.fm1（オンラインラジオ局および音楽推薦サービス）が収集する暗黙のフィードバックと、ユーザが提供する明示的なフィードバックの差異特性について概観する。
It collects implicit feedback about the tracks played by a user, e.g. the number of times a track is played -commonly known as the playcount.
Last.fmでは、ユーザーが再生した楽曲について、再生回数などの暗黙のフィードバックを収集する。
It also allows users to express explicit feedback through its ‘Love a track’ or ‘Ban a track’ feature.
また、'Love a track' や 'Ban a track' といった機能により、ユーザーが明示的にフィードバックをすることも可能です。

In a previous work [6] we presented a detailed examination of these two types of feedback.
以前の研究[6]では，この2種類のフィードバックについて詳細に検討した．
Explicit and implicit feedbacks provide different degrees of expressivity of the user’s preferences.
明示的なフィードバックと暗黙的なフィードバックは、ユーザの嗜好を表現する度合いが異なる。
In order to build a more effective RS and maximise the potential of combining these two types of feedback, we compare the performances of each type of feedback on a RS.
より効果的なRSを構築し、これら2つのタイプのフィードバックを組み合わせる可能性を最大化するために、我々はRS上の各タイプのフィードバックのパフォーマンスを比較する。
For our experiment, we harvested the Last.fm profiles for 527 users, downloading metadata about all the tracks they listened to as well as the tracks they voted for using the ‘Love track’ feature.
実験では、527人のユーザーのLast.fmプロファイルを収集し、彼らが聴いたすべての曲と、「Love track」機能を使って投票した曲に関するメタデータをダウンロードした。
Together this provided us with a rich dataset that we used to experiment upon using the Taste2 recommender engine.
このデータセットを用いて、Taste2レコメンダーエンジンを使った実験を行いました。
We used a collaborative filtering (CF) algorithm to generate the recommendations.
レコメンデーションの生成には、協調フィルタリング（CF）アルゴリズムを使用しました。
However, the choice of the recommender algorithm is orthogonal to our concerns as we are not interested in the performance of the algorithms but rather the performance of the user preference models.
しかし、我々はアルゴリズムの性能ではなく、ユーザー嗜好モデルの性能に興味があるため、レコメンダーアルゴリズムの選択は我々の関心事とは直交しています。

In the next section, we present an overview of the different characteristics of these two types of feedback.
次のセクションでは、これら2種類のフィードバックの異なる特性について概要を示す。
We then provide some notation and describe the datasets we used in Section 3.
次に，セクション3では，いくつかの記法と使用したデータセットについて述べる．
In Section 4 we present the techniques we used for extracting user preferences from our datasets.
セクション4では，データセットからユーザープリファレンスを抽出するために用いた技術を紹介する．
We present our experiments in Section 5, and a discussion of the results in Section 6.
セクション5では我々の実験を紹介し，セクション6ではその結果についての考察を行う．
Finally, we conclude with some related work in Section 7.
最後に，セクション7でいくつかの関連研究を紹介する．

# 2. Explicit and Implicit Feedback 2. 明示的なフィードバックと暗黙的なフィードバック

In order to develop an effective RS, user preferences need to be learned.
効果的なRSを開発するためには、ユーザーの嗜好を学習する必要がある。
However, it is difficult to obtain sufficient and representative feedback from a population of users.
しかし、多数のユーザーから十分かつ代表的なフィードバックを得ることは困難である。
This reluctance to provide explicit feedback can be partially explained by the cognitive effort it requires, and it is likely that other factors as well serve as disincentives.
明示的なフィードバックは、認知的な労力を必要とするため敬遠されがちであり、また、他の要因も阻害要因となっていると思われる。
On the other hand, implicit feedback is abundant.
一方、暗黙的なフィードバックは豊富に存在する。
In terms of modelling the users’ interests, it is generally accepted that explicit feedback is more accurate than implicit feedback [2].
ユーザの関心事をモデル化するという観点からは，明示的なフィードバックの方が暗黙的なフィードバックよりも正確であると一般に受け入れられている[2]．
One possible reason may be because there are several domain-independent, objective, well researched and documented tools, such as Likert scale or questionnaires, for capturing and analysing explicit feedback.
その理由の一つは、明示的なフィードバックを収集・分析するための、リカートスケールやアンケートなど、分野に依存しない客観的でよく研究され文書化されたツールが複数存在するためと思われる。
In contrast, an implicit feedback system relies on the application of domain-dependent tools and methodologies for capturing and interpreting implicit feedback.
対照的に、暗黙のフィードバックシステムは、暗黙のフィードバックを捕捉し解釈するためのドメインに依存したツールや方法論の適用に依存する。
Typically, the system will observe the user’s actions and make inferences about the user’s interests based on these actions.
一般に、システムはユーザーの行動を観察し、これらの行動に基づいてユーザーの興味について推論を行う。
For example, in a music recommender system such as Last.fm, if a user listens to a track 5 times, the system may infer that the user has an interest in that track.
例えば、Last.fmのような音楽推薦システムにおいて、ユーザーがあるトラックを5回聴いた場合、システムはそのユーザーがそのトラックに興味を持っていると推論することができる。

There are similarities and differences between these two types of feedback.
この2つのタイプのフィードバックには、類似点と相違点がある。
Both suffer from noise [1,3,5], and are sensitive to the user’s context, albeit not to the same extent.
両者ともノイズに悩まされ [1,3,5]、同じ程度ではないにせよ、ユーザのコンテクストに敏感である。
In terms of differences, explicit feedback is scarce whereas implicit feedback is abundant.
相違点としては、明示的なフィードバックが少ないのに対して、暗黙的なフィードバックは豊富である。
Explicit feedback is generally more accurate than implicit feedback in representing the user’s interests (although this is dependent on the domain and the RS application).
明示的なフィードバックは、一般に、暗黙的なフィードバックよりもユーザの興味を正確に表現する（ただし、これはドメインとRSアプリケーションに依存する）。
Also, explicit feedback can be positive or negative, whereas implicit feedback is only positive.
また、明示的なフィードバックは肯定的にも否定的にもなりうるが、暗黙的なフィードバックは肯定的でしかない。
Furthermore, explicit feedback tends to concentrate on either side of the rating scale, as users are more likely to express their preferences if they feel strongly for or against an item [2].
さらに、明示的なフィードバックは、評価スケールのどちらかの側に集中する傾向があります。これは、ユーザーが項目に対して強い賛成または反対の感情を抱いている場合、自分の好みを表現する可能性が高くなるためです[2]。

Explicit and implicit feedback provides different degrees of expressivity of the user’s preferences.
明示的フィードバックと暗黙的フィードバックでは、ユーザーの嗜好の表現度合いが異なる。
In typical explicit feedback RS, the user will provide ratings for items on a Likert scale.
典型的な明示的フィードバックRSでは、ユーザは項目に対してリッカート尺度による評価を行う。
The rating scale will usually go from ‘I like it a lot’ to ‘I do not like it’.
評価スケールは通常、「とても好き」から「好きではない」までとなる。
Thus explicit feedback captures both positive and negative user preferences.
このように、明示的なフィードバックは、ユーザーの好みを肯定的にも否定的にも捉えることができる。
On the other hand, implicit feedback can only be positive.
一方、暗黙的なフィードバックは、肯定的なものしか得られない。
For example, if a user did not listen to a track that does not imply he does not like the track.
たとえば、ユーザーがある曲を聴かなかったとしても、その曲が嫌いだということにはならない。
However, implicit feedback can be mapped to degree of preference analogous to going from the middle of a continuous scale to its positive extremity.
しかし、暗黙のフィードバックは、連続的なスケールの中央からその正の極限に行くように、嗜好の程度にマッピングすることができる。
For example, if a user listened to track A, 10 times and track B, 100 times, then we can infer that he has a higher preference for track B than track A. This leads to the point that implicit feedback tend to be relative where as explicit feedback is absolute.
例えば、あるユーザーがトラックAを10回、トラックBを100回聴いたとすると、トラックAよりもトラックBをより好むと推論することができます。
For example, a user listening to a track 10 times may still express high preference if typically the user tends to listen to each track once or twice.
例えば、あるトラックを10回聴いたとしても、通常1～2回しか聴かないユーザーであれば、高い嗜好性を示す可能性があります。
Another point is that implicit feedback is domain dependent.
また、暗黙的なフィードバックはドメインに依存する。
For example, in a movie recommender system, a user may watch an actor or actress 10 times, but that does not imply he has a relative high preference for that artist.
例えば、映画推薦システムにおいて、ユーザーがある俳優や女優を10回見たとしても、そのアーティストに対して相対的に高い嗜好性を持っているとは限りません。
It could be that the artist is a part of a series that the user watches regularly.
そのアーティストが、そのユーザーが定期的に見ているシリーズの一部である可能性もある。

To study the characteristics of implicit and explicit feedbacks, we used data from Last.fm.
暗黙のフィードバックと明示的なフィードバックの特徴を調べるために、我々はLast.fmのデータを使用した。
The latter provides its users the functionality to love (explicit positive feedback) and ban (explicit negative feedback) a track.
Last.fmは、ユーザーが楽曲を好きになったり（明示的なポジティブフィードバック）、禁止したり（明示的なネガティブフィードバック）する機能を提供している。
Last.fm also keeps a count, called playcount, of all the tracks played by a user (implicit feedback).
また、Last.fmは、ユーザーが再生したすべてのトラック（暗黙的なフィードバック）をplaycountと呼ばれるカウントで保持している。
This includes tracks played on the Last.fm website or media players on the user’s computer or portable device.
これには、Last.fmのウェブサイト、ユーザーのコンピュータやポータブルデバイスのメディアプレーヤーで再生されたトラックも含まれます。
It provides plug-in software that work with the media players to send the user information to the Last.fm servers in a process commonly referred to as scrobbling.
Last.fmは、メディアプレーヤーと連携し、一般にスクロブリングと呼ばれるプロセスでユーザー情報をLast.fmサーバーに送信するプラグインソフトウェアを提供しています。
Last.fm provides an extensive set of tools and APIs to harvest its rich dataset.
Last.fmは、その豊富なデータセットを取得するための広範なツールとAPIのセットを提供しています。
Unfortunately, as the API does not expose a user’s banned tracks, so we were only able to build datasets that included positive explicit feedback (loved tracks) and implicit feedback (played tracks).
残念ながら、APIはユーザーの禁止トラックを公開しないため、我々はポジティブな明示的フィードバック（loved tracks）と暗黙的フィードバック（played tracks）を含むデータセットしか構築することができなかった。
In Table 1 below, we summarise all the pertinent characteristics of implicit and explicit feedback.
以下の表1では、暗黙的および明示的なフィードバックの適切な特性をすべてまとめている。

![](https://d3i71xaburhd42.cloudfront.net/273aa8e85c3dbbe7cda45642da0476bfef311ac5/2-Table1-1.png)

In the next section, we introduce some notations used in the
次節では、本書で使用するいくつかの表記法を紹介する。

remainder of this paper and also describe the datasets we
本論文の残りの部分と、我々が作成したデータセットについて説明する。

harvested and mined for our analysis.
を採取し、解析のために採掘した。

# 3. Notations and Definitions 3. 表記と定義

Our dataset is composed of a set of users U, artists A, tracks T, and timestamps Z the set of integers). S is a relation such that: $S \subseteq U * T * A * Z$, describes which users have played which tracks, by which artist at each particular timestamp. Similarly, L is a relation such that $L \subseteq U * T * A * Z$, describing the tracks that users have loved, and when they expressed their affinity. A profile for a user u, is defined as a pair $P_u = (S_u , L_u)$ where $S_u =
(u,t,a,z) \in S

## 3.1. Dataset 3.1. データセット

We first harvested the profiles for 16,394 random users of Last.fm. For each of these users, we collected information about all the tracks they loved. Removing the 6,382 users who did not love any tracks left us with $
U

![](https://d3i71xaburhd42.cloudfront.net/273aa8e85c3dbbe7cda45642da0476bfef311ac5/3-Figure1-1.png)

Figure 1.
図1.
CFD plot of tracks loved by 10,012 users
10,012人のユーザーから愛された楽曲のCFDプロット

![](https://d3i71xaburhd42.cloudfront.net/273aa8e85c3dbbe7cda45642da0476bfef311ac5/3-Figure2-1.png)

Figure 2.
図2.
CFD plot of tracks played by 10,012 users
10,012人のユーザが再生した楽曲のCFDプロット

Typically in music recommender systems, user profile information is recorded on a track level whilst recommendations are made at the artist level [4].
一般に、音楽推薦システムでは、ユーザプロファイル情報はトラックレベルで記録され、推薦情報はアーティストレベルで作成される[4]。
Thus, we aggregated our dataset at the artist level.
このため、我々はデータセットをアーティストレベルで集約した。
We then divided this dataset into two parts.
このデータセットを2つのパートに分割した。
The first part, which we called the Artist Playcount Dataset (initially 865 users and 29,094 unique artists) stores metadata about all the artists played by the various users and the playcount for each artist by each user.
最初の部分は、Artist Playcount Dataset（当初は865ユーザと29,094ユニークなアーティスト）と呼び、様々なユーザが再生したすべてのアーティストに関するメタデータと各ユーザの各アーティストの再生回数を格納しています。
It represents the implicit feedback dataset.
これは、暗黙のフィードバックデータセットを表している。
Similarly, the second part, called the Artist Lovecount Dataset (initially 865 users and 11,090 unique artists) stores metadata about all the artists loved by the users and the lovecount for each artist by each user.
同様に、第2部はArtist Lovecount Dataset（初期値：865ユーザ、11,090アーティスト）と呼ばれ、ユーザが愛したすべてのアーティストに関するメタデータと、各ユーザによる各アーティストのラブカウントが格納されている。
It represents the explicit feedback dataset.
これは、明示的なフィードバックのデータセットである。
In order to avoid the few plays of an artist from affecting the overall performance, we removed from the Artist Playcount Dataset, all records where the user has played an artist less than 20 times.
アーティストの再生回数が全体のパフォーマンスに影響を与えないようにするため、アーティスト再生回数データセットから、ユーザがアーティストを20回未満しか再生していないレコードをすべて削除しました。
This shed a large part of the dataset such that the Artist Playcount Dataset now consisted of 527 users and 2167 unique artists.
これにより、データセットの大部分が削除され、アーティスト再生回数データセットは、527人のユーザーと2167人のユニークなアーティストで構成されるようになりました。
Similarly, we pruned down the Artist Lovecount Dataset to the same 527 users (8242 unique artists) although we did not remove records based on lovecount.
同様に、アーティストLovecount Datasetは、Lovecountに基づくレコードを削除しないものの、同じ527ユーザ（8242ユニーク・アーティスト） にプルーニングされました。
Table 2 below summarises the various characteristics of these two datasets.
以下の表2は、これら2つのデータセットの様々な特性をまとめたものです。

Table 2.
表2.
Characteristics of the two datasets
2つのデータセットの特徴

![](https://d3i71xaburhd42.cloudfront.net/273aa8e85c3dbbe7cda45642da0476bfef311ac5/3-Table2-1.png)

In the next section we discuss how we derived the user preferences for the artists from the above datasets.
次章では、上記のデータセットから、どのようにアーティストに対するユーザーの嗜好を導き出したかについて述べる。

# 4. Calculating User Preferences 4. ユーザープリファレンスの算出

We used the following three methods for calculating the user’s preference for an artist.
ユーザーのアーティストに対する嗜好を算出するために、以下の3つの方法を用いました。
We tested the following three methods for calculating the user’s preference for an artist (user-artist preference):
ユーザーのアーティストに対する好み（ユーザー・アーティスト・プレファレンス）を計算するために、以下の3つの方法をテストしました。

- Absolute: the preference is a count of the number of times a user has played or loved an artist 絶対値：プリファレンスは、ユーザーがそのアーティストを再生した回数、または好きになった回数のカウントです

- Normalise: the preference is the ratio of counts of the number of times a user has played or loved an artist to the total number of artists played or loved by the user. Thus, we normalise the artist playcount or lovecount such to account for a user’s usage of the system. 正規化：プリファレンスは、ユーザーが再生または愛用したアーティストの総数に対する、ユーザーがそのアーティストを再生または愛用した回数のカウントの比率を指します。 したがって、ユーザーのシステムの使用状況を考慮し、アーティストの再生回数や愛用回数を正規化します。

- Log: this is similar to the Absolute measure, except that preference is calculated as the log to base 10 of the artist playcount or lovecount. Log：これはAbsoluteメジャーと似ていますが、Preferenceがアーティストのプレイカウントまたはラブカウントの10の底の対数として計算される点が異なります。

In order to understand the user preference values obtained using the three above methods when applied to the Implicit dataset (Artist Playcount Dataset) and the Explicit dataset (Artist Lovecount Dataset), we show in Figure 3, the histograms of these preference values.
Implicitデータセット（Artist Playcount Dataset）とExplicitデータセット（Artist Lovecount Dataset）に上記の3つの方法を適用して得られたユーザーのプリファレンス値を理解するために、これらのプリファレンス値のヒストグラムを図3に示しています。
For each set of preference values, we divided the range in 5 bins and counted the number of values in each bin.
嗜好値の各セットについて、範囲を5つのビンに分割し、各ビン内の値の数を数えました。

![](https://d3i71xaburhd42.cloudfront.net/273aa8e85c3dbbe7cda45642da0476bfef311ac5/4-Figure3-1.png)

Figure 3.
図3.
Histograms of user preferences
ユーザー嗜好のヒストグラム

# 5. Experiment 5. 実験

In our experiments, we applied user preference data obtained using the above described techniques as input to the Taste Collaborative Filtering (CF) engine from the Apache Mahout project.
実験では、Apache MahoutプロジェクトのTaste Collaborative Filtering (CF)エンジンの入力として、上記の手法で得られたユーザの嗜好データを適用しました。
We setup Taste for user-based CF, using a nearest neighbourhood value of 3 and Pearson Correlation as the measure of similarity.
Tasteは、ユーザベースのCFとして、最近傍値を3とし、類似度の指標としてPearson Correlationを使用するように設定しました。
We used 90% of the user preference data to train the Taste engine and the evaluation was carried out the remaining 10%.
ユーザーの嗜好データの90%をTasteエンジンの学習に使用し、残りの10%で評価を行った。
We measured the outcome of each experiment in terms of the Root Mean Squared Error (RMSE) between the given user preferences and the predicted user preferences.
各実験の結果は、与えられたユーザー嗜好と予測されたユーザー嗜好の間の二乗平均平方根誤差（RMSE）で測定されました。
For each experiment, we did five runs and averaged the results.
各実験について、5回実行し、その結果を平均化しました。

Table 3 shows the evaluation of the three methods for calculating the user preferences for an artist.
表3は，あるアーティストに対するユーザの嗜好を計算するための3つの手法の評価を示している．
Across both datasets, the normalised techniques produced the best results.
両方のデータセットにおいて、正規化された手法が最も良い結果を生みました。
Our better RMSE values than those traditionally seen in RS may be explained by the fact that we are only using positive user preferences – this is a limitation of our datasets and of any feedback dataset collected from Last.fm.
これは、我々のデータセットとLast.fmから収集したフィードバックデータセットの制限事項です。
Bearing in mind that our dataset is relatively small compared to others [10], it may also be the case that we were too aggressive in the preprocessing described in Section 3.1.
私たちのデータセットが他と比較して比較的小さいことを考慮すると[10]、セクション3.1で説明した前処理が積極的すぎたということもあるかもしれません。

# 6. Discussions 6. ディスカッション

As shown in Table 3, calculating user preferences in terms of absolute counts produced the worst results.
表3に示すように、ユーザーの嗜好を絶対数で計算すると、最も悪い結果が得られました。
This is because it does not account for the usage patterns of the user in contrast to normalised figures which produced the best results.
これは、最良の結果をもたらした正規化された数値とは対照的に、ユーザーの使用パターンを考慮していないためである。
If we exclude the esults from the experiment with absolute counts, we notice that both the implicit and explicit datasets produced similar results for the Normalised and Log experiments.
絶対数の実験結果を除くと、暗黙的データセットと明示的データセットの両方が、正規化実験とログ実験で同じような結果を出していることに気づきます。
Despite the different characteristics of these two datasets, they produced similar performances.
この2つのデータセットの特性は異なるにもかかわらず、両者は類似のパフォーマンスを示した。
This is counter intuitive as implicit feedback is seen as less accurate than explicit feedback [1][2].
これは、暗黙的なフィードバックは明示的なフィードバックよりも精度が低いと考えられているため、直感に反しています[1][2]。
The histograms in Figure 3, show that the calculated user preferences are all skewed to the lower end of the scale, except in the case of the user preference values calculated using the Log method on the Implicit dataset (i.e Artist Playcount Dataset).
図3のヒストグラムは、計算されたユーザープレファレンスが、Implicitデータセット（すなわちArtist Playcount Dataset）上でLog法を使用して計算されたユーザープレファレンス値の場合を除き、スケールの下端に偏っていることを示しています。
This shows a lack in diversity of the preference values.
これは、嗜好値の多様性に欠けることを示しています。
The extremely good RMSE values and the lack in diversity in user preference values may be due to the limited size of the dataset and a consequence of the pre-processing we carried out.
RMSE値が非常に良いことと、ユーザ嗜好値の多様性の欠如は、データセットのサイズが限られていることと、我々が実施した前処理の結果である可能性があります。
Another possible explanation we will explore as part of our future work is the suitability of RMSE as the evaluation metric for comparing the performances of the methods for calculating user preferences.
また、ユーザー嗜好の計算方法の性能を比較するための評価指標として、RMSEが適しているかどうかも、今後の研究の一環として検討する予定です。

# 7. Related Work 7. 関連作品

Feedback has been studied extensively in Information Retrieval.
フィードバックは情報検索において広範囲に研究されている。
[7] provides an extensive overview of the literature on implicit feedback in IR and RS.
[7]は、IRとRSにおける暗黙のフィードバックに関する文献の広範囲な概観を提供している。
Most previous works on this topic have studied either implicit or explicit feedback.
このトピックに関するほとんどの先行研究は、暗黙的または明示的なフィードバックを研究している。
[9] compared explicit and implicit feedback for online information retrieval, namely investigating the extent to which the two types of feedback are interchangeable.
[9]は、オンライン情報検索における明示的なフィードバックと暗黙的なフィードバックを比較し、すなわち、2種類のフィードバックがどの程度交換可能であるかを調査している。
They found that some degree of substitution does exist.
彼らは、ある程度の置き換えが存在することを発見した。
There is a disproportionate amount of literature studying implicit feedback for use in web search engines, personalisation and recommender systems.
ウェブ検索エンジン、パーソナライズ、推薦システムで使用するための暗黙のフィードバックを研究する文献は、不釣り合いなほど多くあります。
This is probably due to the fact that it is generally accepted that there is room for improvement in implicit feedback.
これはおそらく、暗黙のフィードバックには改善の余地があると一般に受け止められているためでしょう。
But [1] recently showed that explicit feedback still needs to be improved.
しかし、[1]は最近、明示的なフィードバックはまだ改善される必要があることを示しました。
They found that user variability and inconsistency in providing explicit feedback, which they referred as natural noise negatively affects the accuracy of RS.
彼らは、自然雑音と呼ばれる、明示的なフィードバックを行う際のユーザのばらつきや不一致が、RSの精度に悪影響を与えることを発見した。
They propose a system of re-feedback as a solution and suggest that removing noise in explicit feedback can be more beneficial in improving RS accuracy rather than gathering explicit feedback on unseen items.
彼らは解決策としてリフィードバックのシステムを提案し、未見項目の明示的なフィードバックを集めるよりも、明示的なフィードバックに含まれるノイズを取り除く方がRSの精度向上に有効であることを示唆している。
This natural noise in explicit feedback bears similarity to the differences in relevance judgements that [8] found in their work on personalisation.
この明示的フィードバックにおける自然なノイズは、[8]がパーソナライゼーションに関する研究で見出した関連性判断の違いと類似している。
[10] proposed a method of learning multiple matrices over common items in order to improve overall predictive performance.
[10]は、全体的な予測性能を向上させるために、共通の項目に関する複数の行列を学習する方法を提案した。
Although the authors used datasets from Last.fm to illustrate their techniques, their work is on combination of metadata about played tracks and user generated tags.
また，Last.fm のデータセットを用いているが，再生した楽曲のメタデータとユーザが生成したタグの組み合わせに関する研究である．
Their combination technique can be applied to our explicit and implicit datasets.
このような組み合わせの技術は、我々の明示的・暗黙的なデータセットに適用することができる。
The researchers in [5] studied the use of collaborative filtering on implicit feedback datasets.
5]の研究者は、暗黙のフィードバックデータセットに対する協調フィルタリングの使用について研究している。
They discuss the properties of such datasets and proposed the notion of applying confidence levels to interpret the implicit feedback measures as positive and negative preference values.
彼らはこのようなデータセットの特性について議論し，暗黙のフィードバック尺度をポジティブとネガティブのプリファレンス値として解釈するために信頼度を適用するという概念を提案した．
They test their algorithm for calculating user preferences using Latent factor models rather than CF as we did.
彼らは、我々のようなCFではなく、Latent factor modelを用いてユーザープレファレンスを計算するアルゴリズムをテストしている。
In contrast to our work, they do not have any comparative performance between explicit and implicit feedback as the combination of these two types of feedback was not the aim of their study.
我々の研究とは対照的に、彼らは明示的なフィードバックと暗黙的なフィードバックを組み合わせることが研究の目的ではなかったため、明示的なフィードバックと暗黙的なフィードバックの間の性能比較は行っていない。

# 8. Conclusions 8. 結論

In this paper we focussed on comparing implicit feedback and explicit feedback, two types of feedback with different characteristics.
本論文では、異なる特徴を持つ2種類のフィードバックである暗黙的フィードバックと明示的フィードバックの比較に焦点を当てた。
We built implicit and explicit feedback datasets out of the tracks played and tracks loved, respectively, for a random sample of users on Last.fm.
我々は、Last.fmのランダムなユーザーを対象に、再生したトラックと愛聴したトラックから、それぞれ暗黙的フィードバックと明示的フィードバックのデータセットを作成した。
We compared and contrasted three techniques for extracting user preferences from these datasets.
これらのデータセットからユーザの嗜好を抽出するための3つの手法を比較検討した。
Explicit and implicit feedbacks provide different degrees of expressivity of the user’s preferences.
明示的なフィードバックと暗黙的なフィードバックでは、ユーザの嗜好の表現力が異なる。
In order to build more effective RS and maximising the potential of combining these two types of feedback, we compared the performances of each type of feedback on a RS.
より効果的なRSを構築し、これら2種類のフィードバックを組み合わせることの可能性を最大化するために、我々はRSにおける各タイプのフィードバックの性能を比較した。
Our experiments show that although they have different characteristics, the two datasets produced similar performances.
その結果、2つのデータセットはそれぞれ異なる特徴を持つものの、同様の性能を示すことが分かった。
Our aim in studying explicit and implicit feedback is to better understand their characteristics in order to combine them effectively in a RS.
我々は、明示的・暗黙的なフィードバックを研究することで、その特性をより理解し、RSにおいて効果的に組み合わせることを目的としている。
Thus, in our future work, we will be experimenting with different ways of combining these two types of feedback in a user preference model and finding better evaluation measures that work across datasets.
したがって、今後の研究では、ユーザ嗜好モデルにおいてこれら2種類のフィードバックを組み合わせる様々な方法を実験し、データセット間で有効なより良い評価指標を見つける予定である。