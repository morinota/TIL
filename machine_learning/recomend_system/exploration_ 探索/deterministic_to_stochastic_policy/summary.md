---
format:
  html:
    theme: cosmo
  # revealjs:
  #   # incremental: false
  #   # theme: [default, custom_lab.scss]
  #   theme: [default, custom_lab.scss]
  #   slide-number: true
  #   scrollable: true
  #   logo: https://s3-ap-northeast-1.amazonaws.com/qiita-image-store/0/1697279/dfa905d1c1e242b4e39be182ae21a2b6ac72c0ad/large.png?1655951919
  #   footer: ⇒ [https://qiita.com/morinota](https://qiita.com/morinota)
from: markdown+emoji

fig-cap-location: bottom

title: 確率的(探索的)な推薦方策を考える ~オフライン評価&学習しやすい優しい世界?~
subtitle: y-tech-ai ワクワク勉強会
date: 2024/08/13
author: モーリタ
title-slide-attributes:
  #   data-background-image: https://i.imgur.com/nTazczH.png
  data-background-size: contain
  data-background-opacity: "0.5"
---

## (下書き) 書きたい内容をラフに列挙する

<!-- ## TL;DR -->

- オフライン評価が難しい話を少し
- データ収集方策が決定的だと、オフライン評価がかなり困難になりそう。
  - (確率的な方策を採用したらそれで完結するわけではないが、決定的な方策だともう厳しすぎるので)
- 決定的な推薦方策から確率的な推薦方策への移行アイデアをいくつか考えてみる
- 懸念: オンライン推論の場合、確率的な方策はレイテンシーとか大丈夫??
- 実験してみる。

## はじめに

### なんでこのトピックを??

- 推薦システムのオフライン評価難しい問題。
  - オフライン評価が難しいってことは、オフライン学習も難しいのでは...
- オフライン評価のアプローチを調べていると...
  - 決定的な推薦方策で収集した観測データだと、かなり打ち手がなさそうな印象。
  - 確率的な推薦方策である程度探索的に収集したデータを使えば、打ち手が増えそう。
- というわけで、確率的な推薦方策を本番導入することを色々考えてみた!

ちなみに先日のRecommendation Industry Talksというイベントで「推薦システムを本番導入する上で一番優先すべきだったこと」というタイトルで発表してきましたー!
結論としては、推薦システムのオフライン評価が難しいから一旦諦めて、まずはいかにA/Bテスト(オンライン評価)しやすい基盤を設計することが大事だった、という話を発表してきました!

一方で今回の話は、やっぱりオフライン評価できるに越したことはないから、オフライン評価を少しでも簡単にするための工夫として、確率的な推薦方策の導入を検討してみるという話です。

## 決定的な推薦方策と確率的な推薦方策

- 決定的(deterministic)な推薦方策
  - ある状態において、常に同じアクションを選択する方策。
- 確率的(stochastic)な推薦方策
  - ある状態において、確率的にアクションを選択する方策。

- 例: 特徴量 $\mathbf{x}$ を持つユーザに対して、アイテム集合 $A = \{a_1, a_2, a_3\}$ からアイテムを1つ選択する問題を考える。
  - 決定的な推薦方策: $a_1$ を常に選択する。
  - 確率的な推薦方策: $\{a_1 = 0.5, a_2 = 0.3, a_3 = 0.2\}$ の確率分布に従ってアイテムを選択する。

## オフライン評価の話を少し

### オフライン評価とは？？

Off-Policy Evaluation (OPE) の分野では、オフライン評価とは、以下のような問題を指す。

> データ収集方策 $\pi_{0}$ で収集された観測データを使って、$\pi_{0}$ とは異なる方策 $\pi_{1}$ のオンライン性能を推定する問題

数式の表記は以下:

- $\mathbf{x}$: ユーザ特徴量や状態
- $a \in A$: 意思決定タスクにおいて選択される行動(action)

-

## データ収集方策が決定的だと、オフライン評価がかなり困難になりそう

## 決定的な推薦方策から確率的な推薦方策への移行アイデア達

- プラケットルースモデルに基づくランキングの確率的サンプリング
- ガンベルソフトマックストリックを使って同様のランキングを高速に生成
- epsilon-greedyを使う

## 懸念: オンライン推論の場合、確率的な方策はレイテンシーとか大丈夫??
