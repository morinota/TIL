<!-- title: メディアのミッションによって"良い"ニュース推薦システムって違うのかも! メディアモデルと5つの多様性指標群の論文等を読んで思いを馳せた話-->

こんにちは、ソーシャル経済メディア「NewsPicks」の機械学習エンジニアの森田( [@moritama7431](https://twitter.com/moritama7431) )です。
NewsPicks Advent Calendar 2023 の 14日目です。
昨日は〇〇さんによる『』でした！

そして本日の記事は、ざっくりニュースメディアと推薦システムに関するお話です！少し具体的には、メディアのミッションによって"良い"ニュース推薦システムの性質が異なるかもしれなくて、メディアに合った推薦システムをどのように選ぼうか、という話になります。

本記事の読者層としては、ニュースメディアに関わる方、もしくは推薦システムに関わる方を想定しています。後半パートは推薦システムに関わる方向けの内容かなと思っています。

<!-- (フィルタリングの方針とは、例えば「ユーザの好みに合わせてニュースをパーソナライズする」か「ユーザの好みに合わせずに、社会で議論されているトピックを提供する」か、みたいな話ですね。) -->

本記事の目次は以下の通りです。

- [メディアのミッションによって"良い"ニュース推薦システムって違うかも](#メディアのミッションによって良いニュース推薦システムって違うかも)
  - [そもそも推薦システムってなんだっけ?](#そもそも推薦システムってなんだっけ)
  - [ニュースメディアにおける推薦システムの役割ってなんだっけ?](#ニュースメディアにおける推薦システムの役割ってなんだっけ)
  - [情報のフィルタリングの方針って色々あるよね:4種類のメディアモデル](#情報のフィルタリングの方針って色々あるよね4種類のメディアモデル)
    - [自由主義モデル(The Liberal model)](#自由主義モデルthe-liberal-model)
    - [参加主義モデル(The Participatory model)](#参加主義モデルthe-participatory-model)
    - [議論主義モデル(The Deliberative model)](#議論主義モデルthe-deliberative-model)
    - [批判主義モデル(The Critical model)](#批判主義モデルthe-critical-model)
  - [NewsPicksの場合はどんなニュース推薦が望ましいんだろう?](#newspicksの場合はどんなニュース推薦が望ましいんだろう)
- [メディアに合った推薦システムをどのように選択しようかって話](#メディアに合った推薦システムをどのように選択しようかって話)
  - [精度指標だけでは選べなくない?](#精度指標だけでは選べなくない)
  - [多様性指標群 RADio](#多様性指標群-radio)
    - [Calibration](#calibration)
    - [Fragmentation](#fragmentation)
    - [Activation](#activation)
    - [Representation](#representation)
    - [Alternative Voices](#alternative-voices)
    - [メディアモデルとRADioの関係](#メディアモデルとradioの関係)
  - [RADio のニュース推薦システム内での活用可能性に思いを馳せてみた](#radio-のニュース推薦システム内での活用可能性に思いを馳せてみた)
    - [1つ目: 推論結果の品質の監視](#1つ目-推論結果の品質の監視)
    - [2つ目: 機械学習モデルのオフライン評価](#2つ目-機械学習モデルのオフライン評価)
- [おわりに](#おわりに)

ちなみに本記事の内容は、主に以下の資料を読んでいた際に個人的にNewsPicksでの活用可能性について思いを馳せた話になります...!

- [RADio – Rank-Aware Divergence Metrics to Measure Normative Diversity in News Recommendations](https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf)
- メイン論文の前身的な論文: [Recommenders with a Mission: Assessing Diversity in News Recommendations](https://dl.acm.org/doi/10.1145/3406522.3446019)

# メディアのミッションによって"良い"ニュース推薦システムって違うかも

## そもそも推薦システムってなんだっけ?

まず推薦システムって何なんでしたっけ?
パッと思いつくのは、Amazonで買い物をした時に出てくる「閲覧履歴に基づくおすすめ商品」や、Netflixで映画を見た時に出てくる「おすすめ作品」でしょうか。

![]()

(上画像は、筆者のAmazonの「閲覧履歴に基づくおすすめ商品」の表示結果。なぜかテレビのケーブルばっかりで恥ずかしい...!)

推薦システムの定義として、よく「推薦システム実践入門」の以下の記述が引用されてます。

> 複数の候補からユーザにとって価値のあるものを選び出し、意思決定を支援するシステム

なので、hogehogeですね。
ちなみに、この定義から考えると検索システムも広義の推薦システムに含まれる感じがしますね。システムにおける推薦と検索の違いは、ユーザからのクエリ(検索語)をシステムが受け取るか否かだと思っているのですが、近年の言語モデルの発展によって対話型の推薦システムみたいな話もあるので、徐々に両者の境界が無くなってきている印象もあるなぁ...!

## ニュースメディアにおける推薦システムの役割ってなんだっけ?

さて、ニュースメディアと推薦システムの定義がなんとなく定まったところで、ニュースメディアと推薦システムの関連について考えてみます。

参考文献3によると、ニュース推薦システムの役割を以下のように定義しています。

> ニュース推薦システムの仕事は、増え続けるオンライン情報を**フィルタリング**すること

要するに、メディア側が何も考えずに得た情報全てを垂れ流すと、ニュース・情報が多すぎてユーザが困ってしまうので、何らかの方法で**良い感じにユーザに届く情報を絞り込みましょう**ってことでしょうか...!

そう考えると、アルゴリズムによってユーザの閲読履歴から表示記事をパーソナライズすることも、多くのユーザが読んでいる人気記事を表示することも、情報元が怪しいフェイクニュースを除外することも、編成記者の方が1面に載せる記事を選ぶことも、**いずれも情報をフィルタリングしている**わけなので、全てニュース推薦システムですね...!

(ちなみに推薦システムの方法論の名前には、Collaborative filtering や Content-based filtering など〇〇フィルタリングという名前がちょくちょく出てくるんですよね。情報とかアイテムを絞り込む、選び出す、みたいなニュアンスでしょうか。推薦システムに機械学習を適用する際は、よくアイテムをユーザにとって価値のある順に並び替える「ランキング問題」として扱う印象が強いのですが、そういえば本来やりたいことは価値のある一部のアイテムをフィルタリングすることなんだよなぁ:thinking:、って少ししみじみしました...!)

## 情報のフィルタリングの方針って色々あるよね:4種類のメディアモデル

さて、ここからが本記事のメインの話題になります。
ニュース推薦システムの役割が「情報をフィルタリングすること」だとすると、**フィルタリングの方針ってニュースメディアがユーザに提供したいサービスや社会の中で果たしたいミッションによって異なるよね**、という話です。

例えば、「我々のメディアは、とにかく正確な真実のニュースをユーザに届けたいんだ!」というフェイクニュース絶対殺すマン的なミッションを掲げるメディアの場合を考えてみましょう。この場合、望まれるフィルタリング方針は「フェイクニュースを検知し、信頼性の高いニュースを絞り込む」ことであり、それが実現できればそのメディアにとって"良い"ニュース推薦システムになるんじゃないでしょうか:thinking:

参考文献3では、メディアのミッションや社会での役割について語る際によく使われる**4種類のメディアモデル**に焦点を当てて、それぞれのモデルにおいてニュース推薦がどうあるべきかを検討しています。

- 自由主義モデル(The Liberal model): コンテンツもスタイルも、ユーザの好みに合わせて提供する
- 参加主義モデル(The Participatory model): ユーザが社会で活動するために必要な共通認識を、各ユーザに分かりやすい形で提供する
- 議論主義モデル(The Deliberative model): 現在、社会的な議論の中心にあるトピックを選び、異なる意見や多様な視点を提供する
- 批判主義モデル(The Critical model): 少数派なコミュニティの意見や主張を積極的に提供する

上2つがパーソナライズされたフィルタリング方針(i.e. 推薦システム)。下2つが非パーソナライズのフィルタリング方針ですね。
(ちなみに論文中では、メディアモデル間に優劣はないよ、と強調されています)

### 自由主義モデル(The Liberal model)

1つ目の自由主義モデルは、ユーザが選択した特定の分野での専門性を高められるような情報を提供することを目的としています。

期待される推薦システムの性質(i.e. フィルタリングの方針)は、推薦するニュースのトピックも専門性も、ユーザの好みや能力に合わせてガンガンパーソナライズしていくことです。

例えば、AI関連のニュースをよく読みその専門性を高めていきたいユーザに対しては、AI関連でそのユーザの理解度に合致したニュースばかりをどんどんフィルタリングしていく様なイメージですね。基本的には世の中の多くのメディアがこの自由主義モデル的なニュース推薦システムを採用しているように思いますし、「ニュース推薦」という言葉を聞いて真っ先に思い浮かべるのもこれな気がしますね。

### 参加主義モデル(The Participatory model)

2つ目の参加主義モデルは、ユーザが社会で積極的に参加し活動できるように共通認識を提供することを目的としています。

期待される推薦システムの性質(i.e. フィルタリングの方針)は、ユーザが社会で活動するために必要な共通認識的な情報を、各ユーザに分かりやすい形で提供することです。
自由主義モデルも参加主義モデルもパーソナライズしたニュース推薦を必要とする点で共通していますが、推薦するニュースのトピックをパーソナライズすべきか否かが異なります。
参加主義モデルにおいて、異なるユーザに必ずしも同一のニュース記事を読ませる必要はありませんが、同一のトピックのニュース記事を読ませることは必要です。一方で、推薦するニュースの複雑さに関しては、その共通認識的なトピックに対するユーザの理解度に合わせてパーソナライズすることが求められます。

例えば、メディア側が「生成AI」というトピックを社会活動する上で必要な共通認識だと判断した場合を想像してみます。
この場合にニュース推薦システムに望まれる振る舞いとしては、普段「生成AI」に関する記事をよく読むユーザにもそうでないユーザにも、同じように「生成AI」のトピックに関するニュースを推薦します。そして、「生成AI」に対する理解度が低めのユーザに対しては「生成AI」に関する初心者向けのニュース記事を推薦し、「生成AI」に対する理解度が高いユーザに対しては「生成AI」に関してより専門的なニュース記事を推薦します。

### 議論主義モデル(The Deliberative model)

3つ目の議論主義モデルは、社会におけるさまざまな意見や価値観を提示し、共通の合意を得る、あるいは異なる価値観を受け入れられるような情報をユーザに提供することを目的としています。

期待される推薦システムの性質は、現在社会的な議論の中心となっているトピックに焦点を当てること、そのトピックの中で複数の視点や意見を提示することです。

例えば、メディア側が「気候変動と環境問題」を社会的な議論の中心となっているトピックであるとみなした場合、ニュース推薦システムに期待される振る舞いは、途上国側や先進国側の視点だったり、適応・緩和のための各種アプローチへのpositiveな意見とnegativeな意見だったり、特定の視点に偏らないように多様な情報を推薦記事に含めること、のような感じかなと思います。
(ちなみに自分は元々、都市環境学の分野にいたのですが、こういったトピックでは多様な視点を提供することは重要だよなぁと思ったりしてます...!)

### 批判主義モデル(The Critical model)

4つ目の批判主義モデルは、普段は届きづらい少数派なコミュニティの意見や主張を、ユーザに積極的に提供することを目的としています。

期待される推薦システムの性質は、多数派や社会的強者の視点からの情報に偏らず、少数派や社会的弱者の視点からの情報を積極的に提供することです。

例えば、「白人か否かの人種差別」や「富裕層と貧困層の格差」に関するトピックのニュースをユーザに提供したい場合、通常のオンライン情報は多くが多数派や社会的に力を持つ立場の人々の意見で占められています。しかし、この批判主義モデルでは、少数派だったり社会的な力が弱い方の視点を重視してユーザに提供する様な推薦システムが期待されます。

## NewsPicksの場合はどんなニュース推薦が望ましいんだろう?

さて、メディアの社会における役割にいくつか種類があって、望まれるニュース推薦システムの性質もそれによって異なるよね、という考えが得られました。

ここでは、NewsPicksの場合について考えてみます。

# メディアに合った推薦システムをどのように選択しようかって話

ここからは、主に推薦システム(i.e. フィルタリングの仕組み)を開発する方向けの内容になります。
といっても、パーソナライズ推薦で採用する機械学習モデルの数学的な話ではなく、metricsの話になります。
各メディアが求めるフィルタリング方針と合致した、"良い"ニュース推薦システムをどのように選ぼうか、みたいな話ですね。

## 精度指標だけでは選べなくない?

## 多様性指標群 RADio

参考文献1では、4種類のメディアモデルが推薦システムに期待する性質から導出した、対応した5つの多様性指標群 RADio を提案しています。

- Calibration: 「推薦結果がユーザの好みとどの程度合っているか」を表す指標。
- Fragmentation:「共通したトピックの記事を提供できているか」を表す指標。
- Activation: 「推薦結果のactiveness(感情的な記事か, 理知的な記事か)の多様性」を表す指標。
- Representation: 「推薦結果の視点の多様性」を表す指標。
- Alternative Voices: 「推薦結果の意見の持ち主(Minority/Majority)の多様性」を表す指標。

RADioの全metricsに共通する性質は以下。

- distance metric(同一性, 対称性, 三角形の不等式が成立する)。
- ２つの離散分布間のJS-Divergence。
- 値域が $[0; 1]$。(0に近いほど2つの分布の距離が近い)
  - 異なる推薦モデル間や異なるmetric間で比較したやすい
- rank情報を持った離散分布に適用可能。(rank-awareな指標)

### Calibration

「推薦記事がユーザの好みとどの程度合っているか」を反映したもので、推薦記事リストの分布とユーザの閲読履歴の分布のJSダイバージェンスを意味しています。

$$
Calibration = D_{JS}(P^*(c|H), Q^*(c|R))
\\
= \sum_{c} Q^*(c|R) f(\frac{P^*(c|H)}{Q^*(c|R)})
$$

ここで、$P$ と $Q$ は異なる2つの離散確率関数。添字 $*$ は、推薦記事の順位で重み付けされた確率関数である事を意味しています。(順位による重み付け方法は論文へ!) $H$ はあるユーザの閲読履歴の記事集合。$R$ は推薦モデルによって得られた推薦記事リスト。確率変数 $c$ は記事の属性情報(論文中では、記事のカテゴリやトピック、専門性の高さを採用していました!)。

### Fragmentation

「共通したトピックの記事を提供できているか」の度合いを反映したもので、複数ユーザの推薦記事リストの分布のJSダイバージェンスを意味します。
二人のユーザ $u$ と $v$ の推薦記事リストを比較して算出されます。

$$
Fragmentation = D_{JS}(P^*(e|R^{u}), Q^*(e|R^{v}))
\\
= \sum_{e} Q^*(e|R^v) f(\frac{P^*(e|R^u)}{Q^*(e|R^v)})
$$

ここで、$P$ と $Q$ は異なる2つの離散確率関数。添字 $*$ は 順位で重み付けされた確率関数である事を意味しています。 $R^{u}, R^{v}$ は、任意のユーザ $u$ と $v$ の推薦記事リスト。$e$ は記事のトピックを表す確率変数。

### Activation

「肯定的な記事ばかり推薦してしまってないか、逆に否定的な記事ばかり推薦してしまってないか」の度合いを反映したものです。推薦可能な記事プール $S$ と、推薦記事リスト $R$ のactivation score(=positiveかnegativeか)の分布間のJSダイバージェンスを意味します。

$$
Activation = D_{JS}(P(k|S), Q^*(k|R))
\\
= \sum_{k} Q^*(k|R) f(\frac{P(k|S)}{Q^*(k|R)})
$$

ここで、$P$ と $Q$ は異なる2つの離散確率関数。添字 $*$ は、順位で重み付けされた確率関数である事を意味しています。 $k$ は記事のactivation score(=positiveかnegativeか)を表す離散変数 (論文ではテキストのsentiment analysisで得る事を想定していました!)。

### Representation

「推薦結果の視点の多様性(ex. 政治的トピックや政党の言及など)」の度合いを反映したものです。
記事プール $S$ と、推薦記事リスト $R$ のviewpoint(離散値を想定) の分布間のJSダイバージェンスを意味します。

$$
Representation = D_{JS}(P(p|S), Q^*(p|R))
\\
= \sum_{p} Q^*(p|R) f(\frac{P(p|S)}{Q^*(p|R)})
$$

ここで、$P$ と $Q$ は異なる2つの離散確率関数。添字 $*$ は順位で重み付けされた確率関数を意味しています。 $p$ は記事のviewpointを表す離散変数。(具体的にどうやって記事のviewpointを表す属性情報を得るかはよく分かってない...!)

### Alternative Voices

「意見の声の持ち主(Minority/Majority)の多様性」の度合いを反映したものです。
Representationは意見の中身の多様性であり、Alternative Voicesは意見の声の持ち主の多様性を表すという点で異なります。
(Minority/Majorityの例: 非白人/白人, 非男性/男性, etc.)
記事プール $S$ と、推薦記事リスト $R$ のviewpointの持ち主の分布間のJSダイバージェンスを意味します。

$$
AlternativeVoices = D_{JS}(P(m|S), Q^*(m|R))
\\
= \sum_{m} Q^*(m|R) f(\frac{P(m|S)}{Q^*(m|R)})
$$

ここで、$P$ と $Q$ は異なる2つの離散確率関数。添字 $*$ は順位で重み付けされた確率関数を意味しています。 $m$ は記事の意見の持ち主を表す離散変数。

### メディアモデルとRADioの関係

各メディアモデルとRADioの関係は以下の通りです。

![](https://imgur.com/RZ46Wz5)
(論文より引用)

異なるアルゴリズムから得られた推薦結果のRADioの各値を比較することで、開発者はどの手法が各メディアが求める機能に適しているか定量的に評価できる、という話ですね。

- 自由主義モデルはユーザの好みに合わせた情報を提供したい -> 低いCalibrationと高いFragmentationの性質が望ましい
- 参加主義モデルは社会で必要な共通認識を各ユーザに分かりやすい形で提供したい -> 高いCalibration(complexity)と低いFragmentationの性質が望ましい

ちなみに論文中では、RADioを活用する上での今後の課題として以下のようなことが挙げられています。

- RADioに関連する多くの特徴量の抽出が難しいこと(ここはLLMの普及で多少なりとも難易度低下?:thinking:)
- 現状のRADioはpost-hocな評価指標である点。機械学習モデルの損失関数として活用可能なもののほうが良いよね...!

## RADio のニュース推薦システム内での活用可能性に思いを馳せてみた

最後に、RADioフレームワークを現在の業務上の課題解決に活用できないかなぁ、と思いを馳せてみました。

### 1つ目: 推論結果の品質の監視

最近読んだ[MLOps Maturity Assessment](https://mlops.community/mlops-maturity-assessment/)の項目4や [Booking.comの論文](https://blog.kevinhu.me/2021/04/25/25-Paper-Reading-Booking.com-Experiences/bernardi2019.pdf)の教訓5でも主張されていますが、バッチ推論でもオンライン推論でも推論結果の品質をモニタリングすることは重要だと思っています。
本番環境で推薦システムを運用する際、各種データの分布の変化や特徴量作成・学習・推論パイプラインへのバグの混入などによって、**エラーやレイテンシーの悪化等には現れない推論結果の品質の低下にいち早く気づきたい**という気持ちがありまして...!

<!--
自分が所属するチームでも先日、特徴量の1つとして汎用的に活用する為の記事テキストの新しい文書埋め込みを作るbatch処理を開発し稼働させていたのですが、実は記事テキストの先頭の1文字だけを使って文書埋め込みを作っていたというバグが混入していました...!
そしてこのバグが発見された時期は、対象のbatch処理が稼働し始めてから1~2週間後であり、実際に文書埋め込みを特徴量として使用する機械学習モデルによって出力された推薦記事リストを開発者自身が目視で定性評価した際にやっと何かおかしいと気づき、実装を確認して発見できました。 -->

特に推薦システムなど、ユーザからのフィードバックを教師ラベルとして使用するような機械学習システムの場合は、Incomplete (不完全) feedback や Delayed(遅延) feedback の問題があるため、precisionやrecallなどの教師ラベルに依存した指標では、推論結果の品質悪化を即座に検知するのが難しいです。

よって、**教師ラベルに依存しない評価指標を用いて推論結果の品質を監視したい**、というモチベーションが生まれるんですね。
ちなみにBooking.comの論文では、教師ラベルに依存しない方法として応答分布分析を採用してました。これは「推論結果が正常の場合は、推論結果の分布がこうなるはずだ」という仮定をおき、実際の分布と仮定した分布の差異を監視し、品質悪化を検知する方法でした。

そこで今回、RADioの各指標はいずれも教師ラベルに依存しないので、活用可能性として推論結果の品質監視に思いを馳せたわけです。
ちなみにRADioの各指標はいずれも、推薦結果の分布を他の分布と比較して評価してるので、広義の応答分布分析と言えるのかもしれません:thinking:
特に自由主義モデルや参加主義モデルの文脈では、Calibrationは使いやすいんじゃないかなと思ったりしてました
(ex. 自由主義モデルの場合、金融の記事を良く読むユーザAに対しては、金融の記事をたくさん推薦してあげたい。batch推論にしろonline推論にしろ、ユーザAに対する推薦結果を作成した時点で、Calibration(topic)を算出 -> 値が閾値を超えていたら品質低下として検知、みたいな...?)

### 2つ目: 機械学習モデルのオフライン評価

2つ目は、機械学習モデルのオフライン評価です。これがRADioの本来の用途なのかなと思っています。

ニュース推薦の分野では、metadataとしてテキストが使える事と、ニュースのlifecycleが短く新鮮なcold-start itemを推薦したいusecaseが多い事から、**content-based系の手法**(i.e. id-onlyでない手法)が多く採用されている印象です。

しかし、content-based手法はオフライン実験においてprecisionやrecallなどでは正確に評価しづらく、**一方でid-only手法やmost-popular itemsは過大評価されやすい傾向**があるようです([ニュース推薦のサーベイ論文](https://web-ainf.aau.at/pub/jannach/files/Journal_IPM_2018.pdf)より)。
やっぱりこのあたりの理由としては、人気度バイアスとか、Off-Policy Evaluation分野で言うところのlogging policy由来のバイアスとかが原因なのかな。

前述の通りRADioはいずれも教師ラベルに依存しない指標なので、多少なりともバイアスの影響を受けづらくないだろうか、少なくともid-only手法が過大評価されがち問題は解消できたりしないかな...なんて思ったりしました。
もちろん重み付けunder sampling や色々なOPE推定量など、バイアス除去を試みるアプローチも色々あるので、それらと組み合わせてモデルの取捨選択に使用するのが良いのかもしれません。
(例えばCalibrationの算出に使用するユーザの閲読履歴は、人気度やlogging policy由来のバイアスの影響を受けているから、under sampling的なアプローチと組み合わせるのはどうだろう...! :thinking: )

# おわりに

hogehoge
