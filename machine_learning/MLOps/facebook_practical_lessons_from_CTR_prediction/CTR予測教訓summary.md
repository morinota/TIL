# Facebook広告のCTR予測からの実践的な教訓

## イントロ

- デジタル広告において、機械学習はユーザーに対する候補広告の期待効用（expected utility）を計算する中心的な役割を果たす。
- Facebookの広告は検索クエリに紐付くのではなく、デモグラフィックや興味関心に基づいてターゲットされるため、候補となる広告の量が膨大になる。
  - 逆に、検索クエリに基づく広告では、ユーザの検索クエリにマッチする広告が限られるため、候補広告の数は少なくなるってことか...!:thinking:
- そのため、計算コストの異なる分類器を段階的に適用するカスケード構造(n-stages推薦みたいな??)を採用しており、本論文ではその最終段階である「クリック予測モデル」に焦点を当ててる。

## 実験設定 (Experimental Setup)

- 実験には2013年第4四半期の任意の週のデータを使用し、オフラインデータでオンライントレーニングと予測をシミュレーションした。
- 本実験に使った評価指標は以下。
  - 正規化エントロピー（Normalized Entropy, NE）: 背景CTR（平均クリック率）のエントロピーで正規化した対数損失（Log Loss）。値が低いほど予測が良いことを示す。
  - キャリブレーション（Calibration）: 予測された平均CTRと、実際に観測されたCTRの比率。オークションや入札の成功には正確な確率値が不可欠であるため、単なる順序付け（AUCで測れるもの）以上に重要。

## 予測モデルの構造 (Prediction Model Structure)

- ハイブリッドモデルの採用:
  - ブースティング決定木と、ロジスティック回帰を連結したハイブリッドモデルを提案。
- 決定木による特徴量変換: 
  - 決定木は強力な入力特徴量の変換器として機能する。
  - 各木をカテゴリカル特徴量として扱い、**インスタンスが落ちる「葉（リーフ）」のインデックスを特徴量とする**。
  - これは実数値ベクトルをコンパクトなバイナリ値ベクトルに変換する教師あり符号化と見なせる。
- 性能向上: 
  -  この「決定木＋ロジスティック回帰」の組み合わせは、決定木単独モデルと比較して、正規化エントロピー（NE）を3.4%以上減少させた。
- データの鮮度 (Data Freshness)の話:
  - トレーニングからテストまでの期間が空くほど予測精度は低下する。
  - 週次トレーニングから日次トレーニングに変更するだけでNEは約1%改善される。
  - 決定木はバッチ処理で学習し、線形分類器はオンライン学習でリアルタイムに近い形で学習させることが可能。
- オンライン線形分類器 (Online Linear Classifier)
  - ロジスティック回帰（LR）のための確率的勾配降下法（SGD）の学習率設定を比較した。

##　オンラインデータ結合器 (Online Data Joiner)

- オンライン学習での学習データセットを生成するためのインフラ「Online Joiner」の話。
- 仕組み: 
  - 広告のインプレッション（表示）とクリック（正解ラベル）をストリーム処理で結合。
- 待機ウィンドウ: 
  - クリックが発生するまで待つ時間枠（ウィンドウ）の設定が重要。
  - ウィンドウが長すぎるとメモリを圧迫しデータの鮮度が落ちるが、短すぎるとクリックを取りこぼして学習データが偏る。

## メモリとレイテンシの抑制 (Containing Memory and Latency)

- 大規模システムにおけるトレードオフについての考察の話。
- ブースティング決定木の数: 
  - 木の数を増やすと精度は上がるが、500本を超えると収穫逓減（diminishing return）が見られ、多すぎると過学習の原因になる。
- 特徴量の重要度: 
  - 上位10個の特徴量が全体の重要度の約半分を占める。下位の特徴量を削除しても精度への影響は軽微。
- 履歴 vs コンテキスト: 
  - 過去のクリック数などの「履歴特徴量（Historical features）」は、デバイスや時間帯などの「コンテキスト特徴量（Contextual features）」よりもはるかに強力。
  - ただし、新規ユーザーや新規広告（コールドスタート問題）にはコンテキスト特徴量が不可欠。
  
## 膨大な学習データへの対処(Coping with Massive Training Data)

- データ量を減らして計算コストを抑える手法を評価した話。
