# n週連続推薦システム系論文読んだシリーズ: Facebook広告のCTR予測タスクの実践的な教訓をまとめた論文を読んだ!

## これは何??

- 本記事はn週連続推薦システム系論文読んだシリーズ x 週目の記事です。
  - ちなみに x-1 週目はこちら: []()
- Facebookさんの、広告配信におけるCTR予測タスクの実践的な教訓をまとめた論文を読んでみたメモです。
  - 元論文: [Practical Lessons from Predicting Clicks on Ads at Facebook](/Users/masato.morita/Downloads/paper.pdf)
- ざっくりどんな内容??
  - 教訓1: hoge
  - 教訓2: fuga
  - 教訓3: piyo

## 導入: 本論文のモチベーション

- 「デジタル広告」という産業!
  - 数十億ドル規模の産業であり、かなりデカい市場。
  - かつ毎年どんどん成長してる。
- デジタル広告は「動的」に配分される!
  - ex. ユーザAがサイトを開く → 過去の行動履歴を見る → 「Aさん、これ好きそうかも!」って配信広告をリアルタイムで決める
- デジタル広告における機械学習の役割 = expected utilityの予測!
  - 各ユーザ-広告ペアのexpected utility (=効用や利益の期待値!:thinking:) を確度高く推定できるほど、デジタル広告市場の効率を高めることができる...!
  - ex. 「ユーザuに広告aを見せて購入されるかどうか」を確率変数 r とする (これがutility)。expected utilityは $E_{p(r|u,a)}[r]$ で表される。
- 広告オークションの話(歴史っぽい話!)
  - 2007年にGoogleやYahooは「**クリックされたら広告主がお金を払う(Pay-Per-Click, PPC)**」という広告オークション方式を導入。
  - Microsoft等もこれに追随。
  - 個人的ざっくり理解:
    - 広告主は「1クリックいくら払えるか」を入札。
    - プラットフォームは「クリック数の期待値の予測値」と「入札額」を掛け合わせた値を基に、広告の掲載順位を決定する。
    - **よって、MLによるクリック期待値の予測精度が、広告主のROIやプラットフォームの収益に直接影響を与える**...!!:thinking:
- 検索広告(Googleなど) vs FaceBook広告の違い!
  - 検索広告(Googleなど):
    - ユーザが検索クエリを入力。**クエリにマッチする広告のみが表示されるので、表示される広告の候補数はそこまで多くない!**
  - Facebook広告:
    - ユーザからのクエリがない。
    - デモグラ情報や興味関心に基づいてターゲティングされる。**なので、表示される広告の候補数が膨大になる!**
- 膨大な表示候補をどうやって捌いてるか?
  - リアルタイムに膨大な候補広告に対処するために、**計算コストの異なる分類器を段階的に適用するカスケード構造**を採用してるとのこと。
    - 要するにn-stages推薦っぽい感じ!:thinking:
  - **特に本論文は、その最終段階のクリック予測モデルに焦点を当てた話**。
    - (最後の比較的heavyなモデル...!:thinking:)

## 実験方法

- **過去オフラインデータでオンライン環境を頑張ってシミュレーション**してる。
  - 実験には2013年第4四半期の任意の週のデータを使用。
  - オフラインデータを分割して、**ストリーミングデータっぽく扱ってる**。
  - 全実験で同じデータセットを使用して、実験条件を揃えてる。
- 「予測精度」を評価指標として使ってる(広告の「売上・収益」ではない点に注意!)。
  - 理由: 本論文の目的は、MLモデル自体の設計に関する分析だから!
    - 売上などのビジネス指標だと、オークションロジックや配信制御の影響が混ざって比較しづらい。
  - 具体的に採用した「予測精度」の指標は以下:
    - Normalized Entropy (NE, Normalized Log Loss)
      - 背景CTR（平均クリック率）のエントロピーで正規化した対数損失（Log Loss）。
      - 理由: 広告CTRのスケールの大小に依存しない評価ができるから。
    - Calibration(予測CTRと実際のCTRの比)
      - 理由: 広告間の順位を当てるだけでは不十分。CTRがズレてると、過剰配信や配信不足が起きるため、収益に悪影響が出る。
  - なぜ「AUC」を使わないか?
    - AUCは順位づけの良さは測れるが、**推定値の正確さを測れない**。
    - ex. 全部CTRを2倍の値で予測しても、AUCの値は変わらない。
- 実験してる項目:
  - (1) CTR予測モデルの構造、どれが強い?
    - 単体LR(ロジスティック回帰)
    - 単体GBDT(勾配ブースティング決定木)
    - ハイブリッド。GBDTで特徴量変換 → その出力をLRに入力(leaf idをone-hotで食わせるやつ)
  - (2) データの新鮮さ (Data Freshness)の影響
    - ある1日のデータで学習したモデルを、翌日~数日後のデータで評価(遅延を増やす)
  - (3) オンライン学習時の学習率設定の影響
    - SGDの学習率スキームを複数比較する。
  - (4) BOPR(ベイズオンライン学習) vs online LRの比較
  - (5) オンライン学習を成立させる基盤の設計
    - 実験というより設計検討 + 実運用の知見
  - (6) 大規模運用のトレードオフ: 木の数・特徴数・データ量は"収穫逓減(しゅうかくていげん)"
  - (7) 特徴の種類: historicalがめちゃめちゃ強い。でもcontectualはコールドスタート対応に必須
    - 実験: historicalのみ/contextualのみ/両方の3パターンで比較
  - (8) データサンプリング戦略の話:
    - 実験:
      - uniform subsampling: 全体を間引く
      - negative downsampling: 負例だけ間引く(クラス不均衡対策)


## 実験結果: CTR予測モデルの構造に関して

- ハイブリッドモデルの採用:
  - ブースティング決定木と、ロジスティック回帰を連結したハイブリッドモデルを提案。
- 決定木による特徴量変換: 
  - 決定木は強力な入力特徴量の変換器として機能する。
  - 各木をカテゴリカル特徴量として扱い、**インスタンスが落ちる「葉（リーフ）」のインデックスを特徴量とする**。
  - これは実数値ベクトルをコンパクトなバイナリ値ベクトルに変換する教師あり符号化と見なせる。
- 性能向上: 
  -  この「決定木＋ロジスティック回帰」の組み合わせは、決定木単独モデルと比較して、正規化エントロピー（NE）を3.4%以上減少させた。
- データの鮮度 (Data Freshness)の話:
  - トレーニングからテストまでの期間が空くほど予測精度は低下する。
  - 週次トレーニングから日次トレーニングに変更するだけでNEは約1%改善される。
  - 決定木はバッチ処理で学習し、線形分類器はオンライン学習でリアルタイムに近い形で学習させることが可能。
- オンライン線形分類器 (Online Linear Classifier)
  - ロジスティック回帰（LR）のための確率的勾配降下法（SGD）の学習率設定を比較した。

##　オンラインデータ結合器 (Online Data Joiner)

- オンライン学習での学習データセットを生成するためのインフラ「Online Joiner」の話。
- 仕組み: 
  - 広告のインプレッション（表示）とクリック（正解ラベル）をストリーム処理で結合。
- 待機ウィンドウ: 
  - クリックが発生するまで待つ時間枠（ウィンドウ）の設定が重要。
  - ウィンドウが長すぎるとメモリを圧迫しデータの鮮度が落ちるが、短すぎるとクリックを取りこぼして学習データが偏る。

## メモリとレイテンシの抑制 (Containing Memory and Latency)

- 大規模システムにおけるトレードオフについての考察の話。
- ブースティング決定木の数: 
  - 木の数を増やすと精度は上がるが、500本を超えると収穫逓減（diminishing return）が見られ、多すぎると過学習の原因になる。
- 特徴量の重要度: 
  - 上位10個の特徴量が全体の重要度の約半分を占める。下位の特徴量を削除しても精度への影響は軽微。
- 履歴 vs コンテキスト: 
  - 過去のクリック数などの「履歴特徴量（Historical features）」は、デバイスや時間帯などの「コンテキスト特徴量（Contextual features）」よりもはるかに強力。
  - ただし、新規ユーザーや新規広告（コールドスタート問題）にはコンテキスト特徴量が不可欠。
  
## 膨大な学習データへの対処(Coping with Massive Training Data)

- データ量を減らして計算コストを抑える手法を評価した話。
