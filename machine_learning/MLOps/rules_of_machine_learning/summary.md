## 講演者のfavorite rules

- ルール全体の指針
  - 「**優れた機械学習システムを構築するための鍵は、優れたエンジニアであること**」
    - これは、シンプルなコードの記述、可読性の確保、テストの実施、バージョン管理の活用、そしてローンチと継続的な改善（イテレーション）を行うという、ソフトウェアエンジニアリングの原則を重視するもの。

以下は強調されたお気に入りのルール達:

1. Rule #1: Don’t be afraid to launch a product without machine learning.（機械学習なしで製品をローンチすることを恐れるな。）
   1. 過去のデータと目的を考慮した結果として意思決定を行いますが、**それを実践するにはデータが必要。**
   2. 機械学習は魅力的だが、データが不可欠。**最初に基本的なヒューリスティクス(heuristics)を使用してデータを収集することは、理論的に他の問題のあるデータを流用するよりも優れている可能性が高い**。
      1. ex. 検索システムがある場合まずrecencyでドキュメントの順位づけを行い、**その後にユーザの反応に関するデータを収集することができる**。
   3. 機械学習が製品に絶対に必要でない限り、データが集まるまで使用しないことが推奨される。
2. Rule #2: Make metric design and implementation a priority.（メトリックの設計と実装を優先事項とせよ。）
   1. 最も重要なのは、**プロダクト全体の健全性**である。
   2. ユーザのエンゲージメント(時間を費やしているか、クリックしてるか、コメントやシェアで満足度を示しているか)を確認する多くの方法があるが、**特定のmetricがプロダクトにとって「正しいmetricであるか」について心配する必要はない**。
      1. 言い換えるとこれらのmetricsは、脈拍や血圧のようなものであり、体調が良いことを保証するものではない。変化は良いサインにも悪いサインにもなり得る。
      2. **重要なのは、幅広いmetricsを追跡しそれらがどのように相互作用するかを理解すること。**
3. Rule #3: Choose machine learning over a complex heuristic.(複雑なヒューリスティックよりも機械学習を選べ。)
   1. 例えば動画のランキング付けにおいて、**視聴回数や評価をブレンドする複雑なヒューリスティクスを使うと、達成しようとしている目標が不明確になることがある**。
      1. もし本当にユーザーに動画をクリックしてほしいなら、クリックする確率を予測するモデルを構築し、最もクリックされそうな動画を表示すべき。
      2. ヒューリスティクスやそのインプットをモデルの特徴量として利用することはできるが、モデルの出力(挙動)はobjectiveによって導かれる。
   2. これは「機械学習の基本法則(fundamental law of machine learning)」に関わる。
      1. 十分な規模において、**システムに達成してほしいこと（目的）を形式的に表現する方が、システムに達成させる方法（ヒューリスティクス）を記述するよりも、容易かつ効率的**である。
      2. 初期にはヒューリスティクスを使いますが、データ、計算資源、エンジニアリング資源が増えるにつれて、機械学習が明確な勝者となる。
4. Rule #4: Keep the first model simple and get the infrastructure right.（最初のモデルをシンプルに保ち、インフラストラクチャを正しく構築せよ。）
   1. 機械学習システムの構築にかかる時間とコードの**大半は、データの収集とパイプラインの作成**に費やされる。
      1. 最初のモデルは、非常に基本的なモデルであっても改善効果（リフト）をもたらすことがよくある。
      2. シンプルな特徴量を使うことで、問題や不規則性が発生した場合に原因が簡単に特定でき、インフラストラクチャとデータのテストが容易になる。
   2. **「完璧は善の敵（the perfect is the enemy of the good）」という考え方に基づき、まずは数四半期以内にモデルを世に出すことで、チーム全体が機械学習のサイクルに乗ることができる**。
5. Rule #9: Detect problems before exporting models.（モデルをエクスポートする前に問題を検出せよ。）
   1. 多くの機械学習システムでは、学習したモデルをサービング（本番環境での予測実行）のためにエクスポートする段階が存在する。
   2. エクスポートされたモデルに問題が発生すると、それは**ユーザーに影響を与える問題（user-facing issue）**となる。
   3. 実施すべき健全性チェック（Sanity Checks）
      1. モデルのサイズ: モデルのサイズを確認し、サーバーをクラッシュさせないように。
      2. モデルのパフォーマンス: ホールドアウトデータ（held out data）に対してモデルのパフォーマンスが**妥当（reasonable）**であることを確認。
   4. 保護策には、現在のモデルと比較する、社内で利用する（ドッグフーディング）、そして実験を実行することが含まれる。
6. Rule #12: Don’t overthink which objective you choose to directly optimize first.（最初に直接最適化する目的（objective）を深く考えすぎるな。）
   1. 「時間消費」と「クリック数」のどちらが適切なメトリックか確信がない場合でも、**まずは直接的に帰属可能なメトリックであるクリック数を最適化から始めるべき**。
   2. 最初のモデルは、直接最適化していないメトリックも改善するという現象がよく見られます。すべてのメトリックが増加している場合は、シンプルな目的に留まることができる。
7. Rule #13: Choose a simple, observable and attributable metric for your first objective. （最初の目的に、シンプルで、観測可能で、帰属可能なメトリックを選べ。）
   1. シンプルである理由: ヒューリスティクスが非常に悪い場合、まともなメトリックを目的に選ぶだけで、すべてのメトリックで改善が得られるから。
   2. 観測可能である理由: ユーザーの幸福度のようなものを定義するのは難しく、時間がかかります。また、観測可能なものを予測している方が後でデバッグが容易になる。
   3. 帰属可能である理由: 長期的な目的の帰属は実践上非常に困難であるためです。直接的に帰属可能な目的を改善している限り、長期的なメトリックも改善しているという原則に従う。
8. Rule #29: Log features at serving time. （サービング時に特徴量をログに記録せよ。）
9.  Rule #38: Don’t waste time on new features if online objectives have become the issue.（オンライン目的が問題となっている場合、新しい特徴量に時間を浪費するな。）
    1.  中期的な目標や長期的な目標に、より適合するようにMLのobjectiveを調整するべき。
10. Rule #39: Launch decisions are a proxy for long term goals. （ローンチの意思決定は、長期的な目標の代理指標である。）
    1.  機械学習の専門家は、最適化すべき目的を設定し、それを増加させることがローンチにつながると期待しますが、必ずしもそう簡単ではない。
    2.  「1日あたりのダウンロード数」「1日あたりの時間消費」「1日あたりのクリック数」といった**中期的なメトリック**と、短期的なメトリックとの相関性は不明確。
    3.  さらに、ユーザーの満足、ユーザーの増加、パートナーの満足、利益といった**長期的な目的**が存在する。
    4.  最終的な真の目標は、「有用で高品質な製品と、繁栄する企業」である。







