## refs å¯©åˆ¤

https://matthewmcateer.me/blog/machine-learning-technical-debt/
https://matthewmcateer.me/blog/machine-learning-technical-debt/

# Nitpicking Machine Learning Technical Debt Nitpicking æ©Ÿæ¢°å­¦ç¿’ æŠ€è¡“çš„è² å‚µ

Revisiting a resurging NeurIPS 2015 paper (and 25 best practices more relevant than that for 2020)
å¾©æ´»ã—ãŸNeurIPS 2015ã®è«–æ–‡ã‚’å†è€ƒã™ã‚‹ï¼ˆãã—ã¦2020å¹´ã«å‘ã‘ã¦ã€ãã‚Œã‚ˆã‚Šã‚‚é–¢é€£æ€§ã®é«˜ã„25ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’è€ƒãˆã‚‹ï¼‰

MAY 10, 2020â€‚|â€‚UPDATED JULY 9, 2020
â€‚UPDATED JULY 9, 2020

## Background for this post ã“ã®æŠ•ç¨¿ã®èƒŒæ™¯

I recently revisited the paper Hidden Technical Debt in Machine Learning Systems (Sculley et al.2015) (which Iâ€™ll refer to as the Tech Debt Paper throughout this post for the sake of brevity and clarity).
ç§ã¯æœ€è¿‘ã€Hidden Technical Debt in Machine Learning Systems (Sculley et al.2015)ã¨ã„ã†è«–æ–‡ã‚’èª­ã¿è¿”ã—ãŸï¼ˆç°¡æ½”ã§ã‚ã‹ã‚Šã‚„ã™ãã™ã‚‹ãŸã‚ã«ã€ã“ã®æŠ•ç¨¿ã§ã¯Tech Debt Paperã¨å‘¼ã¶ã“ã¨ã«ã™ã‚‹ï¼‰ã€‚
This was a paper shown at NeurIPS 2015, but it sort of fell to the background because at the time everyone was swooning over projects based on this new â€œGenerative Adversarial Networksâ€ technique from Ian GoodFellow.
ã“ã‚Œã¯NeurIPS 2015ã§ç™ºè¡¨ã•ã‚ŒãŸè«–æ–‡ã ãŒã€å½“æ™‚ã¯ã‚¤ã‚¢ãƒ³ãƒ»ã‚°ãƒƒãƒ‰ãƒ•ã‚§ãƒ­ãƒ¼ã®æ–°ã—ã„ã€Œç”Ÿæˆçš„é€†èª¬çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€æŠ€è¡“ã«åŸºã¥ããƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«çš†ãŒç†±ç‹‚ã—ã¦ã„ãŸãŸã‚ã€èƒŒæ™¯ã«ã¯éš ã‚Œã¦ã„ãŸã‚ˆã†ãªã‚‚ã®ã ã€‚

Now the Tech Debt Paper is making a comeback.
ä»Šã€ãƒ†ãƒƒã‚¯ãƒ»ãƒ‡ãƒƒãƒˆãƒ»ãƒšãƒ¼ãƒ‘ãƒ¼ãŒå¾©æ´»ã—ã¤ã¤ã‚ã‚‹ã€‚
At the time of writing this, there have been 25 papers citing this in the last 75 days.
ã“ã®è¨˜äº‹ã‚’æ›¸ã„ã¦ã„ã‚‹æ™‚ç‚¹ã§ã€éå»75æ—¥é–“ã«25æœ¬ã®è«–æ–‡ãŒå¼•ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚
This is understandable, as machine learning has gotten to the point where we need to worry about technical debt.
æ©Ÿæ¢°å­¦ç¿’ã¯æŠ€è¡“çš„è² å‚µã‚’å¿ƒé…ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã¨ã“ã‚ã¾ã§æ¥ã¦ã„ã‚‹ã®ã ã‹ã‚‰ã€ã“ã‚Œã¯ç†è§£ã§ãã‚‹ã€‚
However, if a lot of people are going to be citing this paper (if not for more than just citing all the papers that have the phrase â€œmachine learning technical debtâ€ in them), we should at least be aware of which parts have and have not stood the test of time.
ã—ã‹ã—ã€ã‚‚ã—å¤šãã®äººãŒã“ã®è«–æ–‡ã‚’å¼•ç”¨ã™ã‚‹ã®ã§ã‚ã‚Œã°ï¼ˆã€Œæ©Ÿæ¢°å­¦ç¿’ã®æŠ€è¡“çš„è² å‚µã€ã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ã‚ºãŒå«ã¾ã‚Œã‚‹è«–æ–‡ã‚’ã™ã¹ã¦å¼•ç”¨ã™ã‚‹ä»¥ä¸Šã®ç†ç”±ãŒãªã„ã¨ã—ã¦ã‚‚ï¼‰ã€å°‘ãªãã¨ã‚‚ã€ã©ã®éƒ¨åˆ†ãŒæ™‚ã®è©¦ç·´ã«è€ãˆã€ã©ã®éƒ¨åˆ†ãŒè€ãˆã‚‰ã‚Œãªã‹ã£ãŸã‹ã‚’èªè­˜ã™ã¹ãã ã€‚
With that in mind, I figured it would save a lot of time and trouble for everyone involved to write up which parts are outdated, and point out the novel methods that have superseded them.
ãã‚Œã‚’å¿µé ­ã«ç½®ã„ã¦ã€ã©ã®éƒ¨åˆ†ãŒæ™‚ä»£é…ã‚Œãªã®ã‹ã‚’æ›¸ãä¸Šã’ã€ãã‚Œã«å–ã£ã¦ä»£ã‚ã£ãŸæ–¬æ–°ãªæ–¹æ³•ã‚’æŒ‡æ‘˜ã™ã‚‹ã“ã¨ã¯ã€é–¢ä¿‚è€…å…¨å“¡ã®æ™‚é–“ã¨æ‰‹é–“ã‚’çœãã“ã¨ã«ãªã‚‹ã¨è€ƒãˆãŸã€‚
Having worked at companies ranging from fast-growing startups to large companies like Google (the company of the Tech Debt Paper authors), and seeing the same machine learning technical debt mistakes being made everywhere, I felt qualified to comment on this.
æ€¥æˆé•·ä¸­ã®æ–°èˆˆä¼æ¥­ã‹ã‚‰ã‚°ãƒ¼ã‚°ãƒ«ï¼ˆTech Debt Paperã®è‘—è€…ã®ä¼šç¤¾ï¼‰ã®ã‚ˆã†ãªå¤§ä¼æ¥­ã¾ã§ã€ã•ã¾ã–ã¾ãªä¼šç¤¾ã§åƒã„ã¦ããŸç§ã¯ã€åŒã˜æ©Ÿæ¢°å­¦ç¿’ã®æŠ€è¡“çš„è² å‚µãƒŸã‚¹ãŒã„ãŸã‚‹ã¨ã“ã‚ã§è¡Œã‚ã‚Œã¦ã„ã‚‹ã®ã‚’ç›®ã®å½“ãŸã‚Šã«ã—ã€ã“ã‚Œã«ã¤ã„ã¦ã‚³ãƒ¡ãƒ³ãƒˆã™ã‚‹è³‡æ ¼ãŒã‚ã‚‹ã¨æ„Ÿã˜ãŸã€‚

This post covers some of the relevant points of the Tech Debt Paper, while also giving additional advice on top thatâ€™s not 5 years out of date.
ã“ã®æŠ•ç¨¿ã§ã¯ã€Tech Debt Paperã®é–¢é€£ãƒã‚¤ãƒ³ãƒˆã‚’ã„ãã¤ã‹å–ã‚Šä¸Šã’ã¤ã¤ã€5å¹´å‰ã®ã‚‚ã®ã§ã¯ãªã„ãƒˆãƒƒãƒ—ã¸ã®è¿½åŠ ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚‚ç´¹ä»‹ã™ã‚‹ã€‚
Some of this advice is in the form of tools that didnâ€™t exist back thenâ€¦and then some is in the form of tools/techniques that definitely did exist that the authors missed a huge opportunity by not bringing up.
ã“ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã®ã„ãã¤ã‹ã¯ã€å½“æ™‚ã¯å­˜åœ¨ã—ãªã‹ã£ãŸãƒ„ãƒ¼ãƒ«ã®å½¢ã‚’ã¨ã£ã¦ã„ã‚‹...ãã—ã¦ã„ãã¤ã‹ã¯ã€è‘—è€…ãŒå–ã‚Šä¸Šã’ãªã‹ã£ãŸã“ã¨ã§å¤§ããªãƒãƒ£ãƒ³ã‚¹ã‚’é€ƒã—ã¦ã—ã¾ã£ãŸã€é–“é•ã„ãªãå­˜åœ¨ã—ã¦ã„ãŸãƒ„ãƒ¼ãƒ«ï¼ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã®å½¢ã‚’ã¨ã£ã¦ã„ã‚‹ã€‚

## Introduction 

Tech debt is an analogy for the long-term buildup of costs when engineers make design choices for speed of deployment over everything else.
æŠ€è¡“çš„è² å‚µã¨ã¯ã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒä»–ã®ã™ã¹ã¦ã‚ˆã‚Šã‚‚é…å‚™ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚’å„ªå…ˆã—ã¦è¨­è¨ˆä¸Šã®é¸æŠã‚’ã—ãŸå ´åˆã«ã€é•·æœŸçš„ã«ç©ã¿é‡ãªã‚‹ã‚³ã‚¹ãƒˆã®ä¾‹ãˆã§ã‚ã‚‹ã€‚
Fixing technical debt can take a lot of work.
æŠ€è¡“çš„è² å‚µã‚’ä¿®æ­£ã™ã‚‹ã«ã¯ã€å¤šãã®åŠ´åŠ›ãŒã‹ã‹ã‚‹ã€‚
Itâ€™s the stuff that turns â€œMove fast and break thingsâ€ into â€œOh no, we went too fast and gotta clean some of this upâ€
"é€Ÿãå‹•ã„ã¦å£Šã™ "ã‚’ "ã‚ã‚ã€ãƒ€ãƒ¡ã ã€æ€¥ãã™ããŸã€‚

Okay, we know technical debt in software is bad, but the authors of this paper assert that technical debt for ML systems specifically is even worse.
ã•ã¦ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®æŠ€è¡“çš„è² å‚µãŒæ‚ªã„ã“ã¨ã¯åˆ†ã‹ã£ã¦ã„ã‚‹ãŒã€ã“ã®è«–æ–‡ã®è‘—è€…ã¯ã€ç‰¹ã«MLã‚·ã‚¹ãƒ†ãƒ ã®æŠ€è¡“çš„è² å‚µã¯ã•ã‚‰ã«æ‚ªã„ã¨ä¸»å¼µã—ã¦ã„ã‚‹ã€‚
The Tech Debt Paper proposes a few types of tech debt in ML, and for some of them a few solutions (like how there are different recycling bins, different types of garbage code need different approaches ğŸš®).
Tech Debt Paperã§ã¯ã€MLã«ãŠã‘ã‚‹æŠ€è¡“çš„è² å‚µã‚’ã„ãã¤ã‹ã®ã‚¿ã‚¤ãƒ—ã«åˆ†é¡ã—ã€ãã®ã†ã¡ã®ã„ãã¤ã‹ã«ã¤ã„ã¦è§£æ±ºç­–ã‚’æç¤ºã—ã¦ã„ã‚‹ï¼ˆãƒªã‚µã‚¤ã‚¯ãƒ«ç”¨ã®ã‚´ãƒŸç®±ãŒç•°ãªã‚‹ã‚ˆã†ã«ã€ç•°ãªã‚‹ã‚¿ã‚¤ãƒ—ã®ã‚´ãƒŸã‚³ãƒ¼ãƒ‰ã«ã¯ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã ğŸš®ï¼‰ã€‚
Given that the Tech Debt Paper was an opinion piece that was originally meant to get peopleâ€™s attention, itâ€™s important to note several pieces of advice from this work that may no longer be relevant, or may have better solutions in the modern day.
Tech Debt PaperãŒå…ƒã€…äººã€…ã®æ³¨ç›®ã‚’é›†ã‚ã‚‹ã“ã¨ã‚’æ„å›³ã—ãŸã‚ªãƒ”ãƒ‹ã‚ªãƒ³ãƒ»ãƒ”ãƒ¼ã‚¹ã§ã‚ã£ãŸã“ã¨ã‚’è€ƒãˆã‚‹ã¨ã€ã“ã®ä½œå“ã«ã‚ã‚‹ã„ãã¤ã‹ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã®ã†ã¡ã€ã‚‚ã¯ã‚„é©åˆ‡ã§ãªã„ã‹ã‚‚ã—ã‚Œãªã„ã‚‚ã®ã€ã‚ã‚‹ã„ã¯ç¾ä»£ã«ãŠã„ã¦ã‚ˆã‚Šè‰¯ã„è§£æ±ºç­–ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã‚‚ã®ã«æ³¨ç›®ã™ã‚‹ã“ã¨ã¯é‡è¦ã§ã‚ã‚‹ã€‚

## Part 1: ML tech debt is worse than you thought ãã®1 MLæŠ€è¡“è² å‚µã¯æƒ³åƒä»¥ä¸Šã«æ·±åˆ»

Youâ€™re all probably familiar by now with technical debt.
æŠ€è¡“çš„è² å‚µã«ã¤ã„ã¦ã¯ã€ã‚‚ã†çš†ã•ã‚“ã‚ˆãã”å­˜çŸ¥ã ã‚ã†ã€‚
The Tech Debt Paper starts with a clarification that by technical debt, weâ€™re not referring to adding new capabilities to existing code.
æŠ€è¡“çš„è² å‚µãƒšãƒ¼ãƒ‘ãƒ¼ã¯ã€æŠ€è¡“çš„è² å‚µã¨ã¯ã€æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã«æ–°ã—ã„æ©Ÿèƒ½ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã‚’æŒ‡ã—ã¦ã„ã‚‹ã®ã§ã¯ãªã„ã¨ã„ã†ã“ã¨ã‚’æ˜ç¢ºã«ã™ã‚‹ã“ã¨ã‹ã‚‰å§‹ã¾ã‚‹ã€‚
This is the less glamorous task of writing unit tests, improving readability, adding documentation, getting rid of unused sections, and other such tasks for the sake of making future development easier.
ã“ã‚Œã¯ã€å˜ä½“ãƒ†ã‚¹ãƒˆã‚’æ›¸ã„ãŸã‚Šã€å¯èª­æ€§ã‚’é«˜ã‚ãŸã‚Šã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã—ãŸã‚Šã€æœªä½¿ç”¨ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–ã‚Šé™¤ã„ãŸã‚Šã¨ã€å°†æ¥ã®é–‹ç™ºã‚’å®¹æ˜“ã«ã™ã‚‹ãŸã‚ã®ã€ã‚ã¾ã‚Šæ´¾æ‰‹ã§ã¯ãªã„ä»•äº‹ã§ã‚ã‚‹ã€‚
Well, since standard software engineering is a subset of the skills needed in machine learning engineering, more familiar software engineering tech debt is just a subset of the space of possible ML tech debt.
æ¨™æº–çš„ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã§å¿…è¦ã¨ã•ã‚Œã‚‹ã‚¹ã‚­ãƒ«ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã§ã‚ã‚‹ãŸã‚ã€ã‚ˆã‚Šèº«è¿‘ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®æŠ€è¡“è² å‚µã¯ã€MLæŠ€è¡“è² å‚µã®å¯èƒ½æ€§ã®ã‚ã‚‹ç©ºé–“ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã«éããªã„ã€‚

## Part 2: The Nebulous Nature of Machine Learning Part 2ï¼š æ©Ÿæ¢°å­¦ç¿’ã®æ›–æ˜§ãªæœ¬è³ª

The Tech Debt Paper section after the intro goes into detail about how the nebulous nature of machine learning models makes dealing with tech debt harder.
ã‚¤ãƒ³ãƒˆãƒ­ã®å¾Œã®ã€Œãƒ†ãƒƒã‚¯ãƒ»ãƒ‡ãƒƒãƒˆãƒ»ãƒšãƒ¼ãƒ‘ãƒ¼ã€ã§ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ›–æ˜§ãªæ€§è³ªãŒã€ãƒ†ãƒƒã‚¯ãƒ»ãƒ‡ãƒƒãƒˆã¸ã®å¯¾å‡¦ã‚’ã„ã‹ã«é›£ã—ãã—ã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦è©³ã—ãè¿°ã¹ã¦ã„ã‚‹ã€‚
A big part of avoiding or correcting technical debt is making sure the code is properly organized and segregated.
æŠ€è¡“çš„è² å‚µã‚’å›é¿ãƒ»ä¿®æ­£ã™ã‚‹ãŸã‚ã®å¤§ããªãƒã‚¤ãƒ³ãƒˆã¯ã€ã‚³ãƒ¼ãƒ‰ãŒé©åˆ‡ã«æ•´ç†ã•ã‚Œã€åˆ†é›¢ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã ã€‚
The fact is we often use machine learning in cases where precise rules or needs are super hard to specify in real code.
å®Ÿéš›ã®ã¨ã“ã‚ã€æ­£ç¢ºãªãƒ«ãƒ¼ãƒ«ã‚„ãƒ‹ãƒ¼ã‚ºã‚’å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ã§æŒ‡å®šã™ã‚‹ã®ãŒéå¸¸ã«é›£ã—ã„å ´åˆã«ã€æ©Ÿæ¢°å­¦ç¿’ã‚’ä½¿ã†ã“ã¨ãŒå¤šã„ã€‚
Instead of hardcoding the rules to turn data into outputs, more often than not weâ€™re trying to give an algorithm the data and the outputs (and sometimes not even that) to output the rules.
ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã«å¤‰ãˆã‚‹ãŸã‚ã«ãƒ«ãƒ¼ãƒ«ã‚’ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ã®ã§ã¯ãªãã€å¤šãã®å ´åˆã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ãƒ‡ãƒ¼ã‚¿ã¨ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’ä¸ãˆã¦ï¼ˆæ™‚ã«ã¯ãã‚Œã•ãˆã‚‚ï¼‰ãƒ«ãƒ¼ãƒ«ã‚’å‡ºåŠ›ã•ã›ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã€‚
We donâ€™t even know what the rules that need segregation and organizing are.
æ£²ã¿åˆ†ã‘ã‚„çµ„ç¹”åŒ–ãŒå¿…è¦ãªãƒ«ãƒ¼ãƒ«ãŒä½•ãªã®ã‹ã•ãˆã‚ã‹ã£ã¦ã„ãªã„ã€‚

Best Practice #1: Use interpretability/explainability tools.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãã®1ï¼š è§£é‡ˆå¯èƒ½æ€§/èª¬æ˜å¯èƒ½æ€§ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã€‚

This is where the problem of entanglement comes in.
ãã“ã§çµ¡ã¿ã®å•é¡ŒãŒå‡ºã¦ãã‚‹ã€‚
Basically, if you change anything about a model, you risk changing the performance of the whole system.
åŸºæœ¬çš„ã«ã€ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦ä½•ã‹ã‚’å¤‰æ›´ã™ã‚Œã°ã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤‰ã‚ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚‹ã€‚
For example, taking a 100-feature model on health records for individuals and adding a 101st feature (like, youâ€™re suddenly listing whether or not they smoked weed).
ä¾‹ãˆã°ã€å€‹äººã®å¥åº·è¨˜éŒ²ã«é–¢ã™ã‚‹100ã®æ©Ÿèƒ½ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã€101ç•ªç›®ã®æ©Ÿèƒ½ã‚’è¿½åŠ ã™ã‚‹ï¼ˆä¾‹ãˆã°ã€çªç„¶ãƒãƒªãƒ•ã‚¡ãƒŠã‚’å¸ã£ãŸã‹ã©ã†ã‹ã‚’åˆ—æŒ™ã™ã‚‹ï¼‰ã€‚
Everythingâ€™s connected.
ã™ã¹ã¦ãŒã¤ãªãŒã£ã¦ã„ã‚‹ã€‚
Itâ€™s almost like dealing with a chaotic system (ironically enough, a few mathematicians have tried to describe neural networks as chaotic attractors as though they were double pendulums or weather systems).
ã¾ã‚‹ã§ã‚«ã‚ªã‚¹ã‚·ã‚¹ãƒ†ãƒ ã‚’æ‰±ã£ã¦ã„ã‚‹ã‚ˆã†ã ï¼ˆçš®è‚‰ãªã“ã¨ã«ã€æ•°äººã®æ•°å­¦è€…ã¯ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ã‚«ã‚ªã‚¹ã‚¢ãƒˆãƒ©ã‚¯ã‚¿ãƒ¼ã¨ã—ã¦ã€ã‚ãŸã‹ã‚‚äºŒé‡æŒ¯ã‚Šå­ã‚„æ°—è±¡ã‚·ã‚¹ãƒ†ãƒ ã®ã‚ˆã†ã«è¡¨ç¾ã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ï¼‰ã€‚

The authors suggest a few possible fixes like ensembling models or high-dimensional visualization tools, but even these fall short if any of the ensembled model outputs are correlated, or if the data is too high-dimensional.
è‘—è€…ã‚‰ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚„é«˜æ¬¡å…ƒã®å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«ãªã©ã€ã„ãã¤ã‹ã®å¯èƒ½ãªè§£æ±ºç­–ã‚’ææ¡ˆã—ã¦ã„ã‚‹ãŒã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã®ã„ãšã‚Œã‹ã«ç›¸é–¢ãŒã‚ã‚‹å ´åˆã‚„ã€ãƒ‡ãƒ¼ã‚¿ãŒé«˜æ¬¡å…ƒã™ãã‚‹å ´åˆã¯ã€ã“ã‚Œã‚‰ã‚‚ä¸ååˆ†ã§ã‚ã‚‹ã€‚
A lot of the recommendations for interpretable ML are a bit vague.
è§£é‡ˆå¯èƒ½ãªMLã«é–¢ã™ã‚‹æè¨€ã®å¤šãã¯ã€å°‘ã—æ›–æ˜§ã ã€‚
With that in mind, I recommend checking out Facebookâ€™s high-dimensional visualization tool, as well as reading by far the best resource Iâ€™ve seen on interpretable machine learning: â€œInterpretable Machine Learningâ€ by Christoph Molnar (available online here)
ã“ã®ã“ã¨ã‚’å¿µé ­ã«ç½®ã„ã¦ã€ãƒ•ã‚§ã‚¤ã‚¹ãƒ–ãƒƒã‚¯ã®é«˜æ¬¡å…ƒå¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã“ã¨ã¨ã€è§£é‡ˆå¯èƒ½ãªæ©Ÿæ¢°å­¦ç¿’ã«ã¤ã„ã¦ç§ãŒè¦‹ãŸä¸­ã§æœ€é«˜ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’èª­ã‚€ã“ã¨ã‚’ãŠå‹§ã‚ã™ã‚‹ï¼š ã‚¯ãƒªã‚¹ãƒˆãƒ•ãƒ»ãƒ¢ãƒ«ãƒŠãƒ¼è‘—ã€Œè§£é‡ˆå¯èƒ½ãªæ©Ÿæ¢°å­¦ç¿’ã€ï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç‰ˆã¯ã“ã¡ã‚‰ï¼‰

Sometimes using more explainable model types, like decision trees, can help with this entanglement problem, but the juryâ€™s still out for best practices for solving this for Neural networks.
æ±ºå®šæœ¨ã®ã‚ˆã†ãªã€ã‚ˆã‚Šèª¬æ˜ã—ã‚„ã™ã„ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’ä½¿ã†ã“ã¨ã§ã€ã“ã®ã‚‚ã¤ã‚Œå•é¡Œã‚’è§£æ±ºã§ãã‚‹ã“ã¨ã‚‚ã‚ã‚‹ãŒã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ»ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«ã¤ã„ã¦ã¯ã€ã¾ã çµè«–ãŒå‡ºã¦ã„ãªã„ã€‚

Best Practice #2: Use explainable model types if possible.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãã®2ï¼š å¯èƒ½ã§ã‚ã‚Œã°ã€èª¬æ˜å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’ä½¿ç”¨ã™ã‚‹ã€‚

Correction Cascades are what happens when some of the inputs to your nebulous machine learning model are themselves nebulous machine learning models.
è£œæ­£ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ã¨ã¯ã€ã‚ãªãŸã®æ¼ ç„¶ã¨ã—ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ã®ä¸€éƒ¨ãŒã€ãã‚Œè‡ªä½“æ¼ ç„¶ã¨ã—ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹å ´åˆã«èµ·ã“ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã€‚
Itâ€™s just setting up this big domino rally of errors.
ãƒ‰ãƒŸãƒå€’ã—ã®ã‚ˆã†ãªå¤§å¤±æ•—ã‚’æ‹›ãã‹ã­ãªã„ã€‚
It is extremely tempting to set up sequences of models like this, for example, when applying a pre-existing model to a new domain (or a â€œstartup pivotâ€ as so many insist on calling it).
ä¾‹ãˆã°ã€æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ–°ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã«é©ç”¨ã™ã‚‹å ´åˆï¼ˆã‚ã‚‹ã„ã¯ã€å¤šãã®äººãŒãã†å‘¼ã¶ã€Œã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ãƒ»ãƒ”ãƒœãƒƒãƒˆã€ï¼‰ã€ã“ã®ã‚ˆã†ã«ä¸€é€£ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šã™ã‚‹ã“ã¨ã¯éå¸¸ã«é­…åŠ›çš„ã§ã‚ã‚‹ã€‚
You might have an unsupervised dimensionality reduction step right before your random forest, but changing the t-SNE parameters suddenly tanks the performance of the rest of the model.
ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®ç›´å‰ã«æ•™å¸«ãªã—æ¬¡å…ƒå‰Šæ¸›ã‚¹ãƒ†ãƒƒãƒ—ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒã€t-SNEã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã™ã‚‹ã¨ã€æ®‹ã‚Šã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒçªç„¶ä½ä¸‹ã™ã‚‹ã€‚
In the worst case scenario, itâ€™s impossible to improve any of the subcomponents without detracting from the performance of the entire system.
æœ€æ‚ªã®å ´åˆã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æãªã†ã“ã¨ãªãã€ã‚µãƒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã©ã‚Œã‹ã‚’æ”¹å–„ã™ã‚‹ã“ã¨ã¯ä¸å¯èƒ½ã ã€‚
Your machine learning pipeline goes from being positive sum to zero sum (thatâ€™s not a term from the Tech Debt Paper, I just felt like not adding it in was a missed opportunity).
ã‚ãªãŸã®æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ã€ãƒ—ãƒ©ã‚¹ãƒ»ã‚µãƒ ã‹ã‚‰ã‚¼ãƒ­ãƒ»ã‚µãƒ ã«ãªã‚‹ï¼ˆã“ã‚Œã¯Tech Debt Paperã®ç”¨èªã§ã¯ãªã„ã€‚ï¼‰

As far as preventing this, one of the better techniques is a variant of greedy unsupervised layer-wise pretraining (or GULP).
ã“ã‚Œã‚’é˜²ãæ–¹æ³•ã¨ã—ã¦ã¯ã€è²ªæ¬²ãªæ•™å¸«ãªã—å±¤åˆ¥äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆGULPï¼‰ã®å¤‰å½¢ãŒã‚ã‚‹ã€‚
Thereâ€™s still some disagreement on the mathematical reasons WHY this works so well, but basically you train the early models or early parts of your ensembles, freeze them, and then work your way up the rest of the sequence (again, not mentioning this in the Tech Debt Paper was another missed opportunity, especially since the technique has existed at least since 2007).
ãªãœã“ã‚ŒãŒã†ã¾ãæ©Ÿèƒ½ã™ã‚‹ã®ã‹ã€ãã®æ•°å­¦çš„ãªç†ç”±ã«ã¤ã„ã¦ã¯ã¾ã æ„è¦‹ãŒåˆ†ã‹ã‚Œã¦ã„ã‚‹ãŒã€åŸºæœ¬çš„ã«ã¯ã€åˆæœŸã®ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®åˆæœŸéƒ¨åˆ†ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ãã‚Œã‚’å‡çµã•ã›ã€ãã‚Œã‹ã‚‰ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®æ®‹ã‚Šã®éƒ¨åˆ†ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã„ãã®ã ï¼ˆç¹°ã‚Šè¿”ã—ã«ãªã‚‹ãŒã€æŠ€è¡“çš„è² å‚µè«–æ–‡ã§ã“ã®ã“ã¨ã«è§¦ã‚Œãªã‹ã£ãŸã®ã¯ã€ç‰¹ã«ã“ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã¯å°‘ãªãã¨ã‚‚2007å¹´ã‹ã‚‰å­˜åœ¨ã—ã¦ã„ãŸãŸã‚ã€ã¾ãŸã¨ãªã„æ©Ÿä¼šæå¤±ã ã£ãŸï¼‰ã€‚

Best Practice #3: Always re-train downstream models in order.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãã®3ï¼š ä¸‹æµã®ãƒ¢ãƒ‡ãƒ«ã¯å¸¸ã«é †ç•ªã«å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã€‚

Another inconvenient feature of machine learning models: more consumers might be relying on the outputs than you realize, beyond just other machine learning models.
æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ã‚‚ã†ä¸€ã¤ã®ä¸éƒ½åˆãªç‰¹å¾´ï¼š ä»–ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã ã‘ã§ãªãã€ã‚ãªãŸãŒæ€ã£ã¦ã„ã‚‹ä»¥ä¸Šã«å¤šãã®æ¶ˆè²»è€…ãŒãã®å‡ºåŠ›ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚
This is what the authors refer to as Undeclared Consumers.
ã“ã‚ŒãŒè‘—è€…ã®è¨€ã†ã€Œç„¡ç”³å‘Šæ¶ˆè²»è€…ã€ã§ã‚ã‚‹ã€‚
The issue here isnâ€™t that the output data is unstructured or not formatted right, itâ€™s that nobodyâ€™s taking stock of just how many systems depend on the outputs.
ã“ã“ã§å•é¡Œãªã®ã¯ã€å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ãŒæ§‹é€ åŒ–ã•ã‚Œã¦ã„ãªã„ã¨ã‹ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒé©åˆ‡ã§ãªã„ã¨ã‹ã„ã†ã“ã¨ã§ã¯ãªãã€ãã®å‡ºåŠ›ã«ã©ã‚Œã ã‘å¤šãã®ã‚·ã‚¹ãƒ†ãƒ ãŒä¾å­˜ã—ã¦ã„ã‚‹ã‹ã‚’èª°ã‚‚æŠŠæ¡ã—ã¦ã„ãªã„ã¨ã„ã†ã“ã¨ã ã€‚
For example, there are plenty of custom datasets on sites like Kaggle, many of which are themselves machine learning model outputs.
ä¾‹ãˆã°ã€Kaggleã®ã‚ˆã†ãªã‚µã‚¤ãƒˆã«ã¯ãŸãã•ã‚“ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã‚ã‚Šã€ãã®å¤šãã¯æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ãã®ã‚‚ã®ã§ã‚ã‚‹ã€‚
A lot of projects and startups will often use datasets like this to build and train their initial machine learning models in lieu of having internal datasets of their own.
å¤šãã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚„æ–°èˆˆä¼æ¥­ã¯ã€è‡ªç¤¾ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æŒã¤ä»£ã‚ã‚Šã«ã€ã“ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦æœ€åˆã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€è¨“ç·´ã™ã‚‹ã“ã¨ãŒå¤šã„ã€‚
Scripts and tasks that are dependent on these can find their data sources changing with little notice.
ã“ã‚Œã‚‰ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚„ã‚¿ã‚¹ã‚¯ã¯ã€æ°—ã¥ã‹ãªã„ã†ã¡ã«ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãŒå¤‰ã‚ã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚
The problem is compounded for APIs that donâ€™t require any kind of sign-in to access data.
ãƒ‡ãƒ¼ã‚¿ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã«ã‚µã‚¤ãƒ³ã‚¤ãƒ³ã‚’å¿…è¦ã¨ã—ãªã„APIã§ã¯ã€å•é¡Œã¯ã•ã‚‰ã«æ·±åˆ»ã«ãªã‚‹ã€‚
Unless you have some kind of barrier to entry for accessing the model outputs, like access keys or service-level agreements, this is a pretty tricky one to handle.
ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã‚„ã‚µãƒ¼ãƒ“ã‚¹ãƒ¬ãƒ™ãƒ«å¥‘ç´„ã®ã‚ˆã†ãªã€ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚ã®ä½•ã‚‰ã‹ã®éšœå£ãŒãªã„é™ã‚Šã€ã“ã‚Œã‚’æ‰±ã†ã®ã¯ã‹ãªã‚Šé›£ã—ã„ã€‚
You may be just saving your model outputs to a file, and then someone else on the team may decide to use those outputs for a model of their own because, hey, why not, the dataâ€™s in the shared directory.
ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦ãŠãã ã‘ã§ã€ãƒãƒ¼ãƒ ã®èª°ã‹ãŒãã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’è‡ªåˆ†ã®ãƒ¢ãƒ‡ãƒ«ã«ä½¿ãŠã†ã¨ã™ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚
Even if itâ€™s experimental code, you should be careful about whoâ€™s accessing model outputs that arenâ€™t verified yet.
ãŸã¨ãˆãã‚ŒãŒå®Ÿé¨“çš„ãªã‚³ãƒ¼ãƒ‰ã§ã‚ã£ã¦ã‚‚ã€ã¾ã æ¤œè¨¼ã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã«èª°ãŒã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‹ã«ã¯æ³¨æ„ã™ã¹ãã ã€‚
This tends to be a big problem with toolkits like JupyterLab (if I could go back in time and add any kind of warning to the Tech Debt Paper, it would be a warning about JupyterLab).
ã“ã‚Œã¯ã€JupyterLabã®ã‚ˆã†ãªãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã§ã¯å¤§ããªå•é¡Œã«ãªã‚ŠãŒã¡ã ï¼ˆéå»ã«ã•ã‹ã®ã¼ã£ã¦Tech Debt Paperã«ä½•ã‚‰ã‹ã®è­¦å‘Šã‚’åŠ ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã¨ã—ãŸã‚‰ã€ãã‚Œã¯JupyterLabã«ã¤ã„ã¦ã®è­¦å‘Šã ã‚ã†ï¼‰ã€‚

Basically fixing this type of technical debt involves cooperation between machine learning engineers and security engineers.
åŸºæœ¬çš„ã«ã€ã“ã®ç¨®ã®æŠ€è¡“çš„è² å‚µã‚’è§£æ±ºã™ã‚‹ã«ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®å”åŠ›ãŒå¿…è¦ã ã€‚

Best Practice #4: Set up access keys, directory permissions, and service-level-agreements.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãã®4ï¼š ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³ã€ã‚µãƒ¼ãƒ“ã‚¹ãƒ¬ãƒ™ãƒ«ã‚¢ã‚°ãƒªãƒ¼ãƒ¡ãƒ³ãƒˆã‚’è¨­å®šã™ã‚‹ã€‚

## Section 3: Data Dependencies (on top of regular dependencies) ã‚»ã‚¯ã‚·ãƒ§ãƒ³3ï¼š ãƒ‡ãƒ¼ã‚¿ä¾å­˜é–¢ä¿‚ (é€šå¸¸ã®ä¾å­˜é–¢ä¿‚ã®ä¸Šã«)

The third section goes a bit deeper with data dependency issues.
ç¬¬3ç¯€ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ä¾å­˜ã®å•é¡Œã‚’ã‚‚ã†å°‘ã—æ·±ãæ˜ã‚Šä¸‹ã’ã‚‹ã€‚
More bad news: in addition to the regular code dependencies of software engineering, machine learning systems will also depend on large data sources that are probably more unstable than the developers realize.
ã•ã‚‰ã«æ‚ªã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚‹ï¼š ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã«ãŠã‘ã‚‹é€šå¸¸ã®ã‚³ãƒ¼ãƒ‰ä¾å­˜ã«åŠ ãˆã€æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ãŠãã‚‰ãé–‹ç™ºè€…ãŒæ€ã£ã¦ã„ã‚‹ä»¥ä¸Šã«ä¸å®‰å®šãªå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã«ã‚‚ä¾å­˜ã™ã‚‹ã“ã¨ã«ãªã‚‹ã€‚

For example, your input data might take the form of a lookup table thatâ€™s changing underneath you, or a continuous data stream, or you might be using data from an API you donâ€™t even own.
ä¾‹ãˆã°ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã¯ãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚ˆã†ãªå½¢ã‹ã‚‚ã—ã‚Œãªã„ã—ã€é€£ç¶šçš„ãªãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‹ã‚‚ã—ã‚Œãªã„ã€‚
Imagine if the host of the MolNet dataset decided to update it with more accurate numbers (ignoring for a moment how they would do this for a moment).
ã‚‚ã—MolNetãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ›ã‚¹ãƒˆãŒã€ã‚ˆã‚Šæ­£ç¢ºãªæ•°å­—ã§æ›´æ–°ã™ã‚‹ã“ã¨ã‚’æ±ºã‚ãŸã¨ã—ãŸã‚‰ã©ã†ã ã‚ã†ï¼ˆå½¼ã‚‰ãŒã©ã®ã‚ˆã†ã«ã™ã‚‹ã®ã‹ã¯ã¡ã‚‡ã£ã¨ç„¡è¦–ã—ã¦ï¼‰ã€‚
While the data may reflect reality more accurately, countless models have been built against the old data, and many of the makers will suddenly find that their accuracy is tanking when they re-run a notebook that definitely worked just last week.
ãƒ‡ãƒ¼ã‚¿ã¯ç¾å®Ÿã‚’ã‚ˆã‚Šæ­£ç¢ºã«åæ˜ ã—ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒã€æ•°ãˆåˆ‡ã‚Œãªã„ã»ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒå¤ã„ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ä½œã‚‰ã‚Œã¦ãŠã‚Šã€ãƒ¡ãƒ¼ã‚«ãƒ¼ã®å¤šãã¯ã€å…ˆé€±ã¾ã§é–“é•ã„ãªãæ©Ÿèƒ½ã—ã¦ã„ãŸãƒãƒ¼ãƒˆã‚’å†å®Ÿè¡Œã™ã‚‹ã¨ã€çªç„¶ãã®ç²¾åº¦ãŒè½ã¡ã¦ã„ã‚‹ã“ã¨ã«æ°—ã¥ãã ã‚ã†ã€‚

One of the proposals by the authors is to use data dependency tracking tools like Photon for versioning.
è‘—è€…ã®ææ¡ˆã®ã²ã¨ã¤ã¯ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã®ãŸã‚ã«Photonã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ä¾å­˜æ€§è¿½è·¡ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†ã“ã¨ã ã€‚
That being said in 2020 we also have newer tools like DVC, which literally just stands for â€œData Version Controlâ€, that make Photon obsolete for the most part.
ã¨ã¯ã„ãˆã€2020å¹´ã«ã¯DVCï¼ˆæ–‡å­—é€šã‚Š "Data Version Control "ã®ç•¥ï¼‰ã®ã‚ˆã†ãªæ–°ã—ã„ãƒ„ãƒ¼ãƒ«ã‚‚ç™»å ´ã™ã‚‹ã€‚
It behaves much the same way as git, and saves a DAG keeping track of the changes in a dataset/database.
gitã¨ã»ã¼åŒã˜ã‚ˆã†ã«å‹•ä½œã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ/ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å¤‰æ›´ã‚’è¿½è·¡ã™ã‚‹DAGã‚’ä¿å­˜ã™ã‚‹ã€‚
Two other great tools to be used together for versioning are Streamlit (for keeping track of experiments and prototypes) and Netflixâ€™s Metaflow.
ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã®ãŸã‚ã«ä¸€ç·’ã«ä½¿ãˆã‚‹ä»–ã®2ã¤ã®ç´ æ™´ã‚‰ã—ã„ãƒ„ãƒ¼ãƒ«ã¯ã€Streamlitï¼ˆå®Ÿé¨“ã‚„ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã®è¿½è·¡ç”¨ï¼‰ã¨Netflixã®Metaflowã ã€‚
How much version control you do will come down to a tradeoff between extra memory and avoiding some giant gap in the training process.
ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚’ã©ã®ç¨‹åº¦è¡Œã†ã‹ã¯ã€ä½™åˆ†ãªãƒ¡ãƒ¢ãƒªã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°éç¨‹ã«ãŠã‘ã‚‹å·¨å¤§ãªã‚®ãƒ£ãƒƒãƒ—ã‚’é¿ã‘ã‚‹ã“ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«å¸°ç€ã™ã‚‹ã€‚
Still, insufficient or inappropriate versioning will lead to enormous survivorship bias (and thus wasted potential) when it comes to model training
ãã‚Œã§ã‚‚ãªãŠã€ä¸ååˆ†ã‚ã‚‹ã„ã¯ä¸é©åˆ‡ãªãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã¯ã€ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®éš›ã«è†¨å¤§ãªã‚µãƒã‚¤ãƒãƒ¼ã‚·ãƒƒãƒ—ãƒ»ãƒã‚¤ã‚¢ã‚¹ï¼ˆã¤ã¾ã‚Šæ½œåœ¨èƒ½åŠ›ã®æµªè²»ï¼‰ã«ã¤ãªãŒã‚‹ã€‚

Best Practice #5: Use a data versioning tool.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#5ï¼š ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã€‚

The data dependency horror show goes on.
ãƒ‡ãƒ¼ã‚¿ä¾å­˜ã®ææ€–ã®ã‚·ãƒ§ãƒ¼ã¯ç¶šãã€‚
Compared to the unstable data dependencies, the underutilized ones might not seem as bad, but thatâ€™s how they get you! Basically, you need to keep a lookout for data thatâ€™s unused, data that was once used but is considered legacy now, and data thatâ€™s redundant because itâ€™s heavily correlated with something else.
ä¸å®‰å®šãªãƒ‡ãƒ¼ã‚¿ä¾å­˜ã«æ¯”ã¹ã‚Œã°ã€ååˆ†ã«æ´»ç”¨ã•ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ã¯ãã‚Œã»ã©æ‚ªã„ã‚‚ã®ã«ã¯è¦‹ãˆãªã„ã‹ã‚‚ã—ã‚Œãªã„ï¼åŸºæœ¬çš„ã«ã¯ã€ä½¿ã‚ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿ã€ã‹ã¤ã¦ä½¿ã‚ã‚Œã¦ã„ãŸãŒä»Šã¯ãƒ¬ã‚¬ã‚·ãƒ¼ã¨ã¿ãªã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã€ä»–ã®ä½•ã‹ã¨å¤§ããç›¸é–¢ã—ã¦ã„ã‚‹ãŸã‚ã«å†—é•·ã«ãªã£ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã«æ³¨æ„ã‚’æ‰•ã†å¿…è¦ãŒã‚ã‚‹ã€‚
If youâ€™re managing a data pipeline where it turns out entire gigabytes are redundant, that will incur development costs on its own just as well.
ã‚®ã‚¬ãƒã‚¤ãƒˆå…¨ä½“ãŒå†—é•·ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç®¡ç†ã—ã¦ã„ã‚‹å ´åˆã€ãã‚Œã ã‘ã§é–‹ç™ºã‚³ã‚¹ãƒˆãŒç™ºç”Ÿã™ã‚‹ã€‚

The correlated data is especially tricky, because you need to figure out which variable is the correlated one, and which is the causative one.
ç›¸é–¢ã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ç‰¹ã«ã‚„ã£ã‹ã„ã§ã€ã©ã®å¤‰æ•°ãŒç›¸é–¢ã®ã‚ã‚‹ã‚‚ã®ã§ã€ã©ã®å¤‰æ•°ãŒå› æœã®ã‚ã‚‹ã‚‚ã®ã‹ã‚’è¦‹æ¥µã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‰ã ã€‚
This is a big problem in biological data.
ã“ã‚Œã¯ç”Ÿç‰©å­¦çš„ãƒ‡ãƒ¼ã‚¿ã§ã¯å¤§ããªå•é¡Œã§ã‚ã‚‹ã€‚
Tools like ANCOVA are increasingly outdated, and theyâ€™re unfortunately being used in scenarios where some of the ANCOVA assumptions definitely donâ€™t apply.
ANCOVAã®ã‚ˆã†ãªãƒ„ãƒ¼ãƒ«ã¯ã¾ã™ã¾ã™æ™‚ä»£é…ã‚Œã«ãªã£ã¦ãã¦ãŠã‚Šã€æ®‹å¿µãªã“ã¨ã«ANCOVAã®ä»®å®šãŒé–“é•ã„ãªãå½“ã¦ã¯ã¾ã‚‰ãªã„ã‚ˆã†ãªã‚·ãƒŠãƒªã‚ªã§ä½¿ã‚ã‚Œã¦ã„ã‚‹ã€‚
A few groups have tried proposing alternatives like ONION and Domain Aware Neural Networks, but many of these are improving upon fairly unimpressive standard approaches.
ONIONã‚„Domain Aware Neural Networkã®ã‚ˆã†ãªä»£æ›¿æ¡ˆã‚’ææ¡ˆã—ã‚ˆã†ã¨ã™ã‚‹ã‚°ãƒ«ãƒ¼ãƒ—ã‚‚ã„ãã¤ã‹ã‚ã‚‹ãŒã€ã“ã‚Œã‚‰ã®å¤šãã¯ã€ã‹ãªã‚Šå°è±¡ã®æ‚ªã„æ¨™æº–çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ”¹è‰¯ã—ãŸã‚‚ã®ã ã€‚
Some companies like Microsoft and QuantumBlack have come up with packages for causal disentanglement (DoWhy and CausalNex respectively).
ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆç¤¾ã‚„QuantumBlackç¤¾ã®ã‚ˆã†ã«ã€å› æœé–¢ä¿‚è§£æ˜ã®ãŸã‚ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆãã‚Œãã‚ŒDoWhyã¨CausalNexï¼‰ã‚’é–‹ç™ºã—ã¦ã„ã‚‹ä¼æ¥­ã‚‚ã‚ã‚‹ã€‚
Iâ€™m particularly fond of DeepMindâ€™s work on Bayesian Causal Reasoning.
ç§ã¯ãƒ‡ã‚£ãƒ¼ãƒ—ãƒã‚¤ãƒ³ãƒ‰ã®ãƒ™ã‚¤ã‚ºå› æœæ¨è«–ã«é–¢ã™ã‚‹ç ”ç©¶ãŒç‰¹ã«å¥½ãã ã€‚
Most of these were not around at the time of the Tech Debt Paperâ€™s writing, and many of these packages have their own usability debt, but itâ€™s important to make it known that ANCOVA is not a one-size-fits-all solution to this.
ã“ã‚Œã‚‰ã®ã»ã¨ã‚“ã©ã¯ã€Tech Debt PaperãŒæ›¸ã‹ã‚ŒãŸæ™‚ç‚¹ã§ã¯å­˜åœ¨ã—ã¦ãŠã‚‰ãšã€ã“ã‚Œã‚‰ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®å¤šãã«ã¯ç‹¬è‡ªã®ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£è² å‚µãŒã‚ã‚‹ãŒã€ANCOVAãŒã“ã‚Œã«å¯¾ã™ã‚‹ä¸‡èƒ½ã®è§£æ±ºç­–ã§ã¯ãªã„ã“ã¨ã‚’çŸ¥ã‚‰ã—ã‚ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ã€‚

Best Practice #6: Drop unused files, extraneous correlated features, and maybe use a causal inference toolkit.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãã®6ï¼š æœªä½¿ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ä½™è¨ˆãªç›¸é–¢ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ã‚’å‰Šé™¤ã—ã€å› æœæ¨è«–ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã€‚

Anyway, the authors were a bit less pessimistic about the fixes for these.
ã„ãšã‚Œã«ã›ã‚ˆã€è‘—è€…ã¯ã“ã‚Œã‚‰ã®ä¿®æ­£ã«ã¤ã„ã¦ã¯å°‘ã—æ‚²è¦³çš„ã§ã¯ãªã‹ã£ãŸã€‚
They suggested a static analysis of data dependencies, giving the one used by Google in their click-through predictions as an example.
å½¼ã‚‰ã¯ã€ã‚°ãƒ¼ã‚°ãƒ«ãŒã‚¯ãƒªãƒƒã‚¯ã‚¹ãƒ«ãƒ¼äºˆæ¸¬ã«ä½¿ç”¨ã—ã¦ã„ã‚‹ã‚‚ã®ã‚’ä¾‹ã«æŒ™ã’ã€ãƒ‡ãƒ¼ã‚¿ã®ä¾å­˜é–¢ä¿‚ã‚’é™çš„ã«åˆ†æã™ã‚‹ã“ã¨ã‚’ææ¡ˆã—ãŸã€‚
Since the Tech Debt Paper was published the pool of options for addressing this has grown a lot.
Tech Debt PaperãŒç™ºè¡¨ã•ã‚Œã¦ä»¥æ¥ã€ã“ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®é¸æŠè‚¢ã¯å¤§å¹…ã«å¢—ãˆãŸã€‚
For example, there are tools like Snorkel which lets you track which slices of data are being used for which experiments.
ä¾‹ãˆã°ã€Snorkelã®ã‚ˆã†ãªãƒ„ãƒ¼ãƒ«ãŒã‚ã‚Šã€ã©ã®ãƒ‡ãƒ¼ã‚¿ã®ã©ã®ã‚¹ãƒ©ã‚¤ã‚¹ãŒã©ã®å®Ÿé¨“ã«ä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ã‚’è¿½è·¡ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
Cloud Services like AWS and Azure have their own data dependency tracking services for DevOps, and thereâ€™s also tools like Red Gate SQL dependency tracker.
AWSã‚„Azureã®ã‚ˆã†ãªã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã¯ã€DevOpsã®ãŸã‚ã«ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ä¾å­˜æ€§è¿½è·¡ã‚µãƒ¼ãƒ“ã‚¹ã‚’æŒã£ã¦ã„ã‚‹ã—ã€Red Gate SQLä¾å­˜æ€§è¿½è·¡ãƒ„ãƒ¼ãƒ«ã®ã‚ˆã†ãªãƒ„ãƒ¼ãƒ«ã‚‚ã‚ã‚‹ã€‚
So, yeah, looks like the authors were justified in being optimistic about that one.
ã ã‹ã‚‰ã€è‘—è€…ãŸã¡ãŒã“ã®ä»¶ã«é–¢ã—ã¦æ¥½è¦³çš„ã§ã‚ã£ãŸã®ã¯æ­£å½“ã ã£ãŸã‚ˆã†ã ã€‚

Best Practice #7: Use any of the countless DevOps tools that track data dependencies.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãã®7ï¼š ãƒ‡ãƒ¼ã‚¿ã®ä¾å­˜é–¢ä¿‚ã‚’è¿½è·¡ã™ã‚‹ç„¡æ•°ã®DevOpsãƒ„ãƒ¼ãƒ«ã®ã„ãšã‚Œã‹ã‚’ä½¿ç”¨ã™ã‚‹ã€‚

## Part 4: Frustratingly undefinable feedback loops ï¼ƒãã®4ï¼å®šç¾©ã§ããªã„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ»ãƒ«ãƒ¼ãƒ—ã«è‹›ç«‹ã¤

Now we had a bit of a hope spot in the previous section, but the bad news doesnâ€™t just stop at data dependencies.
ã—ã‹ã—ã€æ‚ªã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯ãƒ‡ãƒ¼ã‚¿ä¾å­˜ã ã‘ã«ã¨ã©ã¾ã‚‰ãªã„ã€‚
Section 4 of the paper goes into how unchecked feedback loops can influence the machine learning development cycle.
æœ¬ç¨¿ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³4ã§ã¯ã€ãƒã‚§ãƒƒã‚¯ã•ã‚Œã¦ã„ãªã„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ»ãƒ«ãƒ¼ãƒ—ãŒæ©Ÿæ¢°å­¦ç¿’ã®é–‹ç™ºã‚µã‚¤ã‚¯ãƒ«ã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã‹ã«ã¤ã„ã¦è¿°ã¹ã‚‹ã€‚
This can both refer to direct feedback loops like in semi-supervised learning or reinforcement learning, or indirect loops like engineers basing their design choices off of another machine learning output.
ã“ã‚Œã¯ã€åŠæ•™å¸«ä»˜ãå­¦ç¿’ã‚„å¼·åŒ–å­¦ç¿’ã®ã‚ˆã†ãªç›´æ¥çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ»ãƒ«ãƒ¼ãƒ—ã‚’æŒ‡ã™å ´åˆã‚‚ã‚ã‚Œã°ã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒåˆ¥ã®æ©Ÿæ¢°å­¦ç¿’ã®å‡ºåŠ›ã«åŸºã¥ã„ã¦è¨­è¨ˆã®é¸æŠã‚’ã™ã‚‹ã‚ˆã†ãªé–“æ¥çš„ãªãƒ«ãƒ¼ãƒ—ã‚’æŒ‡ã™å ´åˆã‚‚ã‚ã‚‹ã€‚
This is one of the least defined issues in the Tech Debt Paper, but countless other organizations are working on this feedback loop problem, including what seems like the entirety of OpenAI (at least thatâ€™s what the â€œLong Term Safetyâ€ section of their charter, before all that â€œCapped Profitâ€ hubbub).
ã—ã‹ã—ã€OpenAIã®å…¨çµ„ç¹”ãŒã“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã®å•é¡Œã«å–ã‚Šçµ„ã‚“ã§ã„ã‚‹ã‚ˆã†ã ï¼ˆå°‘ãªãã¨ã‚‚ã€å½¼ã‚‰ã®æ†²ç« ã®ã€Œé•·æœŸçš„ãªå®‰å…¨æ€§ã€ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã€ã€Œåˆ©ç›Šã®ä¸Šé™ã€ã®é¨’å‹•ã®å‰ã«ãã†ãªã£ã¦ã„ã‚‹ï¼‰ã€‚
What Iâ€™m trying to say is that if youâ€™re going to be doing research on direct or indirect feedback loops, youâ€™ve got much better and more specific options than this paper.
ç§ãŒè¨€ã„ãŸã„ã®ã¯ã€ç›´æ¥çš„ã‚ã‚‹ã„ã¯é–“æ¥çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã®ç ”ç©¶ã‚’ã™ã‚‹ã®ã§ã‚ã‚Œã°ã€ã“ã®è«–æ–‡ã‚ˆã‚Šã‚‚ã‚‚ã£ã¨å…·ä½“çš„ã§è‰¯ã„é¸æŠè‚¢ãŒã‚ã‚‹ã¨ã„ã†ã“ã¨ã ã€‚

This one goes back on track with solutions that seem a bit more hopeless than the last section.
å‰ç¯€ã‚ˆã‚Šå°‘ã—çµ¶æœ›çš„ã¨æ€ãˆã‚‹è§£æ±ºç­–ã§è»Œé“ä¿®æ­£ã€‚
They give examples of bandit algorithms as being resistant to the direct feedback loops, but not only do those not scale, technical debt accumulates the most when youâ€™re trying to build systems at scale.
å½¼ã‚‰ã¯ã€ç›´æ¥çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ»ãƒ«ãƒ¼ãƒ—ã«å¼·ã„ã¨ã—ã¦ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆãƒ»ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ä¾‹ã‚’æŒ™ã’ã¦ã„ã‚‹ãŒã€ãã‚Œã¯ã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„ã ã‘ã§ãªãã€ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã‚ˆã†ã¨ã™ã‚‹ã¨ãã«æŠ€è¡“çš„è² å‚µãŒæœ€ã‚‚è“„ç©ã•ã‚Œã‚‹ã€‚
Useless.
å½¹ã«ç«‹ãŸãªã„ã€‚
The indirect feedback fixes arenâ€™t much better.
é–“æ¥çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ä¿®æ­£ã¯ã‚ã¾ã‚Šè‰¯ããªã„ã€‚
In fact, the systems in the indirect feedback loop might not even be part of the same organization.
å®Ÿéš›ã€é–“æ¥çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ»ãƒ«ãƒ¼ãƒ—ã«ã‚ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã¯ã€åŒã˜çµ„ç¹”ã«å±ã—ã¦ã„ãªã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚
This could be something like trading algorithms from different firms each trying to meta-game each other, but instead causing a flash crash.
ã“ã‚Œã¯ã€ç•°ãªã‚‹ä¼šç¤¾ã®å–å¼•ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒäº’ã„ã«ãƒ¡ã‚¿ã‚²ãƒ¼ãƒ ã‚’è©¦ã¿ã¦ã„ã‚‹ãŒã€ãã®ä»£ã‚ã‚Šã«ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚’å¼•ãèµ·ã“ã—ã¦ã„ã‚‹ã‚ˆã†ãªã‚‚ã®ã‹ã‚‚ã—ã‚Œãªã„ã€‚
Or a more relevant example in biotech, suppose you have a model thatâ€™s predicting the error likelihood for a variety of pieces of lab equipment.
ã‚ã‚‹ã„ã¯ã€ãƒã‚¤ã‚ªãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã«é–¢é€£ã—ãŸä¾‹ã¨ã—ã¦ã€ã•ã¾ã–ã¾ãªå®Ÿé¨“å™¨å…·ã®èª¤å·®ã®å¯èƒ½æ€§ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ã¨ã™ã‚‹ã€‚
As time goes on, the actual error rate could go down because people have become more practiced with it, or possibly up because the scientists are using the equipment more frequently, but the calibrations havenâ€™t increased in frequency to compensate.
æ™‚é–“ãŒçµŒã¤ã«ã¤ã‚Œã¦ã€å®Ÿéš›ã®èª¤å·®ç‡ã¯ã€äººã€…ãŒã‚ˆã‚Šæ…£ã‚Œè¦ªã—ã‚“ã ãŸã‚ã«ä¸‹ãŒã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã—ã€ç§‘å­¦è€…ãŒã‚ˆã‚Šé »ç¹ã«æ©Ÿå™¨ã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«ãªã£ãŸãŸã‚ã«ä¸ŠãŒã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒã€æ ¡æ­£ã®é »åº¦ã¯ãã‚Œã‚’è£œã†ã»ã©ã«ã¯å¢—ãˆã¦ã„ãªã„ã€‚
Ultimately, fixing this comes down to high-level design decisions, and making sure you check as many assumptions behind your modelâ€™s data (especially the independence assumption) as possible.
çµå±€ã®ã¨ã“ã‚ã€ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ã«ã¯ã€ãƒã‚¤ãƒ¬ãƒ™ãƒ«ãªè¨­è¨ˆä¸Šã®æ±ºå®šã¨ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã®èƒŒå¾Œã«ã‚ã‚‹ä»®å®šï¼ˆç‰¹ã«ç‹¬ç«‹æ€§ã®ä»®å®šï¼‰ã‚’ã§ãã‚‹ã ã‘å¤šãç¢ºèªã™ã‚‹ã“ã¨ã«å°½ãã‚‹ã€‚

This is also an area where many principles and practices from security engineering become very useful (e.g., tracking the flow of data throughout a system, searching for ways the system can be abused before bad actors can make use of them).
ã“ã‚Œã¯ã¾ãŸã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å¤šãã®åŸå‰‡ã¨å®Ÿè·µãŒéå¸¸ã«å½¹ç«‹ã¤åˆ†é‡ã§ã‚‚ã‚ã‚‹ï¼ˆä¾‹ãˆã°ã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿ã®æµã‚Œã‚’è¿½è·¡ã—ã€æ‚ªæ„ã‚ã‚‹è¡Œç‚ºè€…ãŒãã‚Œã‚’åˆ©ç”¨ã™ã‚‹å‰ã«ã€ã‚·ã‚¹ãƒ†ãƒ ãŒæ‚ªç”¨ã•ã‚Œã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹æ–¹æ³•ã‚’æ¢ç´¢ã™ã‚‹ï¼‰ã€‚

Best Practice #8: Check independence assumptions behind models (and work closely with security engineers).
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#8ï¼š ãƒ¢ãƒ‡ãƒ«ã®èƒŒå¾Œã«ã‚ã‚‹ç‹¬ç«‹æ€§ã®å‰ææ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¨ç·Šå¯†ã«é€£æºã™ã‚‹ï¼‰ã€‚

By now, especially after the ANCOVA comments, youâ€™re probably sensing a theme about testing assumptions.
ã•ã¦ã€ç‰¹ã«ANCOVAã®ã‚³ãƒ¡ãƒ³ãƒˆã®å¾Œã§ã¯ã€ä»®å®šã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã¨ã„ã†ãƒ†ãƒ¼ãƒã‚’æ„Ÿã˜ã¦ã„ã‚‹ã“ã¨ã ã‚ã†ã€‚
I wish this was something the authors devoted at least an entire section to.
ã›ã‚ã¦ä¸€ç¯€ã‚’å‰²ã„ã¦ã»ã—ã„ã‚‚ã®ã ã€‚

## Part 5: Common no-no patterns in your ML code ãƒ‘ãƒ¼ãƒˆ5ï¼š MLã‚³ãƒ¼ãƒ‰ã«ã‚ã‚ŠãŒã¡ãªNGãƒ‘ã‚¿ãƒ¼ãƒ³

The â€œAnti-patternsâ€ section of the Tech Debt Paper was a little more actionable than the last one.
Tech Debt Paperã® "Anti-patterns "ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã€å‰å›ã®ã‚‚ã®ã‚ˆã‚Šã‚‚å°‘ã—å®Ÿç”¨çš„ã ã£ãŸã€‚
This part went into higher-level patterns that are much-easier to spot than indirect-feedback loops.
ã“ã®ãƒ‘ãƒ¼ãƒˆã§ã¯ã€é–“æ¥çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«è¦‹ã¤ã‘ã‚„ã™ã„ã€ã‚ˆã‚Šé«˜åº¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã«è¸ã¿è¾¼ã‚“ã ã€‚

(This is actually a table from the Tech Debt Paper, but with hyperlinks to actionable advice on how to fix them.
(ã“ã®è¡¨ã¯ã€å®Ÿéš›ã«ã¯ã€ŒTech Debt Paperã€ã«æ²è¼‰ã•ã‚ŒãŸã‚‚ã®ã ãŒã€ã“ã‚Œã‚‰ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã¸ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯ãŒä»˜ã•ã‚Œã¦ã„ã‚‹ã€‚
This table was possibly redundant, as the authors discuss unique code smells and anti-patterns in ML, but these are all regular software engineering anti-patterns you should address in your code first.)
ã“ã®è¡¨ã¯ã€è‘—è€…ãŒMLã«ãŠã‘ã‚‹ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚³ãƒ¼ãƒ‰è‡­ã‚„ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã¤ã„ã¦è«–ã˜ã¦ã„ã‚‹ãŸã‚ã€ã‚‚ã—ã‹ã—ãŸã‚‰å†—é•·ã‹ã‚‚ã—ã‚Œãªã„ãŒã€ã“ã‚Œã‚‰ã¯ã™ã¹ã¦ã€ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã§æœ€åˆã«å¯¾å‡¦ã™ã¹ãã€é€šå¸¸ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚ã‚‹)ã€‚

The majority of these patterns revolve around the 90% or more of ML code thatâ€™s just maintaining the model.
ã“ã‚Œã‚‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¤§åŠã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’ç¶­æŒã™ã‚‹ã ã‘ã®MLã‚³ãƒ¼ãƒ‰ã®90ï¼…ä»¥ä¸Šã‚’ä¸­å¿ƒã«å±•é–‹ã•ã‚Œã‚‹ã€‚
This is the plumbing that most people in a Kaggle competition might think doesnâ€™t exist.
ã“ã‚Œã¯ã€Kaggleã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«å‚åŠ ã™ã‚‹ã»ã¨ã‚“ã©ã®äººãŒå­˜åœ¨ã—ãªã„ã¨æ€ã†ã‹ã‚‚ã—ã‚Œãªã„é…ç®¡ã§ã™ã€‚
Solving cell segmentation is a lot easier when youâ€™re not spending most of your time digging through the code connecting the Tecan Evo camera to your model input.
Tecan Evoã‚«ãƒ¡ãƒ©ã¨ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ã‚’æ¥ç¶šã™ã‚‹ã‚³ãƒ¼ãƒ‰ã«æ™‚é–“ã‚’è²»ã‚„ã™ã“ã¨ãŒãªã‘ã‚Œã°ã€ç´°èƒåˆ†å‰²ã‚’è§£ãã®ã¯ãšã£ã¨ç°¡å˜ã«ãªã‚‹ã€‚

Best Practice #9: Use regular code-reviews (and/or use automatic code-sniffing tools).
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#9ï¼š å®šæœŸçš„ãªã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å®Ÿæ–½ï¼ˆãŠã‚ˆã³ï¼ã¾ãŸã¯è‡ªå‹•ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒƒãƒ•ã‚£ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ï¼‰ã€‚

The first ML-anti-pattern introduced is called â€œglue codeâ€.
æœ€åˆã«ç´¹ä»‹ã—ãŸMLã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã€Œã‚°ãƒ«ãƒ¼ã‚³ãƒ¼ãƒ‰ã€ã¨å‘¼ã°ã‚Œã‚‹ã€‚
This is all the code you write when youâ€™re trying to fit data or tools from a general-purpose package into a super-specific model that you have.
ã“ã‚Œã¯ã€æ±ç”¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ„ãƒ¼ãƒ«ã‚’ã€ã‚ãªãŸãŒæŒã£ã¦ã„ã‚‹è¶…ç‰¹æ®Šãªãƒ¢ãƒ‡ãƒ«ã«é©åˆã•ã›ã‚ˆã†ã¨ã™ã‚‹ã¨ãã«æ›¸ãã‚³ãƒ¼ãƒ‰ã™ã¹ã¦ã ã€‚
Anyone thatâ€™s ever tried doing something with packages like RDKit knows what Iâ€™m talking about.
RDKitã®ã‚ˆã†ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ã£ã¦ä½•ã‹ã‚’ã—ã‚ˆã†ã¨ã—ãŸã“ã¨ãŒã‚ã‚‹äººãªã‚‰ã€ç§ãŒä½•ã‚’è¨€ã£ã¦ã„ã‚‹ã®ã‹ã‚ã‹ã‚‹ã ã‚ã†ã€‚
Basically, most of the stuff you shove into the utils.py file can count as this (everyone does it).
åŸºæœ¬çš„ã«ã€ã‚ãªãŸãŒutils.pyãƒ•ã‚¡ã‚¤ãƒ«ã«æŠ¼ã—è¾¼ã‚“ã ã‚‚ã®ã®ã»ã¨ã‚“ã©ã¯ã€ã“ã‚Œã¨ã—ã¦æ•°ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™(èª°ã‚‚ãŒã‚„ã£ã¦ã„ã¾ã™)ã€‚
These (hopefully) should be fixable by repackaging these dependencies as more specific API endpoints.
ã“ã‚Œã‚‰ã¯ï¼ˆã†ã¾ãã„ã‘ã°ï¼‰ã€ã“ã‚Œã‚‰ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚ˆã‚Šå…·ä½“çš„ãªAPIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦å†ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åŒ–ã™ã‚‹ã“ã¨ã§ä¿®æ­£ã§ãã‚‹ã¯ãšã ã€‚

Best Practice #10: Repackage general-purpose dependencies into specific APIs.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#10ï¼š æ±ç”¨çš„ãªä¾å­˜é–¢ä¿‚ã‚’ç‰¹å®šã®APIã«ãƒªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã™ã‚‹ã€‚

â€œPipeline junglesâ€ are a little bit tricker, as this is where a lot of glue code accumulates.
ã€Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ»ã‚¸ãƒ£ãƒ³ã‚°ãƒ«ã€ã¯å°‘ã—å„ä»‹ã§ã€ã“ã“ã«ã¯å¤šãã®æ¥ç€å‰¤ã‚³ãƒ¼ãƒ‰ãŒæºœã¾ã£ã¦ã„ã‚‹ã‹ã‚‰ã ã€‚
This is where all the transformations that you add for every little new data source piles up into an ugly amalgam.
ã“ã‚Œã¯ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ ã™ã‚‹ãŸã³ã«ã€ã™ã¹ã¦ã®å¤‰æ›ãŒç©ã¿é‡ãªã‚Šã€é†œã„ã‚¢ãƒãƒ«ã‚¬ãƒ ã«ãªã‚‹ã¨ã“ã‚ã ã€‚
Unlike with Glue Code, the authors pretty much recommend letting go and redesigning codebases like this from scratch.
Glue Codeã¨ã¯ç•°ãªã‚Šã€è‘—è€…ã¯ã“ã®ã‚ˆã†ãªã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã¯æ‰‹æ”¾ã—ã€ã‚¼ãƒ­ã‹ã‚‰å†è¨­è¨ˆã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¦ã„ã‚‹ã€‚
I want to say this is something that has more options nowadays, but when glue code turns into pipeline jungles even tools like Uberâ€™s Michelangelo can become part of the problem.
ã—ã‹ã—ã€ã‚°ãƒ«ãƒ¼ã‚³ãƒ¼ãƒ‰ãŒãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚¸ãƒ£ãƒ³ã‚°ãƒ«ã¨åŒ–ã™ã¨ã€ã‚¦ãƒ¼ãƒãƒ¼ã®ãƒŸã‚±ãƒ©ãƒ³ã‚¸ã‚§ãƒ­ã®ã‚ˆã†ãªãƒ„ãƒ¼ãƒ«ã§ã•ãˆã‚‚å•é¡Œã®ä¸€éƒ¨ã¨ãªã‚Šã†ã‚‹ã€‚

Of course, the advantage of the authorsâ€™ advice is that you can make this replacement code seem like an exciting new project with a cool name thatâ€™s also an obligatory Tolkien reference, like â€œBalrogâ€ (as yes, ignoring unfortunate implications of your project name isnâ€™t just Palantirâ€™s domain.
ã‚‚ã¡ã‚ã‚“ã€è‘—è€…ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã®åˆ©ç‚¹ã¯ã€ã“ã®ç½®ãæ›ãˆã‚³ãƒ¼ãƒ‰ã‚’ã€"Balrog "ã®ã‚ˆã†ãªãƒˆãƒ¼ãƒ«ã‚­ãƒ³ã®å¼•ç”¨ã‚’ç¾©å‹™ã¥ã‘ãŸã‚¯ãƒ¼ãƒ«ãªåå‰ã‚’æŒã¤ã€ã‚¨ã‚­ã‚µã‚¤ãƒ†ã‚£ãƒ³ã‚°ãªæ–°ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚ˆã†ã«è¦‹ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã ï¼ˆãã†ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã®ä¸å¹¸ãªæ„å‘³åˆã„ã‚’ç„¡è¦–ã™ã‚‹ã“ã¨ã¯ã€Palantirã ã‘ã®é ˜åŸŸã§ã¯ãªã„ã€‚
Youâ€™re free to do that as well).
ãã‚Œã‚‚è‡ªç”±ã ï¼‰ã€‚

Best Practice #11: Get rid of Pipeline jungles with top-down redesign/reimplementation.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#11ï¼š ãƒˆãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã®å†è¨­è¨ˆï¼å†å®Ÿè£…ã§ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚¸ãƒ£ãƒ³ã‚°ãƒ«ã‚’ãªãã™ã€‚

On the subject of letting go, experimental code.
æ‰‹æ”¾ã™ã¨ã„ã†ãƒ†ãƒ¼ãƒã§ã¯ã€å®Ÿé¨“çš„ãªã‚³ãƒ¼ãƒ‰ã€‚
Yes, you thought you could just save that experimental code for later.
ãã†ã€ã‚ãªãŸã¯ãã®å®Ÿé¨“çš„ãªã‚³ãƒ¼ãƒ‰ã‚’å¾Œã§ä¿å­˜ã™ã‚Œã°ã„ã„ã¨æ€ã£ã¦ã„ãŸã€‚
You thought you could just put it in an unused function or unreferenced file and it would be all fine.
æœªä½¿ç”¨ã®é–¢æ•°ã‚„å‚ç…§ã•ã‚Œãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã«å…¥ã‚Œã‚Œã°å•é¡Œãªã„ã¨æ€ã£ãŸã®ã ã‚ã†ã€‚
Unfortunately, stuff like this is part of why maintaining backwards compatibility can be such a pain in the neck.
æ®‹å¿µãªãŒã‚‰ã€ã“ã®ã‚ˆã†ãªã“ã¨ãŒå¾Œæ–¹äº’æ›æ€§ã‚’ç¶­æŒã™ã‚‹ã“ã¨ãŒé¦–ã®ç—›ããªã‚‹ç†ç”±ã®ä¸€éƒ¨ãªã®ã ã€‚
Anyone thatâ€™s taken a deep dive into the Tensorflow framework can see the remains of frameworks that were only partially absorbed, experimental code, or even incomplete â€œTODOâ€ code that was left for some other engineer to take care of at a later date.
Tensorflowãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«æ·±ãæ½œã£ãŸã“ã¨ã®ã‚ã‚‹äººãªã‚‰èª°ã§ã‚‚ã€éƒ¨åˆ†çš„ã«ã—ã‹å¸åã•ã‚Œãªã‹ã£ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€å®Ÿé¨“çš„ãªã‚³ãƒ¼ãƒ‰ã€ã‚ã‚‹ã„ã¯å¾Œæ—¥ä»–ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ä»»ã›ã‚‹ãŸã‚ã«æ®‹ã•ã‚ŒãŸä¸å®Œå…¨ãªã€ŒTODOã€ã‚³ãƒ¼ãƒ‰ã®æ®‹éª¸ã‚’è¦‹ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
You probably first came across these while trying to debug your mysteriously failing Tensorflow code.
ãŠãã‚‰ãã€è¬ã®å¤±æ•—ã‚’ã™ã‚‹Tensorflowã‚³ãƒ¼ãƒ‰ã‚’ãƒ‡ãƒãƒƒã‚°ã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã¨ãã«ã€åˆã‚ã¦ã“ã®ã‚ˆã†ãªã‚‚ã®ã«å‡ºä¼šã£ãŸã“ã¨ã ã‚ã†ã€‚
This certainly puts all the compatibility hiccups between Tensorflow 1.X and 2.X in a new light.
ã“ã®ã“ã¨ã¯ã€Tensorflow 1.Xã¨2.Xã®é–“ã®äº’æ›æ€§ã®å•é¡Œã‚’ã€æ–°ãŸãªè¦–ç‚¹ã§ã¨ã‚‰ãˆã‚‹ã“ã¨ã«ãªã‚‹ã€‚
Do yourself a favor, and donâ€™t put off pruning your codebase for 5 years.
è‡ªåˆ†ã®ãŸã‚ã«ã€ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®æ•´ç†ã‚’5å¹´ã‚‚å…ˆå»¶ã°ã—ã«ã—ãªã„ã“ã¨ã ã€‚
Keep doing experiments, but set some criteria for when to quarantine an experiment away from the rest of the code.
å®Ÿé¨“ã¯ç¶šã‘ã‚‹ãŒã€å®Ÿé¨“ã‚’ä»–ã®ã‚³ãƒ¼ãƒ‰ã‹ã‚‰éš”é›¢ã™ã‚‹ã¨ãã®åŸºæº–ã‚’æ±ºã‚ã¦ãŠãã“ã¨ã€‚

Best Practice #12: Set regular checks and criteria for removing code, or put the code in a directory or on a disk far-removed from the business-critical stuff.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#12ï¼š ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤ã™ã‚‹ãŸã‚ã®å®šæœŸçš„ãªãƒã‚§ãƒƒã‚¯ã¨åŸºæº–ã‚’è¨­å®šã™ã‚‹ã€‚ã¾ãŸã¯ã€ã‚³ãƒ¼ãƒ‰ã‚’ãƒ“ã‚¸ãƒã‚¹ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªã‚‚ã®ã‹ã‚‰é ãé›¢ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚„ãƒ‡ã‚£ã‚¹ã‚¯ã«ç½®ãã€‚

Speaking of old code, you know what software engineering has had for a while now? Really great abstractions! Everything from the concept of relational databases to views in web pages.
å¤ã„ã‚³ãƒ¼ãƒ‰ã¨ã„ãˆã°ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢å·¥å­¦ãŒã“ã“ã—ã°ã‚‰ãã®é–“æŒã£ã¦ã„ãŸã‚‚ã®ã‚’ã”å­˜çŸ¥ã ã‚ã†ã‹ï¼Ÿæœ¬å½“ã«ç´ æ™´ã‚‰ã—ã„æŠ½è±¡åŒ–ã ï¼ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ¦‚å¿µã‹ã‚‰ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã®ãƒ“ãƒ¥ãƒ¼ã¾ã§ã€ã™ã¹ã¦ãŒãã†ã ã€‚
There are entire branches of applied category theory devoted to figuring out the best ways to organize code like this.
å¿œç”¨ã‚«ãƒ†ã‚´ãƒªãƒ¼ç†è«–ã«ã¯ã€ã“ã®ã‚ˆã†ã«ã‚³ãƒ¼ãƒ‰ã‚’æ•´ç†ã™ã‚‹æœ€è‰¯ã®æ–¹æ³•ã‚’è§£æ˜ã™ã‚‹ã“ã¨ã«å°‚å¿µã™ã‚‹åˆ†é‡ãŒã‚ã‚‹ã€‚
You know what applied category theory hasnâ€™t quite caught up to yet? Thatâ€™s right, machine learning code organization.
å¿œç”¨ã‚«ãƒ†ã‚´ãƒªãƒ¼ç†è«–ãŒã¾ã è¿½ã„ã¤ã„ã¦ã„ãªã„ã‚‚ã®ã‚’ã”å­˜çŸ¥ã ã‚ã†ã‹ï¼Ÿãã†ã€æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰æ•´ç†ã ã€‚
Software engineering has had decades of throwing abstraction spaghetti at the wall and seeing what sticks.
ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢å·¥å­¦ã¯ã€ä½•åå¹´ã‚‚ã®é–“ã€æŠ½è±¡åŒ–ã‚¹ãƒ‘ã‚²ãƒƒãƒ†ã‚£ã‚’å£ã«æŠ•ã’ã¤ã‘ã€ä½•ãŒãã£ã¤ãã‹ã‚’è¦‹ã¦ããŸã€‚
Machine learning? Aside from Map-Reduce (which is like, not as impressive relational databases) or Async Parameter servers (which nobody can agree on how this should be done), or sync allreduce (which just sucks for most use-cases), we donâ€™t have much to show.
æ©Ÿæ¢°å­¦ç¿’ï¼ŸMap-Reduceï¼ˆã“ã‚Œã¯ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã»ã©å°è±¡çš„ã§ã¯ãªã„ï¼‰ã‚„éåŒæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»ã‚µãƒ¼ãƒãƒ¼ï¼ˆã“ã‚Œã¯ã©ã®ã‚ˆã†ã«è¡Œã†ã¹ãã‹èª°ã‚‚åŒæ„ã§ããªã„ï¼‰ã€sync allreduceï¼ˆã“ã‚Œã¯ã»ã¨ã‚“ã©ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«ã¨ã£ã¦æœ€æ‚ªã ï¼‰ã‚’é™¤ã‘ã°ã€ç§ãŸã¡ã¯ã‚ã¾ã‚Šè¦‹ã›ã‚‹ã‚‚ã®ãŒãªã„ã€‚

In fact, between groups doing research on random networks and Pytorch advertising how fluid the nodes in their neural networks are, Machine Learning has been throwing the abstraction spaghetti clean out the window! I donâ€™t think the authors realized that this problem was going to get MUCH worse as time went on.
å®Ÿéš›ã€ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ç ”ç©¶ã‚’ã—ã¦ã„ã‚‹ã‚°ãƒ«ãƒ¼ãƒ—ã¨ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒãƒ¼ãƒ‰ãŒã„ã‹ã«æµå‹•çš„ã§ã‚ã‚‹ã‹ã‚’å®£ä¼ã—ã¦ã„ã‚‹Pytorchã®é–“ã§ã€æ©Ÿæ¢°å­¦ç¿’ã¯æŠ½è±¡åŒ–ã•ã‚ŒãŸã‚¹ãƒ‘ã‚²ãƒƒãƒ†ã‚£ã‚’çª“ã®å¤–ã«æŠ•ã’æ¨ã¦ã¦ã„ã‚‹ï¼è‘—è€…ãŸã¡ã¯ã€ã“ã®å•é¡ŒãŒæ™‚é–“ãŒçµŒã¤ã«ã¤ã‚Œã¦éå¸¸ã«æ‚ªåŒ–ã—ã¦ã„ãã“ã¨ã«æ°—ã¥ã„ã¦ã„ãªã‹ã£ãŸã¨æ€ã†ã€‚
My recommendation? Read more of the literature on the popular high-level abstractions, and maybe donâ€™t use PyTorch for production code.
ç§ã®ãŠå‹§ã‚ã¯ï¼Ÿä¸€èˆ¬çš„ãªé«˜æ°´æº–æŠ½è±¡åŒ–æ©Ÿèƒ½ã«é–¢ã™ã‚‹æ–‡çŒ®ã‚’ã‚‚ã£ã¨èª­ã‚“ã§ã€PyTorchã‚’ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ã«ä½¿ã‚ãªã„ã“ã¨ã€‚

Best Practice #13: Stay up-to-date on abstractions that are becoming more solidified with time.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ç¬¬13å·ï¼š æ™‚é–“ã®çµŒéã¨ã¨ã‚‚ã«å›ºã¾ã‚Šã¤ã¤ã‚ã‚‹æŠ½è±¡åŒ–ã«ã¤ã„ã¦ã€å¸¸ã«æœ€æ–°ã®æƒ…å ±ã‚’å¾—ã‚‹ã“ã¨ã€‚

Iâ€™ve met plenty of senior machine learning engineers who have pet frameworks that they like to use for most problems.
ç§ã¯ã€å¤šãã®æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ä¼šã£ã¦ããŸãŒã€å½¼ã‚‰ã¯ã»ã¨ã‚“ã©ã®å•é¡Œã§ä½¿ç”¨ã™ã‚‹ãŠæ°—ã«å…¥ã‚Šã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æŒã£ã¦ã„ã‚‹ã€‚
Iâ€™ve also seen many of the same engineers watch their favorite framework fall to pieces when applied to a new context, or get replaced by another framework thatâ€™s functionally indistinguishable.
ã¾ãŸã€åŒã˜ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®å¤šããŒã€ãŠæ°—ã«å…¥ã‚Šã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒæ–°ã—ã„æ–‡è„ˆã«é©ç”¨ã•ã‚ŒãŸã¨ãã«ç²‰ã€…ã«ãªã£ãŸã‚Šã€æ©Ÿèƒ½çš„ã«è¦‹åˆ†ã‘ãŒã¤ã‹ãªã„åˆ¥ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«å–ã£ã¦ä»£ã‚ã‚‰ã‚ŒãŸã‚Šã™ã‚‹ã®ã‚’è¦‹ã¦ããŸã€‚
This is especially prevalent on teams doing anything with distributed machine learning.
ã“ã‚Œã¯ã€åˆ†æ•£å‹æ©Ÿæ¢°å­¦ç¿’ã‚’è¡Œã†ãƒãƒ¼ãƒ ã§ã¯ç‰¹ã«é¡•è‘—ã ã€‚
I want to make something absolutely clear:
ã¯ã£ãã‚Šã•ã›ã¦ãŠããŸã„ã“ã¨ãŒã‚ã‚‹ï¼š

Aside from MapReduce, you should avoid getting too attached to any single framework.
MapReduceã¯åˆ¥ã¨ã—ã¦ã€ç‰¹å®šã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«å›ºåŸ·ã—ã™ãã‚‹ã®ã¯é¿ã‘ã‚‹ã¹ãã ã€‚
If your â€œseniorâ€ machine learning engineer believes with all their being that Michelangelo is the beeâ€™s knees and will solve everything, theyâ€™re probably not all that senior.
ã‚‚ã—ã‚ãªãŸã® "ä¸Šç´š "æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒã€ãƒŸã‚±ãƒ©ãƒ³ã‚¸ã‚§ãƒ­ã“ããŒèœ‚ã®è†ã§ã‚ã‚Šã€ã™ã¹ã¦ã‚’è§£æ±ºã—ã¦ãã‚Œã‚‹ã¨å…¨èº«å…¨éœŠã§ä¿¡ã˜ã¦ã„ã‚‹ã®ã§ã‚ã‚Œã°ã€ãã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¯ãŠãã‚‰ãä¸Šç´šã§ã¯ãªã„ã ã‚ã†ã€‚
While ML engineering has matured, itâ€™s still relatively new.
MLã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯æˆç†Ÿã—ã¦ããŸã¨ã¯ã„ãˆã€ã¾ã æ¯”è¼ƒçš„æ–°ã—ã„ã€‚
An actually â€œseniorâ€ senior ML engineer will probably focus on making workflows that are framework agnostic, since they know most of those frameworks are not long for this world.
å®Ÿéš›ã« "ä¸Šç´š "ã®MLã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¯ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã¨ã‚‰ã‚ã‚Œãªã„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä½œã‚‹ã“ã¨ã«é›†ä¸­ã™ã‚‹ã ã‚ã†ã€‚
âš°ï¸
âš°ï¸

Now, the previous sections mentioned a bunch of distinct scenarios and qualities of technical debt in ML, but they also provide examples of higher-level anti-patterns for ML development.
ã•ã¦ã€ã“ã“ã¾ã§ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€MLã«ãŠã‘ã‚‹æŠ€è¡“çš„è² å‚µã®ã‚·ãƒŠãƒªã‚ªã¨æ€§è³ªã«ã¤ã„ã¦è¿°ã¹ã¾ã—ãŸãŒã€åŒæ™‚ã«MLé–‹ç™ºã«ãŠã‘ã‚‹ã‚ˆã‚Šé«˜åº¦ãªã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¾‹ã‚‚æŒ™ã’ã¾ã—ãŸã€‚

Most of you reading this have probably heard the phrase code-smells going around.
ã“ã‚Œã‚’èª­ã‚“ã§ã„ã‚‹ã»ã¨ã‚“ã©ã®äººã¯ã€ã‚³ãƒ¼ãƒ‰è‡­ãŒã™ã‚‹ã¨ã„ã†è¨€è‘‰ã‚’è€³ã«ã—ãŸã“ã¨ãŒã‚ã‚‹ã ã‚ã†ã€‚
Youâ€™ve probably used tools like good-smell or Pep8-auto-checking (or even the hot new Black auto-formatter that everyone is using on their production python code).
ã‚ãªãŸã¯ãŠãã‚‰ãgood-smellã‚„Pep8-auto-checkingã®ã‚ˆã†ãªãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ãŸã“ã¨ãŒã‚ã‚‹ã§ã—ã‚‡ã†ï¼ˆã‚ã‚‹ã„ã¯ã€èª°ã‚‚ãŒæœ¬ç•ªã®Pythonã‚³ãƒ¼ãƒ‰ã§ä½¿ã£ã¦ã„ã‚‹ãƒ›ãƒƒãƒˆãªæ–°ã—ã„Blackè‡ªå‹•æ•´å½¢ã‚‚ï¼‰ã€‚
Truth be told I donâ€™t like this term â€œcode smellâ€.
å®Ÿã‚’è¨€ã†ã¨ã€ç§ã¯ã“ã®ã€Œã‚³ãƒ¼ãƒ‰è‡­ã€ã¨ã„ã†è¨€è‘‰ãŒå¥½ãã§ã¯ãªã„ã€‚
â€œSmellâ€ always seems to imply something subtle, but the patterns described in the next section are pretty blatant.
ã€ŒåŒ‚ã„ã€ã¯å¸¸ã«å¾®å¦™ãªã‚‚ã®ã‚’æš—ç¤ºã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ãŒã€æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§èª¬æ˜ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã‹ãªã‚Šéœ²éª¨ã ã€‚
Nonetheless, the authors list a few types of code smells that indicate a high level of debt (beyond the usual types of code smells).
ãã‚Œã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€è‘—è€…ã¯ï¼ˆé€šå¸¸ã®ã‚³ãƒ¼ãƒ‰ãƒ»ã‚¹ãƒ¢ãƒ¼ã‚¯ã®ç¨®é¡ã‚’è¶…ãˆã¦ï¼‰é«˜æ°´æº–ã®è² å‚µã‚’ç¤ºã™ã‚³ãƒ¼ãƒ‰ãƒ»ã‚¹ãƒ¢ãƒ¼ã‚¯ã®ç¨®é¡ã‚’ã„ãã¤ã‹æŒ™ã’ã¦ã„ã‚‹ã€‚
For some reason, they only started listing the code-smells halfway into the section on code smells.
ã©ã†ã„ã†ã‚ã‘ã‹ã€å½¼ã‚‰ã¯ã‚³ãƒ¼ãƒ‰è‡­ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®é€”ä¸­ã‹ã‚‰ã—ã‹ã‚³ãƒ¼ãƒ‰è‡­ã‚’åˆ—æŒ™ã—ãªã‹ã£ãŸã€‚

The â€œPlain dataâ€ smell You may have code thatâ€™s dealing with a lot of data in the form of numpy floats.
ãƒ—ãƒ¬ãƒ¼ãƒ³ãªãƒ‡ãƒ¼ã‚¿ã€ã®åŒ‚ã„ numpyã®æµ®å‹•å°æ•°ç‚¹æ•°å½¢å¼ã§å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚
There may be little information preserved about the nature of the data, such as whether your RNA read counts represent samples from a Bernoulli distribution, or whether your float is a log of a number.
RNAãƒªãƒ¼ãƒ‰ã‚«ã‚¦ãƒ³ãƒˆãŒãƒ™ãƒ«ãƒŒãƒ¼ã‚¤åˆ†å¸ƒã‹ã‚‰ã®ã‚µãƒ³ãƒ—ãƒ«ãªã®ã‹ã€ãƒ•ãƒ­ãƒ¼ãƒˆãŒæ•°å€¤ã®å¯¾æ•°ãªã®ã‹ãªã©ã€ãƒ‡ãƒ¼ã‚¿ã®æ€§è³ªã«é–¢ã™ã‚‹æƒ…å ±ã¯ã»ã¨ã‚“ã©ä¿å­˜ã•ã‚Œã¦ã„ãªã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚
They donâ€™t mention this in the Tech Debt Paper, but this is one area where using typing in python can help out.
Tech Debt Paperã§ã¯è§¦ã‚Œã‚‰ã‚Œã¦ã„ãªã„ãŒã€ã“ã‚Œã¯ãƒ‘ã‚¤ã‚½ãƒ³ã§ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã‚’ä½¿ã†ã“ã¨ã§è§£æ±ºã§ãã‚‹åˆ†é‡ã ã€‚
Avoiding unnecessary use of floats, or floats with too much precision will go a long way.
ä¸å¿…è¦ãªæµ®ãè¼ªã®ä½¿ç”¨ã‚„ã€ç²¾åº¦ã®é«˜ã™ãã‚‹æµ®ãè¼ªã®ä½¿ç”¨ã¯é¿ã‘ã‚‹ã¹ãã ã‚ã†ã€‚
Again, using the built-in Decimal or Typing packages will help a lot (and not just for code navigation but also speedups on CPUs).
ç¹°ã‚Šè¿”ã—ã«ãªã‚‹ãŒã€çµ„ã¿è¾¼ã¿ã®Decimalãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚„Typingãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ã†ã“ã¨ã¯å¤§ã„ã«å½¹ç«‹ã¤ï¼ˆã‚³ãƒ¼ãƒ‰ã®ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã ã‘ã§ãªãã€CPUã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã«ã‚‚ã¤ãªãŒã‚‹ï¼‰ã€‚

Best Practice #14: Use packages like Typing and Decimal, and donâ€™t use â€˜float32â€™ for all data objects.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãã®14ï¼š Typingã‚„Decimalã®ã‚ˆã†ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã€ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«'float32'ã‚’ä½¿ç”¨ã—ãªã„ã“ã¨ã€‚

The â€œPrototypingâ€ smell Anyone thatâ€™s been in a hackathon knows that code slapped together in under 24 hours has a certain look to it.
ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã€ã®åŒ‚ã„ ãƒãƒƒã‚«ã‚½ãƒ³ã«å‚åŠ ã—ãŸã“ã¨ã®ã‚ã‚‹äººãªã‚‰èª°ã§ã‚‚ã€24æ™‚é–“ä»¥å†…ã«å©ãå‡ºã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã«ã¯ã‚ã‚‹ç¨®ã®è¦‹æ „ãˆãŒã‚ã‚‹ã“ã¨ã‚’çŸ¥ã£ã¦ã„ã‚‹ã€‚
This ties back into the unused experimental code mentioned earlier.
ã“ã‚Œã¯ã€å…ˆã«è¿°ã¹ãŸæœªä½¿ç”¨ã®å®Ÿé¨“çš„ã‚³ãƒ¼ãƒ‰ã¨é–¢é€£ã—ã¦ã„ã‚‹ã€‚
Yes, you might be all excited to try out the new PHATE dimensionality reduction tool for biological data, but either clean up your code or throw it out.
ç”Ÿç‰©å­¦çš„ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚ã®æ–°ã—ã„æ¬¡å…ƒå‰Šæ¸›ãƒ„ãƒ¼ãƒ«PHATEã‚’è©¦ã™ã“ã¨ã«èˆˆå¥®ã—ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒã€ã‚³ãƒ¼ãƒ‰ã‚’ãã‚Œã„ã«ã™ã‚‹ã‹ã€ãã‚Œã‚’æ¨ã¦ã‚‹ã‹ã®ã©ã¡ã‚‰ã‹ã ã€‚

Best Practice #15: Donâ€™t leave all works-in-progress in the same directory.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#15ï¼š ã™ã¹ã¦ã®ä»•æ›å“ã‚’åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç½®ã‹ãªã„ã€‚
Clean it up or toss it out.
æƒé™¤ã™ã‚‹ã‹æ¨ã¦ã‚‹ã‹ã ã€‚

The â€œMulti-languageâ€ smell Speaking of language typing, multi-language-codebases act almost like a multiplier for technical debt and make it pile up much faster.
å¤šè¨€èªã€è‡­ è¨€èªã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã«ã¤ã„ã¦è¨€ãˆã°ã€å¤šè¨€èªã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã¯æŠ€è¡“çš„è² å‚µã‚’å€å¢—ã•ã›ã‚‹ã‚ˆã†ãªã‚‚ã®ã§ã€è² å‚µã‚’ã‚ˆã‚Šæ—©ãç©ã¿ä¸Šã’ã‚‹ã“ã¨ã«ãªã‚‹ã€‚
Sure, these languages all have their benefits.
ç¢ºã‹ã«ã€ã“ã‚Œã‚‰ã®è¨€èªã«ã¯ã©ã‚Œã‚‚åˆ©ç‚¹ãŒã‚ã‚‹ã€‚
Python is great for building ideas fast.
Pythonã¯ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç´ æ—©ãæ§‹ç¯‰ã™ã‚‹ã®ã«é©ã—ã¦ã„ã‚‹ã€‚
JavaScript is great for interfaces.
JavaScriptã¯ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«æœ€é©ã ã€‚
C++ is great for graphics and making computations go fast.
C++ã¯ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚„è¨ˆç®—ã®é«˜é€ŸåŒ–ã«é©ã—ã¦ã„ã‚‹ã€‚
PHPâ€¦uhhhâ€¦okay maybe not that one.
PHPã¯......ã‚ã‚......ãã†ã‹ã‚‚ã—ã‚Œãªã„ã€‚
Golang is useful if youâ€™re working with kubernetes (and you work at Google).
Golangã¯ã€ã‚ãªãŸãŒkubernetesã‚’ä½¿ã£ã¦ä»•äº‹ã‚’ã—ã¦ã„ã‚‹ãªã‚‰ï¼ˆãã—ã¦ã‚ãªãŸãŒGoogleã§åƒã„ã¦ã„ã‚‹ãªã‚‰ï¼‰å½¹ã«ç«‹ã¤ã€‚
But if youâ€™re making these languages talk to each other there will be a lot of spots for things to go wrong, whether it be broken endpoints or memory leaks.
ã—ã‹ã—ã€ã“ã‚Œã‚‰ã®è¨€èªã‚’äº’ã„ã«ä¼šè©±ã•ã›ã‚‹ã®ã§ã‚ã‚Œã°ã€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ç ´æã‚„ãƒ¡ãƒ¢ãƒªãƒ¼ãƒªãƒ¼ã‚¯ãªã©ã€ã†ã¾ãã„ã‹ãªã„ç‚¹ãŒãŸãã•ã‚“å‡ºã¦ãã‚‹ã ã‚ã†ã€‚
At least in machine learning, there are a few toolkits like Spark and Tensorflow that have similar semantics between languages.
å°‘ãªãã¨ã‚‚æ©Ÿæ¢°å­¦ç¿’ã§ã¯ã€Sparkã‚„Tensorflowã®ã‚ˆã†ã«ã€è¨€èªé–“ã§ä¼¼ãŸã‚ˆã†ãªã‚»ãƒãƒ³ãƒ†ã‚£ã‚¯ã‚¹ã‚’æŒã¤ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆãŒã„ãã¤ã‹ã‚ã‚‹ã€‚
If you absolutely must use multiple languages, at least we now have that going for us post-2015.
ã©ã†ã—ã¦ã‚‚å¤šè¨€èªã‚’ä½¿ã„ãŸã„ã®ã§ã‚ã‚Œã°ã€å°‘ãªãã¨ã‚‚2015å¹´ä»¥é™ã¯ãã‚ŒãŒå¯èƒ½ã ã€‚

Best Practice #16: Make sure endpoints are accounted for, and use frameworks that have similar abstractions between languages.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#16ï¼š ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒè€ƒæ…®ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€è¨€èªé–“ã§åŒæ§˜ã®æŠ½è±¡åº¦ã‚’æŒã¤ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã™ã‚‹ã€‚

(Calling this a code-smell was a weird choice, as this is a pretty blatant pattern even by the standard of usual code-smells)
(é€šå¸¸ã®ã‚³ãƒ¼ãƒ‰è‡­ã®åŸºæº–ã‹ã‚‰ã—ã¦ã‚‚ã€ã“ã‚Œã¯ã‹ãªã‚Šéœ²éª¨ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãªã®ã§ã€ã“ã‚Œã‚’ã‚³ãƒ¼ãƒ‰è‡­ã¨å‘¼ã¶ã®ã¯å¥‡å¦™ãªé¸æŠã ã£ãŸï¼‰ã€‚

## Part 6: Configuration Debt (boring but easy to fix) ã‚³ãƒ³ãƒ•ã‚£ã‚®ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ãƒ‡ãƒƒãƒˆï¼ˆé€€å±ˆã ãŒç°¡å˜ã«è§£æ±ºã§ãã‚‹ï¼‰

The â€œConfiguration debtâ€ section of the Tech Debt Paper is probably the least exciting one, but the problem it describes is the easiest to fix.
Tech Debt Paperã® "Configuration debt "ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã€ãŠãã‚‰ãæœ€ã‚‚ã‚¨ã‚­ã‚µã‚¤ãƒ†ã‚£ãƒ³ã‚°ãªã‚‚ã®ã§ã¯ãªã„ãŒã€ãã“ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹å•é¡Œã¯æœ€ã‚‚ç°¡å˜ã«è§£æ±ºã§ãã‚‹ã‚‚ã®ã§ã‚ã‚‹ã€‚
Basically, this is just the practice of making sure all the tuneable and configurable information about your machine learning pipeline is in one place, and that you donâ€™t have to go searching through multiple directories just to figure out how many units your second LSTM layer had.
åŸºæœ¬çš„ã«ã€ã“ã‚Œã¯æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«é–¢ã™ã‚‹ã™ã¹ã¦ã®èª¿æ•´å¯èƒ½ã§è¨­å®šå¯èƒ½ãªæƒ…å ±ãŒ1ã¤ã®å ´æ‰€ã«ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€2ç•ªç›®ã®LSTMãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ¦ãƒ‹ãƒƒãƒˆæ•°ã‚’æŠŠæ¡ã™ã‚‹ãŸã‚ã ã‘ã«è¤‡æ•°ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢ã™ã‚‹å¿…è¦ãŒãªã„ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã ã€‚
Even if youâ€™ve gotten into the habit of creating config files, the packages and technologies havenâ€™t all caught up with you.
ã‚³ãƒ³ãƒ•ã‚£ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹ç¿’æ…£ãŒèº«ã«ã¤ã„ã¦ã„ãŸã¨ã—ã¦ã‚‚ã€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚„ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ãŒã™ã¹ã¦ã‚ãªãŸã«è¿½ã„ã¤ã„ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã€‚
Aside from some general principles, this part of the Tech Debt Paper doesnâ€™t go into too much detail.
ã„ãã¤ã‹ã®ä¸€èˆ¬åŸå‰‡ã‚’é™¤ã‘ã°ã€æŠ€è¡“è² å‚µå ±å‘Šæ›¸ã®ã“ã®éƒ¨åˆ†ã¯ã‚ã¾ã‚Šè©³ç´°ã«ã¯è§¦ã‚Œã¦ã„ãªã„ã€‚
I suspect that the authors of the Tech Debt Paper were more used to packages like Caffe (in which case yes, setting up configs with Caffe protobufs was objectively buggy and terrible).
Tech Debt Paperã®è‘—è€…ã¯ã€Caffeã®ã‚ˆã†ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«æ…£ã‚Œã¦ã„ãŸã®ã§ã¯ãªã„ã‹ã¨æ€ã†ï¼ˆãã®å ´åˆã€Caffeã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’ä½¿ã£ãŸã‚³ãƒ³ãƒ•ã‚£ã‚°è¨­å®šã¯ã€å®¢è¦³çš„ã«è¦‹ã¦ãƒã‚°ãŒå¤šãã€ã²ã©ã„ã‚‚ã®ã ã£ãŸï¼‰ã€‚

Personally, I would suggest using a framework like tf.Keras or Chainer if youâ€™re going to be setting up configuration files.
å€‹äººçš„ã«ã¯ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹ã®ã§ã‚ã‚Œã°ã€tf.Kerasã‚„Chainerã®ã‚ˆã†ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ã†ã“ã¨ã‚’ãŠå‹§ã‚ã™ã‚‹ã€‚
Most cloud services have some version of configuration management, but outside of that you should at least be prepared to use a config.json file or parameter flags in your code.
ã»ã¨ã‚“ã©ã®ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»ã‚µãƒ¼ãƒ“ã‚¹ã«ã¯ã€ä½•ã‚‰ã‹ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã‚³ãƒ³ãƒ•ã‚£ã‚®ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç®¡ç†ãŒã‚ã‚‹ãŒã€ãã‚Œä»¥å¤–ã§ã¯ã€å°‘ãªãã¨ã‚‚config.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‚„ã‚³ãƒ¼ãƒ‰å†…ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»ãƒ•ãƒ©ã‚°ã‚’ä½¿ã†æº–å‚™ã‚’ã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã€‚

Best Practice #17: Make it so you can set your file paths, hyperparameters, layer type and layer order, and other settings from one location.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãã®17ï¼š ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ç¨®é¡ã€ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®é †åºã€ãã®ä»–ã®è¨­å®šã‚’1ã‚«æ‰€ã§è¡Œãˆã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚

If youâ€™re going to be tuning these settings with a command line, try to use a package like Click instead of Argparse.
ã“ã‚Œã‚‰ã®è¨­å®šã‚’ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã§èª¿æ•´ã™ã‚‹ã®ã§ã‚ã‚Œã°ã€Argparseã®ä»£ã‚ã‚Šã«Clickã®ã‚ˆã†ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ã£ã¦ã¿ã¦ã»ã—ã„ã€‚

## Part 7: The real world dashing your dreams of solving this Part 7ï¼š è§£æ±ºã¸ã®å¤¢ã‚’æ‰“ã¡ç •ãç¾å®Ÿã®ä¸–ç•Œ

Section 7 acknowledges that a lot of managing tech debt is preparing for the fact that youâ€™re dealing with a constantly changing real world.
ç¬¬7ç« ã§ã¯ã€æŠ€è¡“çš„è² å‚µã‚’ç®¡ç†ã™ã‚‹ã“ã¨ã®å¤šããŒã€çµ¶ãˆãšå¤‰åŒ–ã™ã‚‹ç¾å®Ÿã®ä¸–ç•Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®æº–å‚™ã§ã‚ã‚‹ã“ã¨ã‚’èªã‚ã¦ã„ã‚‹ã€‚
For example, you might have a model where thereâ€™s some kind of decision threshold for converting a model output into a classification, or picking a True or False Boolean.
ä¾‹ãˆã°ã€ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’åˆ†é¡ã«å¤‰æ›ã™ã‚‹ãŸã‚ã®ã€ã‚ã‚‹ã„ã¯çœŸã‹å½ã®ãƒ–ãƒ¼ãƒ«å€¤ã‚’é¸ã¶ãŸã‚ã®ã€ã‚ã‚‹ç¨®ã®æ±ºå®šã—ãã„å€¤ãŒã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚
Any group or company that works with biological or health data is familiar with how diagnosis criteria can change rapidly.
ç”Ÿç‰©å­¦çš„ãƒ‡ãƒ¼ã‚¿ã‚„å¥åº·ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†å›£ä½“ã‚„ä¼æ¥­ã§ã‚ã‚Œã°ã€è¨ºæ–­åŸºæº–ãŒã„ã‹ã«æ€¥é€Ÿã«å¤‰åŒ–ã—ã†ã‚‹ã‹ã‚’ç†ŸçŸ¥ã—ã¦ã„ã‚‹ã€‚
You shouldnâ€™t assume the thresholds you work with will last forever, especially if youâ€™re doing anything with bayesian machine learning.
ç‰¹ã«ãƒ™ã‚¤ã‚¸ã‚¢ãƒ³æ©Ÿæ¢°å­¦ç¿’ã§ä½•ã‹ã‚’ã™ã‚‹ã®ã§ã‚ã‚Œã°ãªãŠã•ã‚‰ã ã€‚

Best Practice #18: Monitor the modelsâ€™ real-world performance and decision boundaries constantly.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãã®18ï¼š ãƒ¢ãƒ‡ãƒ«ã®å®Ÿä¸–ç•Œã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨æ„æ€æ±ºå®šã®å¢ƒç•Œã‚’å¸¸ã«ç›£è¦–ã™ã‚‹ã€‚

The section stresses the importance of real-time monitoring; I can definitely get behind this.
ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ»ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¦ã„ã‚‹ã€‚
As for which things to monitor, the paperâ€™s not a comprehensive guide but they give a few examples.
ã©ã®ã‚ˆã†ãªã“ã¨ã‚’ãƒ¢ãƒ‹ã‚¿ãƒ¼ã™ã¹ãã‹ã«ã¤ã„ã¦ã¯ã€ã“ã®è«–æ–‡ã¯åŒ…æ‹¬çš„ãªã‚¬ã‚¤ãƒ‰ã§ã¯ãªã„ãŒã€ã„ãã¤ã‹ã®ä¾‹ã‚’æŒ™ã’ã¦ã„ã‚‹ã€‚
One is to compare the summary statistics for your predicted labels with the summary statistics of the observed labels.
ä¸€ã¤ã¯ã€äºˆæ¸¬ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã®è¦ç´„çµ±è¨ˆé‡ã¨è¦³æ¸¬ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã®è¦ç´„çµ±è¨ˆé‡ã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
Itâ€™s not foolproof, but itâ€™s like checking a small animalâ€™s weight.
ç¢ºå®Ÿã§ã¯ãªã„ãŒã€å°å‹•ç‰©ã®ä½“é‡ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã‚ˆã†ãªã‚‚ã®ã ã€‚
If somethingâ€™s very wrong there, it can alert you to a separate problem very quickly.
ãã“ã«ä½•ã‹å¤§ããªå•é¡ŒãŒã‚ã‚Œã°ã€åˆ¥ã®å•é¡Œã‚’ç´ æ—©ãè­¦å‘Šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚

Best Practice #19: Make sure distribution of predicted labels is similar to distribution of observed labels.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#19ï¼š äºˆæ¸¬ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã®åˆ†å¸ƒãŒã€è¦³æ¸¬ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã®åˆ†å¸ƒã¨é¡ä¼¼ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚

If your system is making any kind of real-world decisions, you probably want to put some kind of rate limiter on it.
ã‚‚ã—ã‚ãªãŸã®ã‚·ã‚¹ãƒ†ãƒ ãŒå®Ÿä¸–ç•Œã§ä½•ã‚‰ã‹ã®æ±ºå®šã‚’ä¸‹ã™ã®ã§ã‚ã‚Œã°ã€ãŠãã‚‰ãä½•ã‚‰ã‹ã®ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒã‚¿ãƒ¼ã‚’ã‹ã‘ãŸã„ã ã‚ã†ã€‚
Even if your system is NOT being trusted with millions of dollars for bidding on stocks, even if itâ€™s just to alert you that somethingâ€™s not right with the cell culture incubators, you will regret not setting some kind of action limit per unit of time.
ãŸã¨ãˆã‚ãªãŸã®ã‚·ã‚¹ãƒ†ãƒ ãŒæ ªã®å…¥æœ­ã§ä½•ç™¾ä¸‡ãƒ‰ãƒ«ã‚‚ä»»ã•ã‚Œã¦ã„ãªãã¦ã‚‚ã€ç´°èƒåŸ¹é¤Šã‚¤ãƒ³ã‚­ãƒ¥ãƒ™ãƒ¼ã‚¿ãƒ¼ã«ä½•ã‹ç•°å¸¸ãŒã‚ã‚‹ã“ã¨ã‚’è­¦å‘Šã™ã‚‹ãŸã‚ã§ã‚ã£ã¦ã‚‚ã€å˜ä½æ™‚é–“ã‚ãŸã‚Šã®ä½•ã‚‰ã‹ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ¶é™ã‚’è¨­å®šã—ãªã‹ã£ãŸã“ã¨ã‚’å¾Œæ‚”ã™ã‚‹ã“ã¨ã«ãªã‚‹ã ã‚ã†ã€‚

Best Practice #20: Put limits on real-world decisions that can be made by machine learning systems.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#20ï¼š æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã§è¡Œãˆã‚‹ç¾å®Ÿä¸–ç•Œã®æ„æ€æ±ºå®šã«åˆ¶é™ã‚’è¨­ã‘ã‚‹ã€‚

You also want to be mindful of any changes with upstream producers of the data your ML pipeline is consuming.
ã¾ãŸã€MLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒæ¶ˆè²»ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®ä¸Šæµç”Ÿç”£è€…ã®å¤‰æ›´ã«ã‚‚æ³¨æ„ã—ãŸã„ã€‚
For example, any company running machine learning on human blood or DNA samples obviously wants to make sure those samples are all collected with a standardized procedure.
ä¾‹ãˆã°ã€äººé–“ã®è¡€æ¶²ã‚„DNAã‚µãƒ³ãƒ—ãƒ«ã‚’ä½¿ã£ã¦æ©Ÿæ¢°å­¦ç¿’ã‚’è¡Œã†ä¼æ¥­ã¯ã€å½“ç„¶ãªãŒã‚‰ã€ãã‚Œã‚‰ã®ã‚µãƒ³ãƒ—ãƒ«ãŒã™ã¹ã¦æ¨™æº–åŒ–ã•ã‚ŒãŸæ‰‹é †ã§æ¡å–ã•ã‚ŒãŸã‚‚ã®ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸã„ã€‚
If a bunch of samples are all coming from a certain demographic, the company should make sure that wonâ€™t skew their analysis.
å¤šãã®ã‚µãƒ³ãƒ—ãƒ«ãŒã™ã¹ã¦ç‰¹å®šã®å±¤ã‹ã‚‰å¾—ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã€ä¼æ¥­ã¯ãã‚ŒãŒåˆ†æã«æ­ªã¿ã‚’ä¸ãˆãªã„ã“ã¨ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
If youâ€™re doing some kind of single-cell sequencing on cultured human cells, you want to make sure youâ€™re not confusing cancer cells dying due to a drug working with, say, an intern accidentally letting the cell cultured dehydrate.
åŸ¹é¤Šã—ãŸãƒ’ãƒˆç´°èƒã®ã‚·ãƒ³ã‚°ãƒ«ã‚»ãƒ«ã‚·ãƒ¼ã‚¯ã‚¨ãƒ³ã‚·ãƒ³ã‚°ã‚’è¡Œã†å ´åˆã€ä¾‹ãˆã°ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ³ãŒåŸ¹é¤Šã—ãŸç´°èƒã‚’èª¤ã£ã¦è„±æ°´ã•ã›ã¦ã—ã¾ã„ã€è–¬å‰¤ãŒä½œç”¨ã—ã¦ãŒã‚“ç´°èƒãŒæ­»æ»…ã™ã‚‹ã®ã¨æ··åŒã—ãªã„ã‚ˆã†ã«ã—ãŸã„ã€‚
The authors say ideally you want a system that can respond to these changes (e.g., logging, turning itself off, changing decision thresholds, alert a technician or whomever does repairs) even when humans arenâ€™t available.
è‘—è€…ã«ã‚ˆã‚Œã°ã€ç†æƒ³çš„ã«ã¯ã€äººé–“ãŒåˆ©ç”¨ã§ããªã„ã¨ãã§ã‚‚ã€ã“ã®ã‚ˆã†ãªå¤‰åŒ–ã«å¯¾å¿œã§ãã‚‹ã‚·ã‚¹ãƒ†ãƒ ï¼ˆä¾‹ãˆã°ã€ãƒ­ã‚°ã‚’è¨˜éŒ²ã—ãŸã‚Šã€é›»æºã‚’åˆ‡ã£ãŸã‚Šã€åˆ¤å®šã—ãã„å€¤ã‚’å¤‰æ›´ã—ãŸã‚Šã€æŠ€è¡“è€…ã‚„ä¿®ç†æ‹…å½“è€…ã«è­¦å‘Šã‚’ç™ºã—ãŸã‚Šï¼‰ãŒæœ›ã¾ã—ã„ã¨ã„ã†ã€‚

Best Practice #21: Check assumptions behind input data.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#21ï¼š å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®èƒŒå¾Œã«ã‚ã‚‹ä»®å®šã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã€‚

## Part 8: The weirdly meta section ãã®8 å¥‡å¦™ãªãƒ¡ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³

The penultimate section of the Tech Debt Paper goes on to mention other areas.
Tech Debt Paperã®æœ€å¾Œã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã€ä»–ã®åˆ†é‡ã«ã¤ã„ã¦ã‚‚è¨€åŠã—ã¦ã„ã‚‹ã€‚
The authors previously mentioned failure of abstraction as a type of technical debt, and apparently that extends to the authors not being able to fit all these technical debt types into the first 7 sections of the paper.
è‘—è€…ã¯ä»¥å‰ã€æŠ€è¡“çš„è² å‚µã®ä¸€ç¨®ã¨ã—ã¦æŠ½è±¡åŒ–ã®å¤±æ•—ã‚’æŒ™ã’ãŸãŒã€ã©ã†ã‚„ã‚‰ãã‚Œã¯ã€ã“ã‚Œã‚‰ã®æŠ€è¡“çš„è² å‚µã‚¿ã‚¤ãƒ—ã‚’ã™ã¹ã¦è«–æ–‡ã®æœ€åˆã®7ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åã‚ã‚‹ã“ã¨ãŒã§ããªã‹ã£ãŸã“ã¨ã«ã¾ã§åŠã‚“ã§ã„ã‚‹ã‚ˆã†ã ã€‚

Sanity Checks
æ­£æ°—åº¦ãƒã‚§ãƒƒã‚¯

Moving on, itâ€™s critically important to have sanity checks on the data.
æ¬¡ã«ã€ãƒ‡ãƒ¼ã‚¿ã®å¥å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã“ã¨ãŒæ±ºå®šçš„ã«é‡è¦ã ã€‚
If youâ€™re training a new model, you want to make sure your model is at least capable of overfitting to one type of category in the data.
æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹å ´åˆã€ãƒ¢ãƒ‡ãƒ«ãŒå°‘ãªãã¨ã‚‚ãƒ‡ãƒ¼ã‚¿ã®1ç¨®é¡ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒˆã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸã„ã€‚
If itâ€™s not converging on anything, you might want to check that the data isnâ€™t random noise before tuning those hyperparameters.
ã‚‚ã—ä½•ã‚‚åæŸã—ãªã„ã®ã§ã‚ã‚Œã°ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã™ã‚‹å‰ã«ã€ãƒ‡ãƒ¼ã‚¿ãŒãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºã§ãªã„ã“ã¨ã‚’ç¢ºèªã—ãŸã»ã†ãŒã„ã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚
The authorâ€™s werenâ€™t that specific, but I figured that was a good test to mention.
è‘—è€…ã¯ãã‚Œã»ã©å…·ä½“çš„ã§ã¯ãªã‹ã£ãŸãŒã€ã“ã‚Œã¯è‰¯ã„ãƒ†ã‚¹ãƒˆã ã¨æ€ã£ãŸã€‚

Best Practice #22: Make sure your data isnâ€™t all noise and no signal by making sure your model is at least capable of overfitting.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#22ï¼š ãƒ¢ãƒ‡ãƒ«ãŒå°‘ãªãã¨ã‚‚ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒˆã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ãŒãƒã‚¤ã‚ºã°ã‹ã‚Šã§ã‚·ã‚°ãƒŠãƒ«ãŒãªã„ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚

Reproducibility
å†ç¾æ€§

Reproducibility.
å†ç¾æ€§ã€‚
Iâ€™m sure many of you on the research team have had a lot of encounters with this one.
ç ”ç©¶ãƒãƒ¼ãƒ ã®çš†ã•ã‚“ã®å¤šããŒã€ã“ã®ä»¶ã«é–¢ã—ã¦å¤šãã®å‡ºä¼šã„ã‚’çµŒé¨“ã—ã¦ã„ã‚‹ã“ã¨ã ã‚ã†ã€‚
Youâ€™ve probably seen code without seed numbers, notebooks written out of order, repositories without package versions.
ã‚·ãƒ¼ãƒ‰ç•ªå·ã®ãªã„ã‚³ãƒ¼ãƒ‰ã€é †ç•ªé€šã‚Šã«æ›¸ã‹ã‚Œã¦ã„ãªã„ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãªã„ãƒªãƒã‚¸ãƒˆãƒªãªã©ã‚’è¦‹ãŸã“ã¨ãŒã‚ã‚‹ã ã‚ã†ã€‚
Since the Tech Debt Paper was written a few have tried making reproducibility checklists.
Tech Debt PaperãŒæ›¸ã‹ã‚Œã¦ä»¥æ¥ã€ä½•äººã‹ãŒå†ç¾æ€§ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’ä½œã‚ã†ã¨ã—ã¦ã„ã‚‹ã€‚
Hereâ€™s a pretty good one that was featured on hacker news about 4 months ago.
4ãƒ¶æœˆã»ã©å‰ã«ãƒãƒƒã‚«ãƒ¼ãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹ã§ç´¹ä»‹ã•ã‚ŒãŸã€ãªã‹ãªã‹è‰¯ã„ã‚‚ã®ãŒã‚ã‚‹ã€‚

Best Practice #23: Use reproducibility checklists when releasing research code.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#23ï¼š ç ”ç©¶ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã™ã‚‹éš›ã«ã¯ã€å†ç¾æ€§ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã€‚

Process Management
ãƒ—ãƒ­ã‚»ã‚¹ç®¡ç†

Most of the types of technical debt discussed so far have referred to single machine learning models, but process management debt is what happens when youâ€™re running tons of models at the same time, and you donâ€™t have any plans for stopping all of them from waiting around for the one laggard to finish.
ã“ã‚Œã¾ã§è¿°ã¹ã¦ããŸæŠ€è¡“çš„è² å‚µã®ã»ã¨ã‚“ã©ã¯ã€å˜ä¸€ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦è¨€åŠã—ã¦ããŸã€‚ã—ã‹ã—ã€ãƒ—ãƒ­ã‚»ã‚¹ç®¡ç†è² å‚µã¨ã¯ã€å¤§é‡ã®ãƒ¢ãƒ‡ãƒ«ã‚’åŒæ™‚ã«å®Ÿè¡Œã—ã¦ã„ã‚‹ã¨ãã«èµ·ã“ã‚‹ã‚‚ã®ã§ã‚ã‚Šã€1ã¤ã®é…ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã®çµ‚äº†ã‚’å¾…ã¤ãŸã‚ã«ã€ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’åœæ­¢ã•ã›ã‚‹è¨ˆç”»ã‚’æŒã£ã¦ã„ãªã„ã€‚
Itâ€™s important not to ignore the system-level smells, also, this is where checking the runtimes of your models becomes extremely important.
ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã®åŒ‚ã„ã‚’ç„¡è¦–ã—ãªã„ã“ã¨ã‚‚é‡è¦ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã“ã¨ãŒéå¸¸ã«é‡è¦ã«ãªã‚‹ã€‚
Machine learning engineering is at least improving at thinking about high-level system design since the Tech Debt Paperâ€™s writing.
æ©Ÿæ¢°å­¦ç¿’å·¥å­¦ã¯ã€å°‘ãªãã¨ã‚‚ãƒ†ãƒƒã‚¯ãƒ»ãƒ‡ãƒƒãƒˆãƒ»ãƒšãƒ¼ãƒ‘ãƒ¼ã®åŸ·ç­†ä»¥æ¥ã€é«˜ãƒ¬ãƒ™ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã‚’è€ƒãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ãã¦ã„ã‚‹ã€‚

Best Practice #24: Make a habit of checking and comparing runtimes for machine learning models.
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#24ï¼š æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€æ¯”è¼ƒã™ã‚‹ç¿’æ…£ã‚’ã¤ã‘ã‚‹ã€‚

Cultural Debt
æ–‡åŒ–çš„è² å‚µ

Cultural debt is the really tricky type of debt.
æ–‡åŒ–çš„å‚µå‹™ã¯ã€æœ¬å½“ã«å„ä»‹ãªã‚¿ã‚¤ãƒ—ã®å‚µå‹™ã§ã‚ã‚‹ã€‚
The authors point out that sometimes thereâ€™s a divide between research and engineering, and that itâ€™s easier to encourage debt-correcting behavior in heterogeneous teams.
è‘—è€…ã‚‰ã¯ã€æ™‚ã¨ã—ã¦ç ”ç©¶ã¨ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®é–“ã«æºãŒã‚ã‚‹ã“ã¨ã€ç•°è³ªãªãƒãƒ¼ãƒ ã§ã¯è² å‚µã‚’ä¿®æ­£ã™ã‚‹è¡Œå‹•ã‚’å¥¨åŠ±ã—ã‚„ã™ã„ã“ã¨ã‚’æŒ‡æ‘˜ã—ã¦ã„ã‚‹ã€‚

Personally, Iâ€™m not exactly a fan of that last part.
å€‹äººçš„ã«ã¯ã€æœ€å¾Œã®éƒ¨åˆ†ã¯ã‚ã¾ã‚Šå¥½ãã§ã¯ãªã„ã€‚
Iâ€™ve witnessed many teams that have individuals that end up reporting to both the engineering directors and the research director.
ç§ã¯ã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼ã¨ãƒªã‚µãƒ¼ãƒãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼ã®ä¸¡æ–¹ã«å ±å‘Šã™ã‚‹ã“ã¨ã«ãªã‚‹å€‹äººãŒã„ã‚‹ãƒãƒ¼ãƒ ã‚’æ•°å¤šãç›®æ’ƒã—ã¦ããŸã€‚
Making a subset of the engineers report to two different branches without the authority to make needed changes is not a solution for technical debt.
å¿…è¦ãªå¤‰æ›´ã‚’è¡Œã†æ¨©é™ã®ãªã„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®ä¸€éƒ¨ã‚’2ã¤ã®ç•°ãªã‚‹æ”¯ç¤¾ã«å ±å‘Šã•ã›ã‚‹ã“ã¨ã¯ã€æŠ€è¡“çš„è² å‚µã®è§£æ±ºç­–ã«ã¯ãªã‚‰ãªã„ã€‚
Itâ€™s a solution insofar as a small subset of engineers take the brunt of the technical debt.
æŠ€è¡“çš„è² å‚µã®å¤§åŠã‚’ä¸€éƒ¨ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒè² ã†ã¨ã„ã†ç‚¹ã§ã¯ã€ã“ã‚Œã¯è§£æ±ºç­–ã ã€‚
The end result is that such engineers usually end up with No Authority Gauntlet Syndrome (NAGS), burn out, and are fired by whichever manager had the least of their objectives fulfilled by the engineer all while the most sympathetic managers are out at Burning Man.
ãã®çµæœã€ãã®ã‚ˆã†ãªã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¯é€šå¸¸ã€æ¨©å¨ãªãã‚¬ãƒ³ãƒˆãƒ¬ãƒƒãƒˆç—‡å€™ç¾¤ï¼ˆNAGSï¼‰ã«é™¥ã‚Šã€ç‡ƒãˆå°½ãã€æœ€ã‚‚åŒæƒ…çš„ãªãƒãƒã‚¸ãƒ£ãƒ¼ãŒãƒãƒ¼ãƒ‹ãƒ³ã‚°ãƒãƒ³ã«å‡ºã‹ã‘ã¦ã„ã‚‹é–“ã«ã€ãã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ã‚ˆã£ã¦æœ€ã‚‚ç›®çš„ã‚’æœãŸã›ãªã‹ã£ãŸãƒãƒã‚¸ãƒ£ãƒ¼ã«è§£é›‡ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚‹ã€‚
If heterogeneity helps, then it needs to be across the entire team.
ã‚‚ã—ç•°è³ªæ€§ãŒå½¹ã«ç«‹ã¤ã®ã§ã‚ã‚Œã°ã€ãã‚Œã¯ãƒãƒ¼ãƒ å…¨ä½“ã«ã‚ãŸã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚

Plus, I think the authors make some of the same mistakes many do when talking about team or company culture.
åŠ ãˆã¦ã€è‘—è€…ã¯ãƒãƒ¼ãƒ ã‚„ä¼æ¥­æ–‡åŒ–ã«ã¤ã„ã¦èªã‚‹ã¨ãã€å¤šãã®äººãŒçŠ¯ã™ã®ã¨åŒã˜é–“é•ã„ã‚’çŠ¯ã—ã¦ã„ã‚‹ã¨æ€ã†ã€‚
Specifically, confusing culture with values.
å…·ä½“çš„ã«ã¯ã€æ–‡åŒ–ã¨ä¾¡å€¤è¦³ã‚’æ··åŒã—ã¦ã„ã‚‹ã“ã¨ã ã€‚
Itâ€™s really easy to list a few aspirational rules for a company or team and call them a culture.
ä¼æ¥­ã‚„ãƒãƒ¼ãƒ ã®ãŸã‚ã«ã„ãã¤ã‹ã®ç†æƒ³çš„ãªãƒ«ãƒ¼ãƒ«ã‚’åˆ—æŒ™ã—ã€ãã‚Œã‚’æ–‡åŒ–ã¨å‘¼ã¶ã®ã¯å®Ÿã«ç°¡å˜ã ã€‚
You donâ€™t need an MBA to do that, but these are more values than actual culture.
ãã®ãŸã‚ã«MBAã¯å¿…è¦ãªã„ãŒã€ã“ã‚Œã¯å®Ÿéš›ã®æ–‡åŒ–ã¨ã„ã†ã‚ˆã‚Šä¾¡å€¤è¦³ã ã€‚
Culture is what people end up doing when theyâ€™re in situations that demand they choose between two otherwise weighted values.
æ–‡åŒ–ã¨ã¯ã€2ã¤ã®ä¾¡å€¤è¦³ã®ã©ã¡ã‚‰ã‹ã‚’é¸ã°ãªã‘ã‚Œã°ãªã‚‰ãªã„çŠ¶æ³ã«ç½®ã‹ã‚ŒãŸã¨ãã€äººã€…ãŒæœ€çµ‚çš„ã«ã¨ã‚‹è¡Œå‹•ã§ã‚ã‚‹ã€‚
This was what got Uber in so much trouble.
ã“ã‚ŒãŒã‚¦ãƒ¼ãƒãƒ¼ã‚’å¤§å•é¡Œã«å·»ãè¾¼ã‚“ã ã€‚
Both competitiveness and honesty were part of their corporate values, but in the end, their culture demanded they emphasized competitiveness over everything else, even if that meant HR violating laws to keep absolute creeps at the company.
ç«¶äº‰åŠ›ã¨èª å®Ÿã•ã®ä¸¡æ–¹ãŒä¼æ¥­ä¾¡å€¤ã®ä¸€éƒ¨ã§ã‚ã£ãŸãŒã€çµå±€ã®ã¨ã“ã‚ã€å½¼ã‚‰ã®ä¼æ¥­æ–‡åŒ–ã¯ã€ãŸã¨ãˆäººäº‹ãŒçµ¶å¯¾çš„ãªä¸æ°—å‘³ãªäººç‰©ã‚’ä¼šç¤¾ã«ç•™ã‚ã¦ãŠããŸã‚ã«æ³•å¾‹ã«é•åã™ã‚‹ã“ã¨ã«ãªã£ã¦ã‚‚ã€ä»–ã®ã™ã¹ã¦ã‚ˆã‚Šã‚‚ç«¶äº‰åŠ›ã‚’é‡è¦–ã™ã‚‹ã“ã¨ã‚’æ±‚ã‚ã¦ã„ãŸã€‚

The issue with tech debt is that it comes up in a similar situation.
æŠ€è¡“å€Ÿé‡‘ã®å•é¡Œã¯ã€åŒã˜ã‚ˆã†ãªçŠ¶æ³ã§å‡ºã¦ãã‚‹ã¨ã„ã†ã“ã¨ã ã€‚
Yes, itâ€™s easy to talk about how much you want maintainable code.
ãã†ã€ä¿å®ˆæ€§ã®é«˜ã„ã‚³ãƒ¼ãƒ‰ã‚’æ±‚ã‚ã‚‹ã®ã¯ç°¡å˜ã ã€‚
But, if everyoneâ€™s racing for a deadline, and writing documentation keeps getting shifted down in priority on the JIRA board, that debt is going to pile up despite your best efforts.
ã—ã‹ã—ã€å…¨å“¡ãŒç· ã‚åˆ‡ã‚Šã«è¿½ã‚ã‚Œã€JIRAãƒœãƒ¼ãƒ‰ä¸Šã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆã®å„ªå…ˆé †ä½ãŒã©ã‚“ã©ã‚“ä¸‹ãŒã£ã¦ã„ãã‚ˆã†ã§ã¯ã€æœ€å–„ã‚’å°½ãã—ã¦ã‚‚è² å‚µãŒç©ã¿é‡ãªã£ã¦ã„ãã“ã¨ã«ãªã‚‹ã€‚

Best Practice #25: Set aside regular, non-negotiable time for dealing with technical debt (whatever form it might take).
ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹#25ï¼š æŠ€è¡“çš„è² å‚µï¼ˆãã‚ŒãŒã©ã®ã‚ˆã†ãªå½¢ã§ã‚ã‚Œï¼‰ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®ã€å®šæœŸçš„ã§è­²ã‚Œãªã„æ™‚é–“ã‚’ç¢ºä¿ã™ã‚‹ã€‚

## Part 9: A technical debt litmus test ãƒ‘ãƒ¼ãƒˆ9 æŠ€è¡“çš„è² å‚µã®ãƒªãƒˆãƒã‚¹è©¦é¨“ç´™

Itâ€™s important to remember that the â€˜debtâ€™ part is just a metaphor.
å€Ÿé‡‘ã€ã¨ã„ã†éƒ¨åˆ†ã¯å˜ãªã‚‹æ¯”å–©ã§ã‚ã‚‹ã“ã¨ã‚’å¿˜ã‚Œã¦ã¯ãªã‚‰ãªã„ã€‚
As much as the authors try to make this seem like something that has more rigor, thatâ€™s all it is.
è‘—è€…ãŒã“ã‚Œã‚’ã‚ˆã‚Šå³å¯†ãªã‚‚ã®ã®ã‚ˆã†ã«è¦‹ã›ã‹ã‘ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ãŒã€ãã‚Œã ã‘ã ã€‚
Unlike most debts, machine learning technical debt is something thatâ€™s hard to measure.
ä»–ã®è² å‚µã¨ã¯ç•°ãªã‚Šã€æ©Ÿæ¢°å­¦ç¿’ã®æŠ€è¡“çš„è² å‚µã¯æ¸¬å®šãŒé›£ã—ã„ã‚‚ã®ã ã€‚
How fast your team is moving at any given time is usually a poor indicator of how much you have (despite what many fresh-out-of-college product managers seem to insist).
ã‚ã‚‹æ™‚ç‚¹ã§ãƒãƒ¼ãƒ ãŒã©ã‚Œãã‚‰ã„ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã§å‹•ã„ã¦ã„ã‚‹ã‹ã¯ã€ï¼ˆå¤šãã®å¤§å­¦å‡ºãŸã¦ã®ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒã‚¸ãƒ£ãƒ¼ãŒä¸»å¼µã—ã¦ã„ã‚‹ã‚ˆã†ã ãŒï¼‰é€šå¸¸ã€è‡ªåˆ†ãŒã©ã‚Œã ã‘ã®ã‚‚ã®ã‚’æŒã£ã¦ã„ã‚‹ã‹ã®æŒ‡æ¨™ã«ã¯ãªã‚‰ãªã„ã€‚
Rather than a metric, the authors suggest 5 questions to ask yourself (paraphrased for clarity here):
æŒ‡æ¨™ã¨ã„ã†ã‚ˆã‚Šã‚‚ã€è‘—è€…ã¯è‡ªå•ã™ã¹ã5ã¤ã®è³ªå•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ï¼ˆã“ã“ã§ã¯ã‚ã‹ã‚Šã‚„ã™ãã™ã‚‹ãŸã‚ã«è¨€ã„æ›ãˆãŸï¼‰ï¼š

How long would it take to get an algorithm from an arbitrary NeurIPS paper running on your biggest data source?
ä»»æ„ã®NeurIPSè«–æ–‡ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ã€ã‚ãªãŸã®æœ€å¤§ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ä¸Šã§å®Ÿè¡Œã•ã›ã‚‹ã«ã¯ã€ã©ã‚Œãã‚‰ã„ã®æ™‚é–“ãŒã‹ã‹ã‚‹ã ã‚ã†ã‹ï¼Ÿ

Which data dependencies touch the most (or fewest) parts of your code?
ã‚³ãƒ¼ãƒ‰ã®ã©ã®éƒ¨åˆ†ã«ã€ã©ã®ãƒ‡ãƒ¼ã‚¿ä¾å­˜æ€§ãŒæœ€ã‚‚å¤šãï¼ˆã‚ã‚‹ã„ã¯æœ€ã‚‚å°‘ãªãï¼‰è§¦ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ

How much can you predict the outcome of changing one part of your system?
ã‚·ã‚¹ãƒ†ãƒ ã®ä¸€éƒ¨åˆ†ã‚’å¤‰æ›´ã—ãŸå ´åˆã®çµæœã‚’ã©ã‚Œã ã‘äºˆæ¸¬ã§ãã‚‹ã‹ï¼Ÿ

Is your ML model improvement system zero-sum or positive sum?
MLãƒ¢ãƒ‡ãƒ«ã®æ”¹å–„ã‚·ã‚¹ãƒ†ãƒ ã¯ã‚¼ãƒ­ã‚µãƒ ã‹ã€ãã‚Œã¨ã‚‚ãƒ—ãƒ©ã‚¹ã‚µãƒ ã‹ï¼Ÿ

Do you even have documentation? Is there a lot of hand-holding through the ramping up process for new-people?
æ–‡æ›¸ã¯ã‚ã‚‹ã®ã‹ï¼Ÿæ–°äººã®ç«‹ã¡ä¸Šã’éç¨‹ã§ã¯ã€æ‰‹å–ã‚Šè¶³å–ã‚Šæ•™ãˆã¦ãã‚Œã¾ã™ã‹ï¼Ÿ

Of course, since 2015, other articles and papers have tried coming up with more precise scoring mechanisms (like scoring rubrics).
ã‚‚ã¡ã‚ã‚“ã€2015å¹´ä»¥é™ã€ä»–ã®è«–æ–‡ã‚„è¨˜äº‹ã§ã‚‚ï¼ˆæ¡ç‚¹åŸºæº–ãªã©ï¼‰ã‚ˆã‚Šæ­£ç¢ºãªæ¡ç‚¹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒè©¦ã¿ã‚‰ã‚Œã¦ã„ã‚‹ã€‚
Some of these have the benefit of being able to create an at-a-glance scoring mechanisms that even if imprecise will help you track technical debt over time.
ã“ã‚Œã‚‰ã®ä¸­ã«ã¯ã€ãŸã¨ãˆä¸æ­£ç¢ºã§ã‚ã£ãŸã¨ã—ã¦ã‚‚ã€æŠ€è¡“çš„è² å‚µã‚’é•·æœŸã«ã‚ãŸã£ã¦è¿½è·¡ã™ã‚‹ã®ã«å½¹ç«‹ã¤ã€ä¸€ç›®ã§ã‚ã‹ã‚‹ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä½œæˆã§ãã‚‹ã¨ã„ã†åˆ©ç‚¹ãŒã‚ã‚‹ã‚‚ã®ã‚‚ã‚ã‚‹ã€‚
Also, thereâ€™s been a ton of advancements in the Interpretable ML tools that were extolled as a solution to some types of technical debt.
ã¾ãŸã€ã‚ã‚‹ç¨®ã®æŠ€è¡“çš„è² å‚µã‚’è§£æ±ºã™ã‚‹ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦ç§°è³›ã•ã‚ŒãŸInterpretable MLãƒ„ãƒ¼ãƒ«ã«ã‚‚å¤§ããªé€²æ­©ãŒã‚ã£ãŸã€‚
With that in mind, Iâ€™m going to recommend â€œInterpretable Machine Learningâ€ by Christoph Molnar (available online here) again.
ãã‚Œã‚’å¿µé ­ã«ç½®ã„ã¦ã€ã‚¯ãƒªã‚¹ãƒˆãƒ•ãƒ»ãƒ¢ãƒ«ãƒŠãƒ¼è‘—ã€è§£é‡ˆå¯èƒ½ãªæ©Ÿæ¢°å­¦ç¿’ã€ï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç‰ˆã¯ã“ã¡ã‚‰ï¼‰ã‚’å†åº¦æ¨è–¦ã—ã¦ãŠã“ã†ã¨æ€ã†ã€‚

## The 25 Best Practices in one place 25ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’ä¸€æŒ™å…¬é–‹

Here are all the Best Practices I mentioned throughout in one spot.
ã“ã“ã§ã¯ã€ç§ãŒã“ã‚Œã¾ã§è¿°ã¹ã¦ããŸãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’ä¸€ç®‡æ‰€ã«ã¾ã¨ã‚ã¦ç´¹ä»‹ã™ã‚‹ã€‚
There are likely many more than this, but tools for fixing technical debt follow the Pareto Principle: 20% of the technical debt remedies can fix 80% of your problems.
ã“ã‚Œä»¥å¤–ã«ã‚‚ãŸãã•ã‚“ã‚ã‚‹ã ã‚ã†ãŒã€æŠ€è¡“çš„è² å‚µã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã¯ãƒ‘ãƒ¬ãƒ¼ãƒˆã®åŸå‰‡ã«å¾“ã£ã¦ã„ã‚‹ï¼š æŠ€è¡“çš„è² å‚µã®20ï¼…ã‚’æ”¹å–„ã™ã‚Œã°ã€å•é¡Œã®80ï¼…ã‚’è§£æ±ºã§ãã‚‹ã€‚

Use interpretability tools like SHAP values
SHAPå€¤ã®ã‚ˆã†ãªè§£é‡ˆå¯èƒ½æ€§ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†

Use explainable model types if possible
å¯èƒ½ã§ã‚ã‚Œã°ã€èª¬æ˜å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’ä½¿ç”¨ã™ã‚‹

Always re-train downstream models
å¸¸ã«ä¸‹æµãƒ¢ãƒ‡ãƒ«ã‚’å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹

Set up access keys, directory permissions, and service-level-agreements.
ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³ã€ã‚µãƒ¼ãƒ“ã‚¹ãƒ¬ãƒ™ãƒ«ã‚¢ã‚°ãƒªãƒ¼ãƒ¡ãƒ³ãƒˆã‚’è¨­å®šã™ã‚‹ã€‚

Use a data versioning tool.
ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã€‚

Drop unused files, extraneous correlated features, and maybe use a causal inference toolkit.
æœªä½¿ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ä½™è¨ˆãªç›¸é–¢ç‰¹å¾´ã‚’å‰Šé™¤ã—ã€å› æœæ¨è«–ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã€‚

Use any of the countless DevOps tools that track data dependencies.
ãƒ‡ãƒ¼ã‚¿ã®ä¾å­˜é–¢ä¿‚ã‚’è¿½è·¡ã™ã‚‹ç„¡æ•°ã®DevOpsãƒ„ãƒ¼ãƒ«ã®ã„ãšã‚Œã‹ã‚’ä½¿ç”¨ã™ã‚‹ã€‚

Check independence assumptions behind models (and work closely with security engineers.
ãƒ¢ãƒ‡ãƒ«ã®èƒŒå¾Œã«ã‚ã‚‹ç‹¬ç«‹æ€§ã®ä»®å®šã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¨ç·Šå¯†ã«é€£æºã™ã‚‹ï¼‰ã€‚

Use regular code-reviews (and/or use automatic code-sniffing tools).
å®šæœŸçš„ã«ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã†ï¼ˆã‚ã‚‹ã„ã¯è‡ªå‹•ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒƒãƒ•ã‚£ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†ï¼‰ã€‚

Repackage general-purpose dependencies into specific APIs.
æ±ç”¨ã®ä¾å­˜é–¢ä¿‚ã‚’ç‰¹å®šã®APIã«ãƒªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã™ã‚‹ã€‚

Get rid of Pipeline jungles with top-down redesign/reimplementation.
ãƒˆãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã®å†è¨­è¨ˆï¼å†å®Ÿè£…ã§ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚¸ãƒ£ãƒ³ã‚°ãƒ«ã‚’ãªãã™ã€‚

Set regular checks and criteria for removing code, or put the code in a directory or on a disk far-removed from the business-critical stuff.
ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤ã™ã‚‹ãŸã‚ã®å®šæœŸçš„ãªãƒã‚§ãƒƒã‚¯ã¨åŸºæº–ã‚’è¨­å®šã™ã‚‹ã‹ã€ãƒ“ã‚¸ãƒã‚¹ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªã‚‚ã®ã‹ã‚‰é ãé›¢ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚„ãƒ‡ã‚£ã‚¹ã‚¯ã«ã‚³ãƒ¼ãƒ‰ã‚’ç½®ãã€‚

Stay up-to-date on abstractions that are becoming more solidified with time
æ™‚ä»£ã¨ã¨ã‚‚ã«å›ºã¾ã‚Šã¤ã¤ã‚ã‚‹æŠ½è±¡åŒ–ã«ã¤ã„ã¦ã€å¸¸ã«æœ€æ–°ã®æƒ…å ±ã‚’å…¥æ‰‹ã™ã‚‹ã€‚

Use packages like Typing and Decimal, and donâ€™t use â€˜float32â€™ for all data objects
Typingã‚„Decimalã®ã‚ˆã†ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ã„ã€ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ãƒ»ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«'float32'ã‚’ä½¿ã‚ãªã„ã€‚

Donâ€™t leave all works-in-progress in the same directory.
ã™ã¹ã¦ã®ä»•æ›å“ã‚’åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç½®ã„ã¦ã¯ã„ã‘ãªã„ã€‚
Clean it up or toss it out.
æƒé™¤ã™ã‚‹ã‹æ¨ã¦ã‚‹ã‹ã ã€‚

Make sure endpoints are accounted, and use frameworks that have similar abstractions between languages
ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒèª¬æ˜ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€è¨€èªé–“ã§åŒæ§˜ã®æŠ½è±¡åŒ–ã‚’æŒã¤ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã™ã‚‹ã€‚

Make it so you can set your file paths, hyperparameters, layer type and layer order, and other settings from one location
ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ç¨®é¡ã€ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®é †åºã€ãã®ä»–ã®è¨­å®šã‚’1ã‚«æ‰€ã§è¡Œãˆã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

Monitor the modelsâ€™ real-world performance and decision boundaries constantly
ãƒ¢ãƒ‡ãƒ«ã®å®Ÿä¸–ç•Œã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨æ„æ€æ±ºå®šã®å¢ƒç•Œã‚’å¸¸ã«ç›£è¦–ã™ã‚‹ã€‚

Make sure distribution of predicted labels is similar to distribution of observed labels
äºˆæ¸¬ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã®åˆ†å¸ƒãŒã€è¦³æ¸¬ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã®åˆ†å¸ƒã¨é¡ä¼¼ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚

Put limits on real-world decisions that can be made by machine learning systems
æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹ç¾å®Ÿä¸–ç•Œã®åˆ¤æ–­ã«åˆ¶é™ã‚’è¨­ã‘ã‚‹

Check assumptions behind input data
å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å‰ææ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹

Make sure your data isnâ€™t all noise and no signal by making sure your model is at least capable of overfitting
ãƒ¢ãƒ‡ãƒ«ãŒå°‘ãªãã¨ã‚‚ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒˆãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ãŒãƒã‚¤ã‚ºã°ã‹ã‚Šã§ã‚·ã‚°ãƒŠãƒ«ãŒãªã„ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã€‚

Use reproducibility checklists when releasing research code
ç ”ç©¶ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã™ã‚‹éš›ã«ã¯ã€å†ç¾æ€§ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã€‚

Make a habit of checking and comparing runtimes for machine learning models
æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€æ¯”è¼ƒã™ã‚‹ç¿’æ…£ã‚’ã¤ã‘ã‚‹ã€‚

Set aside regular, non-negotiable time for dealing with technical debt (whatever form it might take)
æŠ€è¡“çš„è² å‚µï¼ˆãã‚ŒãŒã©ã®ã‚ˆã†ãªå½¢ã§ã‚ã‚Œï¼‰ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®ã€å®šæœŸçš„ã§è­²ã‚Œãªã„æ™‚é–“ã‚’ç¢ºä¿ã™ã‚‹ã€‚