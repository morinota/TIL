refs: https://liuzhenglaichn.gitbook.io/system-design/news-feed/design-a-news-feed-system

# Design a News Feed System ニュースフィードシステムの設計

All the social media sites have some sort of news feed system, like those in Facebook, Twitter, Instagram, Quora, and Medium. 
すべてのソーシャルメディアサイトには、Facebook、Twitter、Instagram、Quora、Mediumなどのニュースフィードシステムの何らかの形態があります。

News feed is a list of posts with text, image, or video generated by other entities in the system tailored for you to read. 
ニュースフィードは、システム内の他のエンティティによって生成されたテキスト、画像、または動画を含む投稿のリストであり、あなたが読むためにカスタマイズされています。
It's constantly updating while other entities creating new posts. 
**他のエンティティが新しい投稿を作成する間、ニュースフィードは常に更新されています。**

<!-- ここまで読んだ -->

## Requirement 要件  

### Functional requirement 機能要件  

1. News feed is generated using the posts from other entities in the system that the user followed or the user might be interested in.  
1. ニュースフィードは、ユーザがフォローしているシステム内の他のエンティティからの投稿や、ユーザが興味を持つ可能性のある投稿を使用して生成されます。  
2. Posts might have text, image and video.  
2. 投稿にはテキスト、画像、動画が含まれる場合があります。  
3. The new posts generated by others should be appended to the news feed of the user.  
3. 他のユーザによって生成された新しい投稿は、ユーザのニュースフィードに追加されるべきです。  

<!-- ここまで読んだ -->

### Non-functional requirement 非機能要件

1. News feed generation: should happen near-real-time. 
   ニュースフィードの生成：ほぼリアルタイムで行われるべきです。
   The latency seen by the end user should be just 1~2 seconds.
   エンドユーザーが感じる遅延は1〜2秒であるべきです。

2. Appending new post: After a new post is sent to the system, it shouldn't take more than 5 seconds to be able to show up in a news feed request.
   **新しい投稿の追加：新しい投稿がシステムに送信された後、ニュースフィードのリクエストに表示されるまでに5秒以上かかるべきではありません。**
   (=つまり、ストリーミングで投稿の特徴量を生成 + リアルタイム推論でランキング生成の仕組みが必要...!:thinking:)

<!-- ここまで読んだ -->

## Capacity Estimation 容量推定

(このあたりのキャパシティの推定の手順とか考え方とか、参考になりそう...!:thinking:)

> During the fourth quarter of 2019, Facebook reported almost 1.66 billion daily active users (DAU). 
2019年第4四半期に、Facebookは**約16.6億のデイリーアクティブユーザー（DAU）**を報告しました。
>Overall, daily active users accounted for 66 percent of monthly active users. 
全体として、**デイリーアクティブユーザーはマンスリーアクティブユーザーの66％を占めて**います。
>With over 2.5 billion monthly active users, Facebook is the most popular social network worldwide. 
**25億を超えるマンスリーアクティブユーザー**を持つFacebookは、世界で最も人気のあるソーシャルネットワークです。
https://www.statista.com/statistics/346167/facebook-global-dau/
https://zephoria.com/top-15-valuable-facebook-statistics/

---

The world population is just 7.8 billion as of March 2020. 
2020年3月時点での世界人口は78億人です。
It means that 21% of world population are Facebook DAU and 32% are MAU. 
これは、世界人口の21％がFacebookのDAUであり、32％がMAUであることを意味します。
That's incredible. 
これは驚くべきことです。

To simplify computation, let's assume the system we are building have 1 billion DAU. 
**計算を簡略化するために、私たちが構築しているシステムには10億のDAUがあると仮定**しましょう。

Assume on average a user follows 500 users or entities on Facebook. 
**平均して、ユーザーはFacebook上で500のユーザーまたはエンティティをフォローしていると仮定**します。
An entity can be a group or a page. 
エンティティはグループまたはページである可能性があります。

<!-- ここまで読んだ -->

### Traffic Estimates トラフィック推定

Assume on average one user fetches news feed 10 times per day. 
**平均して1人のユーザが1日にニュースフィードを10回取得すると仮定**します。
So it's 1e10 requests per day and about 116K QPS.
これにより、1日に1e10(=10 billion=100億)リクエストがあり、約116K(=116 thousand=11万6000) QPS（クエリ毎秒）になります。


<!-- ここまで読んだ! -->

### Storage Estimates ストレージの推定

Assume on average we keep 500 posts of each user's news feed in memory for fast fetch, and each post is 1KB in size. 
平均して、各ユーザのニュースフィードの500件の投稿をメモリに保持し、迅速に取得できるようにすると仮定します。また、各投稿のサイズは1KBです。
So 500 KB per user, 500 TB for all DAUs, and 5000 machines if each of them has 100GB memory.
したがって、ユーザ1人あたり500KB、全DAU（Daily Active Users）で500TB、各マシンが100GBのメモリを持つ場合、5000台のマシンが必要です。

<!-- ここまで読んだ! -->

## System APIs システムAPI

```
getNewsFeed(userId, options?)
```

- userId (GUID): the id of the user who is fetching the news feed userId (GUID): ニュースフィードを取得しているユーザのIDです。

The optional options parameter can contain the following fields:
オプションのoptionsパラメータには、以下のフィールドを含めることができます。

(やっぱりIFとして何らかoptionsを渡せるようにしたいよな〜...! :thinking:)

- afterPostId (GUID): fetch the news feed from after this post. If unspecified, fetch the newest posts. afterPostId (GUID): この投稿の後からニュースフィードを取得します。指定しない場合は、最新の投稿を取得します。
- count (number): the maximum number of posts returned for each request. If unspecified, some default maximum number is set by the backend. count (number): 各リクエストに対して返される最大投稿数です。指定しない場合、バックエンドによってデフォルトの最大数が設定されます。
- excludeReplies (boolean): used to prevent the news feed from containing the replies. excludeReplies (boolean): ニュースフィードに返信を含めないようにするために使用されます。

The return values is a JSON containing a list of news feed items.
返り値は、ニュースフィードアイテムのリストを含むJSONです。

<!-- ここまで読んだ! -->

## Database Design データベース設計

### Entities エンティティ

1. User ユーザ
2. Entity (page, group, etc): entityId, name, description, timestamp 
   エンティティ（ページ、グループなど）：entityId、name、description、timestamp
3. Post: postId, title, text, authorId, timestamp 
   投稿：postId、title、text、authorId、timestamp
4. Media: mediaId, url, timestamp 
   メディア：mediaId、url、timestamp

(ユーザとPost以外の実体ってどんな意味だろ??:thinking:)
(あ、下記の記述を見る感じ、Entityはユーザの特殊版というか、Youtubeでいうところのチャンネル・番組シリーズみたいなものかな??:thinking:)
(また同様に下記を見る感じ、Mediaは一つのPostにいくつか紐づけられ得る画像や動画のことっぽい。:thinking:)

### Relationships 関係

1. Follower-Followee: A User can follow other Users or Entities. (m:n)  
   Follower-Followee: ユーザは他のユーザやエンティティをフォローできます。(m:n)

2. Author-Post: Users and Entities can generate Posts. For simplicity, assume only Users can generate Posts. (1:n; we can embed the authorId)  
   Author-Post: ユーザとエンティティは投稿を生成できます。簡単のため、ここではユーザのみが投稿を生成できると仮定します。(1:n; authorIdを埋め込むことができます)

3. Post-Media: Each Post has some associated Medias. (1:n)  
   Post-Media: 各投稿にはいくつかの関連メディアがあります。(1:n)

<!-- ここまで読んだ! -->

## High-level Design 高レベルデザイン

### Workflows ワークフロー

#### Feed generation フィード生成

When Alice ask for her news feed, the system will:  
アリスがニュースフィードを要求すると、システムは次のように動作します：

1. Get followees: retrieve the IDs of all the users/entities that Alice follows  
   1. フォロワーの取得: アリスがフォローしているすべてのユーザ/エンティティのIDを取得します。

2. Aggregate posts: retrieve latest, most popular and relevant posts for those IDs.  
   2. 投稿の集約: それらのIDに対して最新の、最も人気があり、関連性の高い投稿を取得します。

(↑ここまでが候補Postの収集フェーズ...!:thinking:)

3. Rank posts: rank the posts based on relevance and time.  
   3. 投稿のランク付け: 関連性と時間に基づいて投稿をランク付けします。

4. Cache: cache the feeds generated and return the top 20 posts to Alice  
   4. キャッシュ: **生成されたフィードをキャッシュ**し、アリスに上位20件の投稿を返します。

5. Waterfall flow: When Alice reaches the end of those first 20 posts, another request is sent to fetch the next 20 posts.  
   5. ウォーターフォールフロー: アリスが最初の20件の投稿の終わりに達すると、次の20件の投稿を取得するために別のリクエストが送信されます。
   (20件ずつリクエストが分かれてるのか...!:thinking:)



#### Feed publishing (Live updates) フィードの公開（ライブ更新）

Assume Alice follows Bob, and Bod sends a new post. 
アリスがボブをフォローしていて、ボブが新しい投稿を送信したと仮定します。
The system will need to update Alice's news feed:
システムはアリスのニュースフィードを更新する必要があります：

(下記を見た感じ、ボブが投稿した事をトリガーとして、ボブのフォロワー全員のランキングキャッシュを更新するのか...!:thinking:)
(これって多分、ランキングをキャッシュしてるから必要になる処理であって、ランキングをキャッシュしてないorキャッシュの寿命が短い場合は、ボブの投稿を候補コンテンツに追加するfeature pipelineがストリーミングで走るだけで済む認識...!:thinking:)
(もしくは、ステップ5のユーザへの通知という点では、ストリーミングでランキングを作り直すのは一定必要なのかな...!:thinking:)

1. Get followers: retrieve the IDs of Bob's followers
   1. フォロワーを取得：ボブのフォロワーのIDを取得します。

2. Add posts: Add the post Bob created to the news feed pool of those follower IDs.
   1. 投稿を追加：ボブが作成した投稿をそのフォロワーIDのニュースフィードプール(=候補コンテンツ一覧?)に追加します。

3. Rank posts: rank the posts based on relevance and time.
   1. 投稿をランク付け：関連性と時間に基づいて投稿をランク付けします。

4. Update Cache: update the ranked post into cache
   1. キャッシュを更新：ランク付けされた投稿をキャッシュに更新します。

5. Notify followers: let the follower know that there are new posts. (See Server-to-client Communication)
   1.  フォロワーに通知：フォロワーに新しい投稿があることを知らせます。（サーバーからクライアントへの通信を参照）

<!-- ここまで読んだ! -->

### Components 構成要素

1. Web servers: maintains connections with the users.  
   1. Webサーバー: ユーザとの接続を維持します。
2. Application server: executes the workflows mentioned above.  
   1. アプリケーションサーバー: 上記のワークフローを実行します。
3. Database and cache:  
   1. データベースとキャッシュ:  
   User/Entity: relational database  
   ユーザ/エンティティ: リレーショナルデータベース  
   Post: relational database  
   投稿: リレーショナルデータベース  
   Media (image/video): blob storage  
   メディア（画像/動画）: BLOBストレージ  
   Metadata: relational database  
   メタデータ: リレーショナルデータベース  

4.  Dedicated services: 専用サービス:  
    1.  Feed generation フィード生成  
    2.  Feed notification  フィード通知  

<!-- ここまで読んだ! -->

### Architecture アーキテクチャ

## Detailed Design 詳細設計  
### Feed generation フィード生成  
#### Basic Implementation (Fan-out read) 基本実装（ファンアウトリード）

```
SELECT FeedItemID FROM FeedItem WHERE SourceID in(
SELECT EntityOrFriendID FROM UserFollow WHERE UserID =
<current_user_id>
)ORDER BY CreationDate DESCLIMIT 100
```
```
SELECT FeedItemID FROM FeedItem WHERE SourceID in
SELECT FeedItemID FROM FeedItem WHERE SourceID in
(
SELECT EntityOrFriendID FROM UserFollow WHERE UserID =
<current_user_id>
)
(
SELECT EntityOrFriendID FROM UserFollow WHERE UserID =
<current_user_id>
)
ORDER BY CreationDate DESC
ORDER BY CreationDate DESC
LIMIT 100
LIMIT 100
```

Issues of this implementation:  
この実装の問題点：

1. Super slow for users with a lot of friends/follows as we have to perform sorting/merging/ranking on a huge number of posts  
   1. 友達やフォローが多いユーザーにとって非常に遅く、膨大な数の投稿に対してソート、マージ、ランキングを行う必要があります。

2. We generate the timeline when a user loads their page. This could be quite slow and have high latency.  
   2. ユーザーがページを読み込むときにタイムラインを生成します。これは非常に遅く、高いレイテンシを持つ可能性があります。

3. For live updates, each status update will result in feed updates for all followers. This could result in high backlogs in our Newsfeed Generation Service.  
   3. ライブアップデートの場合、各ステータス更新はすべてのフォロワーに対するフィード更新を引き起こします。これにより、ニュースフィード生成サービスに高いバックログが発生する可能性があります。

To improve the efficiency, we can pre-generate the timeline and store it in a memory.  
効率を改善するために、タイムラインを事前に生成し、メモリに保存することができます。



#### Offline Generation (Fan-out write) オフライン生成（ファンアウト書き込み）

We can have dedicated servers that are continuously generating users' newsfeed and storing them in memory. 
専用のサーバーを用意し、ユーザーのニュースフィードを継続的に生成してメモリに保存することができます。

Whenever a user requests for the news feed, we can simply serve it from the pre-generated, stored location. 
ユーザーがニュースフィードを要求すると、事前に生成された保存場所から単純に提供できます。

How many feed items should we store in memory for a user's feed? 
ユーザーのフィードのために、メモリにどれだけのフィードアイテムを保存すべきでしょうか？

Adjust on usage pattern. 
使用パターンに応じて調整します。

Should we generate (and keep in memory) newsfeed for all users? 
すべてのユーザーのためにニュースフィードを生成（およびメモリに保持）すべきでしょうか？

For users that don't login frequently. 
頻繁にログインしないユーザーの場合です。

Simple solution: LRU based cache. 
簡単な解決策：LRUベースのキャッシュです。

Smarter solution: learn the login pattern of users. What time? Which days of week? 
より賢い解決策：ユーザーのログインパターンを学習します。何時に？週のどの日に？



### Feed publishing フィードの公開

The process of pushing a post to all the followers is called afanout.
投稿をすべてのフォロワーにプッシュするプロセスは、afanoutと呼ばれます。



#### fanout read (pull) ファンアウトリード（プル）

When you request for news feed, you creates a read request to the system. 
ニュースフィードをリクエストすると、システムに対してリードリクエストが作成されます。
With fanout read, the read request is fanned out to all your followees to read their posts. 
ファンアウトリードでは、リードリクエストがすべてのフォロイーに配信され、彼らの投稿を読むことができます。

Pro: 利点
1. The cost of write operation is low. 
1. 書き込み操作のコストは低いです。
2. Easier to do different aggregation strategies when reading the data. 
2. データを読み取る際に、異なる集約戦略を実行するのが容易です。

Con: 欠点
1. The read operation is super costly for a user who has lots of followees. 
1. フォロイーが多いユーザーにとって、リード操作は非常にコストがかかります。
2. new data can't be shown to the users until they pull. 
2. 新しいデータは、ユーザーがプルするまで表示されません。
3. If we periodically pull to fetch latest posts, it's hard to find the right pull cadence and most of the pull requests will result in an empty response, causing waste of resources. 
3. 最新の投稿を取得するために定期的にプルすると、適切なプルの間隔を見つけるのが難しく、ほとんどのプルリクエストが空の応答を返し、リソースの無駄を引き起こします。

This architecture is better for write-intensive application. 
このアーキテクチャは、書き込み集約型アプリケーションに適しています。



#### fanout write (push) 

When you send a new post, you creates a write request to the system. 
新しい投稿を送信すると、システムに書き込みリクエストが作成されます。 
With fanout write, the write request is fanned out to all your followers to update their newsfeed. 
ファンアウト書き込みでは、書き込みリクエストがすべてのフォロワーに配信され、彼らのニュースフィードが更新されます。

Pro: 
利点: 
1. The cost of read operation is low. 
1. 読み取り操作のコストは低いです。 

Con: 
欠点: 
1. The write operation is super costly for a user who has millions of followers. 
1. 書き込み操作は、数百万のフォロワーを持つユーザーにとって非常に高コストです。 
2. For inactive users or those rarely log in, pre-computing news feeds waste computing resources. 
2. 非アクティブなユーザーやほとんどログインしないユーザーにとって、ニュースフィードの事前計算は計算リソースを無駄にします。 

The write operation is super costly for a user who has millions of followers. 
書き込み操作は、数百万のフォロワーを持つユーザーにとって非常に高コストです。 
For inactive users or those rarely log in, pre-computing news feeds waste computing resources. 
非アクティブなユーザーやほとんどログインしないユーザーにとって、ニュースフィードの事前計算は計算リソースを無駄にします。 

This architecture is better for read-intensive application. 
このアーキテクチャは、読み取り集約型アプリケーションに適しています。 
Take twitter as example, its readRate >> writeRate. 
Twitterを例に取ると、読み取り率は書き込み率よりもはるかに高いです。 

For systems have less latency requirement, we can use this approach as well. 
レイテンシ要件が少ないシステムでは、このアプローチを使用することもできます。 
For example, WeChat Public Accounts do fanout write and all their followers get notified after some latency ranging from seconds to minutes. 
例えば、WeChatの公式アカウントはファンアウト書き込みを行い、すべてのフォロワーは数秒から数分の遅延の後に通知を受け取ります。



#### Hybrid ハイブリッド

Idea 1. For users who has lots of followers, stop fanout write for their new posts. 
アイデア1. フォロワーが多いユーザに対しては、新しい投稿のファンアウト書き込みを停止します。 
Instead, the followers fanout read the celebrities' updates.
その代わりに、フォロワーは有名人の更新をファンアウトして読みます。

Idea 2. When users send new posts, limit the fanout write to only their online followers.
アイデア2. ユーザが新しい投稿を送信する際には、ファンアウト書き込みをオンラインのフォロワーのみに制限します。

How many feed items can we return to the client in each request?
各リクエストでクライアントに返すことができるフィードアイテムの数はどれくらいですか？ 
The backend should have some maximum limit. 
バックエンドには最大制限が必要です。 
But it should be configurable by the client so that different client (mobile vs desktop) can have different limits.
ただし、異なるクライアント（モバイルとデスクトップ）で異なる制限を持てるように、クライアントによって設定可能であるべきです。

Should we always notify users if there are new posts available for their newsfeed?
ユーザに対して、ニュースフィードに新しい投稿がある場合は常に通知すべきでしょうか？ 
For mobile devices where data usage is relatively expensive, "Live Update" should be configurable by the client.
データ使用量が比較的高価なモバイルデバイスの場合、「ライブアップデート」はクライアントによって設定可能であるべきです。



## Feed Ranking フィードランキング

Instead of simply ranking the feeds chronologically, today's ranking algorithms also try to ensure that posts of higher relevance are ranked higher.
単にフィードを時系列でランク付けするのではなく、今日のランキングアルゴリズムは、より関連性の高い投稿が高くランク付けされるように努めています。

- Select features that can determine the relevance of a feed item, e.g. number of likes, comments, shares, time of update, whether the post has images/videos, etc.
- フィードアイテムの関連性を決定できる特徴を選択します。例えば、いいねの数、コメント、シェア、更新時刻、投稿に画像や動画が含まれているかどうかなどです。

- Compute the score based on the features.
- 特徴に基づいてスコアを計算します。

- Rank the posts using the score.
- スコアを使用して投稿をランク付けします。

Set up metrics like user stickiness, retention, ads revenue, etc. to determine whether our ranking algorithm are good.
ユーザーの定着率、リテンション、広告収益などの指標を設定して、私たちのランキングアルゴリズムが良いかどうかを判断します。



## Data Partitioning データの分割  
### Sharding posts and metadata 投稿とメタデータのシャーディング  
As we have more users and posts, we need to scale our system by distributing our data onto multiple machines such that we can read/write efficiently.  
ユーザと投稿が増えるにつれて、私たちはデータを複数のマシンに分散させることによってシステムをスケールアップする必要があります。これにより、効率的に読み書きができるようになります。



### Sharding feed data フィードデータのシャーディング

Since we only store a limited number of feeds in memory, we shouldn't distribute the feed data of one user onto multiple servers.
私たちはメモリに限られた数のフィードしか保存しないため、1人のユーザのフィードデータを複数のサーバに分散させるべきではありません。

We can partition the user feed data based on userId.
ユーザフィードデータをuserIdに基づいてパーティション分割できます。

We hash the userId and map the hash to a cache server.
私たちはuserIdをハッシュ化し、そのハッシュをキャッシュサーバにマッピングします。

We would need to use consistent hashing.
一貫したハッシュを使用する必要があります。



## Questions 質問

1. is Facebook using SQL or NoSQL?https://blog.yugabyte.com/facebooks-user-db-is-it-sql-or-nosql/
1. FacebookはSQLを使用していますか、それともNoSQLですか？https://blog.yugabyte.com/facebooks-user-db-is-it-sql-or-nosql/

2. How is the pagination implemented if the posts are not sorted chronologically?
2. 投稿が時系列でソートされていない場合、ページネーションはどのように実装されていますか？

3. Sharding data in designing twitter.
3. Twitterの設計におけるデータのシャーディング。

is Facebook using SQL or NoSQL?https://blog.yugabyte.com/facebooks-user-db-is-it-sql-or-nosql/
FacebookはSQLを使用していますか、それともNoSQLですか？https://blog.yugabyte.com/facebooks-user-db-is-it-sql-or-nosql/

How is the pagination implemented if the posts are not sorted chronologically?
投稿が時系列でソートされていない場合、ページネーションはどのように実装されていますか？

Sharding data in designing twitter.
Twitterの設計におけるデータのシャーディング。

PreviousData Partitioning
前のデータパーティショニング

Previous
前

Data Partitioning
データパーティショニング

NextTimeline creation with sharded data
次はシャーディングされたデータによるタイムラインの作成

Next
次

Timeline creation with sharded data
シャーディングされたデータによるタイムラインの作成

Last updated2 years ago
最終更新：2年前

Was this helpful?
役に立ちましたか？
