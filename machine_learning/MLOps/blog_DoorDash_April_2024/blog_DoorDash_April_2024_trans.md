## refs: refs：

https://doordash.engineering/2024/04/23/building-doordashs-product-knowledge-graph-with-large-language-models/
https://doordash.engineering/2024/04/23/building-doordashs-product-knowledge-graph-with-large-language-models/

# Building DoorDash’s Product Knowledge Graph with Large Language Models 大規模言語モデルによるDoorDashの商品知識グラフの構築

DoorDash’s retail catalog is a centralized dataset of essential product information for all products sold by new verticals merchants – merchants operating a business other than a restaurant, such as a grocery, a convenience store, or a liquor store.
DoorDashのリテールカタログは、新業態の加盟店（食料品店、コンビニエンスストア、酒屋など、レストラン以外の事業を営む加盟店）が販売する全商品の必須商品情報を一元化したデータセットである。
Within the retail catalog, each SKU, or stock keeping unit, is represented by a list of product attributes.
小売カタログでは、各SKU(Stock Keeping Unit, 在庫管理単位)は商品属性のリストで表される。
Figure 1 shows an example SKU and some of its attributes as it is stored in the retail catalog.
図1は、リテール・カタログに格納されているSKUとその属性の例を示している。

![]()
Figure 1: An example SKU and some of its attributes in the retail catalog
図1：リテールカタログにおけるSKUとその属性の例

Having high-quality, complete, and accurate product attributes for each SKU is a critical part of a first-class shopping experience, providing:
**各SKUに高品質で完全かつ正確な商品属性を持たせることは、一流のショッピング体験を提供する上で重要な要素**である:

- **Better selection & fulfillment** — Customers can find an item on DoorDash easily, confident that what they order matches what they want.
  より良い選択とフルフィルメント — 顧客はDoorDashで商品を簡単に見つけることができ、注文したものが自分の欲しいものと一致していることを確信している。
  Dashers, the service’s delivery drivers, have comprehensive information to find the correct product in the store.
  このサービスの配達ドライバーであるダッシャーは、店内で正しい商品を見つけるための総合的な情報を持っている。
- **Better personalization**.
  より良いパーソナライゼーション。
  Product attributes allow DoorDash to group products based on commonalities, building a product profile for each customer around their affinities to certain attributes.
  商品属性により、**DoorDashは共通点に基づいて商品をグループ化し、特定の属性に対する顧客の親和性を中心に、各顧客のための商品プロファイルを構築することができる**。
  These are the building blocks for providing highly relevant and personalized shopping recommendations.
  これらは、関連性の高い、パーソナライズされたショッピングの推薦を提供するための構成要素である。

When a merchant comes onboard at DoorDash, we add their internal SKU data — raw merchant data — to our retail catalog.
加盟店がDoorDashに登録すると、我々は彼らの内部SKUデータ(**生の加盟店データ**)をリテールカタログに追加する。
SKU data from different merchants come in varying formats and quality; they may, for example, have missing or incorrect attribute values.
**異なる加盟店からのSKUデータは、形式も品質も様々である。例えば、属性値が欠落していたり、間違っていたりすることがある**。
To ensure our catalog’s quality does not degrade, we standardize and enrich raw merchant data.
**カタログの品質が低下しないように、我々は加工されていない加盟店データを標準化し、enrich(ex. 欠損属性の補完??)する**。
Historically, this SKU enrichment of extracting and tagging attributes has been a purely manual process led by contract operators.
**歴史的に、属性の抽出とタグ付けのSKUエンリッチメントは、契約オペレーターによって純粋に手作業で行われてきた。**(なるほど...!Curationと近い??:thinking:)
But outsourcing this task leads to long turnaround times, high costs, and so many inaccuracies that a second human must audit the results generated by the first.
**しかし、この作業をアウトソーシング(=外部に委託?)すると、納期が長くなり、コストが高くなり、1人目の人間が作成した結果を2人目の人間が監査しなければならないほど不正確になる**。(確かに...!:thinking:)
As our catalog expands, we seek new approaches driven by machine learning to auto-enrich SKU data.
カタログの拡大に伴い、**SKUデータを自動的にエンリッチするために機械学習によって推進される新しいアプローチを模索している**。

Extracting attribute-value information from unstructured data is formally known as named-entity recognition; most recent approaches model the extraction task as a token classification.
**構造化されていないデータから属性値情報を抽出すること**は、正式には**named-entity recognition(=固有表現認識)**として知られており、最近のアプローチの多くは、抽出タスクをトークン分類としてモデル化している。
For instance, given the item name “Dove Silk Glow Body Wash 500 ml,” a token classifier would tag each entity in the item name as shown in Table 1.
例えば、「Dove Silk Glow Body Wash 500 ml」という商品名が与えられた場合、トークン分類器は商品名の各エンティティに表1のようなタグを付ける。
(ブランド名、製品名、容量、単位、などの属性情報を抽出するのか...!:thinking:)

![table1]()
Table 1: Classifying item name tokens to product attributes
表1：商品名トークンを商品属性に分類する

<!-- ここまで読んだ! -->

## Building an attribute extraction model 属性抽出モデルの構築

Building an in-house attribute extraction/tagging model from scratch requires a significant amount of labeled training data to reach the desired accuracy.
**社内で属性抽出/タグ付けモデルをゼロから構築するには、目標の精度に到達するために多くのラベル付きトレーニングデータが必要**である。(うんうん...!:thinking:)
This is often known as the cold-start problem of natural language processing, or NLP.
これは**自然言語処理（NLP）のコールドスタート問題としてよく知られている**。(色んな分野で"cold-start"問題があるんだな...!:thinking:)
Data collection slows model development, delays adding new items to the active catalog, and creates high operator costs.
データ収集はモデル開発を遅らせ、アクティブなカタログに新しいアイテムを追加するのを遅らせ(新しいnamed-entityの追加に対応できないってこと...?:thinking:)、オペレーターのコストを高める。

<!-- ここまで読んだ! -->

### Using LLMs to circumvent the cold-start problem コールドスタート問題を回避するためのLLMの使用

Large language models, or LLMs, are deep-learning models trained on vast amounts of data.
大規模言語モデル（LLM）は、膨大な量のデータでトレーニングされたディープラーニングモデルである。
Examples include OpenAI’s GPT-4, Google’s Bard, and Meta’s Llama.
例えば、OpenAIのGPT-4、GoogleのBard、MetaのLlamaなどだ。
Because of their broad knowledge, LLMs can perform NLP with reasonable accuracy without requiring many, if any, labeled examples.
LLMは幅広い知識を備えているため、多くのラベル付き例を必要とせずに、合理的な精度でNLPを実行することができる。
A variety of prompts can be used to instruct LLMs to solve different NLP problems.
さまざまなプロンプトを使用して、LLMに異なるNLP問題を解決するように指示できる。

We will highlight here how we use LLMs to extract product attributes from unstructured SKU data, allowing us to build a high-quality retail catalog that delivers the best possible experience for users in all new verticals.
ここでは、**非構造化SKUデータから商品属性を抽出するためにLLMを使用する方法**について説明し、新しい全業態のユーザに最高の体験を提供する高品質なリテールカタログを構築する方法を強調する。
In the following sections, we describe three projects in which we used LLMs to build ML products for attribute extraction.
以下のセクションでは、**属性抽出のためにLLMを使用してMLプロダクトを構築した3つのプロジェクト**について説明する。

### Brand extraction ブランド抽出

Brand is a critical product attribute used to distinguish one company’s products from all others.
ブランドは、ある企業の製品を他のすべての製品と区別するために使用される重要なプロダクト属性である。
At DoorDash, a hierarchical knowledge graph defines a brand, including entities such as manufacturer, parent brand, and sub-brand, as shown in Figure 2.
ドアダッシュでは、図2に示すように、**メーカー、親ブランド、サブブランドなどのエンティティを含むhierarchicalな (階層的な) knowledge graph**がブランドを定義している。

![figure2]()
Figure 2: Brand taxonomy breaks brands into entities such as manufacturer, parent brand, and sub-brand
図2：ブランド分類法は、メーカー、親ブランド、サブブランドなどのエンティティにブランドを分割する

Accurate brand tagging offers a number of downstream benefits, including increasing the reach of sponsored ads and the granularity of product affinity.
正確なブランド・タグ付けは、スポンサー広告のリーチを拡大し、製品アフィニティの粒度を高めるなど、**下流に多くの利益をもたらす**。
Because the number of real-world brands is technically infinite, DoorDash’s brand taxonomy is never complete.
現実世界のブランド数は技術的に無限であるため、ドアダッシュのブランド分類法は決して完全ではない。
As the product spectrum expands, new brands must be ingested to close any coverage gaps.
製品スペクトルが拡大するにつれて、カバーギャップを埋めるために新しいブランドを取り入れなければならない。
Previously, brand ingestion was a reactive and purely manual process to fulfill business needs.
**以前は、ブランドの取り込みは、ビジネスニーズを満たすための反応的で純粋な手作業だった**。
This limited the volume of new brands that could be added, often failed to address much of the coverage gap, and led to duplicate brands, making it difficult to manage the taxonomy system.
このため、新たに追加できるブランドの量が制限され、カバーギャップの多くを解消できず、重複したブランドが生じ、タクソノミシステムを管理するのが難しくなった。

To this end, we built an LLM-powered brand extraction pipeline that can proactively identify new brands at scale, improving both efficiency and accuracy during brand ingestion.
この目的のために、**私たちはLLMを利用したブランド抽出パイプラインを構築しました**。このパイプラインは、新しいブランドを大規模にプロアクティブに識別することができ、ブランド取り込み時の効率と精度の両方を向上させます。
(LLMで学習データを作ってるんじゃなくて、そのまま推論用として使ってる???:thinking:)
Figure 3 shows our end-to-end brand ingestion pipeline, which follows these steps:
図3は、エンド・ツー・エンドのブランド・インジェスト・パイプラインを示している：

- 1. Unstructured product description is passed to our in-house brand classifier
     構造化されていない商品説明は、社内のブランド分類器に渡されます。
- 2. SKUs that cannot be tagged confidently to one of the existing brands are passed to an LLM for brand extraction
     既存のブランドのいずれかに確実にタグ付けできないSKUは、ブランド抽出のためにLLMに渡される。
- 3. The extraction output is passed to a second LLM, which retrieves similar brands and example item names from an internal knowledge graph to decide whether the extracted brand is a duplicate entity
     抽出出力は2番目のLLMに渡され、2番目のLLMは、抽出されたブランドが重複エンティティであるかどうかを判断するために、内部の知識グラフから類似ブランドとアイテム名の例を検索します。
- 4. The new brand enters our knowledge graph and the in-house classifier is retrained with the new annotations
     (既存の知識グラフに存在しないブランドだった場合は) 新しいブランドが知識グラフに入り、社内の分類器が新しいアノテーションで再トレーニングされます。

![figure3]()
Figure 3: LLM-powered brand ingestion pipeline
図3：LLMを利用したブランド取り込みパイプライン
(Inference pipelineに該当するよね...!:thinking:)

### Organic product labeling オーガニック製品の表示

Consumers care about dietary attributes when building their carts and are more likely to engage with a product if it tailors to their personal preference.
**消費者はカートを構築する際に食事の属性を気にし、個人的な嗜好に合わせた商品であれば、より興味を持つ可能性が高い**。(これはニュースにも言えそうな気がする...??:thinking:)
Last year, we stood up a model to label all organic grocery products.
昨年、私たちはすべてのオーガニック食料品製品にラベルを付けるモデルを立ち上げました。
The end goal was to enable personalized discovery experiences such as showing a Fresh & Organic carousel to a consumer whose past orders showed a strong affinity towards organic products.
最終的なゴールは、過去の注文がオーガニック製品に強い親和性を示している消費者に、フレッシュ＆オーガニックのカルーセルを表示するなど、パーソナライズされた発見体験を可能にすることでした。
(最終的にはこの属性情報を使ってパーソナライズされた推薦を行うことが目的だったのか:thinking:)

The end-to-end pipeline takes a waterfall approach, leveraging existing data where applicable to boost speed, accuracy, and coverage.
エンド・ツー・エンドのパイプラインは、ウォーターフォール・アプローチを採用し、既存のデータを活用することで、スピード、精度、カバレッジを向上させる。
This process can be broken down roughly into three buckets:
このプロセスは、**大まかに3つのバケツに分けることができる**: (3種類の方法でオーガニック食品をfilteringするってこと??:thinking:)

- **String matching**: We find exact mention of the keyword “organic” in the product title.
  文字列のマッチング： 商品タイトルに「オーガニック」というキーワードが含まれていることを確認します。
  This approach offered the highest precision and decent coverage, but it missed cases where “organic” is misspelled / dropped or has a slightly different presentation in the data.
  この方法は最も精度が高く、カバー率もそこそこだったが、「organic」のスペルミスや脱落、あるいはデータの表現が微妙に異なるケースを見逃していた。(確かに...!:thinking:)
- **LLM reasoning**: We leverage LLMs to determine whether a product is organic based on available product information.
  LLMの推論: LLMを活用し、入手可能な製品情報に基づいて製品がオーガニックかどうかを判断する。
  This information could come directly from merchants or via optical character recognition extraction from packaging photos.
  この(入力)情報は、加盟店から直接入手することも、パッケージ写真からoptical character recognition(OCR, 光学式文字認識)で抽出することもできる。
  This approach improved coverage by addressing major challenges faced by string matching and has better than human precision.
  このアプローチは、文字列マッチングが直面する主要な課題に対処することでカバレッジを向上させ、人間よりも優れた精度を持つ。
- **LLM agent**: LLMs conduct online searches of product information and pipe the search results to another LLM for reasoning.
  LLMエージェント： **LLMは商品情報をオンラインで検索し**、検索結果を別のLLMにパイプで送り、推論させる。
  This approach further boosted our coverage.
  このアプローチによって、我々のカバー率はさらに高まった。

Figure 4 shows the LLM-powered pipeline for tagging our catalog SKUs with organic labels.
図4は、カタログのSKUにオーガニック・ラベルのタグを付けるための、LLMを利用したパイプラインを示している。

![figure4]()
Figure 4: LLM-powered tagging

By leveraging LLMs and agents, we overcame the challenge of insufficient data and answered inferential questions via searching and reasoning using external data.
LLMとエージェントを活用することで、不十分なデータの課題を克服し、外部データを使用して検索と推論を行うことで推論的な問題に答えた。
Enhancing coverage of organic labels enabled us to launch item carousels that target customers’ with strong organic affinity, which improved our top-line engagement metrics.
オーガニックラベルのカバレッジを向上させることで、**オーガニックに強い親和性を持つ顧客をターゲットにしたアイテムカルーセルを立ち上げ**、トップラインのエンゲージメントメトリクスを向上させた。
(特定のユーザにだけ、オーガニック食品セクションを表示させた、みたいな感じか...!:thinking:)

<!-- ここまで読んだ! -->

### Generalized attribute extraction 一般化された属性抽出

Entity resolution is the process of determining whether two SKUs refer to the same underlying product.
[entity resolution(=エンティティの解像度?)](https://towardsdatascience.com/entity-resolution-identifying-real-world-entities-in-noisy-data-3e8c59f4f41c)とは、**2つのSKUが同じ基礎製品を参照しているかどうかを決定するプロセス**である。
(SKUが同じ商品かどうかを判定するプロセスね。メルカリさんとかでも必要そう...!:thinking:)
For example, “Corona Extra Mexican Lager (12 oz x 12 ct)” sold by Safeway is the same product as “Corona Extra Mexican Lager Beer Bottles, 12 pk, 12 fl oz” sold by BevMo!.
例えば、Safewayが販売している「Corona Extra Mexican Lager (12 oz x 12 ct)」は、BevMo!が販売している「Corona Extra Mexican Lager Beer Bottles, 12 pk, 12 fl oz」と同じ製品である。(売り主が違うケースか、これもまさにメルカリさんと同じだ...!:thinking:)
We need accurate entity resolution to build a global catalog that can reshape the way customers shop while unlocking sponsored ads.
スポンサード広告を解き放ちながら、顧客がショッピングする方法を変えることができるグローバル・カタログを構築するために、**正確なentity resolutionが必要である**。
(merchant SKUとGlobal SKUの関連付け...!:thinking:)
(ニュースにおいても、異なる出版社の同じトピックに関するニュースか否かを判定するのはentity resolutionの一種かも?? どんな効果があるかまだちゃんと想像できてないけど...!:thinking:)

![Figure5: Entity resolution is the backbone of sponsored ads]()

Determining whether two SKUs refer to the same underlying product is a challenging problem.
2つのSKUが同じ基礎製品(=Global SKU!)を参照しているかどうかを判断するのは難しい問題である。
It requires validating that both SKUs match all attributes exactly, which means there must be accurate extraction of all applicable attributes in the first place.
これは、両方のSKUがすべての属性と完全に一致していることを検証する必要があるため、**まず最初にすべての適用可能な属性を正確に抽出する必要がある**。
Products from different categories are characterized by different sets of uniquely defining attributes.
異なるカテゴリの製品は、独自に定義された属性の異なるセットで特徴付けられている。
For example, an alcohol product is uniquely defined by attributes such as vintage, aging, and flavor.
例えば、アルコール製品は、ヴィンテージ、熟成、風味などの属性によって独自に定義される。
Starting with limited human-generated annotations, we used LLMs to build a generalized attribute extraction model.
限られた人間が生成したアノテーションから始めて、LLMを使って一般化された属性抽出モデルを構築した。(entity resolutionのための属性抽出モデル...!)

We used LLMs and retrieval augmented generation, or RAG, to accelerate label annotations.
LLMと[RAG（retrieval augmented generation）](https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/)を用いて**ラベルアノテーションを高速化**した。
For each unannotated SKU, we first leverage OpenAI embeddings and the approximate nearest neighbors technique to retrieve the most similar SKUs from our golden annotation set.
各アノテーションされていないSKUについて、まずOpenAIの埋め込みと近似最近傍技術を活用し、ゴールデンアノテーションセットから最も類似したSKU (=これはmerchant SKU??)を検索する。
We pass these golden annotation examples to GPT-4 as in-context examples to generate labels for the unannotated SKU.
これらのゴールデンアノテーションの例をインコンテクスト例としてGPT-4に渡し、アノテーションされていないSKUのラベルを生成する。
Choosing examples based on embedding similarity is advantageous over random selection because the selected examples are more likely to be relevant to the assigned task and reduces hallucination.
埋め込み類似度に基づいてexampleを選択することは、ランダム選択よりも有利であり、選択された例が割り当てられたタスクに関連している可能性が高く、幻覚を減らす。
Ultimately, the generated annotations are used to fine-tune an LLM for more scalable inference.
最終的に、**生成されたアノテーションは、よりスケーラブルな推論のためにLLMをfine-tuningするために使用される**。(でも学習もLLMでやらせるんだ...!:thinking:)

This approach enabled us to generate annotations within a week that would otherwise require months to collect, allowing us to focus on the actual model development to de-risk our goal.
このアプローチにより、通常であれば収集に数ヶ月を要するアノテーションを1週間以内に生成することができ、実際のモデル開発に集中することができ、目標のリスクを回避することができた。

<!-- ここまで読んだ! -->

## Downstream impacts 下流への影響

Attribute extraction not only allows us to better represent each product in the catalog but also empowers downstream ML models that improve a customer's shopping experience.
属性抽出は、カタログ内の各商品をよりよく表現することを可能にするだけでなく、**顧客のショッピング体験を向上させる下流のMLモデルにも力を与えます**。
Attributes such as brand and organic tag are important features in our personalized ranking models, which recommend items that reflect a consumer’s unique needs and preferences.
ブランドやオーガニックタグなどの属性は、消費者独自のニーズや嗜好を反映したアイテムを推奨するパーソナライズされたランキングモデルにおいて重要な特徴量である。
And attributes such as product category and size enable recommending more relevant substitutions when the original item is out of stock, giving customers a smooth fulfillment experience.
また、商品カテゴリーやサイズなどの属性は、**元の商品が在庫切れの場合により関連性の高い代替品を推奨することを可能にし**、顧客にスムーズなfulfillment(=満たす?)体験を提供する。

<!-- ここまで読んだ! -->

## Looking into the future 未来への展望

So far, most of our attribute extraction models are built on top of text-based inputs.
これまでのところ、**属性抽出モデルのほとんどはテキストベースの入力**の上に構築されている。
A challenge with this approach, however, is the presence of abstraction and abbreviations within written product descriptions.
しかし、このアプローチで課題となるのは、文章化された商品説明の中に抽象的な表現や略語が存在することである。
Fortunately, product image quality varies less across merchants.
幸いなことに、商品の画質は加盟店によってそれほど差がない。
We are actively exploring recent advances in multimodal LLMs that can process text and images together; currently, we are experimenting with multimodal attribute extraction through Visual QA and Chat + OCR.
私たちは、**テキストと画像を一緒に処理できる最新のマルチモーダルLLMの進歩**を積極的に探求しています。現在、Visual QAとChat + OCRを通じてマルチモーダル属性抽出を実験しています。
(画像からの属性抽出も行うようになるのか...!:thinking:)
Our Engineering team is also building foundational technologies and infrastructures to allow Dashers to take product photos so that we can perform attribute extraction directly on in-store items.
私たちのエンジニアリング・チームは、Dashers(=お店側のユーザ)が商品の写真を撮ることができるようにするための基盤技術とインフラを構築しており、店内の商品に直接属性抽出を行うことができるようにしています。

As we identify more areas where LLMs can be used, we are also working with our ML Platform team to democratize their use across DoorDash through a centralized model platform where anyone can easily prompt-engineer, fine-tune, and deploy LLMs.
LLMを利用できる分野が増えるにつれて、MLプラットフォームチームと協力して、誰もが簡単にプロンプトエンジニアリング、fine-tune、LLMをデプロイできる中央モデルプラットフォームを通じて、**DoorDash全体でLLMを民主化**しています。
