# Bayesian Personalized Ranking from Implicit Feedback

published date: hogehoge September 2022,
authors: Wondo Rhee, Sung Min Cho, Bongwon Suh
url(paper): https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf
(勉強会発表者: morinota)

---

n週連続推薦システム系論文読んだシリーズ 36 週目の記事になります。
ちなみに35週目は [タイトル](url) でした!

## どんなもの?

- 読んだきっかけ:
  - Work In ProgressさんのPodcast配信 -> NetflixさんのABテストに関するブログ連載 -> X(旧Twitter)さんのABテストのサンプルサイズ設計に関するブログを読んで、もう少しABテストの設計周りの雰囲気を掴みたいと思い、参考文献に記載されてた本論文を読むに至りました:)
- 概要:
  - Webサービスにおける制御実験のpracticeやguidelineについてまとめた論文。
- 本記事では、以下の3つの資料を参考にしながら理解したことをまとめつつ、特に推薦システムのABテストに関して思いを馳せる。

## ABテストってどんなものだっけ?

- hoge

## コントロール実験に関する用語の定義

### Overall Evaluation Criterion (OEC, 総合評価基準):

- 実験を経て改善させたい目的となる定量的な指標 (i.e. netflixさんの資料における primary decision metric?:thinking:)
- 実験によっては複数の目的がある場合もある。その場合は、複数の指標を重み付けして組み合わせた単一のOECを用意することが推奨される。

### Factor

- OECに影響を与えると考えられる、制御可能な実験変数 ()
- factorには値(levelやversionとも呼ばれる)が割り当てられる。
  - (例えばpush通知のパーソナライスするか否かのABテストの場合、factor = is_personalized, value = true or false、みたいな?:thinking:)
- 単純なA/Bテストでは、2つの値(=AとB)を持つ単一のfactorを持つ。

### Variant

- factorにlevel(=値)を割り当てることで、ユーザ体験がテストされる。
  - 既存のバージョンを指定する特別なvariantであるcontrolと、新しいversionを試すvariantであるtreatmentがある。
  - ex) 施策にバグがあった場合、実験は中止され、すべてのユーザがコントロールの variant を割り当てられる。

### Experimental unit (実験単位)

### primary decision metricとかの話は書きたい。

## 意思決定のためのツールとしての統計的仮説検定

- 誰もが、ABテストを経てなるべく正しい意思決定をしたいよね...!
- でもまず認識すべきこと: **意思決定に対するどんなアプローチも、不確実性や間違いを犯す可能性を完全に排除することはできない**。
  - -> 統計的仮説検定のアプローチは、結果の不確実性や意思決定のエラーを犯す確率を定量化・理解するために有効。
- ABテスト結果に基づく意思決定のエラーには、2種類ある:
  - **false positive(type 1 error)**: 実際には施策に効果がないのに、効果があると判断してしまう。
    - (写真を猫か猫以外かで判定する機械学習モデルで例えると、猫以外の写真を猫だと判定してしまうこと!)
    - (統計的仮説検定も、「施策に効果があると言える」と「効果があると言える十分な証拠がない」を判定する2値分類モデルとして捉えることができるな...:thinking:)
  - **false negative(type 2 error)**: 実際には施策に効果があるのに、効果がないと判断してしまう。
    - (写真を猫か猫以外かで判定する機械学習モデルで例えると、猫の写真を猫ではないと判定してしまうこと!)
- 残念ながら、これらのエラーの両方を完全に排除することはできない。
  - 基本的に両者の確率はトレードオフの関係にあるから。
  - false positiveされやすさが極めて小さくなるように実験をデザインすると、必然的にfalse negativeされやすさが大きくなる。
- -> **我々が可能 & 目指すべきことは、この2種類のエラーの原因を定量化し、理解し、コントロールすること**。

### false positive(type 1 error)に関する概念の整理

- 優れた仮説(施策)とprimary decision metricへの明確な理解を得たあとは、ABテストを設計するための統計的な側面について考えていく。
- このプロセスは通常、**acceptable(許容可能な) false positive rateを固定することから始まる**。
  - 慣例では、**許容可能なfalse positive rateは5%**に設定されることが多い。
    - i.e. 「実際には施策に効果がない場合において、1回/20回くらいは誤って効果があると判断すること」を許容すること。
    - (i.e. 我々は、猫以外の写真の5%くらいを猫であると誤ってラベル付けしてしまうことを許容するよ!:thinking:)
    - 「acceptable false positive rateが5%」は「significance level(有意水準)が5%」とも言い換えられる。
- false positive rateとp-value(p値)との関連:
  - false positive rateは、観測されたtreatmentとcontrolのmetric値の **statistical significance(統計的有意性)** と密接に関連する。そして statistical significanceは、p-valueを用いて計算される。
  - p値の解釈: 実際にはtreatmentとcontrolに差がない場合に、今回の観測結果と同じような結果が得られる確率。

#### statistical significanceとp-valueの概念を直感的に理解するためのコインの例

- コインの例、あまりに単純なシナリオすぎない?? -> 多くの企業はbinary metricに関心あるからそんなことない!
  - -> コインが表か否か = binary metric。
  - netflixを含む多くの企業では、施策の適用によって**binary user activityの割合に違いが生じるか(ex. クリックするか否か、継続するか否か)**をABテストで検証・理解したい...!
- コインが不公平かどうかを判断したいケースを想定する。
  - コインを100回ひっくり返して、表が出た割合を計算する実験。
  - 仮にコインが完全に公平(=コインが従う確率分布の期待値が0.5)だったとしても、正確に50回表が出ることを期待できない。ランダム性(i.e. noise)があるから。(確率的試行なので...!)
  - じゃあ「コインが公平である」という主張を棄却するのに十分な証拠は何か?
    - 60回表が出た場合、不公平だと結論づけられる? 70回? 80回? 90回?
  - 判断方法を揃え、関連するfalse positive rateを理解する方法が必要...!
    - (ここでfalse positiveは、公平なコインなのに誤って不公平だと判断すること:thinking:)
- 思考の練習:
  - 1. まずコインは公平である(i.e. パラメータp=0.5のベルヌーイ分布に従う...!:thinking:)と仮定する = Null Hypothesis (帰無仮説) (帰無仮説は常に現状維持や公平であることを表明する)
  - 2. 何が帰無仮説に対する有力な証拠となるかを判断するために、帰無仮説が真であると仮定して、あらゆる可能性のある観測結果の確率を計算する。(i.e. p=0.5, n=100の二項分布の確率質量関数を計算する...!:thinking:)
    - (確率分布の自体が試行回数nに依存してるから、ABテストの判定はサンプルサイズに色々依存してそうって話は、ここでも何となく想像できそう...!:thinking:)
    - 計算した結果が図3(黒&青、色は無視):
    - (ここのpは、確率分布の形を決めるパラメータの意味。p値の意味ではない点に注意:thinking:)
  - 3. **コインが公平であるという仮定の下での結果の確率分布(図3)を、実験で収集されたデータと比較**できる。
    - 実験で収集された観測結果は、100回のうち55回表だったとする。
    - **「コインが公平であるという主張を棄却する上で、この観測結果がどの程度有力な証拠か??」の度合いを定量化したい**...!
    - -> 観測結果よりも発生しづらいすべての結果に関連する確率を足し合わせる(i.e. 累積質量)
      - (単峰性の確率分布を前提にしてるのかな。まあ統計的仮説検定で使う分布って単峰性か...:thinking:)
      - この例では、表と裏のどちらがより起こりやすいかという仮定をしてない(i.e. 両側検定)ので、55%以上が表になる確率と55%以上が裏になる確率を累積する。
    - この累積した確率質量が、**p-value**と呼ばれるもの。
      - この例では0.32となる。
      - 解釈: 公平なコインで100回ひっくり返す実験を何度も繰り返した場合、そのうちの32%の実験で少なくとも55回以上表が出るもしくは55回以上裏が出るような結果になるはず...!

![figure3]()

- コインが不公平であるという有意な証拠があるかどうか、**p値をどう使えばいい**??
  - -> **最初に定義したacceptable false positive rate=5%に基づく**。p値が0.05%未満の場合、統計的に有意な証拠があると判断し、帰無仮説を棄却する。
    - (公正なコインを仮定した場合、その観測結果が十分に起こりにくいのであれば、コインは公正ではないと判断 i.e. 意思決定して良さそうだよね...!正しい意思決定っぽい...!:thinking:)

#### 関連する概念1: Rejection Region(棄却域)

- 統計的仮説検定の判定ルールのもう一つの見方が、rejection region(棄却域)を定義すること。
  - **rejection regionとp値には等価性があり、どちらも同じ判定(意思決定)を導く**: 観測値がrejection regionに含まれる場合、その時のp値は0.05%未満である。
    - (=うんうん、やってることは同じ...!:thinking:)
  - コインが不公平であると結論づける観測値の集合を用意しておくという観点。
- rejection regionの定義も、**acceptable false positive rate=5%**に基づく。
  - コインが公平である(i.e. 帰無仮説が真である)と仮定し、**確率質量の累積値が0.05%を超えないような最も発生しづらい観測結果の集合**として、rejection regionを定義する。
    - この集合には、帰無仮説が正しい場合に最も極端な結果、つまり帰無仮説(の棄却?)に対する証拠が最も強い観測結果たちが含まれる。
  - もし収集された観測結果がrejection regionに含まれていたら、帰無仮説をrejectする。
    - コイン実験の例では、表40回未満と表60回以上の観測結果がrejection regionに含まれる。(図3の青色の観測結果の集合)
- rejection regionの境界値(コインの例では40回と60回)を、**critical value(臨界値?)**と呼ぶ。

#### 関連する概念2: Confidence Intervals(信頼区間)

- rejection regionと同様にp値と関連する概念が、Confidence Interval(信頼区間)。
  - **信頼区間とp値には等価性があり、どちらも同じ判定(意思決定)を導く**。
  - -> p値が0.05%未満である = null valueが95% confidence intervalの外側にある。
- confidence intervalも、p値やrejection regionと同様にacceptable false positive rate=5%に基づく。(まあ等価性があるので当然か...!:thinking:)
  - p値やrejection regionの概念はまず帰無仮説が真であるという仮定から導かれる概念だが、**confidence Intervalの場合は観測結果から導かれる**。
- コインの例での思考練習:
  - **ある観測結果が与えられた時、どのnull value(帰無値)であれば(i.e. どの帰無仮説であれば??:thinking:)棄却されないという判定(意思決定)を導くだろうか?**
    - (null value = 帰無仮説が真の場合の検定統計量の期待値? 例えば公平なコインを帰無仮説とした場合は検定統計量の期待値は50%?:thinking:)
  - コインの例では、55%表が出たという観測結果が得られると仮定した場合に、公平なコインである(i.e. 表が出る確率が50%である)という帰無仮説は棄却されなかった。また同様に、表が出る確率が47.5％、50％、60％であるという帰無仮説も棄却されない。
  - -> 55%表という観測結果に対して、帰無仮説が棄却されない値には、約45％から65％表が出るというnull valueが含まれる。(この境界値は、rejection regionの概念における critical valueと同じ値...!でも意味合いは異なるよね:thinking:)
- このnull valueの値域が、confidence interval(信頼区間): (ある観測結果が与えられた条件で)**帰無仮説が棄却されないnull valueの値の集合**。
  - ちなみに、acceptable false positive rate=5% (i.e. significance level=5%)に設定している場合は、95% confidence intervalと呼ばれる。
    - 解釈: 実験を繰り返し行うと、95% confidence intervalはtrue value(=コインの例では、真の表が出る確率。真の分布の期待値?)を、実験回数における95%の割合でカバーする。
    - (自分はこの解釈をまだ理解できてない...!true valueの話が急に出てくる? confidence intervalは仮説検定というよりはtrue valueの推定の概念なのかな??:thinking:)
    - (まあp-valueによる意思決定 = rejection regionによる意思決定 = confidence intervalによる意思決定ならば、必ずしもこの解釈を理解していることはABテストを運用する上では必須ではなさそう??:thinking:)

![figure4]()

### false negative(type 2 error)に関する概念の整理

### Null Hypothesis (帰無仮説)

### Confidence level (信頼度)

### Power (検出力)

### A/A test

## 意思決定のためのツールとしての統計的仮説検定
