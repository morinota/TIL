## link リンク

- [tech blog](https://netflixtechblog.medium.com/recsysops-best-practices-for-operating-a-large-scale-recommender-system-95bbe195a841) テックブログ](https://netflixtechblog.medium.com/recsysops-best-practices-for-operating-a-large-scale-recommender-system-95bbe195a841)

- [paper](https://dl.acm.org/doi/fullHtml/10.1145/3460231.3474620) [paper](https://dl.acm.org/doi/fullHtml/10.1145/3460231.3474620)

# RecSysOps: Best Practices for Operating a Large-Scale Recommender System RecSysOps： 大規模レコメンダーシステム運用のベストプラクティス

Operating a large-scale recommendation system is a complex undertaking: it requires high availability and throughput, involves many services and teams, and the environment of the recommender system changes every second.
大規模なレコメンデーションシステムの運用は複雑な仕事である： 高い可用性とスループットが要求され、多くのサービスやチームが関与し、推薦システムの環境は刻々と変化する。
For example, new members or new items may come to the service at any time.
例えば、新メンバーや新アイテムがいつでもサービスに登場する可能性がある。
New code and new ML models get deployed to production frequently.
新しいコードや新しいMLモデルは、本番環境に頻繁にデプロイされる。
One question we need to address at Netflix is how can we ensure the healthy operation of our recommender systems in such a dynamic environment?
Netflixで取り組むべき問題のひとつは、このようなダイナミックな環境において、レコメンダー・システムを健全に運用するにはどうすればいいかということだ。

In this blog post, we introduce RecSysOps a set of best practices and lessons that we learned while operating large-scale recommendation systems at Netflix.
このブログポストでは、Netflixで大規模なレコメンデーションシステムを運用する中で学んだベストプラクティスと教訓をまとめたRecSysOpsを紹介する。
These practices helped us to keep our system healthy while 1) reducing our firefighting time, 2) focusing on innovations and 3) building trust with our stakeholders.
これらの実践により、1）消火活動の時間を短縮し、2）イノベーションに集中し、3）ステークホルダーとの信頼を築きながら、システムを健全に保つことができた。

RecSysOps has four key components: issue detection, issue prediction, issue diagnosis and issue resolution.
RecSysOpsには4つの主要コンポーネントがある： 課題検出、課題予測、課題診断、課題解決である。
Next we will go over each component and share some of our learnings.
次に、各コンポーネントについて説明し、私たちの学びを共有する。

## Issue Detection 問題の検出

Within the four components of RecSysOps, issue detection is the most critical one because it triggers the rest of steps.
RecSysOpsの4つのコンポーネントの中で、問題の検出は最も重要なものである。
Lacking a good issue detection setup is similar to driving a car with your eyes closed.
優れた問題検出のセットアップを欠くことは、目をつぶって車を運転することに似ている。

Formally, issue detection is pretty straightforward; if something is wrong in production we need to be able to detect it quickly.
形式的には、問題の検出は非常に簡単だ。本番で何か問題が発生した場合、それを迅速に検出できなければならない。
However, there are endless ways for things to go wrong and many of them we may not yet have encountered.
しかし、物事がうまくいかない方法は無限にあり、その多くはまだ遭遇していないかもしれない。
Below are some of the lessons that we learned to increase our coverage in detecting issues.
以下は、問題を発見するカバー率を高めるために私たちが学んだ教訓の一部である。

The very first step is to incorporate all the known best practices from related disciplines.
その第一歩は、関連分野の既知のベストプラクティスをすべて取り入れることだ。
Because creating recommendation systems involves software engineering and machine learning, this includes all DevOps and MLOps practices such as unit testing, integration testing, continuous integration, checks on data volume and checks on model metrics.
レコメンデーションシステムの構築には、ソフトウェアエンジニアリングと機械学習が含まれるため、ユニットテスト、統合テスト、継続的インテグレーション、データ量のチェック、モデルメトリクスのチェックなど、あらゆるDevOpsとMLOpsの実践が含まれる。
Fortunately, there are many available resources such as this paper [1] with checklists that can be used to examine an ML system and identify its gaps.
幸いなことに、この論文[1]のように、MLシステムを調査し、そのギャップを特定するために使用できるチェックリストがある。

The second step is to monitor the system end-to-end from your perspective.
第二のステップは、あなたの視点からシステムをエンド・ツー・エンドで監視することである。
In a large-scale recommendations system many teams are often involved and from the perspective of an ML team we have both upstream teams (who provide data) and downstream teams (who consume the model).
大規模なレコメンデーションシステムでは、多くのチームが関与することが多く、MLチームから見ると、上流チーム（データを提供するチーム）と下流チーム（モデルを消費するチーム）の両方が存在する。
One thing we learned was not to rely only on partner teams’ audits.
ひとつ学んだのは、パートナーチームの監査だけに頼らないことだ。
It is best to audit (from our own perspective) all inputs and outputs, e.g.models and scores generated by those models.
すべてのインプットとアウトプット、例えばモデルやそのモデルによって生成されたスコアなどを（自分たちの視点から）監査するのがベストだ。
For example, we might be interested in a specific fraction of the data generated by the upstream team and changes in this fraction may not show up in the overall audits of that team.
例えば、私たちは上流チームが生成したデータの特定の割合に興味があるかもしれず、この割合の変化はそのチームの全体的な監査には現れないかもしれない。
As another example, if a team is interested in consuming our model and making predictions, we can work with them to log details of the model predictions, e.g.features, for a fraction of traffic and audit them from our own perspective.
別の例として、あるチームが私たちのモデルを使用して予測を行うことに興味を持っている場合、私たちはそのチームと協力して、トラフィックの一部について、モデルの予測の詳細、例えば特徴などを記録し、私たち自身の視点からそれらを監査することができる。
This type of end-to-end audits helped us find many issues both downstream and upstream, especially at the start of new projects involving new data sources.
このようなエンドツーエンドの監査は、特に新しいデータソースを含む新しいプロジェクトの開始時に、下流と上流の両方で多くの問題を発見するのに役立ちました。

The third step for getting a comprehensive coverage is to understand your stakeholders’ concerns.
包括的な補償を得るための第3のステップは、利害関係者の懸念を理解することである。
This is the best way to increase the coverage of the issue detection component.
これは、問題検出コンポーネントのカバレッジを高める最善の方法である。
In the context of our recommender systems we have two major perspectives: our members and items.
私たちのレコメンダー・システムの文脈では、2つの主要な視点がある： メンバー」と「アイテム」です。

From the member perspective, the problem is pretty straightforward.
メンバーから見れば、この問題は非常に簡単だ。
If a member chooses an item that was not ranked high by the serving ranking model, it is a potential issue.
サービング・ランキング・モデルで上位にランクされていないアイテムをメンバーが選んだ場合、それは潜在的な問題となる。
Thus, monitoring and analyzing these cases is important to identify problems and are also a great source of inspiration for future innovations.
したがって、こうした事例を監視・分析することは、問題を特定するために重要であり、また将来のイノベーションのための大きなインスピレーションの源でもある。

From the items’ perspective we need to make sure to engage with teams responsible for items and understand their concerns.
アイテムの観点からは、アイテムを担当するチームと確実に関わり、彼らの懸念を理解する必要がある。
In the case of Netflix, these teams indicated concerns about proper item cold-starting and potential production bias.
ネットフリックスの場合、これらのチームは、適切なアイテムのコールドスタートと潜在的な生産バイアスについて懸念を示した。
These are both active research areas in the RecSys community, but to start with we helped those teams define metrics around their concerns and build tools to monitor them.
この2つはRecSysコミュニティで活発に研究されている分野だが、私たちはまず、これらのチームが懸念事項に関するメトリクスを定義し、それを監視するツールを構築するのを支援した。
We also helped them provide insight into whether or not those problems were occurring on a per-item basis.
私たちはまた、それらの問題が項目ごとに発生しているかどうかについての洞察を提供する手助けもした。
We later integrated those tools directly into our issue detection component.
私たちは後に、これらのツールを問題検出コンポーネントに直接統合した。
This enabled us to 1) expand the issue detection coverage and 2) proactively address key issues related to items and build trust with our stakeholders.
これにより、1）課題検出範囲を拡大し、2）項目に関する重要課題に積極的に取り組み、ステークホルダーとの信頼関係を構築することができた。

Summary:
概要

Implement all the known best practices
既知のベストプラクティスをすべて実施する

Monitor the system end-to-end your own way
システムをエンド・ツー・エンドで監視する

Understand your stakeholders’ concerns
利害関係者の懸念を理解する

## Issue Prediction 問題予測

Detecting production issues quickly is great but it is even better if we can predict those issues and fix them before they are in production.
生産上の問題を素早く検出することは素晴らしいことだが、そのような問題を予測し、生産に入る前に修正することができればさらに良い。
As an example, proper cold-starting of an item (e.g.a new movie, show, or game) is important at Netflix because each item only launches once.
例えば、ネットフリックスでは、アイテム（新しい映画、番組、ゲームなど）の適切なコールドスタートが重要である。
So we wondered if we could predict if an item is going to have a cold-start issue before its launch date.
そこで私たちは、発売日前にコールドスタートの問題が発生するかどうかを予測できないかと考えた。
This requires predicting predictions of our future production model, which is challenging.
そのためには、将来の生産モデルを予測する必要があるが、これは難しい。
Using historical data points we built a model that could predict the behavioral statistics of our production model on the day of launch.
過去のデータポイントを使って、ローンチ当日のプロダクションモデルの行動統計を予測できるモデルを構築した。
This model enables us to catch potential issues related to cold-starting of items a week or more in advance, which leaves us time to fix the issue before items comes to the service.
このモデルによって、コールドスタートに関する潜在的な問題を1週間以上前に発見することができる。

Summary:
概要

Try to predict issues before they happen instead of detecting them after they hit production
生産に支障をきたしてから問題を発見するのではなく、問題が起こる前に予測するようにする。

## Issue Diagnosis 問題診断

Once an issue is identified with either detection or prediction models, the next phase is to find its root cause.
検出モデルまたは予測モデルによって問題が特定されたら、次の段階はその根本原因を見つけることである。
The first step in this process is to reproduce the issue in isolation.
このプロセスの最初のステップは、問題を単独で再現することである。
However, large-scale recommender systems are very dynamic and we may not be able to reproduce the issue by simply re-running the code e.g.the underlying input data or feature values might have changed.
しかし、大規模なレコメンダーシステムは非常に動的であり、コードを再実行するだけでは問題を再現できない可能性がある。
Therefore to reproduce the issue we need to set up proper logging in advance.
したがって、この問題を再現するには、事前に適切なロギングを設定する必要がある。
This includes logging of item candidates, context, features, serving model id or anything that is needed to reproduce the issue.
これには、アイテム候補、コンテキスト、フィーチャー、サービングモデルID、または問題を再現するために必要なあらゆるもののロギングが含まれます。
To reduce the cost, this information is logged for a fraction of the traffic.
コストを削減するため、この情報はトラフィックのごく一部で記録される。
In this case, we need to carefully design a sampling method that has sufficient coverage of all important slices of the traffic.
この場合、トラフィックのすべての重要なスライスを十分にカバーするサンプリング方法を注意深く設計する必要がある。

The next step after reproducing the issue is to figure out if the issue is related to inputs of the ML model or the model itself.
問題を再現した後の次のステップは、問題がMLモデルの入力に関係しているのか、モデル自体に関係しているのかを突き止めることです。
To understand if the issue is related to the input data we need to verify that the inputs are accurate and valid.
問題が入力データに関連しているかどうかを理解するためには、入力が正確で有効かどうかを検証する必要がある。
While it might be possible for some feature values to trace them back to their original facts and verify them, there could be many features that involve complex data processing or features that are machine learning models themselves.
特徴量の中には、元の事実をたどって検証できるものもあるかもしれないが、複雑なデータ処理を伴う特徴量や、機械学習モデルそのものである特徴量も多いだろう。
Thus, in practice validating the input values is a challenging problem.
したがって、実際には入力値の検証は難しい問題である。

A simple solution is to compare the feature values with corresponding values of a comparable item or member.
単純な解決策は、特徴値を、比較可能なアイテムまたはメンバーの対応する値と比較することである。
This enables us to determine if a feature value is within the expected range.
これにより、ある特徴量が予想される範囲内にあるかどうかを判断することができる。
While simple, this method is highly effective for flagging anomalies.
単純ではあるが、この方法は異常のフラグを立てるのに非常に効果的である。
For example in one case this method flagged abnormal values related to language features of an item.
例えば、ある事例では、この方法は項目の言語的特徴に関連する異常値にフラグを立てた。
Upon further investigation we found that the language of that item was not configured properly in the upstream database.
さらに調査したところ、そのアイテムの言語が上流のデータベースで適切に設定されていないことがわかりました。

If all input features are right, the next step is to dig deep inside the ML model and its training data to find the root cause of the issue.
すべての入力特徴が正しい場合、次のステップは、MLモデルとそのトレーニングデータの内部を深く掘り下げ、問題の根本原因を見つけることである。
There are many tools for model inspection as well as model interpretation, e.g.Shap [2] and Lime [3].
Shap[2]やLime[3]など、モデル検査やモデル解釈のためのツールは数多くある。
Based on the architecture of the model, we can also develop custom tools to check for expected properties.
モデルのアーキテクチャに基づいて、期待される特性をチェックするためのカスタムツールを開発することもできる。
For example visualizing nodes of decision trees or layers of a neural network.
例えば、決定木のノードやニューラルネットワークのレイヤーを視覚化する。
This type of analysis once helped us to identify a bug in handling missing values and in another case helped us to identify a faulty segment of training data.
この種の分析によって、欠損値処理のバグを特定できたこともあったし、訓練データの欠陥セグメントを特定できたこともあった。

Summary:
概要

Set up logging to reproduce issue
問題を再現するためのロギングの設定

Develop tools to check validity of inputs
入力の妥当性をチェックするツールを開発する

Develop tools to inspect internal components of ML models
MLモデルの内部コンポーネントを検査するツールの開発

## Issue Resolution 問題解決

Once the root cause of an issue is identified, the next step is to fix the issue.
問題の根本原因が特定されたら、次のステップは問題を解決することだ。
This part is similar to typical software engineering: we can have a short-term hotfix or a long-term solution.
この部分は典型的なソフトウェア・エンジニアリングに似ている： 短期的な応急処置もあれば、長期的な解決策もある。
However, applying a hotfix for an ML model is challenging.
しかし、MLモデルにホットフィックスを適用するのは難しい。
This is because these models are highly optimized, can take a while to train, and any manual alteration will likely result in suboptimal recommendations.
というのも、これらのモデルは高度に最適化されており、トレーニングに時間がかかり、手作業で変更を加えると、最適とは言えないレコメンデーションになる可能性が高いからだ。
So how can we hotfix the problem while minimizing the cost to the rest of the ecosystem? The solution requires domain insight and creativity that highly depends on the product, platform and stakeholders.
では、エコシステムの他の部分へのコストを最小限に抑えながら、問題をホットフィックスするにはどうすればいいのだろうか？その解決策には、製品、プラットフォーム、利害関係者に大きく依存するドメインの洞察力と創造性が必要だ。
Since each hotfix has its own trade-offs, it is better to have a menu of hotfix solutions prepared ahead of time.
それぞれのHotfixにはトレードオフがあるため、前もってHotfixソリューションのメニューを用意しておく方がよい。
This enables us to quickly choose and deploy the most appropriate one for each situation.
そのため、それぞれの状況に応じて最適なものを迅速に選択し、配備することができる。

Beyond fixing the issue another phase of issue resolution is improving RecSysOps itself.
問題解決のもう一つの段階は、RecSysOpsそのものを改善することである。
For example:
例えば、こうだ：

Is it possible to detect the issue faster? or maybe predict it?
問題をより早く発見することは可能か、あるいは予測することは可能か？

Is it possible to improve our tools to diagnose the issue faster?
より早く問題を診断するためにツールを改善することは可能ですか？

Finally, it is important to make RecSysOps as frictionless as possible.
最後に、RecSysOpsを可能な限り摩擦のないものにすることが重要である。
This makes the operations smooth and the system more reliable.
これにより、オペレーションがスムーズになり、システムの信頼性が高まる。
For example:
例えば、こうだ：

Make sure that checks in detection or prediction components are running on a regular automated basis.
検出または予測コンポーネントのチェックが定期的に自動実行されていることを確認する。

If human judgment is needed at some step, e.g.diagnosis or resolutions, make sure that person has all required information ready.
診断や解決など、何らかの段階で人間の判断が必要な場合は、その人間が必要な情報をすべて準備していることを確認する。
This will enable them to make informed decisions quickly
これによって、十分な情報に基づいた迅速な意思決定が可能になる

Make sure that deploying a hotfix is as simple as a couple of clicks
Hotfixの導入がクリック数回で完了するようにします。

Summary:
概要

Have a collection of hotfix strategies ready and quantify the trade-off associated with each one
ホットフィックス戦略のコレクションを用意し、それぞれに関連するトレードオフを定量化する。

With every incident make RecSysOps better
インシデントごとにRecSysOpsを改善する

Make RecSysOps as frictionless as possible
RecSysOpsを可能な限り摩擦のないものにする

## Conclusion 結論

In this blog post we introduced RecSysOps with a set of best practices and lessons that we’ve learned at Netflix.
このブログ記事では、Netflixで学んだベストプラクティスと教訓をもとにRecSysOpsを紹介した。
RecSysOps consists of four components: issue detection, issue prediction, issue diagnosis and issue resolution.
RecSysOpsは4つのコンポーネントで構成されている： 問題の検出、問題の予測、問題の診断、問題の解決です。
We think these patterns are useful to consider for anyone operating a real-world recommendation system to keep it performing well and improve it over time.
これらのパターンは、実世界の推薦システムを運用するすべての人にとって、そのパフォーマンスを維持し、長期的に改善するために考慮すべき有用なものであると考える。
Developing such components for a large-scale recommendation system is an iterative process with its own challenges and opportunities for future work.
大規模な推薦システムのためにこのようなコンポーネントを開発することは、独自の課題と今後の研究の機会を伴う反復プロセスである。
For example, different kinds of models may be needed for doing issue detection and prediction.
例えば、問題の検出と予測を行うためには、異なる種類のモデルが必要になるかもしれない。
For issue diagnosis and resolution, a deeper understanding of ML architectures and design assumptions is needed.
問題の診断と解決のためには、MLのアーキテクチャと設計の前提をより深く理解する必要がある。
Overall, putting these aspects together has helped us significantly reduce issues, increased trust with our stakeholders, and allowed us to focus on innovation.
全体として、これらの側面をまとめることで、問題を大幅に削減し、ステークホルダーとの信頼を高め、イノベーションに集中できるようになった。

We are always looking for more people to join our team.
私たちは常に、チームに加わってくれる仲間を募集しています。
If you are interested, make sure to take a look at our jobs page.
興味のある方は、求人ページをぜひご覧ください。