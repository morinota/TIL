# 5. Heterogeniety in Treatment Effects(HTE) 5. æ²»ç™‚åŠ¹æœã«ãŠã‘ã‚‹ç•°è³ªæ€§(HTE)

## 5.1. Problem # 5.1.Problem

Without loss of generality, we consider the case that there is only one treatment and one control.
ä¸€èˆ¬æ€§ã‚’æãªã‚ãªã„ã‚ˆã†ã«ã€æ²»ç™‚ã¨å¯¾ç…§ãŒ1ã¤ãšã¤ã—ã‹ãªã„å ´åˆã‚’è€ƒãˆã‚‹ã€‚
Under the potential outcome framework, (ğ‘Œ(1), ğ‘Œ(0)) is the potential outcome pairs and ğœ = ğ‘Œ(1) âˆ’ ğ‘Œ(0) is the individual treatment effect.
æ½œåœ¨çš„ã‚¢ã‚¦ãƒˆã‚«ãƒ ã®æ çµ„ã¿ã§ã¯ã€$(Y(1), Y(0))$ ã¯æ½œåœ¨çš„ãªã‚¢ã‚¦ãƒˆã‚«ãƒ ã®ãƒšã‚¢ã§ã‚ã‚Šã€$\tau = Y(1) - Y(0)$ ã¯å€‹ã€…ã®æ²»ç™‚åŠ¹æœã§ã‚ã‚‹ã€‚
The primary goal of an A/B test is to understand the average treatment effect (ATE), ğ¸(ğœ).
A/Bãƒ†ã‚¹ãƒˆã®ä¸»ãªç›®çš„ã¯ã€**average treatment effect (ATE)**ã€$E(\tau)$ ã‚’ç†è§£ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚
Although it is obvious that knowing individual effect is ideal, it is also impossible as we cannot observe the counterfactual.
å€‹ã€…ã®åŠ¹æœã‚’çŸ¥ã‚‹ã“ã¨ãŒç†æƒ³çš„ã§ã‚ã‚‹ã“ã¨ã¯æ˜ã‚‰ã‹ã ãŒã€åå®Ÿä»®æƒ³ã‚’è¦³å¯Ÿã™ã‚‹ã“ã¨ã¯ä¸å¯èƒ½ã§ã‚ã‚‹ã€‚
The closest thing is the conditional average treatment effect (CATE) [74], ğ¸(ğœ|ğ‘‹), where ğ‘‹ is some attribute or side information about each individual that is not affected by the treatment.
æœ€ã‚‚è¿‘ã„ã‚‚ã®ã¯ã€**conditional average treatment effectï¼ˆCATEï¼‰**[74]ã€$E(\tau|X)$ ã§ã‚ã‚Šã€$X$ ã¯æ²»ç™‚ã«å½±éŸ¿ã‚’å—ã‘ãªã„å„å€‹äººã«é–¢ã™ã‚‹å±æ€§ã‚„å‰¯æƒ…å ±ã§ã‚ã‚‹ã€‚
This makes CATE the best regression prediction of individual treatment effect ğœ based on ğ‘‹.
ã“ã‚Œã«ã‚ˆã‚Šã€CATEã¯ $X$ ã«åŸºã¥ãå€‹ã€…ã®æ²»ç™‚åŠ¹æœ $\tau$ ã®æœ€è‰¯ã®å›å¸°äºˆæ¸¬ã¨ãªã‚‹ã€‚

Attributes ğ‘‹ can be either discrete/categorical or continuous.
å±æ€§ $X$ ã¯é›¢æ•£çš„/ã‚«ãƒ†ã‚´ãƒªãƒ¼çš„ã§ã‚ã‚‹ã‹ã€é€£ç¶šçš„ã§ã‚ã‚‹ã‹ã®ã„ãšã‚Œã‹ã§ã‚ã‚‹ã€‚
Categorical ğ‘‹ segments the whole population into subpopulations, or segments.
**ã‚«ãƒ†ã‚´ãƒªãƒ¼ $X$ ã¯ã€å…¨äººå£ã‚’ã‚µãƒ–ãƒãƒ”ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ã¾ãŸã¯ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã™ã‚‹**ã€‚
In practice, the industry almost entirely uses categorical attributes.
å®Ÿéš›ã«ã¯ã€æ¥­ç•Œã¯ã»ã¨ã‚“ã©ã™ã¹ã¦ã‚«ãƒ†ã‚´ãƒªãƒ¼å±æ€§ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã€‚
Even continuous attributes are made discrete and considered ordered categorical segments.
é€£ç¶šçš„ãªå±æ€§ã‚‚é›¢æ•£çš„ãªã‚‚ã®ã¨ã•ã‚Œã€é †åºä»˜ã‘ã‚‰ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªãƒ¼åŒºåˆ†ã¨ã¿ãªã•ã‚Œã‚‹ã€‚(ãªã‚‹ã»ã©...?ãã†ãªã®ã‹...!)

Perhaps the most interesting cases are when treatment moves the same metric in different directions, or when the same metric has statistically significant movement in one segment but not in another segment.
ãŠãã‚‰ãæœ€ã‚‚èˆˆå‘³æ·±ã„ã‚±ãƒ¼ã‚¹ã¯ã€è¤‡æ•°ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§treatmentãŒåŒã˜ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ç•°ãªã‚‹æ–¹å‘ã«å‹•ã‹ã™å ´åˆã€ã¾ãŸã¯åŒã˜ãƒ¡ãƒˆãƒªãƒƒã‚¯ãŒ1ã¤ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§çµ±è¨ˆçš„ã«æœ‰æ„ãªå‹•ãã‚’ç¤ºã™ãŒã€åˆ¥ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§ã¯ãã†ã§ã¯ãªã„å ´åˆã§ã‚ã‚‹ã€‚
Assume, for a given segment, say market, a metric moves positively for some markets but negatively for another, both highly statistically significant.
ã‚ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆä¾‹ãˆã°å¸‚å ´ï¼‰ã«ãŠã„ã¦ã€ã‚ã‚‹æŒ‡æ¨™ãŒã‚ã‚‹å¸‚å ´ã§ã¯ãƒ—ãƒ©ã‚¹ã«å‹•ãã€åˆ¥ã®å¸‚å ´ã§ã¯ãƒã‚¤ãƒŠã‚¹ã«å‹•ãã€ã©ã¡ã‚‰ã‚‚çµ±è¨ˆçš„ã«éå¸¸ã«æœ‰æ„ã§ã‚ã£ãŸã¨ã™ã‚‹ã€‚
Making the same ship decision for all segments would be sub-optimal.
ã™ã¹ã¦ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§åŒã˜ship(=é©ç”¨)ã®æ±ºå®šã‚’ã™ã‚‹ã“ã¨ã¯ã€æœ€é©ã§ã¯ãªã„ã ã‚ã†ã€‚
Such cases uncover key insights about the differences between segments.
ã“ã®ã‚ˆã†ãªäº‹ä¾‹ã‹ã‚‰ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“ã®é•ã„ã«é–¢ã™ã‚‹é‡è¦ãªæ´å¯ŸãŒæ˜ã‚‰ã‹ã«ãªã‚‹ã€‚
Further investigation is needed to understand why the treatment was not appreciated in some markets and identify opportunities for improvement.
ã“ã®trearmentãŒã„ãã¤ã‹ã®å¸‚å ´ã§è©•ä¾¡ã•ã‚Œãªã‹ã£ãŸç†ç”±ã‚’ç†è§£ã—ã€æ”¹å–„ã®æ©Ÿä¼šã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã«ã¯ã€ã•ã‚‰ãªã‚‹èª¿æŸ»ãŒå¿…è¦ã§ã‚ã‚‹ã€‚
In some cases adaptive models can be used to fit different treatments on different types of users [6, 52, 53, 77].
å ´åˆã«ã‚ˆã£ã¦ã¯ã€é©å¿œãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€ç•°ãªã‚‹ã‚¿ã‚¤ãƒ—ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç•°ãªã‚‹æ²»ç™‚ã‚’é©åˆã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹[6, 52, 53, 77]ã€‚

However, most common cases of HTE only show difference in magnitude, not direction.
ã—ã‹ã—ã€ä¸€èˆ¬çš„ãªHTE(Heterogeniety Treatment Effects)ã®ã‚±ãƒ¼ã‚¹ã®ã»ã¨ã‚“ã©ã¯ã€æ–¹å‘ã§ã¯ãªãã€å¤§ãã•ã®é•ã„ã‚’ç¤ºã™ã ã‘ã§ã‚ã‚‹ã€‚
Knowledge of these differences can be valuable for detecting outlier segments that may be indicative of bugs affecting a segment, or for encouraging further investment into different segments based on results.
ã“ã‚Œã‚‰ã®é•ã„ã®çŸ¥è­˜ã¯ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ãƒã‚°ã®æŒ‡æ¨™ã¨ãªã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ã‚¢ãƒ¼ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã«è²´é‡ã§ã‚ã‚Šã€çµæœã«åŸºã¥ã„ã¦ç•°ãªã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¸ã®ã•ã‚‰ãªã‚‹æŠ•è³‡ã‚’å¥¨åŠ±ã™ã‚‹ãŸã‚ã«ã‚‚å½¹ç«‹ã¤ã€‚

<!-- ã“ã“ã¾ã§èª­ã‚“ã  -->

## 5.2. Common Solutions and Challenges

### 5.2.1. Common Segments 5.2.1. å…±é€šã‚»ã‚°ãƒ¡ãƒ³ãƒˆ

It is a very common practice to define key segments based on product and user knowledge.
è£½å“ã‚„ãƒ¦ãƒ¼ã‚¶ã®çŸ¥è­˜ã«åŸºã¥ã„ã¦ä¸»è¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å®šç¾©ã™ã‚‹ã®ã¯ã€ã”ãä¸€èˆ¬çš„ãªã‚„ã‚Šæ–¹ã ã€‚
Where possible, it is preferred to define segments so that the treatment does not interact with the segment definition to avoid bias.
å¯èƒ½ã§ã‚ã‚Œã°ã€ãƒã‚¤ã‚¢ã‚¹ã‚’é¿ã‘ã‚‹ãŸã‚ã«ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå®šç¾©ã¨treatmentãŒç›¸äº’ä½œç”¨ã—ãªã„ã‚ˆã†ã«ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å®šç¾©ã™ã‚‹ã“ã¨ãŒæœ›ã¾ã—ã„ã€‚(RCTã®ãƒ©ãƒ³ãƒ€ãƒ åŒ–ãŒã‚»ã‚°ãƒ¡ãƒ³ãƒˆå®šç¾©ã¨ç›¸é–¢ã—ãªã„ã‚ˆã†ã«ã€ã¿ãŸã„ãªã“ã¨ã‹ãª?)
Here are some of commonly defined segments for many software products and services:
ä»¥ä¸‹ã¯ã€å¤šãã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢è£½å“ã‚„ã‚µãƒ¼ãƒ“ã‚¹ã«ãŠã„ã¦ä¸€èˆ¬çš„ã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§ã‚ã‚‹

#### Market/country:

Market is commonly used by all companies with global presence who are running experiments and shipping features across different markets.
å¸‚å ´ã¯ã€ç•°ãªã‚‹å¸‚å ´ã«å®Ÿé¨“ã‚’å®Ÿæ–½ã—ã€æ©Ÿèƒ½ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¦ã„ã‚‹ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¼æ¥­ã«ã‚ˆã£ã¦ä¸€èˆ¬çš„ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚
When there are too many markets, it is useful to put them into larger categories or buckets like markets already with high penetration and growing markets or markets clustered by language.
å¸‚å ´ãŒå¤šã™ãã‚‹å ´åˆã€å¸‚å ´ãŒã™ã§ã«æµ¸é€ã—ã¦ã„ã‚‹å¸‚å ´ã‚„æˆé•·å¸‚å ´ã€è¨€èªã«ã‚ˆã£ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åŒ–ã•ã‚ŒãŸå¸‚å ´ãªã©ã€ã‚ˆã‚Šå¤§ããªã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚„ãƒã‚±ãƒƒãƒˆã«åˆ†é¡ã™ã‚‹ã“ã¨ãŒæœ‰åŠ¹ã§ã‚ã‚‹ã€‚

#### 2.User activity level:

Classifying users based on their activity level into heavy, light and new users can show interesting HTE.
ãƒ¦ãƒ¼ã‚¶ã®æ´»å‹•ãƒ¬ãƒ™ãƒ«ã«åŸºã¥ã„ã¦ãƒ¦ãƒ¼ã‚¶ã‚’é‡åº¦ã€è»½åº¦ã€æ–°è¦ãƒ¦ãƒ¼ã‚¶ã«åˆ†é¡ã™ã‚‹ã“ã¨ã§ã€èˆˆå‘³æ·±ã„HTEãŒç¤ºã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚
It is important to have this classification based on data before the experiment started to avoid any bias.
ãƒã‚¤ã‚¢ã‚¹ã‚’é¿ã‘ã‚‹ãŸã‚ã«ã€å®Ÿé¨“ãŒé–‹å§‹ã•ã‚Œã‚‹å‰ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã“ã®åˆ†é¡ã‚’è¡Œã†ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ã€‚

#### 3.Device and platform:

Today most products have both desktop and mobile application.
ä»Šæ—¥ã€ã»ã¨ã‚“ã©ã®è£½å“ã¯ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã¨ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ä¸¡æ–¹ã‚’æŒã£ã¦ã„ã‚‹ã€‚
We can test most backend server-side features across devices and platforms.
ãƒ‡ãƒã‚¤ã‚¹ã‚„ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’å•ã‚ãšã€ã»ã¨ã‚“ã©ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ã®æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
With device and platform fragmentation, it is getting harder to eliminate bugs for all devices and platforms.
ãƒ‡ãƒã‚¤ã‚¹ã‚„ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®åˆ†æ•£åŒ–ã«ã‚ˆã‚Šã€ã™ã¹ã¦ã®ãƒ‡ãƒã‚¤ã‚¹ã‚„ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®ãƒã‚°ã‚’æ’é™¤ã™ã‚‹ã®ãŒé›£ã—ããªã£ã¦ã„ã¾ã™ã€‚
Using device and platform segments in A/B testing is essential to flag potential bugs using live traffic.
A/Bãƒ†ã‚¹ãƒˆã§ãƒ‡ãƒã‚¤ã‚¹ã¨ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã¯ã€ãƒ©ã‚¤ãƒ–ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦æ½œåœ¨çš„ãªãƒã‚°ã‚’ãƒ•ãƒ©ã‚°ä»˜ã‘ã™ã‚‹ãŸã‚ã«ä¸å¯æ¬ ã§ã‚ã‚‹ã€‚(??)
For example, in a recent experiment, a feature of the Outlook mobile app was moving key metrics on all Android devices except a few versions, which indicated further investigation was needed.
ä¾‹ãˆã°ã€æœ€è¿‘ã®å®Ÿé¨“ã§ã¯ã€Outlookãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªã®æ©Ÿèƒ½ãŒã€ä¸€éƒ¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’é™¤ã„ã¦ã™ã¹ã¦ã®Androidãƒ‡ãƒã‚¤ã‚¹ã§ä¸»è¦ãªãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ç§»å‹•ã—ã¦ã„ãŸãŸã‚ã€ã•ã‚‰ãªã‚‹èª¿æŸ»ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚
Device and platforms also represent different demographics.
ãƒ‡ãƒã‚¤ã‚¹ã‚„ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚‚ã¾ãŸã€ã•ã¾ã–ã¾ãªå±¤ã‚’è¡¨ã—ã¦ã„ã‚‹ã€‚
Many studies show a difference between iOS users and Android users.
å¤šãã®èª¿æŸ»ã§ã€iOSãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨Androidãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é•ã„ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚

#### 4.Time and day of week:

Another common segment used is time.
ã‚‚ã†ä¸€ã¤ã®ä¸€èˆ¬çš„ã«ä½¿ç”¨ã•ã‚Œã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯æ™‚é–“ã§ã‚ã‚‹ã€‚
Plotting the effects delta or percent delta by day can show interesting patterns, such as the weekday and weekend effect, reveal a novelty effect [13], and help flag data quality issues.
æ—¥ã”ã¨ã«åŠ¹æœã®ãƒ‡ãƒ«ã‚¿(=å·®åˆ†)ã‚„ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆãƒ‡ãƒ«ã‚¿ã‚’ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ã“ã¨ã§ã€å¹³æ—¥ã¨é€±æœ«ã®åŠ¹æœã€æ–°è¦æ€§ã®åŠ¹æœ[13]ãªã©ã€èˆˆå‘³æ·±ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ãƒ‡ãƒ¼ã‚¿å“è³ªã®å•é¡Œã‚’ãƒ•ãƒ©ã‚°ä»˜ã‘ã™ã‚‹ã®ã«å½¹ç«‹ã¤ã€‚

#### 5.Product specific segments:

LinkedIn segmented users by normal user and recruiter.
LinkedInã¯ã€é€šå¸¸ã®ãƒ¦ãƒ¼ã‚¶ã¨ãƒªã‚¯ãƒ«ãƒ¼ã‚¿ã«ã‚ˆã£ã¦ãƒ¦ãƒ¼ã‚¶ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã—ã¦ã„ã‚‹ã€‚
On Twitter, some handles can belong to a single user, so it is useful to segment Twitter handles by primary or secondary account.
Twitterã§ã¯ã€ã„ãã¤ã‹ã®ãƒãƒ³ãƒ‰ãƒ«ãŒ1äººã®ãƒ¦ãƒ¼ã‚¶ã«å±ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€Twitterãƒãƒ³ãƒ‰ãƒ«ã‚’ä¸»è¦ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¨å‰¯æ¬¡ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ã‚ˆã£ã¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã™ã‚‹ã“ã¨ãŒæœ‰ç”¨ã§ã‚ã‚‹ã€‚
For Netflix, network speed and device types have proved to be good segments.
Netflixã®å ´åˆã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€Ÿåº¦ã¨ãƒ‡ãƒã‚¤ã‚¹ã®ç¨®é¡ãŒè‰¯ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§ã‚ã‚‹ã“ã¨ãŒè¨¼æ˜ã•ã‚Œã¦ã„ã‚‹ã€‚
Airbnb has found that segments of customers based on whether they have booked before and based on from where they first arrived on Airbnb site are useful.
Airbnbã¯ã€ä»¥å‰ã«äºˆç´„ã—ãŸã‹ã©ã†ã‹ã‚„ã€Airbnbã®ã‚µã‚¤ãƒˆã‚’æœ€åˆã«è¨ªã‚ŒãŸå ´æ‰€ã«åŸºã¥ã„ã¦é¡§å®¢ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã™ã‚‹ã“ã¨ãŒæœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ãŸã€‚

### 5.2.2. Methodology and Computation 5.2.2. æ–¹æ³•è«–ã¨è¨ˆç®—

Our community recognizes a lot of recent work from both academia and industry.
ç§ãŸã¡ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¯ã€å­¦ç•Œã¨ç”£æ¥­ç•Œã®ä¸¡æ–¹ã‹ã‚‰å¤šãã®æœ€è¿‘ã®ä»•äº‹ã‚’èªã‚ã¦ã„ã‚‹ã€‚
The most common mental model is the linear model with a first-order interaction term between treatment assignment and covariates ğ‘‹: ğ‘Œ = ğœƒ + ğ›¿ğ‘‡ + ğ›½ Ã— ğ‘‡ Ã— ğ‘‹ + ğœ– .
æœ€ã‚‚ä¸€èˆ¬çš„ãªãƒ¡ãƒ³ã‚¿ãƒ«ãƒ»ãƒ¢ãƒ‡ãƒ«ã¯ã€treatmentå‰²ã‚Šå½“ã¦ã¨å…±å¤‰é‡ $X$ ã®é–“ã®1æ¬¡ã®ç›¸äº’ä½œç”¨é …ã‚’æŒã¤ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ï¼š$Y = \theta + \delta T + \beta \times T \times X + \epsilon$ã€‚

Most useful segments used by the community are categorical, so the linear model suffices.
ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã§ä½¿ç”¨ã•ã‚Œã‚‹ã»ã¨ã‚“ã©ã®æœ‰ç”¨ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ã§ã‚ã‚‹ãŸã‚ã€ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã§ååˆ†ã§ã‚ã‚‹ã€‚
There is consensus that the first-order treatment effect adjustment by a single covariate, such as a segment of one categorical variable, is the most actionable.
1ã¤ã®å…±å¤‰é‡ï¼ˆä¾‹ãˆã°ã€1ã¤ã®ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼‰ã«ã‚ˆã‚‹1æ¬¡æ²»ç™‚åŠ¹æœã®èª¿æ•´ãŒæœ€ã‚‚å®Ÿè¡Œå¯èƒ½ã§ã‚ã‚‹ã¨ã„ã†åˆæ„ãŒã‚ã‚‹ã€‚
One active area of research is adapting more MLMs for identifying HTE [74].
HTEã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã«ã€ã‚ˆã‚Šå¤šãã®MLM(=??)ã‚’é©å¿œã•ã›ã‚‹ã“ã¨ãŒã€æ´»ç™ºãªç ”ç©¶åˆ†é‡ã®1ã¤ã§ã‚ã‚‹[74]ã€‚

Nevertheless, there are a lot of outstanding challenges: 1.
ã¨ã¯ã„ãˆã€æœªè§£æ±ºã®èª²é¡Œã‚‚å¤šã„ï¼š

- 1. **Computation scale:** Because A/B tests routinely analyze hundreds or thousands of metrics on millions of experiment units (users), the resources and time spent on an automatically scheduled analysis cannot be too much to ensure that results are not delayed and are not too expensive to generate.
     è¨ˆç®—è¦æ¨¡ï¼š A/Bãƒ†ã‚¹ãƒˆã¯ã€ä½•ç™¾ã‚‚ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ä½•ç™¾ä¸‡ã‚‚ã®å®Ÿé¨“å˜ä½ï¼ˆãƒ¦ãƒ¼ã‚¶ï¼‰ã§å®šæœŸçš„ã«åˆ†æã™ã‚‹ãŸã‚ã€çµæœãŒé…ã‚Œã‚‹ã“ã¨ãªãã€ç”Ÿæˆã«é«˜ã™ããªã„ã“ã¨ã‚’ä¿è¨¼ã™ã‚‹ãŸã‚ã«ã€è‡ªå‹•ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã•ã‚ŒãŸåˆ†æã«è²»ã‚„ã•ã‚Œã‚‹ãƒªã‚½ãƒ¼ã‚¹ã¨æ™‚é–“ã¯å¤šã™ãã¦ã¯ãªã‚‰ãªã„ã€‚
     There is a desire to use a simple algorithm directly formulated using sufficient statistics, instead of using individual-unit level data.
     å€‹ä½“ãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ä»£ã‚ã‚Šã«ã€ååˆ†ãªçµ±è¨ˆé‡ã‚’ä½¿ç”¨ã—ã¦ç›´æ¥å®šå¼åŒ–ã•ã‚ŒãŸå˜ç´”ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã—ãŸã„ã¨ã„ã†è¦æœ›ãŒã‚ã‚‹ã€‚
- 2.**Low Signal Noise Ratio (SNR)**: A/B testing is already dealing with low power to estimate the average treatment effect.
  ä½ä¿¡å·é›‘éŸ³æ¯”ï¼ˆSNRï¼‰ï¼š A/Bãƒ†ã‚¹ãƒˆã¯ã™ã§ã«å¹³å‡æ²»ç™‚åŠ¹æœã‚’æ¨å®šã™ã‚‹ãŸã‚ã®ä½ã„ãƒ‘ãƒ¯ãƒ¼ã‚’æ‰±ã£ã¦ã„ã‚‹ã€‚
  Learning HTE is even harder than learning ATE because of the reduced sample sizes in each subpopulation.
  HTEã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã¯ã€å„ã‚µãƒ–ãƒãƒ”ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒæ¸›å°‘ã™ã‚‹ãŸã‚ã€ATEã‚’å­¦ç¿’ã™ã‚‹ã‚ˆã‚Šã‚‚ã•ã‚‰ã«é›£ã—ã„ã€‚

- 3.**Multiple Testing Problem** [66]: There is a severe multiple testing problem when looking at many metrics, and many possible ways to segment the population. 3.å¤šé‡æ¤œå®šå•é¡Œ [66]ï¼å¤šãã®æŒ‡æ¨™ã‚’è¦‹ã‚‹å ´åˆã€ã¾ãŸæ¯é›†å›£ã‚’åŒºåˆ†ã™ã‚‹å¤šãã®å¯èƒ½ãªæ–¹æ³•ã‚’è¦‹ã‚‹å ´åˆã€æ·±åˆ»ãªå¤šé‡æ¤œå®šã®å•é¡ŒãŒã‚ã‚‹ã€‚
  This issue, along with low SNR further complicates HTE estimations.
  ã“ã®å•é¡Œã¯ã€ä½SNRã¨ã¨ã‚‚ã«HTEæ¨å®šã‚’ã•ã‚‰ã«è¤‡é›‘ã«ã™ã‚‹ã€‚

- 4.**Interpretable and memorable results**: Most experimenters are not experts in statistics or machine learning. 4.è§£é‡ˆå¯èƒ½ã§è¨˜æ†¶ã«æ®‹ã‚‹çµæœï¼š ã»ã¨ã‚“ã©ã®å®Ÿé¨“è€…ã¯çµ±è¨ˆã‚„æ©Ÿæ¢°å­¦ç¿’ã®å°‚é–€å®¶ã§ã¯ãªã„ã€‚
  You must have concise and memorable result summaries to facilitate experimenters to act.
  å®Ÿé¨“è€…ãŒè¡Œå‹•ã™ã‚‹ãŸã‚ã«ã¯ã€ç°¡æ½”ã§è¨˜æ†¶ã«æ®‹ã‚‹çµæœã®è¦ç´„ãŒå¿…è¦ã§ã‚ã‚‹ã€‚
- 5.Absolute vs. Relative: While determining the HTE, you must decide whether you will use absolute CATE or relative CATE (as a percentage of average value of the metric in control).
  çµ¶å¯¾çš„å¯¾ç›¸å¯¾çš„ï¼š HTEã‚’æ±ºå®šã™ã‚‹éš›ã€çµ¶å¯¾çš„CATEã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€ç›¸å¯¾çš„CATEï¼ˆç®¡ç†å¯¾è±¡ã®æŒ‡æ¨™ã®å¹³å‡å€¤ã«å¯¾ã™ã‚‹ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã‚’æ±ºå®šã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚
  In many cases it makes sense to use the relative CATE as the baseline or the average value of a control metric can be very different for different segments, like different countries.
  å¤šãã®å ´åˆã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã—ã¦ç›¸å¯¾çš„ãªCATEã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã¯ç†ã«ã‹ãªã£ã¦ã„ã‚‹ã€‚ã‚ã‚‹ã„ã¯ã€ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«æŒ‡æ¨™ã®å¹³å‡å€¤ã¯ã€ç•°ãªã‚‹å›½ã®ã‚ˆã†ã«ç•°ãªã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§å¤§ããç•°ãªã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚
  Use a relative CATE to normalize the treatment effect in different segments.
  ç•°ãªã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«ãŠã‘ã‚‹æ²»ç™‚åŠ¹æœã‚’æ­£è¦åŒ–ã™ã‚‹ãŸã‚ã«ã€ç›¸å¯¾çš„CATEã‚’ä½¿ç”¨ã™ã‚‹ã€‚
  (çµ¶å¯¾å€¤ã‹ã€ä½•å€ã€ã¿ãŸã„ãªç›¸å¯¾çš„ãªè¡¨ç¾ã‚’ä½¿ã†ã‹ã€ã¿ãŸã„ãªè©±...??:thinking_face:)

To tackle these challenges, there are common approaches companies take.
ã“ã‚Œã‚‰ã®èª²é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€ä¼æ¥­ãŒå–ã‚‹ä¸€èˆ¬çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒã‚ã‚‹ã€‚

- 1. Separate on-demand and scheduled analysis.
     For ondemand analysis, people are willing to spend more resources and wait longer to get results.
     ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰åˆ†æã§ã¯ã€äººã€…ã¯çµæœã‚’å¾—ã‚‹ãŸã‚ã«ã‚ˆã‚Šå¤šãã®ãƒªã‚½ãƒ¼ã‚¹ã‚’è²»ã‚„ã—ã€ã‚ˆã‚Šé•·ãå¾…ã¤ã“ã¨ã‚’å­ã‚ãªã„ã€‚
     For this kind of one-off analysis, linear regression with sparsity (L1 and elastic net) and tree-based algorithms, like causal tree, are very popular.
     ã“ã®ã‚ˆã†ãªä¸€å›é™ã‚Šã®åˆ†æã«ã¯ã€ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã‚’æŒã¤ç·šå½¢å›å¸°ï¼ˆL1ã‚„ã‚¨ãƒ©ã‚¹ãƒ†ã‚£ãƒƒã‚¯ãƒãƒƒãƒˆï¼‰ã‚„ã€å› æœæœ¨ã®ã‚ˆã†ãªæœ¨ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒéå¸¸ã«ã‚ˆãä½¿ã‚ã‚Œã‚‹ã€‚
     Double ML also gained a lot of attention recently [14].
     æœ€è¿‘ã§ã¯ã€Double MLã‚‚å¤šãã®æ³¨ç›®ã‚’é›†ã‚ã¦ã„ã‚‹[14]ã€‚
- 2. Because of the challenge of low SNR and multiple testing, sparse modeling is a must. 2.ä½SNRã¨å¤šé‡æ¤œå®šã®èª²é¡Œã®ãŸã‚ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã¯å¿…é ˆã§ã‚ã‚‹ã€‚
     Even if the ground truth is not sparse, there are limited resources that experimenters can spend on learning and taking actions based on HTE.
     ground-truthãŒã‚¹ãƒ‘ãƒ¼ã‚¹ã§ãªãã¦ã‚‚ã€å®Ÿé¨“è€…ãŒHTEã«åŸºã¥ã„ã¦å­¦ç¿’ã—ã€è¡Œå‹•ã‚’èµ·ã“ã™ãŸã‚ã«è²»ã‚„ã™ã“ã¨ãŒã§ãã‚‹ãƒªã‚½ãƒ¼ã‚¹ã¯é™ã‚‰ã‚Œã¦ã„ã‚‹ã€‚
     Sparse modeling forces concise results.
- 3. To make results memorable, when certain segment has many values, markets might have a lot of values, it is desired to merge those values based on a common effect. 3.çµæœã‚’è¨˜æ†¶ã«æ®‹ã‚‹ã‚‚ã®ã«ã™ã‚‹ãŸã‚ã«ã€ã‚ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒå¤šãã®å€¤ã‚’æŒã¤å ´åˆã€å¸‚å ´ã¯å¤šãã®å€¤ã‚’æŒã¤å¯èƒ½æ€§ãŒã‚ã‚Šã€å…±é€šã®åŠ¹æœã«åŸºã¥ã„ã¦ãã‚Œã‚‰ã®å€¤ã‚’ãƒãƒ¼ã‚¸ã™ã‚‹ã“ã¨ãŒæœ›ã¾ã‚Œã‚‹ã€‚
     For instance, the effect might be different for Asian markets compared to rest of the world.
     **ä¾‹ãˆã°ã€ã‚¢ã‚¸ã‚¢å¸‚å ´ã¨ãã‚Œä»¥å¤–ã®å¸‚å ´ã§ã¯åŠ¹æœãŒç•°ãªã‚‹ã‹ã‚‚ã—ã‚Œãªã„**ã€‚
     Instead of reporting market HTE and list treatment effect estimates for individual markets, it is better to merge Asian markets and the rest of the world, and report only two different effect estimates.
     å€‹ã€…ã®å¸‚å ´ã«ã¤ã„ã¦ã€å¸‚å ´HTEã¨ãƒªã‚¹ãƒˆæ²»ç™‚åŠ¹æœæ¨å®šå€¤ã‚’å ±å‘Šã™ã‚‹ä»£ã‚ã‚Šã«ã€ã‚¢ã‚¸ã‚¢å¸‚å ´ã¨ãã®ä»–ã®å¸‚å ´ã‚’çµ±åˆã—ã€2ã¤ã®ç•°ãªã‚‹åŠ¹æœæ¨å®šå€¤ã®ã¿ã‚’å ±å‘Šã™ã‚‹æ–¹ãŒã‚ˆã„ã€‚
     Algorithms that can perform regression and clustering is preferred in these cases, including Fused Lasso [69] and Total Variation Regularization.
     ã“ã®ã‚ˆã†ãªã‚±ãƒ¼ã‚¹ã§ã¯ã€Fused Lasso [69]ã‚„Total Variation Regularizationãªã©ã€å›å¸°ã¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œã§ãã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒå¥½ã¾ã‚Œã¾ã™ã€‚

<!-- â†‘ã®ç« ã‚ˆãã‚ã‹ã£ã¦ãªã„...! -->

### 5.2.3. Correlation is not Causation 5.2.3. ç›¸é–¢é–¢ä¿‚ã¯å› æœé–¢ä¿‚ã§ã¯ãªã„

Another difficulty in acting based on HTE results is more fundamental: HTE results are not causal, only correlational.
HTEã®çµæœã«åŸºã¥ã„ã¦è¡Œå‹•ã™ã‚‹ã“ã¨ã®ã‚‚ã†ä¸€ã¤ã®é›£ã—ã•ã¯ã€ã‚ˆã‚Šæ ¹æœ¬çš„ãªã‚‚ã®ã§ã‚ã‚‹ï¼š HTEã®çµæœã¯å› æœé–¢ä¿‚ã§ã¯ãªãã€ç›¸é–¢é–¢ä¿‚ã«ã™ããªã„ã€‚
HTE is a regression to predict individual treatment effect based on covariates ğ‘‹.
**HTEã¯ã€å…±å¤‰é‡ğ‘‹ã«åŸºã¥ã„ã¦å€‹ã€…ã®æ²»ç™‚åŠ¹æœã‚’äºˆæ¸¬ã™ã‚‹å›å¸°ã§ã‚ã‚‹ã€‚** (HTEã£ã¦ãã†ãªã®ã‹...!)
There is no guarantee that predictor ğ‘‹ explains the root cause of the HTE.
äºˆæ¸¬å¤‰æ•°ğ‘‹ãŒHTEã®æ ¹æœ¬åŸå› ã‚’èª¬æ˜ã™ã‚‹ã¨ã„ã†ä¿è¨¼ã¯ãªã„ã€‚
In fact, when covariates ğ‘‹ are correlated, there might be even issues like collinearity.
å®Ÿéš›ã€å…±å¤‰é‡ğ‘‹ãŒç›¸é–¢ã—ã¦ã„ã‚‹å ´åˆã€å…±ç·šæ€§ã®ã‚ˆã†ãªå•é¡Œã•ãˆã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚
For example, we may find HTE in devices showing iOS users and Android users have different effect.
ä¾‹ãˆã°ã€iOSãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ãƒ³ãƒ‰ãƒ­ã‚¤ãƒ‰ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã¯ã€HTEãŒç•°ãªã‚‹åŠ¹æœã‚’ç¤ºã™ãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚
Do we know if device is the reason why the treatment effects are different? Of course not.
æ²»ç™‚åŠ¹æœãŒç•°ãªã‚‹ç†ç”±ãŒãƒ‡ãƒã‚¤ã‚¹ã«ã‚ã‚‹ã®ã‹ã©ã†ã‹ã€ã‚ã‹ã£ã¦ã„ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿã‚‚ã¡ã‚ã‚“ã‚ã‹ã‚‰ãªã„ã€‚
iOS and Android users are different in many ways.
iOSã¨ã‚¢ãƒ³ãƒ‰ãƒ­ã‚¤ãƒ‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å¤šãã®ç‚¹ã§ç•°ãªã£ã¦ã„ã‚‹ã€‚
To help experimenters investigate the difference, an HTE model that can adjust the contribution of devices by other factors would be more useful.
å®Ÿé¨“è€…ãŒãã®é•ã„ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã«ã¯ã€ä»–ã®è¦å› ã«ã‚ˆã£ã¦ãƒ‡ãƒã‚¤ã‚¹ã®è²¢çŒ®åº¦ã‚’èª¿æ•´ã§ãã‚‹HTEãƒ¢ãƒ‡ãƒ«ãŒã‚ˆã‚Šæœ‰ç”¨ã§ã‚ã‚ã†ã€‚
Historical patterns and knowledge about whether investigating a segment ğ‘‹ helped to understand HTE of a metric ğ‘€ could provide extra side information.
æ­´å²çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„ã€ã‚ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’èª¿æŸ»ã™ã‚‹ã“ã¨ãŒãã®æŒ‡æ¨™ã®HTEã‚’ç†è§£ã™ã‚‹ã®ã«å½¹ç«‹ã£ãŸã‹ã©ã†ã‹ã«ã¤ã„ã¦ã®çŸ¥è­˜ã¯ã€ä½™åˆ†ãªã‚µã‚¤ãƒ‰æƒ…å ±ã‚’æä¾›ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚

# 6. Developing Experimentation Culture 6. å®Ÿé¨“æ–‡åŒ–ã®ç™ºå±•

<!-- section 5ã®ç†è§£ã¯ä¸€æ—¦é£›ã°ãã†! section 6ãŒå¤§äº‹ãã†...! -->

## 6.1. Problem # 6.1.Problem

Culture is the tacit social order of an organization.
**æ–‡åŒ–ã¨ã¯ã€çµ„ç¹”ã®æš—é»™ã®ç¤¾ä¼šç§©åº**ã§ã‚ã‚‹ã€‚
It shapes attitudes and behaviors in wide-ranging and durable ways.
ãã‚Œã¯ã€åºƒç¯„ã‹ã¤æ°¸ç¶šçš„ãªæ–¹æ³•ã§æ…‹åº¦ã‚„è¡Œå‹•ã‚’å½¢æˆã™ã‚‹ã€‚
Cultural norms define what is encouraged, discouraged, accepted, or rejected within a group [35].
**æ–‡åŒ–çš„è¦ç¯„ã¯ã€é›†å›£ã®ä¸­ã§ä½•ãŒå¥¨åŠ±ã•ã‚Œã€ä½•ãŒè½èƒ†ã•ã‚Œã€ä½•ãŒå—ã‘å…¥ã‚Œã‚‰ã‚Œã€ä½•ãŒæ‹’å¦ã•ã‚Œã‚‹ã‹ã‚’è¦å®šã™ã‚‹ã‚‚ã®**ã§ã‚ã‚‹ï¼»35ï¼½ã€‚
There is a big challenge in creating an experiment-driven product development culture in an organization.
çµ„ç¹”å†…ã«å®Ÿé¨“ä¸»å°ã®è£½å“é–‹ç™ºæ–‡åŒ–ã‚’ç”Ÿã¿å‡ºã™ã«ã¯ã€å¤§ããªèª²é¡ŒãŒã‚ã‚‹ã€‚

Cultural change involves transformation of an organization through multiple phases.
æ–‡åŒ–çš„å¤‰åŒ–ã«ã¯ã€è¤‡æ•°ã®æ®µéšã‚’çµŒãŸçµ„ç¹”ã®å¤‰é©ãŒå«ã¾ã‚Œã‚‹ã€‚
There may be hubris at first, where every idea of the team is considered a winner.
æœ€åˆã¯æ€ã„ä¸ŠãŒã‚ŠãŒã‚ã‚Šã€ãƒãƒ¼ãƒ ã®ã™ã¹ã¦ã®ã‚¢ã‚¤ãƒ‡ã‚¢ãŒå‹è€…ã¨ã¿ãªã•ã‚Œã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚
Then there may be introduction of some skepticism as the team begins experimentation and its intuition gets challenged.
ãƒãƒ¼ãƒ ãŒå®Ÿé¨“ã‚’é–‹å§‹ã—ã€ãã®ç›´æ„ŸãŒå•ã‚ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ã¨ã€æ‡ç–‘çš„ãªè¦‹æ–¹ãŒå°å…¥ã•ã‚Œã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚
Finally, a culture develops where there is humility about our value judgement of different ideas, and better understanding of the product and customers [3].
æœ€çµ‚çš„ã«ã¯ã€ç•°ãªã‚‹ã‚¢ã‚¤ãƒ‡ã‚¢ã«å¯¾ã™ã‚‹ä¾¡å€¤åˆ¤æ–­ã«è¬™è™šã«ãªã‚Šã€è£½å“ã‚„é¡§å®¢ã«å¯¾ã™ã‚‹ç†è§£ã‚’æ·±ã‚ã‚‹æ–‡åŒ–ãŒè‚²ã¾ã‚Œã‚‹[3]ã€‚

It is well known that our intuition is a poor judge for the value of ideas.
ç§ãŸã¡ã®ç›´æ„ŸãŒã‚¢ã‚¤ãƒ‡ã‚¢ã®ä¾¡å€¤ã‚’åˆ¤æ–­ã™ã‚‹ã®ã«é©ã—ã¦ã„ãªã„ã“ã¨ã¯ã‚ˆãçŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ã€‚
Case studies at Microsoft showed a third of all ideas tested through an OCE succeed in showing statistically significant improvements in key metrics of interest, and a third showed statistically significant regressions.
Microsoftã®äº‹ä¾‹ç ”ç©¶ã§ã¯ã€OCEã‚’é€šã˜ã¦ãƒ†ã‚¹ãƒˆã•ã‚ŒãŸã™ã¹ã¦ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã®ã†ã¡ã€3åˆ†ã®1ãŒèˆˆå‘³ã®ã‚ã‚‹ä¸»è¦ãªãƒ¡ãƒˆãƒªãƒƒã‚¯ã§çµ±è¨ˆçš„ã«æœ‰æ„ãªæ”¹å–„ã‚’ç¤ºã—ã€3åˆ†ã®1ãŒçµ±è¨ˆçš„ã«æœ‰æ„ãªé€€è¡Œã‚’ã—ã‚ã—ãŸã€‚
Similar results have been noted by many major software companies [3, 17, 28, 47, 56, 60].
åŒæ§˜ã®çµæœã¯ã€å¤šãã®å¤§æ‰‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ä¼šç¤¾ã§ã‚‚æŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹[3, 17, 28, 47, 56, 60]ã€‚
Yet it can be hard to subject your idea to an OCE and receive negative feedback, especially when you have spent a lot of time working on implementing it and selling it to your team.
**ã¨ã¯ã„ãˆã€è‡ªåˆ†ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’OCEã®å¯¾è±¡ã«ã—ã¦å¦å®šçš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ã‘ã‚‹ã®ã¯ã€ç‰¹ã«ã€ãã®ã‚¢ã‚¤ãƒ‡ã‚¢ã®å®Ÿè£…ã‚„ãƒãƒ¼ãƒ ã¸ã®å£²ã‚Šè¾¼ã¿ã«å¤šãã®æ™‚é–“ã‚’è²»ã‚„ã—ã¦ããŸã¨ãã«ã¯ã€ã¤ã‚‰ã„ã“ã¨ã‹ã‚‚ã—ã‚Œãªã„**ã€‚
This phenomenon is not unique to the software industry.
ã“ã®ç¾è±¡ã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢æ¥­ç•Œã«é™ã£ãŸã“ã¨ã§ã¯ãªã„ã€‚
It is generally referred to as Semmelweis Reflex, based on the story of the long and hard transition of mindset among doctors about the importance of hygiene and having clean hands and scrubs before visiting a patient [65].
ã“ã‚Œã¯ä¸€èˆ¬ã«ã‚»ãƒ³ãƒ¡ãƒ«ãƒ¯ã‚¤ã‚¹åå°„ã¨å‘¼ã°ã‚Œã‚‹ã‚‚ã®ã§ã€åŒ»å¸«ãŒæ‚£è€…ã‚’è¨ªå•ã™ã‚‹å‰ã«æ¸…æ½”ãªæ‰‹ã¨ã‚¹ã‚¯ãƒ©ãƒ–ã‚’ä½¿ã„ã€è¡›ç”Ÿã‚’ä¿ã¤ã“ã¨ã®é‡è¦æ€§ã«ã¤ã„ã¦ã€é•·ãå³ã—ã„æ„è­˜æ”¹é©ã‚’è¡Œã£ãŸã¨ã„ã†ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ã„ã‚‹[65]ã€‚
It takes a while to transition from a point where negative experiment results feel like someone telling you that your baby is ugly.
å¦å®šçš„ãªå®Ÿé¨“çµæœãŒã€èª°ã‹ã«ã€Œã‚ãªãŸã®èµ¤ã¡ã‚ƒã‚“ã¯é†œã„ã€ã¨è¨€ã‚ã‚ŒãŸã‚ˆã†ã«æ„Ÿã˜ã‚‹ã¨ã“ã‚ã‹ã‚‰ç§»è¡Œã™ã‚‹ã«ã¯ã€ã—ã°ã‚‰ãæ™‚é–“ãŒã‹ã‹ã‚‹ã€‚
You must enact a paradigm shift to put your customers and business in focus and listen to customer responses.
é¡§å®¢ã¨ãƒ“ã‚¸ãƒã‚¹ã«ç„¦ç‚¹ã‚’å½“ã¦ã€é¡§å®¢ã®åå¿œã«è€³ã‚’å‚¾ã‘ã‚‹ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ãƒ»ã‚·ãƒ•ãƒˆã‚’å®Ÿæ–½ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚
At that point, negative experiment results are celebrated as saving customers and your business from harm.
ãã®æ™‚ç‚¹ã§ã€**å¦å®šçš„ãªå®Ÿé¨“çµæœã¯ã€é¡§å®¢ã¨ã‚ãªãŸã®ãƒ“ã‚¸ãƒã‚¹ã‚’å®³ã‹ã‚‰æ•‘ã†ã‚‚ã®ã¨ã—ã¦ç§°è³›ã•ã‚Œã‚‹**ã€‚
Note that not only bad ideas (including bloodletting [11]) appear as great ideas to a human mind, we are also likely to discount the value of great ideas (including good hand hygiene for doctors [65]).
äººé–“ã®å¿ƒã«ã¯ã€æ‚ªã„ã‚¢ã‚¤ãƒ‡ã‚¢ï¼ˆç€‰è¡€[11]ã‚’å«ã‚€ï¼‰ãŒç´ æ™´ã‚‰ã—ã„ã‚¢ã‚¤ãƒ‡ã‚¢ã«è¦‹ãˆã‚‹ã ã‘ã§ãªãã€**ç´ æ™´ã‚‰ã—ã„ã‚¢ã‚¤ãƒ‡ã‚¢ï¼ˆåŒ»å¸«ã®æ‰‹æŒ‡è¡›ç”Ÿã®è‰¯ã•[65]ã‚’å«ã‚€ï¼‰ã®ä¾¡å€¤ã‚‚å‰²ã‚Šå¼•ã„ã¦è€ƒãˆã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã‚ˆã†**ã€‚
There are cases where an idea that languished in the product backlog for months as no one thought it was valuable turns out to be one of the best ideas for the product in its history [51].
èª°ã‚‚ãã‚ŒãŒä¾¡å€¤ãŒã‚ã‚‹ã¨ã¯æ€ã‚ãªã‹ã£ãŸãŸã‚ã«ã€ä½•ãƒ¶æœˆã‚‚è£½å“ã®ãƒãƒƒã‚¯ãƒ­ã‚°ã«æ”¾ç½®ã•ã‚Œã¦ã„ãŸã‚¢ã‚¤ãƒ‡ã‚¢ãŒã€ãã®è£½å“ã®æ­´å²ä¸Šæœ€é«˜ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã®1ã¤ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ãŸäº‹ä¾‹ã‚‚ã‚ã‚‹[51]ã€‚

A culture of working together towards the common goal of improving products through OCEs amplifies the benefits of controlled experimentation at scale [32].
OCEã‚’é€šã˜ã¦è£½å“ã‚’æ”¹å–„ã™ã‚‹ã¨ã„ã†å…±é€šã®ç›®æ¨™ã«å‘ã‹ã£ã¦å”åŠ›ã™ã‚‹æ–‡åŒ–ã¯ã€å¤§è¦æ¨¡ãªå®Ÿé¨“ã®åˆ©ç‚¹ã‚’å¢—å¹…ã•ã›ã‚‹[32]ã€‚
This paves the way for frictionless integration of OCEs into the development process, and makes it easy to run an OCE to test an idea, get automated and trustworthy analysis of this experiment quickly, and interpret the results to take the next step: ship the feature, iterate, or discard the idea.
ã“ã‚Œã«ã‚ˆã‚Šã€OCEã‚’é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹ã«æ‘©æ“¦ãªãçµ±åˆã™ã‚‹é“ãŒé–‹ã‹ã‚Œã€ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ãƒ†ã‚¹ãƒˆã—ã€ã“ã®å®Ÿé¨“ã®è‡ªå‹•åŒ–ã•ã‚ŒãŸä¿¡é ¼æ€§ã®ã‚ã‚‹åˆ†æã‚’è¿…é€Ÿã«è¡Œã„ã€çµæœã‚’è§£é‡ˆã—ã¦æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¸ã‚€ã“ã¨ãŒå®¹æ˜“ã«ãªã‚‹ï¼šæ©Ÿèƒ½ã‚’ãƒªãƒªãƒ¼ã‚¹ã™ã‚‹ã€åå¾©ã™ã‚‹ã€ã¾ãŸã¯ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç ´æ£„ã™ã‚‹ã€‚
A strong experimentation culture ensures that all changes to the product are tested using OCEs and teams benefit from OCEs discovering valuable improvements while not degrading product quality.
å¼·åŠ›ãªå®Ÿé¨“æ–‡åŒ–ã¯ã€è£½å“ã¸ã®ã™ã¹ã¦ã®å¤‰æ›´ãŒOCEã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆã•ã‚Œã€ãƒãƒ¼ãƒ ãŒè£½å“ã®å“è³ªã‚’ä½ä¸‹ã•ã›ã‚‹ã“ã¨ãªãã€ä¾¡å€¤ã‚ã‚‹æ”¹å–„ã‚’ç™ºè¦‹ã™ã‚‹OCEã‹ã‚‰åˆ©ç›Šã‚’å¾—ã‚‹ã“ã¨ã‚’ä¿è¨¼ã™ã‚‹ã€‚
It allows you to streamline product development discussions so everyone understands the OEC for the product and can take an objective decision to ship a feature based on the impact on the OEC metric.
ã“ã‚Œã«ã‚ˆã‚Šã€**è£½å“é–‹ç™ºã®è­°è«–ã‚’åŠ¹ç‡åŒ–ã—ã€è£½å“ã®OECã‚’ç†è§£ã—ã¦ã„ã‚‹ã™ã¹ã¦ã®äººãŒã€OECæŒ‡æ¨™ã¸ã®å½±éŸ¿ã«åŸºã¥ã„ã¦æ©Ÿèƒ½ã‚’ãƒªãƒªãƒ¼ã‚¹ã™ã‚‹ãŸã‚ã®å®¢è¦³çš„ãªæ„æ€æ±ºå®šã‚’è¡Œã†ã“ã¨ãŒã§ãã‚‹**ã€‚(OECã®ä½œã‚Šæ–¹å¤§äº‹ã ã‚ˆãª...!)
This gives developers freedom to build and test different ideas with minimum viable improvements without having to sell the entire team on the idea beforehand.
ã“ã‚Œã«ã‚ˆã£ã¦é–‹ç™ºè€…ã¯ã€æœ€å°é™ã®æ”¹å–„ã‚’ä¼´ã†ã•ã¾ã–ã¾ãªã‚¢ã‚¤ãƒ‡ã‚¢ã‚’æ§‹ç¯‰ã—ã€ãƒ†ã‚¹ãƒˆã™ã‚‹è‡ªç”±ã‚’æŒã¤ã“ã¨ãŒã§ãã€äº‹å‰ã«ãƒãƒ¼ãƒ å…¨ä½“ã«ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å£²ã‚Šè¾¼ã‚€å¿…è¦ãŒãªããªã‚‹ã€‚
And allows the team to make future decisions to invest in a product area based on changes to the OEC metric due to features seen in that area.
ã¾ãŸã€ãã®é ˜åŸŸã§è¦‹ã‚‰ã‚Œã‚‹æ©Ÿèƒ½ã«ã‚ˆã‚‹OECæŒ‡æ¨™ã®å¤‰åŒ–ã«åŸºã¥ã„ã¦ã€è£½å“é ˜åŸŸã«æŠ•è³‡ã™ã‚‹ãŸã‚ã®å°†æ¥ã®æ„æ€æ±ºå®šã‚’ãƒãƒ¼ãƒ ã«è¡Œã†ã“ã¨ãŒã§ãã‚‹ã€‚

<!-- ã“ã“ã¾ã§èª­ã‚“ã ! -->

## 6.2. Common Solutions and Challenges

There are many cultural aspects to adoption of OCEs at scale to have a trustworthy estimate of the impact of every change made to a product.
è£½å“ã«åŠ ãˆã‚‰ã‚ŒãŸã™ã¹ã¦ã®å¤‰æ›´ã®å½±éŸ¿ã‚’ä¿¡é ¼ã§ãã‚‹ã‚ˆã†ã«è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€OCEã®å¤§è¦æ¨¡ãªæ¡ç”¨ã«ã¯å¤šãã®æ–‡åŒ–çš„å´é¢ãŒã‚ã‚‹ã€‚

### 6.2.1. Experimentation Platform and Tools 6.2.1. å®Ÿé¨“ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¨ãƒ„ãƒ¼ãƒ«

First, we need to make sure that the experimentation platform has the right set of capabilities to support the team.
**ã¾ãšã€å®Ÿé¨“ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãŒãƒãƒ¼ãƒ ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹é©åˆ‡ãªæ©Ÿèƒ½ã‚’å‚™ãˆã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚‹**ã€‚
It must be able to test the hypothesis of interest to the product team.
è£½å“ãƒãƒ¼ãƒ ã«ã¨ã£ã¦é–¢å¿ƒã®ã‚ã‚‹ä»®èª¬ã‚’æ¤œè¨¼ã§ããªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚
To do that one of the of the most important things required is a set of trustworthy and easily interpretable metrics to evaluate a change made to the product.
ãã®ãŸã‚ã«å¿…è¦ãªæœ€ã‚‚é‡è¦ãªã‚‚ã®ã®1ã¤ã¯ã€**è£½å“ã«åŠ ãˆã‚‰ã‚ŒãŸå¤‰æ›´ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ä¿¡é ¼æ€§ã®ã‚ã‚‹ã‹ã¤ç°¡å˜ã«è§£é‡ˆã§ãã‚‹metricsã®ã‚»ãƒƒãƒˆ**ã§ã‚ã‚‹ã€‚
In addition, itâ€™s useful if there are easy tools to manage multiple experiments and clearly communicate results from these experiments.
ã•ã‚‰ã«ã€è¤‡æ•°ã®å®Ÿé¨“ã‚’ç®¡ç†ã—ã€å®Ÿé¨“çµæœã‚’æ˜ç¢ºã«ä¼ãˆã‚‹ãŸã‚ã®ç°¡å˜ãªãƒ„ãƒ¼ãƒ«ãŒã‚ã‚‹ã¨ä¾¿åˆ©ã§ã‚ã‚‹ã€‚

### 6.2.2. Practices, Policies and Capabilities 6.2.2. å®Ÿè·µã€æ–¹é‡ã€èƒ½åŠ›

The second aspect deals with creating right set of practices, policies, and capabilities to encourage teams to test every change made to their product using OCEs.
ç¬¬äºŒã®å´é¢ã¯ã€OCEã‚’ä½¿ç”¨ã—ã¦è£½å“ã«åŠ ãˆã‚‰ã‚ŒãŸã™ã¹ã¦ã®å¤‰æ›´ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã“ã¨ã‚’ãƒãƒ¼ãƒ ã«å¥¨åŠ±ã™ã‚‹ãŸã‚ã®ã€**é©åˆ‡ãªãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã€ãƒãƒªã‚·ãƒ¼ã€ãŠã‚ˆã³èƒ½åŠ›ã®ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹ã“ã¨**ã§ã‚ã‚‹ã€‚
The following are strategies that different companies use to achieve this goal.
ä»¥ä¸‹ã¯ã€ã“ã®ç›®æ¨™ã‚’é”æˆã™ã‚‹ãŸã‚ã«å„ä¼æ¥­ãŒæ¡ç”¨ã—ã¦ã„ã‚‹æˆ¦ç•¥ã§ã‚ã‚‹ã€‚

#### High Touch:

Once per quarter, the LinkedIn experimentation team handpicks a few business-critical teams, prioritizes these teams, and then works closely with them on their needs.
LinkedInã®å®Ÿé¨“ãƒãƒ¼ãƒ ã¯ã€å››åŠæœŸã«ä¸€åº¦ã€ãƒ“ã‚¸ãƒã‚¹ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªãƒãƒ¼ãƒ ã‚’æ•°ãƒãƒ¼ãƒ é¸ã³ã€å„ªå…ˆé †ä½ã‚’ã¤ã‘ã€ãã®ãƒãƒ¼ãƒ ã®ãƒ‹ãƒ¼ã‚ºã¨å¯†æ¥ã«é€£æºã—ã¾ã™ã€‚
At the end of the quarter the team agrees theyâ€™ll use that experiment platform going forward, and the experimentation team continues to monitor them.
å››åŠæœŸã®çµ‚ã‚ã‚Šã«ã¯ã€ãƒãƒ¼ãƒ ã¯ãã®å®Ÿé¨“ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’ä»Šå¾Œã‚‚ä½¿ç”¨ã™ã‚‹ã“ã¨ã«åŒæ„ã—ã€å®Ÿé¨“ãƒãƒ¼ãƒ ã¯ãã‚Œã‚’ç›£è¦–ã—ç¶šã‘ã‚‹ã€‚
Over several years a data-driven culture is built.
æ•°å¹´ã‹ã‘ã¦ãƒ‡ãƒ¼ã‚¿ä¸»å°ã®æ–‡åŒ–ãŒæ§‹ç¯‰ã•ã‚Œã‚‹ã€‚
Managers and directors now rely on development teams running experiments before features launch.
ä»Šã‚„ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚„ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼ã¯ã€é–‹ç™ºãƒãƒ¼ãƒ ãŒæ©Ÿèƒ½ã‚’ç«‹ã¡ä¸Šã’ã‚‹å‰ã«å®Ÿé¨“ã‚’è¡Œã†ã“ã¨ã«ä¾å­˜ã—ã¦ã„ã‚‹ã€‚

The Microsoft experimentation team selects product teams to onboard based on factors indicative of the impact experimentation has on the product.
ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®å®Ÿé¨“ãƒãƒ¼ãƒ ã¯ã€å®Ÿé¨“ãŒè£½å“ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’ç¤ºã™è¦å› ã«åŸºã¥ã„ã¦ã€å‚åŠ ã™ã‚‹è£½å“ãƒãƒ¼ãƒ ã‚’é¸æŠã™ã‚‹ã€‚
The experimentation team works very closely with product teams over multiple years to advance the adoption of experimentation and its maturity over time.
**å®Ÿé¨“ãƒãƒ¼ãƒ ã¯ã€è¤‡æ•°å¹´ã«ã‚ãŸã‚Šè£½å“ãƒãƒ¼ãƒ ã¨å¯†æ¥ã«å”åŠ›ã—ã€å®Ÿé¨“ã®å°å…¥ã¨ãã®æˆç†Ÿã‚’é•·æœŸçš„ã«é€²ã‚ã‚‹**ã€‚(ã†ã¡ã®ãƒãƒ¼ãƒ ã®å ´åˆã¯ã€å®Ÿé¨“ãƒãƒ¼ãƒ  = ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒ¼ãƒ ã‹ã‚‚ã€‚)
The downside of the High Touch approach is the large overhead in having a deep engagement with every team, and it may become a bottleneck for scaling.
ãƒã‚¤ãƒ»ã‚¿ãƒƒãƒãƒ»ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ¬ ç‚¹ã¯ã€ã™ã¹ã¦ã®ãƒãƒ¼ãƒ ã¨ã®æ·±ã„é–¢ä¸ã«ã‚ˆã‚‹å¤§ããªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã§ã‚ã‚Šã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚

#### Top down buy in:

It can help if there is a buy-in into experimentation by leadership and they expect every change tested in a controlled experiment.
ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—å±¤ãŒå®Ÿé¨“ã«è³›åŒã—ã€ç®¡ç†ã•ã‚ŒãŸå®Ÿé¨“ã§ã™ã¹ã¦ã®å¤‰æ›´ãŒãƒ†ã‚¹ãƒˆã•ã‚Œã‚‹ã“ã¨ã‚’æœŸå¾…ã—ã¦ã„ã‚‹å ´åˆã€ãã‚Œã¯åŠ©ã‘ã«ãªã‚‹ã€‚
Further they can set team goals based on moving a metric in controlled experiments.
ã•ã‚‰ã«ã€å½¼ã‚‰ã¯ç®¡ç†ã•ã‚ŒãŸå®Ÿé¨“ã§æŒ‡æ¨™ã‚’å‹•ã‹ã™ã“ã¨ã«åŸºã¥ã„ã¦ãƒãƒ¼ãƒ ã®ç›®æ¨™ã‚’è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
This creates a culture where all ship decisions are talked about in terms of their impact on key metrics.
ã“ã‚Œã«ã‚ˆã‚Šã€**ã™ã¹ã¦ã®èˆ¹ã®æ±ºå®šãŒä¸»è¦ãªæŒ‡æ¨™ã¸ã®å½±éŸ¿ã¨ã„ã†è¦³ç‚¹ã‹ã‚‰èªã‚‰ã‚Œã‚‹æ–‡åŒ–ãŒç”Ÿã¾ã‚Œã‚‹**ã€‚
The product teams celebrate shipping changes that improve key metrics, and equally importantly, celebrate not shipping changes that would cause a regression in key metrics.
**è£½å“ãƒãƒ¼ãƒ ã¯ã€ä¸»è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ”¹å–„ã™ã‚‹å¤‰æ›´ã‚’å‡ºè·ã™ã‚‹ã“ã¨ã‚’ç¥ã„ã€åŒæ§˜ã«é‡è¦ãªã“ã¨ã¯ã€ä¸»è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å¾Œé€€ã•ã›ã‚‹ã‚ˆã†ãªå¤‰æ›´ã‚’å‡ºè·ã—ãªã„ã“ã¨ã‚’ç¥ã†**ã€‚
It is important that the teamâ€™s key metrics are determined beforehand and agreed upon by the team.
**ãƒãƒ¼ãƒ ã®é‡è¦ãªæŒ‡æ¨™ã‚’äº‹å‰ã«æ±ºå®šã—ã€ãƒãƒ¼ãƒ ã§åˆæ„ã—ã¦ãŠãã“ã¨ãŒé‡è¦ã§ã‚ã‚‹**ã€‚(ã†ã‚“ã†ã‚“...!)
It is prudent to be cautious about preventing the gaming of metrics or over fitting metric flaws, where the metrics of interest move but are not indicative of improvement in the product.
ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã‚²ãƒ¼ãƒŸãƒ³ã‚°ã‚„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ¬ é™¥ã®éå‰°é©åˆã‚’é˜²ãã“ã¨ã«æ³¨æ„ã™ã‚‹ã“ã¨ãŒè³¢æ˜ã§ã‚ã‚‹ã€‚èˆˆå‘³ã®ã‚ã‚‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒå‹•ããŒã€è£½å“ã®æ”¹å–„ã‚’ç¤ºã—ã¦ã„ãªã„å ´åˆãŒã‚ã‚‹ã€‚
At Netflix a long-standing culture of peer review of experiment results is organized around frequent â€œProduct Strategyâ€ forums where results are summarized and debated amongst experimenters, product managers, and leadership teams before an experiment is â€œrolled outâ€.
ãƒãƒƒãƒˆãƒ•ãƒªãƒƒã‚¯ã‚¹ã§ã¯ã€å®Ÿé¨“çµæœã®é•·å¹´ã«ã‚ãŸã‚‹**åŒåƒšã«ã‚ˆã‚‹æŸ»èª­æ–‡åŒ–**ãŒã€å®Ÿé¨“ãŒã€Œãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã€ã•ã‚Œã‚‹å‰ã«ã€å®Ÿé¨“è€…ã€è£½å“ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã€ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—ãƒãƒ¼ãƒ ã®é–“ã§çµæœãŒè¦ç´„ã•ã‚Œã€è­°è«–ã•ã‚Œã‚‹é »ç¹ãªã€Œè£½å“æˆ¦ç•¥ã€ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã®å‘¨ã‚Šã«çµ„ç¹”ã•ã‚Œã¦ã„ã‚‹ã€‚

#### Negative and positive case studies:

Stories about surprising negative results where a feature that is widely acclaimed as a positive causes a large regression in key metrics, or a surprising positive incident where a small change no one believed would be of consequence causes a large improvement in a metric were great drivers for cultural change.
åºƒãç§°è³›ã•ã‚Œã¦ã„ã‚‹æ©Ÿèƒ½ãŒå¤§ããªä¸»è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å¾Œé€€ã‚’å¼•ãèµ·ã“ã™ã¨ã„ã†é©šãã¹ãå¦å®šçš„ãªçµæœã‚„ã€èª°ã‚‚ãŒé‡è¦ã§ã‚ã‚‹ã¨ã¯æ€ã‚ãªã‹ã£ãŸå°ã•ãªå¤‰æ›´ãŒå¤§ããªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ”¹å–„ã‚’å¼•ãèµ·ã“ã™ã¨ã„ã†é©šãã¹ãè‚¯å®šçš„ãª**äº‹ä¾‹ã«ã¤ã„ã¦ã®è©±ã¯ã€æ–‡åŒ–ã®å¤‰åŒ–ã‚’ä¿ƒé€²ã™ã‚‹å¤§ããªè¦å› **ã§ã‚ã£ãŸã€‚(ã‚ªãƒ•ãƒ©ã‚¤ãƒ³è©•ä¾¡ã®è©±ã¯ã¾ã•ã«ã“ã‚Œã‹ã‚‚...!)
These cases drive home a humbling point that our intuition is not a good judge of the value of ideas.
ã“ã‚Œã‚‰ã®ã‚±ãƒ¼ã‚¹ã¯ã€ç§ãŸã¡ã®ç›´æ„Ÿã¯ã‚¢ã‚¤ãƒ‡ã‚¢ã®ä¾¡å€¤ã‚’åˆ¤æ–­ã™ã‚‹ã®ã«é©ã—ã¦ã„ãªã„ã¨ã„ã†è¬™è™šãªæŒ‡æ‘˜ã‚’çªãã¤ã‘ã¦ã„ã‚‹ã€‚
There are some documented examples the best OCEs with surprising outcomes [4].
é©šãã¹ãçµæœã‚’ã‚‚ãŸã‚‰ã—ãŸæœ€é«˜ã®OCEã®ä¾‹ãŒã„ãã¤ã‹æ–‡æ›¸åŒ–ã•ã‚Œã¦ã„ã‚‹[4]ã€‚
For instance, an engineer at Bing had the idea to make ad titles longer for ads with very short titles.
ä¾‹ãˆã°ã€**Bingã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒã€éå¸¸ã«çŸ­ã„ã‚¿ã‚¤ãƒˆãƒ«ã®åºƒå‘Šã«å¯¾ã—ã¦åºƒå‘Šã‚¿ã‚¤ãƒˆãƒ«ã‚’é•·ãã™ã‚‹ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’æŒã£ã¦ã„ãŸ**ã€‚
The change was a simple and cheap, but it was not developed for many months as neither the developer nor the team had much confidence in the idea.
ã“ã®å¤‰æ›´ã¯ã‚·ãƒ³ãƒ—ãƒ«ã§å®‰ä¾¡ãªã‚‚ã®ã ã£ãŸãŒã€é–‹ç™ºè€…ã‚‚ãƒãƒ¼ãƒ ã‚‚ã“ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã«ã‚ã¾ã‚Šè‡ªä¿¡ã‚’æŒã£ã¦ã„ãªã‹ã£ãŸãŸã‚ã€ä½•ã‚«æœˆã‚‚é–‹ç™ºãŒé€²ã¾ãªã‹ã£ãŸã€‚
When it was finally tested, it caused one of the biggest increases in Bing revenue in history [51].
**æœ€çµ‚çš„ã«ãƒ†ã‚¹ãƒˆã•ã‚ŒãŸã¨ãã«ã¯ã€Bingå²ä¸Šæœ€å¤§ç´šã®åç›Šã®å¢—åŠ ã‚’å¼•ãèµ·ã“ã—ãŸ**[51]ã€‚

#### Safe Rollout:

It is easier to get a team to adopt experimentation when it fits into their existing processes and makes them better.
**å®Ÿé¨“ãŒãƒãƒ¼ãƒ ã®æ—¢å­˜ã®ãƒ—ãƒ­ã‚»ã‚¹ã«é©åˆã—ã€ãã‚Œã‚‰ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚ˆã‚Šè‰¯ãã™ã‚‹ã¨ã€å®Ÿé¨“ã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ã¯ç°¡å˜ã§ã‚ã‚‹**ã€‚
Some teams at Microsoft and Google began using experimentation as a way to do safe feature rollouts to all users, where an A/B test runs automatically during deployment as the feature is gradually turned on for a portion of users (Treatment) and others (Control) donâ€™t have the feature turned on.
ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã‚„ã‚°ãƒ¼ã‚°ãƒ«ã®ä¸€éƒ¨ã®ãƒãƒ¼ãƒ ã¯ã€**å…¨ãƒ¦ãƒ¼ã‚¶ã«å®‰å…¨ã«æ©Ÿèƒ½ã‚’ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã™ã‚‹æ–¹æ³•ã¨ã—ã¦ã€å®Ÿé¨“ã‚’ä½¿ã„å§‹ã‚ãŸ**ã€‚ãã“ã§ã¯ã€ä¸€éƒ¨ã®ãƒ¦ãƒ¼ã‚¶ (Treatment)ã«ã¯æ©Ÿèƒ½ã‚’å¾ã€…ã«ã‚ªãƒ³ã«ã—ã€ä»–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆControlï¼‰ã«ã¯æ©Ÿèƒ½ã‚’ã‚ªãƒ³ã«ã—ãªã„ã‚ˆã†ã«ã€**ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ã«A/Bãƒ†ã‚¹ãƒˆã‚’è‡ªå‹•çš„ã«å®Ÿè¡Œã™ã‚‹**ã€‚
During this controlled feature rollout, the featureâ€™s impact estimate on key reliability and userbehavior metrics helped find bugs.
ã“ã®ç®¡ç†ã•ã‚ŒãŸæ©Ÿèƒ½ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã®é–“ã€**ä¸»è¦ãªä¿¡é ¼æ€§ã¨ãƒ¦ãƒ¼ã‚¶è¡Œå‹•ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«å¯¾ã™ã‚‹æ©Ÿèƒ½ã®å½±éŸ¿ã®æ¨å®šå€¤ãŒãƒã‚°ã‚’è¦‹ã¤ã‘ã‚‹ã®ã«å½¹ç«‹ã£ãŸ**ã€‚(=ã“ã®ãƒã‚°ã‚’è¦‹ã¤ã‘ã‚‹ã®ã«å½¹ç«‹ã£ãŸã€ã¨ã„ã†ã®ãŒã€Œãƒãƒ¼ãƒ ã®æ—¢å­˜ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚ˆã‚Šè‰¯ãã—ã¦ã„ã‚‹ã€ã¨ã„ã†ç‚¹ãªã®ã‹...!:thinking_face:)

This method helps gain a toe hold in the feature teamâ€™s development process.
ã“ã®æ–¹æ³•ã¯ã€æ©Ÿèƒ½ãƒãƒ¼ãƒ ã®é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã‘ã‚‹è¶³å ´ã‚’å¾—ã‚‹ã®ã«å½¹ç«‹ã¤ã€‚
Over time, as the feature team started seeing value in experimentation, they looked forward to using experimentation to test more hypotheses.
æ™‚ãŒçµŒã¤ã«ã¤ã‚Œã¦ã€æ©Ÿèƒ½ãƒãƒ¼ãƒ ã¯å®Ÿé¨“ã‚’ä½¿ã£ã¦ã•ã‚‰ã«å¤šãã®ä»®èª¬ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã“ã¨ã‚’æ¥½ã—ã¿ã«ã—ã¦ã„ãŸã€‚

#### Report cards and Gamification:

Microsoft found that they encourage the adoption of OCEs in a set of teams by having a report card for each team that assesses their experimentation maturity level [31].
ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã¯ã€**å„ãƒãƒ¼ãƒ ã«å¯¾ã—ã¦å®Ÿé¨“ã®æˆç†Ÿåº¦ãƒ¬ãƒ™ãƒ«ã‚’è©•ä¾¡ã™ã‚‹æˆç¸¾è¡¨ã‚’æŒã¤ã“ã¨ã§ã€ä¸€é€£ã®ãƒãƒ¼ãƒ ã«OCEã®æ¡ç”¨ã‚’å¥¨åŠ±ã™ã‚‹ã“ã¨ãŒã§ãã‚‹**ã“ã¨ã‚’ç™ºè¦‹ã—ãŸ[31]ã€‚
This report card gives the team a way to think about the potential of using experiments to improve the product.
ã“ã®æˆç¸¾è¡¨ã¯ã€å®Ÿé¨“ã‚’ä½¿ã£ã¦è£½å“ã‚’æ”¹å–„ã™ã‚‹å¯èƒ½æ€§ã«ã¤ã„ã¦è€ƒãˆã‚‹æ–¹æ³•ã‚’ãƒãƒ¼ãƒ ã«ä¸ãˆã‚‹ã€‚
It gives the team a measure of its status and relative status among other teams and helps highlight key areas where they can invest to further improve.
ã“ã‚Œã«ã‚ˆã‚Šã€ãƒãƒ¼ãƒ ã®åœ°ä½ã¨ä»–ã®ãƒãƒ¼ãƒ ã¨ã®ç›¸å¯¾çš„ãªåœ°ä½ãŒæ¸¬å®šã•ã‚Œã€ã•ã‚‰ãªã‚‹æ”¹å–„ã®ãŸã‚ã«æŠ•è³‡ã§ãã‚‹é‡è¦ãªåˆ†é‡ãŒæµ®ãå½«ã‚Šã«ãªã‚‹ã€‚

Booking.com is experimenting with gamification in their experimentation platform where users of the platform can receive badges to encourage the adoption of good practices.
Booking.comã¯ã€**å½¼ã‚‰ã®å®Ÿé¨“ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã‚²ãƒ¼ãƒŸãƒ•ã‚£ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è©¦ã—ã¦ãŠã‚Šã€ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®ãƒ¦ãƒ¼ã‚¶ã¯ã€è‰¯ã„å®Ÿè·µã®æ¡ç”¨ã‚’å¥¨åŠ±ã™ã‚‹ãŸã‚ã«ãƒãƒƒã‚¸ã‚’å—ã‘å–ã‚‹ã“ã¨ãŒã§ãã‚‹**ã€‚

Twitter and Microsoft also use mascots, like duck [70] and HiPPO [37] to spread awareness about experimentation in their companies.
ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ç¤¾ã‚„ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆç¤¾ã‚‚ã€ã‚¢ãƒ’ãƒ«[70]ã‚„HiPPO[37]ã®ã‚ˆã†ãªãƒã‚¹ã‚³ãƒƒãƒˆã‚’ä½¿ã£ã¦ã€è‡ªç¤¾ã«ãŠã‘ã‚‹å®Ÿé¨“ã«ã¤ã„ã¦ã®èªè­˜ã‚’åºƒã‚ã¦ã„ã‚‹ã€‚(??)

#### Education and support:

When a company tests thousands of experiments a year, it is impossible for experimentation teams to monitor each experiment to ensure that experiment analysis is trustworthy.
ä¼æ¥­ãŒå¹´é–“ä½•åƒã‚‚ã®å®Ÿé¨“ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹å ´åˆã€**å®Ÿé¨“ãƒãƒ¼ãƒ ãŒå„å®Ÿé¨“ã‚’ç›£è¦–ã—ã¦å®Ÿé¨“åˆ†æãŒä¿¡é ¼ã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã¯ä¸å¯èƒ½**ã§ã‚ã‚‹ã€‚
It is important that each team has subject matter experts to help them run experiments and ensure that they obtain reliable and trustworthy results.
å„ãƒãƒ¼ãƒ ãŒå®Ÿé¨“ã‚’è¡Œã„ã€ä¿¡é ¼ã§ãã‚‹çµæœã‚’å¾—ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã«ã¯ã€å„åˆ†é‡ã®å°‚é–€å®¶ãŒã„ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ã€‚
Educating team members on how to use OCEs to test hypotheses and how to avoid common pitfalls is critical in scaling experimentation adoption.
**ä»®èª¬ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«OCEã‚’ã©ã®ã‚ˆã†ã«ä½¿ç”¨ã—ã€ã‚ˆãã‚ã‚‹è½ã¨ã—ç©´ã‚’ã©ã®ã‚ˆã†ã«é¿ã‘ã‚‹ã‹ã«ã¤ã„ã¦ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã‚’æ•™è‚²ã™ã‚‹ã“ã¨ã¯ã€å®Ÿé¨“ã®æ¡ç”¨ã‚’æ‹¡å¤§ã™ã‚‹ä¸Šã§æ¥µã‚ã¦é‡è¦**ã§ã‚ã‚‹ã€‚
We will discuss this important point in detail in section 7.
ã“ã®é‡è¦ãªç‚¹ã«ã¤ã„ã¦ã¯ã€ç¬¬7ç¯€ã§è©³è¿°ã™ã‚‹ã€‚

<!-- ã“ã“ã¾ã§èª­ã‚“ã ! -->

# 7. Training Others in the Organisation to scale Experimentation 7. å®Ÿé¨“è¦æ¨¡ã‚’æ‹¡å¤§ã™ã‚‹ãŸã‚ã«çµ„ç¹”å†…ã®ä»–è€…ã‚’è¨“ç·´ã™ã‚‹

## 7.1. Problem # 7.1.Problem

While the concept of an A/B test is simple, there can be complex practical issues in designing an experiment to test a particular feature and analyzing the results of the experiment.
A/Bãƒ†ã‚¹ãƒˆã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆã¯ã‚·ãƒ³ãƒ—ãƒ«ã ãŒã€ç‰¹å®šã®æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ãŸã‚ã®å®Ÿé¨“ã‚’è¨­è¨ˆã—ã€å®Ÿé¨“çµæœã‚’åˆ†æã™ã‚‹ã«ã¯ã€è¤‡é›‘ãªç¾å®Ÿçš„å•é¡ŒãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
Product teams need custom support when running experiments, because they often have very specific questions that cannot be answered with a simple set of frequently answered questions.
è£½å“ãƒãƒ¼ãƒ ã¯ã€å®Ÿé¨“ã‚’è¡Œã†éš›ã«ã‚«ã‚¹ã‚¿ãƒ ã‚µãƒãƒ¼ãƒˆã‚’å¿…è¦ã¨ã™ã‚‹ã€‚ãªãœãªã‚‰ã€ã‚ˆãã‚ã‚‹è³ªå•ã®å˜ç´”ãªã‚»ãƒƒãƒˆã§ã¯ç­”ãˆã‚‰ã‚Œãªã„ã‚ˆã†ãªã€éå¸¸ã«å…·ä½“çš„ãªè³ªå•ãŒã‚ˆãã‚ã‚‹ã‹ã‚‰ã ã€‚
A centralized support function does not scale very well.
ä¸­å¤®é›†æ¨©çš„ãªã‚µãƒãƒ¼ãƒˆæ©Ÿèƒ½ã¯ã€ã‚ã¾ã‚Šã†ã¾ãã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„ã€‚
Central teams end up spending too much time on support and not enough on other things.
ã‚»ãƒ³ãƒˆãƒ©ãƒ«ãƒ»ãƒãƒ¼ãƒ ã¯ã‚µãƒãƒ¼ãƒˆã«å¤šãã®æ™‚é–“ã‚’è²»ã‚„ã—ã€ä»–ã®ã“ã¨ã«ååˆ†ãªæ™‚é–“ã‚’å‰²ã‘ãªããªã£ã¦ã—ã¾ã†ã€‚
Additionally, specific product domain knowledge is often required to provide support.
ã•ã‚‰ã«ã€ã‚µãƒãƒ¼ãƒˆã‚’æä¾›ã™ã‚‹ãŸã‚ã«ã¯ã€ç‰¹å®šã®è£½å“åˆ†é‡ã®çŸ¥è­˜ãŒå¿…è¦ã«ãªã‚‹ã“ã¨ã‚‚å¤šã„ã€‚
A centralized support function requires deep knowledge of all supported products, which is often not feasible.
ã‚µãƒãƒ¼ãƒˆæ©Ÿèƒ½ã‚’ä¸€å…ƒåŒ–ã™ã‚‹ã«ã¯ã€ã™ã¹ã¦ã®ã‚µãƒãƒ¼ãƒˆå¯¾è±¡è£½å“ã«é–¢ã™ã‚‹æ·±ã„çŸ¥è­˜ãŒå¿…è¦ã ãŒã€ãã‚Œã¯ã—ã°ã—ã°å®Ÿç¾ä¸å¯èƒ½ã§ã‚ã‚‹ã€‚
Conversely, anyone providing support needs fundamental experimentation knowledge, which might be easier to scale.
é€†ã«ã€ã‚µãƒãƒ¼ãƒˆã‚’æä¾›ã™ã‚‹äººã¯ã€åŸºç¤çš„ãªå®Ÿé¨“ã®çŸ¥è­˜ãŒå¿…è¦ã§ã€ãã®æ–¹ãŒã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ã‚„ã™ã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚
Such democratization of knowledge and expertise enables a better experimentation culture.
ã“ã®ã‚ˆã†ãªçŸ¥è­˜ã¨å°‚é–€çŸ¥è­˜ã®æ°‘ä¸»åŒ–ã«ã‚ˆã£ã¦ã€ã‚ˆã‚Šè‰¯ã„å®Ÿé¨“æ–‡åŒ–ãŒå¯èƒ½ã«ãªã‚‹ã€‚

## 7.2. Common Solutions and Challenges

Across different companies, there are a few key practical challenges in spreading the expertise about OCEs that enable experimentation at scale.
æ§˜ã€…ãªä¼æ¥­ã«ãŠã„ã¦ã€å¤§è¦æ¨¡ãªå®Ÿé¨“ã‚’å¯èƒ½ã«ã™ã‚‹OCEã«é–¢ã™ã‚‹å°‚é–€çŸ¥è­˜ã‚’æ™®åŠã•ã›ã‚‹ã«ã¯ã€ã„ãã¤ã‹ã®é‡è¦ãªç¾å®Ÿçš„èª²é¡ŒãŒã‚ã‚‹ã€‚
â€¢ How do we set up a community to support experimenters? â€¢ How do we incorporate them in the experiment lifecycle? â€¢ How do we incentivize these people? â€¢ How do we quantify their impact? â€¢ How do we train them? â€¢ How do we maintain quality standards? Here are examples from several companies on how they tried to solve these challenges.

- å®Ÿé¨“è€…ã‚’æ”¯æ´ã™ã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’ã©ã®ã‚ˆã†ã«ç«‹ã¡ä¸Šã’ã‚‹ã‹ï¼Ÿ- å®Ÿé¨“è€…ã‚’å®Ÿé¨“ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã«çµ„ã¿è¾¼ã‚€ã«ã¯ï¼Ÿ- å®Ÿé¨“è€…ã«ã‚¤ãƒ³ã‚»ãƒ³ãƒ†ã‚£ãƒ–ã‚’ä¸ãˆã‚‹ã«ã¯ï¼Ÿ- å½¼ã‚‰ã®å½±éŸ¿ã‚’ã©ã®ã‚ˆã†ã«å®šé‡åŒ–ã™ã‚‹ã‹ï¼Ÿ- ã©ã®ã‚ˆã†ã«å½¼ã‚‰ã‚’è¨“ç·´ã™ã‚‹ã‹ï¼Ÿ- ã©ã†ã‚„ã£ã¦å“è³ªåŸºæº–ã‚’ç¶­æŒã™ã‚‹ã®ã‹ï¼Ÿã“ã‚Œã‚‰ã®èª²é¡Œã‚’ã©ã®ã‚ˆã†ã«è§£æ±ºã—ã‚ˆã†ã¨ã—ãŸã®ã‹ã€ã„ãã¤ã‹ã®ä¼æ¥­ã®ä¾‹ã‚’ç´¹ä»‹ã—ã‚ˆã†ã€‚

### 7.2.1. Yandex: â€œExperts on Experimentâ€ 7.2.1. ãƒ¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ "å®Ÿé¨“ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ"

At Yandex, a program called â€œExperts on Experimentâ€ exists to scale support.
ãƒ¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ã¯ã€ã‚µãƒãƒ¼ãƒˆã‚’æ‹¡å¤§ã™ã‚‹ãŸã‚ã«ã€ŒExperts on Experimentã€ã¨å‘¼ã°ã‚Œã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã€‚
These Experts are handpicked from product teams by the central experimentation group.
ã“ã‚Œã‚‰ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã¯ã€ä¸­å¤®å®Ÿé¨“ã‚°ãƒ«ãƒ¼ãƒ—ã«ã‚ˆã£ã¦è£½å“ãƒãƒ¼ãƒ ã‹ã‚‰å³é¸ã•ã‚Œã‚‹ã€‚
Any experiments must be approved by an Expert before they are allowed to ship.
ã„ã‹ãªã‚‹å®Ÿé¨“ã‚‚ã€å‡ºè·å‰ã«ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®æ‰¿èªã‚’å¾—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚
Experts are motivated because their product needs approval before shipping, so they voluntarily sign up to be an Expert.
ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€å‡ºè·å‰ã«è£½å“ã®æ‰¿èªãŒå¿…è¦ãªãŸã‚ã€è‡ªç™ºçš„ã«ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã¨ã—ã¦ç™»éŒ²ã™ã‚‹ã“ã¨ã ã€‚
Their application is then reviewed by the central experimentation group.
ãã®å¾Œã€ä¸­å¤®ã®å®Ÿé¨“ã‚°ãƒ«ãƒ¼ãƒ—ãŒç”³è«‹ã‚’å¯©æŸ»ã™ã‚‹ã€‚
Experts are motivated by the status provided by being an Expert.
å°‚é–€å®¶ã¯ã€å°‚é–€å®¶ã§ã‚ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã‚‚ãŸã‚‰ã•ã‚Œã‚‹åœ°ä½ã«ã‚ˆã£ã¦å‹•æ©Ÿã¥ã‘ã‚‰ã‚Œã‚‹ã€‚
They get a digital badge in internal staff systems, so their status is visible to others.
ç¤¾å†…ã®ã‚¹ã‚¿ãƒƒãƒ•ãƒ»ã‚·ã‚¹ãƒ†ãƒ ã«ã¯ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ»ãƒãƒƒã‚¸ãŒè¡¨ç¤ºã•ã‚Œã€ãã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã¯ä»–ã®ã‚¹ã‚¿ãƒƒãƒ•ã«ã‚‚ã‚ã‹ã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã€‚
There are no clear KPIs for the program.
ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®æ˜ç¢ºãªKPIã¯ãªã„ã€‚
There is a checklist of minimum experience and an informal interview process involved in becoming an expert.
ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã«ãªã‚‹ãŸã‚ã«ã¯ã€æœ€ä½é™ã®çµŒé¨“ã«é–¢ã™ã‚‹ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã¨éå…¬å¼ã®é¢æ¥ãƒ—ãƒ­ã‚»ã‚¹ãŒã‚ã‚‹ã€‚

### 7.2.2. Amazon: â€œWeblab Bar Raisersâ€ 7.2.2. ã‚¢ãƒã‚¾ãƒ³ "ã‚¦ã‚§ãƒ–ãƒ©ãƒœãƒ»ãƒãƒ¼ãƒ¬ã‚¤ã‚¶ãƒ¼"

Weblab is Amazonâ€™s experimentation platform.
ã‚¦ã‚§ãƒ–ãƒ©ãƒœã¯ã‚¢ãƒã‚¾ãƒ³ã®å®Ÿé¨“ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã ã€‚
In 2013, Amazonâ€™s Personalization team piloted a â€œWeblab Bar Raisersâ€ program in their local organization with the intention of raising the overall quality of experimental design, analysis, and decision making.
2013å¹´ã€ã‚¢ãƒã‚¾ãƒ³ã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ãƒãƒ¼ãƒ ã¯ã€å®Ÿé¨“ãƒ‡ã‚¶ã‚¤ãƒ³ã€åˆ†æã€æ„æ€æ±ºå®šã®å…¨ä½“çš„ãªè³ªã‚’é«˜ã‚ã‚‹ã“ã¨ã‚’æ„å›³ã—ã¦ã€ã€ŒWeblab Bar Raisersã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç¾åœ°çµ„ç¹”ã§è©¦é¨“çš„ã«å®Ÿæ–½ã—ãŸã€‚
The initial Bar Raisers were selected to be high-judgment, experienced experimenters, with an ability to teach and influence.
æœ€åˆã®ãƒãƒ¼ãƒ¬ã‚¤ã‚¶ãƒ¼ã¯ã€åˆ¤æ–­åŠ›ãŒé«˜ãã€çµŒé¨“è±Šå¯Œãªå®Ÿé¨“è€…ã§ã‚ã‚Šã€æ•™ãˆã‚‹èƒ½åŠ›ã¨å½±éŸ¿åŠ›ã‚’æŒã¤è€…ãŒé¸ã°ã‚ŒãŸã€‚
Expectations for the role were clearly defined and documented and, after a few iterations, the program was expanded company wide.
å½¹å‰²ã«å¯¾ã™ã‚‹æœŸå¾…ã¯æ˜ç¢ºã«å®šç¾©ã•ã‚Œã€æ–‡æ›¸åŒ–ã•ã‚Œã€ä½•åº¦ã‹ç¹°ã‚Šè¿”ã•ã‚ŒãŸå¾Œã€ã“ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯å…¨ç¤¾çš„ã«æ‹¡å¤§ã•ã‚ŒãŸã€‚
Bar Raiser review is not mandatory for all organizations; often because not enough Bar Raisers are available.
ãƒãƒ¼ãƒ¬ã‚¤ã‚¶ãƒ¼ã®å¯©æŸ»ã¯ã€ã™ã¹ã¦ã®å›£ä½“ã«ç¾©å‹™ä»˜ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã€‚
Bar Raisers spend about 2â€“4 hours per week providing OCE support.
ãƒãƒ¼ãƒ»ãƒ¬ã‚¤ã‚¶ãƒ¼ã¯ã€OCEã®ã‚µãƒãƒ¼ãƒˆã«é€±2ï½4æ™‚é–“ç¨‹åº¦ã‚’è²»ã‚„ã—ã¦ã„ã‚‹ã€‚
Incentives rely on Bar Raisers buying into the mission of the program, which contributes to their personal growth and status within the company.
ã‚¤ãƒ³ã‚»ãƒ³ãƒ†ã‚£ãƒ–ã¯ã€ãƒãƒ¼ãƒ»ãƒ¬ã‚¤ã‚¶ãƒ¼ãŒãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ä½¿å‘½ã‚’ç†è§£ã—ã€å€‹äººçš„ãªæˆé•·ã¨ç¤¾å†…ã§ã®åœ°ä½å‘ä¸Šã«è²¢çŒ®ã™ã‚‹ã“ã¨ã«ä¾å­˜ã—ã¦ã„ã‚‹ã€‚
A mentorship program, where existing Bar Raisers train new ones, exists to ensure that new Bar Raisers are brought up to speed quickly.
æ—¢å­˜ã®ãƒãƒ¼ãƒ»ãƒ¬ã‚¤ã‚¶ãƒ¼ãŒæ–°ã—ã„ãƒãƒ¼ãƒ»ãƒ¬ã‚¤ã‚¶ãƒ¼ã‚’æ•™è‚²ã™ã‚‹ãƒ¡ãƒ³ã‚¿ãƒ¼ã‚·ãƒƒãƒ—ãƒ»ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒã‚ã‚Šã€æ–°ã—ã„ãƒãƒ¼ãƒ»ãƒ¬ã‚¤ã‚¶ãƒ¼ãŒè¿…é€Ÿã«ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã€‚

### 7.2.3. Twitter: â€œExperiment Shepherdsâ€ 7.2.3. ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ ã€Œã‚·ã‚§ãƒ‘ãƒ¼ãƒ‰ã®å®Ÿé¨“

At Twitter, the â€œExperiment Shepherdsâ€ program, founded three years ago by a product group including the current CTO, now has approximately 50 shepherds.
ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ç¤¾ã§ã¯ã€ç¾CTOã‚’å«ã‚€è£½å“ã‚°ãƒ«ãƒ¼ãƒ—ãŒ3å¹´å‰ã«è¨­ç«‹ã—ãŸã€Œã‚¨ã‚¯ã‚¹ãƒšãƒªãƒ¡ãƒ³ãƒˆãƒ»ã‚·ã‚§ãƒ‘ãƒ¼ãƒ‰ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒã‚ã‚Šã€ç¾åœ¨ç´„50äººã®ã‚·ã‚§ãƒ‘ãƒ¼ãƒ‰ãŒã„ã‚‹ã€‚
Most of these are engineers with experience running experiments.
ãã®ã»ã¨ã‚“ã©ã¯å®Ÿé¨“ã®çµŒé¨“ã‚’æŒã¤ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã ã€‚
There are strict entry requirements.
å³ã—ã„å…¥å›£æ¡ä»¶ãŒã‚ã‚‹ã€‚
Experiment owners implicitly opt-in for review: either pre-test or pre-launch.
å®Ÿé¨“æ‰€æœ‰è€…ã¯æš—é»™ã®ã†ã¡ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã‚ªãƒ—ãƒˆã‚¤ãƒ³ã™ã‚‹ï¼š ãƒ—ãƒ¬ãƒ†ã‚¹ãƒˆã¾ãŸã¯ãƒ—ãƒ¬ãƒ­ãƒ¼ãƒ³ãƒã€‚
Shepherds have on-call duty one week a year to triage incoming requests.
ã‚·ã‚§ãƒ‘ãƒ¼ãƒ‰ã¯å¹´ã«1é€±é–“ã€ã‚ªãƒ³ã‚³ãƒ¼ãƒ«å½“ç•ªãŒã‚ã‚Šã€å¯„ã›ã‚‰ã‚Œã‚‹ä¾é ¼ã‚’ãƒˆãƒªã‚¢ãƒ¼ã‚¸ã™ã‚‹ã€‚
Incentives include feelings of responsibility for the product and acknowledgement of contribution during performance review.
ã‚¤ãƒ³ã‚»ãƒ³ãƒ†ã‚£ãƒ–ã«ã¯ã€è£½å“ã«å¯¾ã™ã‚‹è²¬ä»»æ„Ÿã‚„ã€æ¥­ç¸¾è©•ä¾¡æ™‚ã«è²¢çŒ®ãŒèªã‚ã‚‰ã‚Œã‚‹ã“ã¨ãªã©ãŒå«ã¾ã‚Œã‚‹ã€‚
There are no clear impact KPIs, but qualitatively impact seems to exist.
æ˜ç¢ºãªã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆKPIã¯ãªã„ãŒã€å®šæ€§çš„ã«ã¯ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒã‚ã‚‹ã‚ˆã†ã ã€‚
There is a structured training program consisting of one hour of classroom training per week for two months.
2ãƒ¶æœˆé–“ã€é€±1æ™‚é–“ã®åº§å­¦ç ”ä¿®ã‹ã‚‰ãªã‚‹ä½“ç³»çš„ãªç ”ä¿®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒã‚ã‚‹ã€‚
These classes cover seven topics (e.g.dev cycle, ethics, metrics, stats 101).
ã“ã‚Œã‚‰ã®ã‚¯ãƒ©ã‚¹ã¯7ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ï¼ˆé–‹ç™ºã‚µã‚¤ã‚¯ãƒ«ã€å€«ç†ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€çµ±è¨ˆ101ãªã©ï¼‰ã‚’ã‚«ãƒãƒ¼ã—ã¦ã„ã‚‹ã€‚
There are also case study-based discussions.
ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã«åŸºã¥ã„ãŸãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã‚‚ã‚ã‚‹ã€‚

### 7.2.4. Booking.com: â€œExperimentation Ambassadorsâ€ 7.2.4. ãƒ–ãƒƒã‚­ãƒ³ã‚°ãƒ»ãƒ‰ãƒƒãƒˆã‚³ãƒ  "å®Ÿé¨“å¤§ä½¿"

At Booking.com, the â€œExperimentation Ambassadorsâ€ program started about six months ago.
ãƒ–ãƒƒã‚­ãƒ³ã‚°ãƒ»ãƒ‰ãƒƒãƒˆã‚³ãƒ ã§ã¯ã€åŠå¹´ã»ã©å‰ã‹ã‚‰ã€Œå®Ÿé¨“å¤§ä½¿ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’é–‹å§‹ã—ãŸã€‚
The central experimentation organization handpicked people (~15) with experimentation experience and interest in providing support in product organizations that seemed to need the most support.
ä¸­å¤®ã®å®Ÿé¨“çµ„ç¹”ã¯ã€å®Ÿé¨“çµŒé¨“ãŒã‚ã‚Šã€æœ€ã‚‚ã‚µãƒãƒ¼ãƒˆã‚’å¿…è¦ã¨ã—ã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹è£½å“çµ„ç¹”ã§ã‚µãƒãƒ¼ãƒˆã‚’æä¾›ã™ã‚‹ã“ã¨ã«é–¢å¿ƒã®ã‚ã‚‹äººã€…ï¼ˆã€œ15äººï¼‰ã‚’å³é¸ã—ãŸã€‚
Ambassadors form the first line of support with a clear escalation path and priority support from the central organization.
ã‚¢ãƒ³ãƒã‚µãƒ€ãƒ¼ã¯ã€æ˜ç¢ºãªã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ãƒ‘ã‚¹ã¨ä¸­å¤®çµ„ç¹”ã‹ã‚‰ã®å„ªå…ˆçš„ãªã‚µãƒãƒ¼ãƒˆã«ã‚ˆã£ã¦ã€ã‚µãƒãƒ¼ãƒˆã®ç¬¬ä¸€ç·šã‚’å½¢æˆã™ã‚‹ã€‚
Ambassadors are hooked into the central support ticketing system so that they are aware of other open support questions and can pick up tickets as they see fit.
ã‚¢ãƒ³ãƒã‚µãƒ€ãƒ¼ã¯ä¸­å¤®ã®ã‚µãƒãƒ¼ãƒˆãƒã‚±ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ã«æ¥ç¶šã•ã‚Œã€ä»–ã®æœªè§£æ±ºã®ã‚µãƒãƒ¼ãƒˆã«é–¢ã™ã‚‹è³ªå•ã‚’æŠŠæ¡ã—ã€é©åˆ‡ã¨æ€ã‚ã‚Œã‚‹ãƒã‚±ãƒƒãƒˆã‚’ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
They are included in the experimentation organizationâ€™s internal communications, to keep them aware of current developments or issues.
å®Ÿé¨“çµ„ç¹”ã®å†…éƒ¨ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«å‚åŠ ã•ã›ã€ç¾åœ¨ã®é€²å±•ã‚„å•é¡Œã‚’å¸¸ã«æŠŠæ¡ã•ã›ã‚‹ã€‚
There is a monthly meeting to discuss product needs and concerns.
è£½å“ã®ãƒ‹ãƒ¼ã‚ºã‚„æ‡¸å¿µäº‹é …ã‚’è©±ã—åˆã†æœˆä¾‹ä¼šè­°ãŒã‚ã‚‹ã€‚
Incentives for Ambassadors include feeling responsible for the product, getting priority support from the central organization, and acknowledgement on their performance review.
ã‚¢ãƒ³ãƒã‚µãƒ€ãƒ¼ã¸ã®ã‚¤ãƒ³ã‚»ãƒ³ãƒ†ã‚£ãƒ–ã¨ã—ã¦ã¯ã€è£½å“ã«å¯¾ã™ã‚‹è²¬ä»»ã‚’æ„Ÿã˜ã‚‹ã“ã¨ã€ä¸­å¤®çµ„ç¹”ã‹ã‚‰ã®å„ªå…ˆçš„ãªã‚µãƒãƒ¼ãƒˆã‚’å—ã‘ã‚‹ã“ã¨ã€æ¥­ç¸¾è©•ä¾¡ã§èªã‚ã‚‰ã‚Œã‚‹ã“ã¨ãªã©ãŒã‚ã‚‹ã€‚
There are no clear impact or quality KPIs, but there are plans to include these as the program scales.
æ˜ç¢ºãªå½±éŸ¿ã‚„è³ªã®KPIã¯ãªã„ãŒã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®è¦æ¨¡ãŒæ‹¡å¤§ã™ã‚‹ã«ã¤ã‚Œã¦ã€ã“ã‚Œã‚‰ã‚’å«ã‚ã‚‹è¨ˆç”»ãŒã‚ã‚‹ã€‚
There is no specific training for Ambassadors, but there is extensive general experiment training for all experimenters, including Ambassadors.
ã‚¢ãƒ³ãƒã‚µãƒ€ãƒ¼ã®ãŸã‚ã®ç‰¹åˆ¥ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ãªã„ãŒã€ã‚¢ãƒ³ãƒã‚µãƒ€ãƒ¼ã‚’å«ã‚€ã™ã¹ã¦ã®å®Ÿé¨“è€…ã‚’å¯¾è±¡ã¨ã—ãŸåºƒç¯„ãªä¸€èˆ¬å®Ÿé¨“ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã‚ã‚‹ã€‚

### 7.2.5. Booking.com: â€œPeer-Review Programâ€ 7.2.5. ãƒ–ãƒƒã‚­ãƒ³ã‚°ãƒ»ãƒ‰ãƒƒãƒˆã‚³ãƒ  ã€Œãƒ”ã‚¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»ãƒ—ãƒ­ã‚°ãƒ©ãƒ 

Booking.com also has a separate â€œPeer-Review Programâ€ aimed at getting people involved in providing pro-active feedback to experimenters.
Booking.comã¯ã¾ãŸã€å®Ÿé¨“è€…ã«ç©æ¥µçš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã™ã‚‹ãŸã‚ã«äººã€…ã‚’å·»ãè¾¼ã‚€ã“ã¨ã‚’ç›®çš„ã¨ã—ãŸã€Œãƒ”ã‚¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€ã‚’åˆ¥é€”ç”¨æ„ã—ã¦ã„ã‚‹ã€‚
Anyone in the company can opt-in to the program.
ç¤¾å†…ã®èª°ã§ã‚‚ã“ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã«å‚åŠ ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
Every week participants are paired with a random counterpart.
æ¯é€±ã€å‚åŠ è€…ã¯ãƒ©ãƒ³ãƒ€ãƒ ãªç›¸æ‰‹ã¨ãƒšã‚¢ã‚’çµ„ã‚€ã€‚
Currently approximately 80 people participate.
ç¾åœ¨ç´„80äººãŒå‚åŠ ã—ã¦ã„ã‚‹ã€‚
Each pair picks a random experiment to review.
å„ãƒšã‚¢ãŒãƒ©ãƒ³ãƒ€ãƒ ã«å®Ÿé¨“ã‚’é¸ã³ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ã€‚
The experiment platform includes a â€œgive me a random experimentâ€ button for this purpose.
å®Ÿé¨“ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ã¯ã€ã“ã®ç›®çš„ã®ãŸã‚ã«ã€Œãƒ©ãƒ³ãƒ€ãƒ ãªå®Ÿé¨“ã‚’ã™ã‚‹ã€ãƒœã‚¿ãƒ³ãŒç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã€‚
The platform also supports built-in commenting and threading as part of the reporting interface.
ã¾ãŸã€ã“ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¯ã€ãƒ¬ãƒãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ»ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ä¸€éƒ¨ã¨ã—ã¦ã€ãƒ“ãƒ«ãƒˆã‚¤ãƒ³ã®ã‚³ãƒ¡ãƒ³ãƒˆã¨ã‚¹ãƒ¬ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã€‚
Incentives to participate include making new friends, learning new things, and reward badges displayed on the platform interface.
æ–°ã—ã„å‹é”ã‚’ä½œã£ãŸã‚Šã€æ–°ã—ã„ã“ã¨ã‚’å­¦ã‚“ã ã‚Šã€ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹ã«è¡¨ç¤ºã•ã‚Œã‚‹å ±é…¬ãƒãƒƒã‚¸ãªã©ã€å‚åŠ ã¸ã®ã‚¤ãƒ³ã‚»ãƒ³ãƒ†ã‚£ãƒ–ãŒã‚ã‚‹ã€‚
There are KPIs defined around reviews and comments.
ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨ã‚³ãƒ¡ãƒ³ãƒˆã«é–¢ã™ã‚‹KPIãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹ã€‚
Newcomers are paired with experienced users the first few times to ensure that they are brought up to speed.
æ–°äººã¯ã€æœ€åˆã®æ•°å›ã¯çµŒé¨“è±Šå¯Œãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ãƒšã‚¢ã‚’çµ„ã¿ã€ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å›³ã‚‹ã€‚
A one-page guide for writing good reviews is also available [33].
è‰¯ã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æ›¸ããŸã‚ã®1ãƒšãƒ¼ã‚¸ã®ã‚¬ã‚¤ãƒ‰ã‚‚ç”¨æ„ã•ã‚Œã¦ã„ã‚‹[33]ã€‚

### 7.2.6. Microsoft: Center of Excellence Model 7.2.6. ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆ ã‚»ãƒ³ã‚¿ãƒ¼ãƒ»ã‚ªãƒ–ãƒ»ã‚¨ã‚¯ã‚»ãƒ¬ãƒ³ã‚¹ãƒ»ãƒ¢ãƒ‡ãƒ«

At Microsoft, a data scientist or two from the central experimentation platform team (Analysis & Experimentation) work very closely with a product team.
ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã§ã¯ã€ä¸­å¤®ã®å®Ÿé¨“ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãƒãƒ¼ãƒ ï¼ˆåˆ†æã¨å®Ÿé¨“ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆãŒ1äººã‹2äººã€è£½å“ãƒãƒ¼ãƒ ã¨å¯†æ¥ã«é€£æºã—ã¦ã„ã‚‹ã€‚
At first, the data scientists from the experimentation platform handle almost all support needs for the product and gain good insight into the product, business, customers, technology, and data.
æœ€åˆã®ã†ã¡ã¯ã€å®Ÿé¨“ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆãŒè£½å“ã«é–¢ã™ã‚‹ã»ã¼ã™ã¹ã¦ã®ã‚µãƒãƒ¼ãƒˆãƒ‹ãƒ¼ã‚ºã«å¯¾å¿œã—ã€è£½å“ã€ãƒ“ã‚¸ãƒã‚¹ã€é¡§å®¢ã€ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã€ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹å„ªã‚ŒãŸæ´å¯Ÿã‚’å¾—ã‚‹ã€‚
At the same time, the data scientists work on transferring knowledge and expertise to champions in the product team.
åŒæ™‚ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã¯çŸ¥è­˜ã¨å°‚é–€çŸ¥è­˜ã‚’è£½å“ãƒãƒ¼ãƒ ã®ãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³ã«ä¼ãˆã‚‹ä½œæ¥­ã‚‚è¡Œã†ã€‚
The expectation is that over time, as more experiments are run, the product team will become more self-sufficient in running trustworthy experiments, and the person from the central experimentation platform team helps with a smaller and smaller percentage of experimentsâ€”those that are unique or have issues.
æ™‚é–“ã®çµŒéã¨ã¨ã‚‚ã«ã€ã‚ˆã‚Šå¤šãã®å®Ÿé¨“ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã«ã¤ã‚Œã¦ã€è£½å“ãƒãƒ¼ãƒ ã¯ä¿¡é ¼ã§ãã‚‹å®Ÿé¨“ã®å®Ÿè¡Œã«ãŠã„ã¦ã‚ˆã‚Šè‡ªç«‹çš„ã«ãªã‚Šã€ä¸­å¤®ã®å®Ÿé¨“ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãƒãƒ¼ãƒ ã‹ã‚‰ã®æ‹…å½“è€…ã¯ã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå®Ÿé¨“ã‚„å•é¡Œã®ã‚ã‚‹å®Ÿé¨“ãªã©ã€ã‚ˆã‚Šå°‘ãªã„å‰²åˆã®å®Ÿé¨“ã‚’æ”¯æ´ã™ã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚
The data scientists from the central team and champions from the product team usually conduct further training to educate the entire product team on best practices and processes for running experiments.
ä¸­å¤®ãƒãƒ¼ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã¨è£½å“ãƒãƒ¼ãƒ ã®ãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³ã¯ã€é€šå¸¸ã€å®Ÿé¨“ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¨ãƒ—ãƒ­ã‚»ã‚¹ã«ã¤ã„ã¦è£½å“ãƒãƒ¼ãƒ å…¨ä½“ã‚’æ•™è‚²ã™ã‚‹ãŸã‚ã«ã€ã•ã‚‰ãªã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿæ–½ã™ã‚‹ã€‚
The experimentation team maintains a monthly scorecard to measure the goals of each product onboarding for running trustworthy experiments at scale.
å®Ÿé¨“ãƒãƒ¼ãƒ ã¯ã€ä¿¡é ¼ã«è¶³ã‚‹å®Ÿé¨“ã‚’å¤§è¦æ¨¡ã«è¡Œã†ãŸã‚ã«ã€å„è£½å“ã®ã‚ªãƒ³ãƒœãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ç›®æ¨™ã‚’æ¸¬å®šã™ã‚‹ã‚¹ã‚³ã‚¢ã‚«ãƒ¼ãƒ‰ã‚’æ¯æœˆç®¡ç†ã—ã¦ã„ã‚‹ã€‚
These goals are set at the beginning of every year.
ã“ã‚Œã‚‰ã®ç›®æ¨™ã¯æ¯å¹´åˆã‚ã«è¨­å®šã•ã‚Œã‚‹ã€‚
Every six weeks, the data scientists and champions review the experimentation operations in the product where successes and failures from the past are highlighted along with a plan to address gaps and opportunities.
6é€±é–“ã”ã¨ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã¨ãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³ã¯ã€è£½å“ã«ãŠã‘ã‚‹å®Ÿé¨“ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€éå»ã®æˆåŠŸä¾‹ã¨å¤±æ•—ä¾‹ãŒã€ã‚®ãƒ£ãƒƒãƒ—ã¨ãƒãƒ£ãƒ³ã‚¹ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®è¨ˆç”»ã¨ã¨ã‚‚ã«å¼·èª¿ã•ã‚Œã‚‹ã€‚
The incentives for data scientists and champions are partially tied to the success of experimentation in their respective products.
ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã¨ãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³ã®ã‚¤ãƒ³ã‚»ãƒ³ãƒ†ã‚£ãƒ–ã¯ã€ãã‚Œãã‚Œã®è£½å“ã«ãŠã‘ã‚‹å®Ÿé¨“ã®æˆåŠŸã«éƒ¨åˆ†çš„ã«çµã³ã¤ã„ã¦ã„ã‚‹ã€‚
The central experimentation team holds a weekly experiment review, where any experiment owner can share their experiment and request feedback from the data scientists.
ä¸­å¤®å®Ÿé¨“ãƒãƒ¼ãƒ ã¯æ¯é€±å®Ÿé¨“ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’é–‹å‚¬ã—ã€å®Ÿé¨“ã‚ªãƒ¼ãƒŠãƒ¼ã¯èª°ã§ã‚‚è‡ªåˆ†ã®å®Ÿé¨“ã‚’å…±æœ‰ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ±‚ã‚ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
The central experimentation team also conducts a monthly Introduction to Experimentation class and Experiment Analysis lab open to everyone at Microsoft.
ä¸­å¤®å®Ÿé¨“ãƒãƒ¼ãƒ ã¯ã¾ãŸã€ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®èª°ã‚‚ãŒå‚åŠ ã§ãã‚‹å®Ÿé¨“å…¥é–€ã‚¯ãƒ©ã‚¹ã¨å®Ÿé¨“åˆ†æãƒ©ãƒœã‚’æ¯æœˆé–‹å‚¬ã—ã¦ã„ã‚‹ã€‚
In addition, twice a year the team hosts a meeting focused on experiments and discusses the best controlled experiments.
ã•ã‚‰ã«ã€å¹´ã«2å›ã€ãƒãƒ¼ãƒ ã¯å®Ÿé¨“ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’é–‹å‚¬ã—ã€æœ€å–„ã®å¯¾ç…§å®Ÿé¨“ã«ã¤ã„ã¦è­°è«–ã—ã¦ã„ã‚‹ã€‚
This provides product teams an opportunity to showcase their strengths in experimentation and learn from other teams.
ã“ã‚Œã¯ã€è£½å“ãƒãƒ¼ãƒ ãŒå®Ÿé¨“ã«ãŠã„ã¦è‡ªåˆ†ãŸã¡ã®å¼·ã¿ã‚’ç™ºæ®ã—ã€ä»–ã®ãƒãƒ¼ãƒ ã‹ã‚‰å­¦ã¶æ©Ÿä¼šã‚’æä¾›ã™ã‚‹ã€‚

### 7.2.7. Google: Just-in-time Education Model 7.2.7. ã‚°ãƒ¼ã‚°ãƒ« ã‚¸ãƒ£ã‚¹ãƒˆãƒ»ã‚¤ãƒ³ãƒ»ã‚¿ã‚¤ãƒ ã®æ•™è‚²ãƒ¢ãƒ‡ãƒ«

Google has used a variety of approaches, but one of the most successful relies heavily on just-in-time education [67].
ã‚°ãƒ¼ã‚°ãƒ«ã¯ã•ã¾ã–ã¾ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä½¿ã£ã¦ã„ã‚‹ãŒã€æœ€ã‚‚æˆåŠŸã—ã¦ã„ã‚‹ã®ã¯ã€ã‚¸ãƒ£ã‚¹ãƒˆãƒ»ã‚¤ãƒ³ãƒ»ã‚¿ã‚¤ãƒ æ•™è‚²ã«å¤§ããä¾å­˜ã—ã¦ã„ã‚‹ã‚‚ã®ã [67]ã€‚
For example, for experiment design, they have a checklist that asks experimenters a series of questions, ranging from â€œwhat is your hypothesis?â€ to â€œhow will you measure success?â€ and â€œhow big of a change do you need to detect?â€ Google has an â€œexperiment councilâ€ of experts who review the checklists, and have found consistently that the first time through, an experimenter needs handholding.
ä¾‹ãˆã°ã€å®Ÿé¨“ãƒ‡ã‚¶ã‚¤ãƒ³ã«ã¤ã„ã¦ã¯ã€"ä»®èª¬ã¯ä½•ã‹ï¼Ÿ"ã‹ã‚‰ "ã©ã®ã‚ˆã†ã«æˆåŠŸã‚’æ¸¬å®šã™ã‚‹ã®ã‹ï¼Ÿ"ã€"ã©ã®ç¨‹åº¦ã®å¤‰åŒ–ã‚’æ¤œå‡ºã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã®ã‹ï¼Ÿ"ã¾ã§ã€ä¸€é€£ã®è³ªå•ã‚’å®Ÿé¨“è€…ã«æŠ•ã’ã‹ã‘ã‚‹ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆãŒã‚ã‚‹ã€‚ã‚°ãƒ¼ã‚°ãƒ«ã«ã¯ã€ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’è¦‹ç›´ã™å°‚é–€å®¶ã‹ã‚‰ãªã‚‹ "å®Ÿé¨“è©•è­°ä¼š "ãŒã‚ã‚Šã€åˆå›ã¯å®Ÿé¨“è€…ãŒæ‰‹å–ã‚Šè¶³å–ã‚Šæ•™ãˆã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚’ä¸€è²«ã—ã¦ç™ºè¦‹ã—ã¦ã„ã‚‹ã€‚
But on subsequent experiments, less handholding is needed, and the experimenter starts teaching their team members.
ã—ã‹ã—ã€ãã®å¾Œã®å®Ÿé¨“ã§ã¯ã€æ‰‹å–ã‚Šè¶³å–ã‚Šæ•™ãˆã‚‹å¿…è¦ã¯ãªããªã‚Šã€å®Ÿé¨“è€…ã¯ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã«æ•™ãˆå§‹ã‚ã‚‹ã€‚
As they become more experienced, some experimenters can become experts and perform reviews.
çµŒé¨“ã‚’ç©ã‚€ã«ã¤ã‚Œã¦ã€å°‚é–€å®¶ã«ãªã£ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã†å®Ÿé¨“è€…ã‚‚å‡ºã¦ãã‚‹ã€‚
Some teams have sufficient expertise that they can retire the entire checklist process.
ãƒãƒ¼ãƒ ã«ã‚ˆã£ã¦ã¯ã€ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã®å…¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’å¼•é€€ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã»ã©ã®å°‚é–€çŸ¥è­˜ã‚’æŒã£ã¦ã„ã‚‹ã€‚
For analysis, Google has an experiment review similar to Microsoft.
åˆ†æã«é–¢ã—ã¦ã¯ã€ã‚°ãƒ¼ã‚°ãƒ«ã¯ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã¨åŒæ§˜ã®å®Ÿé¨“ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã£ã¦ã„ã‚‹ã€‚
The advantage is both just-in-time education to experimenters about interpreting experiment results and metaanalysis by experts to find the larger patterns.
ãã®åˆ©ç‚¹ã¯ã€å®Ÿé¨“çµæœã®è§£é‡ˆã«é–¢ã™ã‚‹å®Ÿé¨“è€…ã¸ã®ã‚¸ãƒ£ã‚¹ãƒˆã‚¤ãƒ³ã‚¿ã‚¤ãƒ ã®æ•™è‚²ã¨ã€ã‚ˆã‚Šå¤§ããªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã®å°‚é–€å®¶ã«ã‚ˆã‚‹ãƒ¡ã‚¿åˆ†æã®ä¸¡æ–¹ã§ã‚ã‚‹ã€‚
