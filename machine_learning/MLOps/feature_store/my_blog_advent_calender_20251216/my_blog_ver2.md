# NewsPicksで価値を発揮する特徴量ストアに重要そうな観点たち ~SageMaker Feature Storeを4ヶ月試験運用した学びから見えてきたこと~

皆さんこんにちは! ソーシャル経済メディア「NewsPicks」プロダクトエンジニアの森田( [@moritama7431](https://twitter.com/moritama7431) )です:)
この記事は [NewsPicks アドベントカレンダー 2025](https://qiita.com/advent-calendar/2024/newspicks) の16日目の記事です。

---

さて本日は、ざっくり機械学習のプロダクトへの実応用や MLOps に関する内容です！
本記事は、

- **機械学習をプロダクトに本番導入している／これから導入したいソフトウェアエンジニア**  
- **特徴量ストア(Feature Store)の導入や運用に悩んでいる方**  

向けに、  
**NewsPicksで SageMaker Feature Store を4ヶ月間試験運用して得られた実運用の学び**を言語化して整理してみました:) 
もちろん皆さんのMLOps活動の参考になれば嬉しいですし、何か気になる点があればぜひお気軽にコメントやXで反応いただけたら喜びます！

## TL;DR

- + **特徴量(Feature)はMLプロダクトの成否を左右する“中心資産”**だが、本番運用では管理・提供が一気に難しくなる。**特徴量ストア(Feature Store)**はその課題解消を担う重要コンポーネント。
- SageMaker Feature Store を約4ヶ月試験運用した結果、NewsPicksの文脈では以下の4つの観点が特徴量ストアにとって重要だと感じた:
  1. リアルタイム推論に必要な特徴量を低レイテンシーで提供できること
  2. ストリーミング/マイクロバッチでの高頻度の読み書きに対応できること
  3. 歴史的特徴量の backfill が容易であること
  4. 日常的に使われている DWH / BI ツールからアクセスしやすいこと
- これらの試験運用で得た知見を踏まえ、現在は自社プロダクトのユースケース・ワークロード・コスト構造に合わせて最適化しやすいよう、S3×Iceberg（オフライン）＋DynamoDB（オンライン）を軸にした自前 Feature Store への段階的移行を検討。

## 背景: 本記事を書く意味づけ

### まず特徴量は、機械学習プロダクトの成否を左右する中心資産だ!

まず特徴量に関する話を少しまとめさせてください!
機械学習プロジェクトに関わったことがある方なら「特徴量」という言葉を聞いたことがあるかもしれません。
「特徴量(Feature)」とは、ある対象(entity, ex. ユーザ, 記事, etc.)の属性(property)を数値化したもので、機械学習モデルの入力情報として予測や意思決定に役立つデータのことを指します。
例えばNewsPicksプロダクト内での特徴量の例としては、以下のようなものがあります。

- entityがユーザの場合の特徴量: 年齢、性別、過去のニュース閲覧履歴, アクセス頻度, etc.
- entityが記事の場合の特徴量: 記事のカテゴリ, 公開日時, 著者情報, 閲読数, etc.

「そりゃそうだ!」と思われるかもですが、**機械学習モデルの予測や意思決定の性能は入力する特徴量に大きく依存**します。
入力情報を元に機械学習モデルが出力を計算する訳ですし...!

既存文献でも以下のように機械学習プロダクト・プロジェクトにおける特徴量の重要性が強調されています。

> Most of the problems you will face are, in fact, engineering problems. Even with all the resources of a great machine learning expert, most of the gains come from great features, not great machine learning algorithms.
> (あなたが直面するほとんどの問題は、実際にはエンジニアリングの問題です。優れた機械学習の専門家のすべてのリソースを持っていても、ほとんどの利益は優れた特徴量から得られ、優れた機械学習アルゴリズムからは得られません。)
> (ブログ記事「Rules of Machine Learning: Best Practices for ML Engineering」より引用)

> Not surprisingly, the most important thing is to have the right features.
> (驚くべきことではないが、最も重要なことは適切な特徴量を持つことです。)
> (論文「Facebook広告のCTR予測からの実践的な教訓」より引用)

つまりこのセクションでは、**まず特徴量が機械学習モデルの性能、ひいては機械学習プロダクト・プロジェクトの成否を左右する重要な中心資産なんだー！**ということを共有したかったのでした:)

### そして特徴量ストアは、プロダクション環境で特徴量を活用して価値を発揮する上で重要なコンポーネントだ!

さて前サブセクションで「特徴量は機械学習プロダクトの成否を左右する中心資産だ!」と述べましたが、“最初のPoC段階” では特徴量の運用はそこまで難しくありません。
主にDWHやdatalakeからデータを直接引っこ抜いて、 CSVやparquetファイルをこねくり回して、「学習用の特徴量できた！モデルも学習できた！性能評価もできた！Yes！」 という世界では、特徴量は全て開発者の手元にあり、再現性も整合性もほぼ問題になりません。
さらにPoCでは、特徴量の生成に何秒かかろうが、学習用に集計に数時間かかろうが全く困らないので、レイテンシ要件やスループット要件の懸念もありません。

PoC段階で特徴量生成 -> 学習 -> 推論の一連の流れを実装すると、例えば以下のような設計になるのではないでしょうか??
またPoCを超えて本番プロダクトにMLを組み込む段階でも、例えば日次や週次バッチで特徴量生成・学習・推論を一括で行えばOKなユースケースの場合は、この設計でも十分に運用可能だと思います。

![PoC時での特徴量生成 -> 学習 -> 推論の流れのイメージ図]()

---

しかし一方で、**プロダクション環境にMLを組み込んだ瞬間、特徴量運用の難易度は一気に跳ね上がります。**
実運用では、例えば次のような課題が出てきます。

- あれ、新規ユーザや新規アイテムを扱いたいからモデルの推論にリアルタイム性が求められるんだけど...
  - 特徴量ってレイテンシー要件を満たせる範囲でリアルタイムに作成できるんだっけ? :thinking:
  - モデルの学習時と推論時で、特徴量の生成ロジックって一貫してるっけ?? 一貫性を保証できるっけ?? :thinking:
  - 特徴量は事前計算しておくとしたら保存場所は?? datalakeやDWHだと低レイテンシでアクセスできないよね...でも学習とかの際はむしろ高スループットでアクセスしたいし...! :thinking:
  - リアルタイムアクセス用にキーバリューストア、バッチアクセス用にDWHとかdatalakeとか複数の保存場所を用意するとして、両者の一貫性の保証はどうやろう...!:thinking:
- 自社プロダクト内で機械学習やアルゴリズムを扱うユースケースもチームも増えてきたんだけど...
  - 同じような特徴量をユースケース毎に別々の生成ロジックで作って試行錯誤しちゃってない?? いい感じに共有できた方が改善のiteration早く回せそう...!:thinking:
  - リアルタイム推論のユースケース達がそれぞれ特徴量を事前計算してキャッシュする仕組みを持っちゃってるな、毎回キャッシュの仕組みを追加するのも開発コスト高いし、運用コスト・認知負荷も高くなってきた...!:thinking:
- 過去のユーザ行動などの歴史的特徴量が、推薦タスクなどでは効果的だから使いたいんだけど...
  - 学習時に未来の情報が漏洩(future data leak)しないように、歴史的特徴量についてある1時点の値を正しく再現できるようにしたいんだけど、どう管理したらいいんだっけ...!:thinking:

![PoC時のまま、本番プロダクトの機械学習モデルの運用を組み込んだアーキテクチャ図]()

さて、上記のような特徴量周りの実運用のあれこれの課題解決の責務を担う役割として導入されるのが **特徴量ストア(Feature Store)** というコンポーネントです。

特徴量ストアは、例えば以下のような機能を提供することで上記の課題の解消を図ります。

- 特徴量生成と学習 & 推論を分離したアーキテクチャの提供
  - 特徴量生成ロジックを独立させることで、学習時と推論時で一貫性のある特徴量を提供できる。
  - 事前計算したリッチな特徴量をリアルタイム推論で活用できる。
- 低レイテンシー & 高スループットな特徴量アクセス基盤(オンラインストア & オフラインストア)の提供
  - リアルタイム推論に必要な特徴量を低レイテンシーで提供できる。
  - バッチ学習に必要な特徴量を高スループットで提供できる。
  - 両者の整合性の保証は特徴量ストアが担保する。
- 様々な種類の特徴量を一元管理
  - 特徴量の再利用がしやすくなる。
  - オフライン&オンラインストアを内包してる事で、高スループットのオフラインアクセス、低レイテンシーのオンラインアクセス両方に対応できる。
- 歴史的特徴量はtimestamp付きで管理
  - 過去のある1時点の特徴量を正しく再現し、学習時のデータリーク問題を防止できる。

特徴量ストアを採用した場合のアーキテクチャ例は例えば以下のようになります。
(ちなみに FTI Pipelines Architectureと呼ばれる設計思想です。もし興味があればこちらの元記事もぜひご覧ください: [hoge]())

![特徴量ストアを導入した場合のアーキテクチャ図]()

という訳でこのセクションでは、PoC段階ではそこまで難しくなかった特徴量運用が、プロダクション環境に組み込んだ瞬間に一気に難易度が上がる! だから特徴量ストアは、プロダクション環境で特徴量まわりの運用課題を解決して機械学習で価値を発揮するための重要なコンポーネントなんだ〜! ということを主張したかったのでした。

---

### NewsPicksでも特徴量の運用課題が現実的な問題になってきた...!

なお、ここまで述べてきた特徴量運用の課題は、NewsPicksにおいても徐々に現実的な問題となってきていました。
求められる推薦手法の高度化に伴い、扱う特徴量はより多様かつ複雑になってきています。
またここ1年ほどで、事業部向かいのチームを含めてML活用の裾野が広がり、特徴量の共有・再利用・発見しやすさといった観点も無視できなくなってきました。

こうした背景から、私たちはSagemaker Feature Storeを試験的に導入して新規プロジェクトを中心に約4ヶ月間運用を行ってきました。
本記事では、その試験運用を通じて得られた学びとして「NewsPicksで真に価値を発揮する特徴量ストアに重要そうな観点たち」を共有したいと思います。

## 本論: NewsPicksで真に価値を発揮する特徴量ストアに重要そうな観点たち

ここからは、SageMaker Feature Store を約4ヶ月試験運用してみた経験をもとに、NewsPicksの特徴量ストアが真に価値を発揮するために重要だと感じた観点を紹介します。

NewsPicksの特徴量ストアが満たすべき要件として、特に重要だと感じた観点は次の4つです。

1. リアルタイム推論に必要な特徴量を低レイテンシーで提供できること
2. ストリーミング/マイクロバッチ更新へのコスト効率と耐性があること
3. 歴史的特徴量の backfill が容易であること
4. 日常的に使われている DWH / BI ツールからアクセスしやすいこと

以下で順に紹介していきます。

### その1: リアルタイム推論時に必要な特徴量を低レイテンシーで提供できること

この観点については SageMaker Feature Store の試験運用を始める前から「必須だよね」という認識はありました (でも重要観点として一応挙げさせてください!:pray:)。
というのも、NewsPicksにおける機械学習の主要なユースケースの1つが、**ニュース推薦や検索といったコンテンツの編成・配信を最適化するタスクであり、ここではリアルタイム性が重視される場面が多いため**です。
ニュースはlifetimeが短く、新着ニュースを興味がありそうなユーザに素早く届けられるかがユーザ体験の質を左右します。
また、ユーザの行動も高速に変化するため、その反応を即座に次の推薦へ反映できることが重要です。

こうした背景から、リアルタイム推論のユースケースが多いNewsPicksでは、低レイテンシで特徴量を取得できるオンラインストア機能が、特徴量ストアに強く求められます。
一見すると当たり前の要件に見えるかもしれませんが、**すべてのプロダクトにとってオンラインストア機能が必須というわけではない**、という点は意識しておく必要があります。
実際、現在ベンダー各社から提供されているフルマネージドな特徴量ストアの中にも、オンラインストア機能を前提としていない、あるいはオフライン中心の設計を採用しているものも存在します。

例えば、映画やドラマのようにアイテムのlifetimeが比較的長いプロダクトでは、新しいアイテムを即時に推薦に反映する必要性はそこまで高くありません。実際、Netflixの推薦システムでは日次バッチで推論を行っているという話もあり、このようなケースでは高スループットなオフラインストア機能だけで十分に成立することもあります。
ただちなみに、アイテムのlifetimeが長い場合でも、ユーザの行動履歴や嗜好の変化を素早く反映したい場合には、リアルタイム推論が求められることもあります。その場合は、やはりオンラインストア機能が必要になる可能性は高いでしょう。

というわけで、リアルタイム推論への対応はプロダクト特性に依存する要件ですが、少なくともNewsPicksの文脈においては、オンラインで低レイテンシーに特徴量を提供できることは、特徴量ストアが価値を発揮するための前提条件の1つだと感じています。

### 2. 歴史的特徴量の　backfill が容易で現実的なコストで耐えられること

「その1」で述べた通り、NewsPicksでは推薦や検索といったコンテンツ編成・配信の最適化タスクが多く、こうしたユースケースでは**ユーザの過去のリアクション履歴などの歴史的特徴量（historical feature）**が非常に高い価値を発揮します。そのため、特徴量ストアがこれらの歴史的特徴量を適切に管理・運用できることは、重要な要件の1つです。

もちろん、学習時の future data leak を防ぐために、過去のある時点 $t$ における特徴量の値を正しく再現できることは前提条件です。しかし、試験運用を通してそれ以上に重要だと感じたのが、**歴史的特徴量の backfill をどれだけ容易に行えるか**という点でした。

ここでいう 「歴史的特徴量のbackfill」とは、過去のある時点 $t$ における特徴量値を、特定の期間全体にわたって再計算し、保存し直す作業を指します。モデル性能を改善する過程では、**新しい歴史的特徴量を追加したり、既存の特徴量の生成ロジックを変更したりすること**が頻繁に発生します。そのたびに、過去の各時点における特徴量値を再計算して学習データを作り直す必要があります。

このため、特徴量生成パイプラインは状態を持たず、冪等性を保った設計であることが望ましく、同時に特徴量ストア側も backfill 時に大量の書き込みを効率よく処理できることが求められます。

![]()

一方で、この観点は SageMaker Feature Store を試験運用する中で、明確な課題として浮き彫りになりました。
SageMaker Feature Store には、オフラインストアのみに書き込む公式な API が存在せず、書き込み時には必ずオンライン・オフライン両方への処理が発生します。そのため、過去の古い期間を対象とする歴史的特徴量の backfill であっても、**リアルタイム推論用に最新の特徴量を保持するためのオンラインストアに対して書き込みリクエストが発生**してしまいます。
しかし、これらのデータは学習用途でのみ利用されるものであり、オンラインストアに保存する必要は本来ありません。
実際には、タイムスタンプを見て現存レコードより古い場合は更新されないものの、書き込みリクエスト自体は発生するため、結果として DynamoDB 相当の不要な書き込みコストが積み重なりやすい構造になっていました。

この課題感は[既存のブログ記事](https://towardsdatascience.com/ingesting-historical-feature-data-into-sagemaker-feature-store-5618e41a11e6/)でも指摘されており、この課題を回避するためには、公式の書き込み API を使わず、オフラインストアの内部実装を理解した上で直接書き込む処理を自前で実装する必要がありました。
ただ、この仕様によってオンラインストアとオフラインストアの整合性・一貫性が強く保証されている点は非常に理解できます。**ただ、歴史的特徴量を多用するNewsPicksのユースケースでは、backfill 時のコストが無視できないレベルになる可能性がありました。**

歴史的特徴量の backfill は、MLモデルの性能改善におけるイテレーションを回す上で欠かせない作業です。もし backfill が重く、高コストで、時間もかかる仕組みだと、特徴量の追加やロジック変更を気軽に試せなくなり、結果として改善のスピードが落ちてしまいます。
仮にbackfillができない場合どうなるかというと、新しい特徴量を導入するたびに本番リリース後のログ蓄積を待つ必要があり、学習データが揃うまで何週間も改善を止めざるを得ない、という状況にもなりかねません。

こうした理由から、特に歴史的特徴量を活用するMLユースケースが多いNewsPicksにおいては、**backfill が容易で、かつ現実的なコストで耐えられる特徴量ストアであること**が、非常に重要な要件だと感じています。

### 3. ストリーミング / マイクロバッチでの高頻度の読み書きに現実的なコストで耐えられること

NewsPicksはニュース記事を扱うプロダクトであるため、新しいコンテンツが継続的に流入します。そのため、新規ニュースが公開されたタイミングでできるだけ早く特徴量を生成し、興味を持ちそうなユーザに届けたいという要求が自然に生まれます。加えて、クリックや閲覧といったユーザのリアクションに基づく特徴量も、なるべく小さなラグで更新し、パーソナライズされたフィードに反映したいという意図があります。

こうした背景から、**特徴量生成パイプラインは日次バッチだけでなく、ストリーミングやマイクロバッチで稼働させたいケース**が多くなります。その結果、**特徴量ストア側にも高頻度な読み書きに耐えられる特性**が求められます。
具体的には、並列書き込みに弱かったり、アクセスが集中した際にレイテンシが大きく悪化したりする仕組みでは運用が難しくなります。また、ストリーミング処理を行うだけでコストが急激に膨らんでしまうような設計も厳しいです。

この観点においては、SageMaker Feature Store は要件を比較的よく満たしていました。オンラインストアは DynamoDB をベースとしており、高頻度な読み書きや並列アクセスに強い設計になっています。また、オフラインストアは S3 + Iceberg をベースとしてるためコストを抑えつつ柔軟に運用することが可能でした。

常に新しいニュース記事が流入し、ユーザの行動も継続的に発生するNewsPicksのようなプロダクトにおいては、**ストリーミング / マイクロバッチでの高頻度な読み書きを、現実的なコストで継続できること**が、特徴量ストアが本番で価値を発揮するための重要な要件だと感じています。

### 4. 日常的に使われている DWH / BI ツールからアクセスしやすいこと

特徴量は、それを必要とする任意のチームが容易にアクセスできる必要があります。
既存の文献でも、**価値を発揮する特徴量ストアの重要な要件の1つとして、共有可能性（discoverability）**が挙げられています。

> Having a single repository of features that data scientists can search and reuse to help solve their problems is crucial to their productivity.  
> (データサイエンティストが自分の問題を解決するために検索・再利用できる単一の特徴量リポジトリを持つことは、生産性にとって非常に重要です。)
> Easily searching through those features, whether that be through SQL or a dataframe-like API, is a must-have for data scientists to be successful.
> (SQLやデータフレームのようなAPIを通じて、それらの特徴量を簡単に検索できることは、データサイエンティストが成功するために必須です。)
> ([5 Minimum Requirements of an Operational Feature Store](https://medium.com/data-for-ai/5-minimum-requirements-of-an-operational-feature-store-ab1436ca1a2c) より引用)

この観点で SageMaker Feature Store を試験運用してみると、NewsPicksの開発組織のワークフローとは必ずしも噛み合っていない部分が見えてきました。
SageMaker Feature Store のオフラインストアは S3 + Iceberg をベースとしており、AWS公式の SageMaker Python SDK を使えば、Athena 経由で SQL クエリを投げて特徴量にアクセスできます。

しかし、NewsPicksでは日常的なデータ分析や調査に、SnowflakeやSnowsight（SnowflakeのWeb UI）を中心とした DWH / BI 環境を主に利用しています。そのため、ちょっとした確認のために Athena を経由して S3 上の Iceberg テーブルにクエリを投げる、という体験は、開発メンバーにとってあまり馴染みがあるものではありませんでした。
例えば、「このユーザはどんな特徴量を持っているんだっけ?」とか「この記事の特徴量はどういう値になってるんだっけ?」といった疑問をパッと調べたい場合に、Snowflake 経由でクエリを投げて確認できれば非常に楽なのですが、Athena経由だとハードルがかなり高い訳です。
また、分析用途として Snowsight 上の notebook で Tree 系モデルを使い、特徴量の重要度分析を行いたい、といったユースケースもありました。この点でも、Athena ではなく Snowflake 経由で特徴量にアクセスできることが望ましい状況でした。

そこで、SageMaker Feature Store が生成する S3 上の Iceberg テーブルを、Snowflake の外部テーブルとしてマウントすることも試みましたが、連携には苦戦しました。
具体的には、Sagemaker側でのIceberg テーブルの初期化時に生成される 0 byte の data file が Snowflake 側で読み込みエラーを引き起こし、外部テーブルとして取り込めないという問題に直面しました。当時は明確な解決策が見つからず連携を断念したのでした。

こうした経験から、**NewsPicksで日常的に使われている DWH / BI ツールから、特徴量ストアに自然にアクセスできること**は、想像以上に重要な要件だと感じています。
技術的に正しく設計されていても、特徴量が「見つけにくい」「触りにくい」状態では再利用は進まず、結果として特徴量ストアの価値も十分に引き出せません。NewsPicksの文脈では、特に Snowflake を中心とした分析体験と親和性の高い形で特徴量にアクセスできることが、重要なポイントでした。

## 学びを踏まえて、今後の改善の話:

これまでの試験運用を踏まえ、現在はフルマネージドな特徴量ストアをそのまま使い続けるのではなく、**AWSのメジャーなサービスを組み合わせた自前の Feature Store へ段階的に移行することを検討しています。**
具体的には、オフラインストアとして S3テーブルバケット × Icebergテーブル形式、オンラインストアとして DynamoDB を中心に据えた構成です。

この判断に至った背景には、フルマネージドサービスを採用するメリットと、自前で構築するメリットを比較した結果、**今のNewsPicksの文脈では後者の方が柔軟性と学習コストの面で有利だと判断したため**です。

Sagemaker Feature Store を試験運用する中で、前述したいくつかの重要要件を満たすのが難しい場面がありました。
特に、歴史的特徴量の backfill に関しては、オフラインストアのみに書き込む公式 API が存在しないため、大量の読み書きが発生する backfill 処理が高コストになりがちでした。これを回避するには、結局オフラインストアへ直接書き込む処理を自前で実装する必要があり、フルマネージドサービスとしての恩恵が薄れてしまいます。

また、特徴量の発見しやすさ・アクセスしやすさという観点でも課題がありました。
AWS公式の SageMaker Python SDK は Athena 経由でのアクセスを前提としていましたが、NewsPicksでは Snowflake を中心に DWH / BI ツールを構成しており、日常的な分析フローとの親和性は高くありませんでした。S3 上の Iceberg テーブルを Snowflake から直接参照することも試みましたが、Iceberg テーブルの内部仕様に起因する問題に直面し、スムーズな連携には至りませんでした。こうした点を解消しようとすると、結果的に内部実装を深く理解し、細かくカスタマイズする必要が出てきます。この点でもフルマネージドサービスの恩恵が薄れる感がありました。

さらに、**フルマネージドサービスゆえの学習コスト**の高さも無視できませんでした。
SageMaker Feature Store は比較的新しいサービスであり、仕様や挙動を正しく理解するまでに一定の時間がかかります。加えて、自社のワークロードに合わせたコスト最適化やパフォーマンス改善を行おうとすると、抽象化の内側を理解する必要があり、その点でも自前実装との差が縮まっていく印象を受けました。

こうした学びを踏まえ、S3 × Iceberg と DynamoDB といった、**NewsPicks開発組織にとって馴染みのある AWS の基盤サービスを組み合わせた Feature Store** を構築することで、学習コストを抑えつつ、これまで挙げてきた要件をより素直に満たせるのではないかと考えています。データストアの実体が明確である分、コスト構造や挙動も把握しやすく、プロダクト要件に応じた調整もしやすくなります。

もちろん、これは「フルマネージドサービスを使うべきではない」という話ではありません。
**実際、最初に SageMaker Feature Store を試験運用した判断は非常に良かったと感じています。**AWS 上で稼働する NewsPicks のシステムと親和性が高く、少ない開発コストで特徴量ストアを素早く立ち上げることができましたし、抽象化された特徴量管理基盤として、多くの学びを得ることができました。
現在検討している自前 Feature Store の設計も、SageMaker Feature Store を通じて得た理解を強く反映しています。S3 上の Iceberg テーブルを用いたオフラインストア、DynamoDB を用いたオンラインストア、timestamp カラムを活用した歴史的特徴量の管理など、その多くは試験運用の経験があったからこそ自然に導かれた選択です。

## まとめ

本記事では、SageMaker Feature Store を約4ヶ月試験運用した経験をもとに、NewsPicksで特徴量ストアが真に価値を発揮するために重要だと感じた観点を整理しました。具体的には以下の4点です。

- (1) リアルタイム推論に必要な特徴量を低レイテンシーで提供できること
- (2) ストリーミング/マイクロバッチでの高頻度の読み書きに対応できること
- (3) 歴史的特徴量の backfill が容易であること
- (4) 日常的に使われている DWH / BI ツールからアクセスしやすいこと

これらはNewsPicksの文脈で特徴量ストアが価値を出すための前提条件であり、現在検討している自前 Feature Store 構築においても指針になっています。







