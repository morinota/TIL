# NewsPicksで価値を発揮する特徴量ストアに重要そうな観点たち ~SageMaker Feature Storeを4ヶ月試験運用した学びから見えてきたこと~

皆さんこんにちは! ソーシャル経済メディア「NewsPicks」プロダクトエンジニアの森田( [@moritama7431](https://twitter.com/moritama7431) )です:)
この記事は [NewsPicks アドベントカレンダー 2025](https://qiita.com/advent-calendar/2024/newspicks) の16日目の記事です。

---

さて本日は、ざっくり機械学習のプロダクトへの実応用や MLOps に関する内容です！
本記事は、

- **機械学習をプロダクトに本番導入している／これから導入したいソフトウェアエンジニア**  
- **特徴量ストア(Feature Store)の導入や運用に悩んでいる方**  

向けに、  
**NewsPicksで SageMaker Feature Store を4ヶ月間試験運用して得られた実運用の学び**を言語化して整理してみました:) 
もちろん皆さんのMLOps活動の参考になれば嬉しいですし、何か気になる点があればぜひお気軽にコメントやXで反応いただけたら喜びます！

## TL;DR

- hoge

## 背景: 特徴量って? 特徴量ストアって?? なんで必要になってるの??

### まず特徴量は、機械学習プロダクトの成否を左右する中心資産だ!

まず特徴量に関する話を少しまとめさせてください!
機械学習プロジェクトに関わったことがある方なら「特徴量」という言葉を聞いたことがあるかもしれません。
「特徴量(Feature)」とは、ある対象(entity, ex. ユーザ, 記事, etc.)の属性(property)を数値化したもので、機械学習モデルの入力情報として予測や意思決定に役立つデータのことを指します。
例えばNewsPicksプロダクト内での特徴量の例としては、以下のようなものがあります。

- entityがユーザの場合の特徴量: 年齢、性別、過去のニュース閲覧履歴, アクセス頻度, etc.
- entityが記事の場合の特徴量: 記事のカテゴリ, 公開日時, 著者情報, 閲読数, etc.

「そりゃそうだ!」と思われるかもですが、**機械学習モデルの予測や意思決定の性能は入力する特徴量に大きく依存**します。
入力情報を元に機械学習モデルが出力を計算する訳ですし...!

既存文献でも以下のように機械学習プロダクト・プロジェクトにおける特徴量の重要性が強調されています。

> Most of the problems you will face are, in fact, engineering problems. Even with all the resources of a great machine learning expert, most of the gains come from great features, not great machine learning algorithms.
> (あなたが直面するほとんどの問題は、実際にはエンジニアリングの問題です。優れた機械学習の専門家のすべてのリソースを持っていても、ほとんどの利益は優れた特徴量から得られ、優れた機械学習アルゴリズムからは得られません。)
> (ブログ記事「Rules of Machine Learning: Best Practices for ML Engineering」より引用)

> Not surprisingly, the most important thing is to have the right features.
> (驚くべきことではないが、最も重要なことは適切な特徴量を持つことです。)
> (論文「Facebook広告のCTR予測からの実践的な教訓」より引用)

つまりこのセクションでは、**まず特徴量が機械学習モデルの性能、ひいては機械学習プロダクト・プロジェクトの成否を左右する重要な中心資産なんだー！**ということを共有したかったのでした:)

### そして特徴量ストアは、プロダクション環境で特徴量を活用して価値を発揮する上で重要なコンポーネントだ!

さて前サブセクションで「特徴量は機械学習プロダクトの成否を左右する中心資産だ!」と述べましたが、“最初のPoC段階” では特徴量の運用はそこまで難しくありません。
主にDWHやdatalakeからデータを直接引っこ抜いて、 CSVやparquetファイルをこねくり回して、「学習用の特徴量できた！モデルも学習できた！性能評価もできた！Yes！」 という世界では、特徴量は全て開発者の手元にあり、再現性も整合性もほぼ問題になりません。
さらにPoCでは、特徴量の生成に何秒かかろうが、学習用に集計に数時間かかろうが全く困らないので、レイテンシ要件やスループット要件の懸念もありません。

PoC段階で特徴量生成 -> 学習 -> 推論の一連の流れを実装すると、例えば以下のような設計になるのではないでしょうか??
またPoCを超えて本番プロダクトにMLを組み込む段階でも、例えば日次や週次バッチで特徴量生成・学習・推論を一括で行えばOKなユースケースの場合は、この設計でも十分に運用可能だと思います。

![PoC時での特徴量生成 -> 学習 -> 推論の流れのイメージ図]()

---

しかし一方で、**プロダクション環境にMLを組み込んだ瞬間、特徴量運用の難易度は一気に跳ね上がります。**
実運用では、例えば次のような課題が出てきます。
