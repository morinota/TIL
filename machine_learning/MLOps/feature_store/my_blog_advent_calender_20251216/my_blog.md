# NewsPicksで真に価値を発揮する特徴量ストアに重要そうな観点たち ~SageMaker Feature Storeを4ヶ月試験運用した学びから見えてきたこと~

皆さんこんにちは! ソーシャル経済メディア「NewsPicks」プロダクトエンジニアの森田( [@moritama7431](https://twitter.com/moritama7431) )です:)
この記事は [NewsPicks アドベントカレンダー 2025](https://qiita.com/advent-calendar/2024/newspicks) の16日目の記事です。

---

さて本日は、ざっくり機械学習のプロダクトへの実応用や MLOps に関する内容です。

本記事は、  
- **機械学習をプロダクトに本番導入している／これから導入したいエンジニア**  
- **Feature Store の導入や運用に悩んでいる方**  

向けに、  
**NewsPicksで SageMaker Feature Store を4ヶ月間試験運用して得られた実運用の学び**を整理したものです。


## TL;DR

<!-- - **特徴量は ML プロダクトの価値を左右する中心資産**であり、
  本番運用では PoC 以上に扱いが難しくなる。
  その課題を抜本的に解決するために「Feature Store」という概念が重要。

- **NewsPicks でも Feature Store の必要性が急速に高まっていた。**  
  理由は大きく2つ：  
  ① 推薦モデルの高度化（context-aware化）が進み、扱う特徴量が多様化した  
  ② ML 活用者が増え、特徴量の共有・再利用の重要度が上がった

- **4ヶ月の試験運用を経て、NewsPicksで価値を発揮する Feature Store の核心となる観点は以下の4つだと分かった：**
  1. **歴史的特徴量の管理 & backfill が容易であること**  
  2. **ストリーミング／マイクロバッチ更新に現実的なコストで耐えられること**  
  3. **新しい特徴量の試行錯誤を高速・低コストで回せること**  
  4. **ML利用者がアクセスしやすく、特徴量が発見しやすいこと**

- **SageMaker Feature Store を4ヶ月試験運用した結果、NewsPicksのユースケースでは4観点を最適形で満たすのが難しい部分も見えてきた。**  
  特に backfill コスト、高頻度書き込みのコストに加え、  
  **フルマネージドサービス特有の“仕様理解・運用最適化にかかる開発者の学習コスト（認知負荷）”が大きかったため、**  
  現在は **S3×Iceberg（オフライン）＋DynamoDB（オンライン）を組み合わせた“自前 Feature Store”の運用へ移行する取り組みを進めている。**

- 結論として、Feature Store は  
  **「特徴量を保存する場所」ではなく、MLプロダクトの開発速度と品質を継続的に高めるための“基盤”である。** -->

## はじめに

## 背景: NewsPicksで機械学習の成果をスケールさせるために特徴量ストアが必要になってきた感がある

### まず特徴量は、機械学習プロダクトの成否を左右する中心資産だ!

まず「特徴量(Feature)」とは、ある対象(entity, ex. ユーザ, 記事, etc.)の属性(property)を数値化したもので、機械学習モデルの入力情報として予測や意思決定に役立つデータのことを指します。
例えばNewsPicksプロダクト内での特徴量の例としては、以下のようなものがあります。

- ユーザの特徴量: 年齢、性別、過去のニュース閲覧履歴, アクセス頻度, etc.
- 記事の特徴量: 記事のカテゴリ, 公開日時, 著者情報, 閲読数, etc.

機械学習モデルの性能は入力する特徴量に大きく依存します。
既存文献では以下のように機械学習プロダクト・プロジェクトにおける特徴量の重要性が強調されています。

> Most of the problems you will face are, in fact, engineering problems. Even with all the resources of a great machine learning expert, most of the gains come from great features, not great machine learning algorithms.
> (あなたが直面するほとんどの問題は、実際にはエンジニアリングの問題です。優れた機械学習の専門家のすべてのリソースを持っていても、ほとんどの利益は優れた特徴量から得られ、優れた機械学習アルゴリズムからは得られません。)
> (ブログ記事「Rules of Machine Learning: Best Practices for ML Engineering」より引用)

> Not surprisingly, the most important thing is to have the right features.
> (驚くべきことではないが、最も重要なことは適切な特徴量を持つことです。)
> (論文「Facebook広告のCTR予測からの実践的な教訓」より引用)

このサブセクションでとにかく主張したかったことは、特徴量が機械学習プロダクト・プロジェクトの成否を左右する中心資産であるということです。

### そして特徴量ストアは、プロダクション環境で特徴量を活用して価値を発揮する上で重要なコンポーネントだ!

さて前サブセクションで「特徴量は機械学習プロダクトの成否を左右する中心資産だ!」と述べましたが、“最初のPoC段階” では特徴量の運用はそこまで難しくありません。
主にDWHやdatalakeからデータを直接引っこ抜いて、 CSVやparquetファイルをこねくり回して、「学習用の特徴量できた！モデルも学習できた！性能評価もできた！Yes！」 という世界では、特徴量は全て開発者の手元にあり、再現性も整合性もほぼ問題になりません。
さらにPoCでは、特徴量の生成に何秒かかろうが、学習用に集計に数時間かかろうが全く困らないので、レイテンシ要件やスループット要件の懸念もありません。

![PoC時での特徴量生成 -> 学習 -> 推論の流れのイメージ図]()

またPoCを超えて本番プロダクトにMLを組み込む段階でも、例えば日次や週次バッチで特徴量生成・学習・推論を一括で行えばOKなユースケースの場合は、この設計・運用でも十分に運用可能だと思います。

しかし一方で、**プロダクション環境にMLを組み込んだ瞬間、特徴量運用の難易度は一気に跳ね上がります。**
実運用では、例えば次のような課題が出てきます。

- あれ、新規ユーザや新規アイテムを扱いたいからモデルの推論にリアルタイム性が求められるんだけど...
  - 特徴量ってレイテンシー要件を満たせる範囲でリアルタイムに作成できるんだっけ? :thinking:
  - モデルの学習時と推論時で、特徴量の生成ロジックって一貫してるっけ?? 一貫性を保証できるっけ?? :thinking:
  - 特徴量は事前計算しておくとしたら保存場所は?? datalakeやDWHだと低レイテンシでアクセスできないよね...でも学習とかの際はむしろ高スループットでアクセスしたいし...! :thinking:
  - リアルタイムアクセス用にキーバリューストア、バッチアクセス用にDWHとかdatalakeとか複数の保存場所を用意するとして、両者の一貫性の保証はどうやろう...!:thinking:
- 自社プロダクト内で機械学習やアルゴリズムを扱うユースケースもチームも増えてきたんだけど...
  - 同じような特徴量をユースケース毎に別々の生成ロジックで作って試行錯誤しちゃってない?? いい感じに共有できた方が改善のiteration早く回せそう...!:thinking:
  - リアルタイム推論のユースケース達がそれぞれ特徴量を事前計算してキャッシュする仕組みを持っちゃってるな、毎回キャッシュの仕組みを追加するのも開発コスト高いし、運用コスト・認知負荷も高くなってきた...!:thinking:
- 過去のユーザ行動などの歴史的特徴量が、推薦タスクなどでは効果的だから使いたいんだけど...
  - 学習時に未来の情報が漏洩(future data leak)しないように、歴史的特徴量についてある1時点の値を正しく再現できるようにしたいんだけど、どう管理したらいいんだっけ...!:thinking:

![PoC時のまま、本番プロダクトの機械学習モデルの運用を組み込んだイメージ図]()

上記のような特徴量周りの実運用のあれこれの課題解決の責務を担う役割として導入されるのが **特徴量ストア(Feature Store)** というコンポーネントです。
特徴量ストアは、例えば以下のような機能を提供することで上記の課題の解消を図ります。

- 特徴量生成と学習 & 推論を分離したアーキテクチャの提供
  - 特徴量生成ロジックを独立させることで、学習時と推論時で一貫性のある特徴量を提供できる。
  - 事前計算したリッチな特徴量をリアルタイム推論で活用できる。
- 低レイテンシー & 高スループットな特徴量アクセス基盤(オンラインストア & オフラインストア)の提供
  - リアルタイム推論に必要な特徴量を低レイテンシーで提供できる。
  - バッチ学習に必要な特徴量を高スループットで提供できる。
  - 両者の整合性の保証は特徴量ストアが担保する。
- 様々な種類の特徴量を一元管理
  - 特徴量の再利用がしやすくなる。
  - オフライン&オンラインストアを内包してる事で、高スループットのオフラインアクセス、低レイテンシーのオンラインアクセス両方に対応できる。
- 歴史的特徴量はtimestamp付きで管理
  - 過去のある1時点の特徴量を正しく再現し、学習時のデータリーク問題を防止できる。

![特徴量ストアありver.のアーキテクチャ(FTI Pipelines Architecture)]()

このサブセクションで伝えたかったメッセージは、**PoC は簡単。でも本番運用では特徴量が一気に“技術負債の塊”になる。その負債を抜本的に解消するための仕組みが Feature Store なんだ！**ということでした。

<!-- ### そしてNewsPicksでも特徴量ストアの必要性が高まってきた感がある!

ここまで一般的な課題を述べてきましたが、NewsPicksでもFeature Storeの必要性は明確に高まってきています。  
その主な理由は **2つ** です。

---

#### 1. 推薦まわりの高度化（context-aware化）が進んだため

これまでは協調フィルタリング → 内容ベースが中心で、特徴量の種類もそこまで多くありませんでした。
しかし最近は、よりユーザの文脈（context）を理解した推薦が求められています。

- 直近の閲覧履歴  
- 時間帯・デバイス情報  
- Pick傾向  
- 30日集計などの歴史的特徴量  
- リアルタイム行動の反映  

こうした **多種多様な特徴量** を扱う必要が出てきたことで、  
オフライン・オンライン双方で整合性を保ちながら管理する難度が一気に上がりました。

また、複雑な context-aware 推薦の運用ノウハウが社内に十分蓄積されていなかったため、  
まずは **マネージドなFeature Storeを実際に使って運用感覚を掴む** 必要もありました。

---

#### 2. ML活用者の増加で、特徴量の共有・再利用が重要になったため

ここ1年で、事業部向かいの **ストリームアラインドチーム** が  
MLによる機能改善や分析に積極的に取り組むようになりました。  
Claude Codeなどの登場で、ML活用のハードルが下がったことも大きいです。

その結果、

- チームごとに似た特徴量が量産される  
- 特徴量の意味・定義・責任者が分からない  
- どの特徴量を使えばいいか判断しづらい  

といった **再利用性・発見性（discoverability）の問題** が顕在化してきました。

---

このように、

- 推薦手法の高度化（＝特徴量の多様化・複雑化）  
- ML活用者の増加（＝特徴量の共有・再利用ニーズの増加）  

この2つが重なった結果、  
NewsPicksでも **Feature Storeという“特徴量運用の基盤”が必要なフェーズに入った** と感じています。

この前提があった上で、私たちは **SageMaker Feature Storeを4ヶ月試験運用** し、  
「NewsPicksにとって本当に必要なFeature Storeの観点」を整理しました。 
次の章でその4つの観点を紹介します。 -->

## 本論: NewsPicksで真に価値を発揮する特徴量ストアに重要そうな観点たち

ここからは、SageMaker Feature Store を約4ヶ月試験運用してみた経験をもとに、NewsPicksプロダクトの特徴量ストアが真に価値を発揮するために重要だと感じた観点を紹介します。

自社の特徴量ストアが満たすべき要件として、特に重要だと感じた観点は次の5つです。

1. リアルタイム推論に必要な特徴量を低レイテンシーで提供できること
2. ストリーミング/マイクロバッチ更新へのコスト効率と耐性があること
3. 歴史的特徴量の backfill が容易であること
4. 新しい特徴量の試行錯誤を高速・低コストで回せること
5. ML利用者がアクセスしやすく、特徴量が発見しやすいこと

以下で順に紹介していきます。

### その1: リアルタイム推論時に必要な特徴量を低レイテンシーで提供できること

- 書きたいこと
  - この観点は既知。試験運用の前から明らかではあった。
  - NewsPicksにおけるMLの主要なユースケースの1つが、推薦や検索などのコンテンツ編成・配信の最適化タスクであり、リアルタイム性が求められる場合が多い。
    - 理由は以下:
      - 1つ目: ニュースコンテンツのlifetimeが短いため、新着ニュースをなるべく興味がありそうなユーザに届けたい。
      - 2つ目: ユーザのあるニュースに対するポジティブなリアクションを、なるべく早く次の推薦に反映したい。
  - その点で、リアルタイム推論のユースケースが多いNewsPicksでは、特徴量ストアにオンラインストア機能が求められる。
  - 当たり前?って思われるかもだが、全てのプロダクトでオンラインストア機能が必要なわけでもないと思う。
    - 例えば映画などのlifetimeが長いアイテムを扱うプロダクトでは、新しいアイテムを即時に推薦する必要性が低く、日次バッチで推論を回すだけで十分かもしれない。Netflixのおすすめ機能では日次バッチで推論してると書いてあった。この場合、高スループットなアクセスができるオフラインストア機能だけで問題なさそう。
      - ただちなみに、アイテム側のlifetimeが長くても、ユーザ側の行動履歴などの特徴量をなるべく迅速に反映したい場合はバッチではなくリアルタイム推論が必要かも。その場合はオンラインストア機能が必要になることも全然ありそう。
    - また実際、現在の特徴量ストアのマネージドサービス達の全てがオンラインストア機能を備えているわけでもない。

### 1. 歴史的特徴量の　backfill が容易で現実的なコストで耐えられること

- ざっくり書きたいこと
  - NewsPicksでは推薦や検索などのコンテンツ編成・配信の最適化タスクが多い。
  - こういったタスクでは、ユーザの過去のリアクション履歴などの**歴史的特徴量(historical feature)の活用**が高い価値を発揮する。
  - なので特徴量ストアの要件として、歴史的特徴量をいい感じに管理・運用できることは重要。
    - 学習時のデータリーク(future data leak)を防ぐために、過去のある時点(tの時点)における特徴量の値を正しく再現できること、これはまあ当然必須。
  - そして歴史的特徴量をいい感じに活用する上で、試験運用を通して特に重要だと感じたのが backfill の容易さ だった。
    - backfill = ある時点 t における特徴量値を一括で再計算して保存すること。
    - モデルの性能を改善するために、新しい歴史的特徴量を追加したり、既存の歴史的特徴量の生成ロジックを変更したりする。
    - この際、学習データ期間の各時点 t における特徴量値を一括で再計算して保存する必要がある。
    - なので、特徴量生成パイプラインは状態を持たずに冪等性を持つべきだし、**特徴量ストアは backfill 時に大量の書き込みを効率的に行えることが重要**。
  - そしてこの観点が、Sagemaker Feature Storeを試験運用した際に、課題だった。
    - なぜなら、SageMaker Feature Storeにはオフラインストア限定の書き込みAPIが存在せずに、必ずオンライン/オフラインストア両方に書き込み処理が発生するため、backfill時に大量の書き込みを行う場合に高コストになりがちだった。
      - 歴史的特徴量のbackfillは、主に過去の古い期間の特徴量の値を再計算して保存する。一方でオンラインストアはリアルタイム推論用なので、過去の古い期間の特徴量値をオンラインストアに書き込む必要は基本的にない。
      - しかしSageMaker Feature Storeでは、backfill時にオンラインストアへの不要な書き込みが大量に発生(実際にはtimestampを見て現存レコードより新しいか判定され、古ければ更新はされない)し、高コストになりがちだった。(DynamoDBと同じくらいの書き込み料金がかかるイメージ)
      - この課題は、他ブログ記事でも言及されていた。
        - [Ingesting Historical Feature Data into SageMaker Feature Store](https://towardsdatascience.com/ingesting-historical-feature-data-into-sagemaker-feature-store-5618e41a11e6/)
      - この課題を回避するために、Sagemaker Feature Storeの公式の書き込みAPIを使わずに、オフラインストアのみに直接書き込みを行う処理を自前で実装する必要があった。
      - ただもちろんこの仕様自体のお気持ちは理解できる。この仕様にすることで、オンラインストアとオフラインストアの整合性・一貫性を強力に保証できるから。ただ歴史的特徴量を多用する我々の場合は、backfill時のコストが無視できないレベルで大きくなる可能性があった。
  - 歴史的特徴量の backfill は、MLモデルの性能改善のiterationを回す上で非常に重要な作業。
    - なのでもしbackfillが重い・高い・遅い特徴量ストアだと、気軽に特徴量の追加・ロジック変更ができず、試行錯誤のコストが高いため億劫になり、改善のiterationが滞るリスク。
    - 逆に、もしbackfillを迂闊にできない状況だと何が起こる?
      - 新しい歴史的特徴量を追加したり既存の歴史的特徴量のロジックを変更した時に、本番システムをリリースして特徴量ログを集め始めて学習データが十分に集まるのを待つ必要が出てきてしまう。
  - なので、特に歴史的特徴量を活用するMLユースケースが多いNewsPicksでは、backfillのしやすい特徴量ストアである事が重要な要件。

### 2. ストリーミング / マイクロバッチでの高頻度の読み書きに現実的なコストで耐えられること

- 書きたいこと
  - NewsPicksはニュース記事を扱うので、新規ニュースが常に入ってくる。
    - よって、新規ニュースが入ってきた時になるべく早く特徴量生成して、興味のあるユーザに届けたい。
    - また、ユーザのリアクション関連の特徴量も、なるべく少ないラグで更新して、パーソナライズフィード内に反映できるようにしたい意図もある。
  - 上記の経緯から、特徴量生成パイプラインをストリーミングやマイクロバッチで稼働させたいことも多い。
  - そのために、特徴量ストアが持つ特性として、高頻度の読み書きに対応できることが望ましい。
    - 例えば、並列での書き込みなどが苦手だったりすると困る。
    - また、ストリーミングで読み書きするとめっちゃ高額なコストがかかる...みたいな状況は避けたい。
  - ちなみにこの観点は、Sagemaker Feature Storeは要件を満たしていた。
    - オンラインストアはDynamoDBベースなので、高頻度の読み書きに強い。
    - オフラインストアはS3+Icebergベースなので、マイクロバッチでの書き込みも比較的安価にできる。
  - よって、常に新しいニュース記事が入ってくるNewsPicksにおいて、
    ストリーミング/マイクロバッチでの高頻度の読み書きに現実的なコストで耐えられることは重要な要件。

### 4. 開発組織内の機械学習やアルゴリズムを作る人たちが発見しやすく、アクセスしやすいこと

- ざっくり書きたいこと
  - 特徴量は、それを必要とする任意のチームがアクセスできる必要がある。
    - 既存文献でも、価値を発揮する特徴量ストアの重要な要件の1つとして、共有可能性が挙げられていた。
      - 参考: [5 Minimum Requirements of an Operational Feature Store](https://medium.com/data-for-ai/5-minimum-requirements-of-an-operational-feature-store-ab1436ca1a2c)
      - >Having a single repository of features that data scientists can search and reuse to help solve their problems is crucial to their productivity. (データサイエンティストが自分の問題を解決するために検索・再利用できる単一の特徴量リポジトリを持つことは、生産性にとって非常に重要です。)
      - >Easily searching through those features, whether that be through SQL or a dataframe-like API, is a must-have for data scientists to be successful. (SQLやデータフレームのようなAPIを通じて、それらの特徴量を簡単に検索できることは、データサイエンティストが成功するために必須です。)
  - Sagemaker Feature Storeを試験運用してどうだったか?
    - オフラインストアがS3+Icebergベースで AWS公式のSagemaker Python SDKではAthena経由でSQLクエリを投げられるようになってた。
    - しかしNewsPicksではDWH/BIツールとして主にmetabaseやsnowsight (Snowflake のweb UI) を使っているため、Athena経由でのアクセスはあまり親和性が高くなかった。
      - パッと、「このユーザってどんな特徴量持ってるんだっけ?」とか「この記事の特徴量ってどういう値になってるんだっけ?」とかを調べたい場合に、Athena経由でS3上のIcebergテーブルにアクセスするのはNewsPicksの開発メンバーにとってはあまり馴染みがなく、ハードルが高かった。Snowflake経由でクエリを投げてパッと確認できたらかなり嬉しい。
      - また、分析目的でsnowsight上のnotebookでTree系モデルを使って特徴量の重要度分析をしたい用途もあり、その点でもAthenaではなくSnowflake経由で特徴量にアクセスできることが望ましかった。
    - そのため、Sagemaker Feature Storeが作ったS3上のIcebergテーブルをSnowflakeの外部テーブルとしてマウントを試みたが連携に苦戦。
      - ちなみに具体的に苦戦した理由: Sagemaker側固有の仕様?が理由なのか、Icebergテーブルの初期化時に 0 byteのdata fileが生成されており。それがSnowflake側では0 byte fileの読み込みエラーを引き起こし、外部テーブルとして取り込めず。良い解消方法があるかもしれないがパッとわからず断念。
  - よって、NewsPicksで活用されてるDWH/BIツールから特徴量ストアにアクセスしやすいことは重要な要件だった (具体的にはSnowflake)

## 学びを踏まえて、今後の改善の話:

- 


### まとめ

4ヶ月の試験運用を経て、

1. **歴史的特徴量の管理 & backfill の容易さ**  
2. **ストリーミング/マイクロバッチ更新へのコスト効率と耐性**  
3. **新しい特徴量の試行錯誤を高速・低コストで回せること**  
4. **ML利用者がアクセスしやすく、発見しやすいこと**

この4点こそ、NewsPicksで Feature Store が“真に価値を発揮するための核心”だと感じています。

## 今後の取り組み: 自前Feature Storeへの移行を検討している理由

4ヶ月間の試験運用で、SageMaker Feature Store は「抽象化された特徴量管理基盤」として学びも多く、  
運用の勘所を掴む上ではとても有益でした。

一方で、NewsPicksのユースケースに照らしてみると  
**今回整理した4つの重要観点を“すべて”満たすのは難しい部分がある** ことも分かってきました。

特に以下の点は、自前で設計したほうが柔軟に最適化できると判断しています。

- **歴史的特徴量のbackfillが高コストになりがち**
  - オフラインストアへの大量書き込みに専用APIが無く、Icebergを直接操作する必要があった  
  - 「特徴量を増やすほど backfill コストが指数的に増える」構造は避けたい

- **ストリーミング/マイクロバッチでの高頻度書き込みが高コスト化しやすい**
  - サービス特性上 “書き込み回数が多い” ため、料金モデルとの相性がシビア

- **学習コストの高さ**
  - マイナーサービスゆえに仕様や挙動の理解に時間がかかる  
  - コスト最適化・高速化のためには結局“内部構造を深く理解してカスタム”する必要があった

こういった背景から、  
今後は **S3 × Iceberg（オフラインストア） + DynamoDB（オンラインストア）** を中心にした  
“自前 Feature Store” の構築を段階的に検討しています。

もちろん、フルマネージドがダメという話ではなくて、  
**「自社のユースケース・ワークロード・コスト構造を踏まえると、自前のほうがフィットする部分が大きく見えてきた」**  
というのが率直な結論です。

## おわりに

本記事では、SageMaker Feature Store を4ヶ月間試験運用した経験をもとに、  
NewsPicksで真に価値を発揮する Feature Store に重要だと感じた観点を整理しました。

まとめると、重要なのは次の4点でした。

1. **歴史的特徴量の管理 & backfill が容易であること**  
2. **ストリーミング/マイクロバッチ更新へのコスト効率と耐性**  
3. **新しい特徴量の試行錯誤を高速・低コストで回せること**  
4. **ML利用者がアクセスしやすく、特徴量が発見しやすいこと**

機械学習プロダクトの成否は、突き詰めると特徴量の良し悪しに大きく依存します。  
そして、その重要な特徴量を「できるだけ早く・安全に」本番プロダクト上で活用できる状態にすることが、  
機械学習で継続的に成果を出す上で欠かせないと感じています。
そのために、特徴量ストアという要素を改めて見つめ直し、  
特徴量を本番で使いやすくするための基盤にしっかり向き合うことには、  
十分な価値があると考えています。

もし同じような課題に取り組んでいる方がいれば、  
ぜひ気軽にコメント・議論してもらえると嬉しいです！



