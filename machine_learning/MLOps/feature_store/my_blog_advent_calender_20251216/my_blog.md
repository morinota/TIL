# NewsPicksで真に価値を発揮する特徴量ストアに重要そうな観点たち ~SageMaker Feature Storeを4ヶ月試験運用した学びから見えてきたこと~

皆さんこんにちは! ソーシャル経済メディア「NewsPicks」プロダクトエンジニアの森田( [@moritama7431](https://twitter.com/moritama7431) )です:)
この記事は [NewsPicks アドベントカレンダー 2025](https://qiita.com/advent-calendar/2024/newspicks) の16日目の記事です。

---

さて本日は、ざっくり機械学習のプロダクトへの実応用や MLOps に関する内容です！
本記事は、

- **機械学習をプロダクトに本番導入している／これから導入したいソフトウェアエンジニア**  
- **特徴量ストア(Feature Store)の導入や運用に悩んでいる方**  

向けに、  
**NewsPicksで SageMaker Feature Store を4ヶ月間試験運用して得られた実運用の学び**を言語化して整理してみました:) 
もちろん皆さんのMLOps活動の参考になれば嬉しいですし、何か気になる点があればぜひお気軽にコメントやXで反応いただけたら喜びます:)


## TL;DR

<!-- - **特徴量は ML プロダクトの価値を左右する中心資産**であり、
  本番運用では PoC 以上に扱いが難しくなる。
  その課題を抜本的に解決するために「Feature Store」という概念が重要。

- **NewsPicks でも Feature Store の必要性が急速に高まっていた。**  
  理由は大きく2つ：  
  ① 推薦モデルの高度化（context-aware化）が進み、扱う特徴量が多様化した  
  ② ML 活用者が増え、特徴量の共有・再利用の重要度が上がった

- **4ヶ月の試験運用を経て、NewsPicksで価値を発揮する Feature Store の核心となる観点は以下の4つだと分かった：**
  1. **歴史的特徴量の管理 & backfill が容易であること**  
  2. **ストリーミング／マイクロバッチ更新に現実的なコストで耐えられること**  
  3. **新しい特徴量の試行錯誤を高速・低コストで回せること**  
  4. **ML利用者がアクセスしやすく、特徴量が発見しやすいこと**

- **SageMaker Feature Store を4ヶ月試験運用した結果、NewsPicksのユースケースでは4観点を最適形で満たすのが難しい部分も見えてきた。**  
  特に backfill コスト、高頻度書き込みのコストに加え、  
  **フルマネージドサービス特有の“仕様理解・運用最適化にかかる開発者の学習コスト（認知負荷）”が大きかったため、**  
  現在は **S3×Iceberg（オフライン）＋DynamoDB（オンライン）を組み合わせた“自前 Feature Store”の運用へ移行する取り組みを進めている。**

- 結論として、Feature Store は  
  **「特徴量を保存する場所」ではなく、MLプロダクトの開発速度と品質を継続的に高めるための“基盤”である。** -->

## はじめに

## 背景: NewsPicksで機械学習の成果をスケールさせるために特徴量ストアが必要になってきた感がある

### まず特徴量は、機械学習プロダクトの成否を左右する中心資産だ!

まず「特徴量(Feature)」とは、ある対象(entity, ex. ユーザ, 記事, etc.)の属性(property)を数値化したもので、機械学習モデルの入力情報として予測や意思決定に役立つデータのことを指します。
例えばNewsPicksプロダクト内での特徴量の例としては、以下のようなものがあります。

- ユーザの特徴量: 年齢、性別、過去のニュース閲覧履歴, アクセス頻度, etc.
- 記事の特徴量: 記事のカテゴリ, 公開日時, 著者情報, 閲読数, etc.

機械学習モデルの性能は入力する特徴量に大きく依存します。
既存文献では以下のように機械学習プロダクト・プロジェクトにおける特徴量の重要性が強調されています。

> Most of the problems you will face are, in fact, engineering problems. Even with all the resources of a great machine learning expert, most of the gains come from great features, not great machine learning algorithms.
> (あなたが直面するほとんどの問題は、実際にはエンジニアリングの問題です。優れた機械学習の専門家のすべてのリソースを持っていても、ほとんどの利益は優れた特徴量から得られ、優れた機械学習アルゴリズムからは得られません。)
> (ブログ記事「Rules of Machine Learning: Best Practices for ML Engineering」より引用)

> Not surprisingly, the most important thing is to have the right features.
> (驚くべきことではないが、最も重要なことは適切な特徴量を持つことです。)
> (論文「Facebook広告のCTR予測からの実践的な教訓」より引用)

このサブセクションでとにかく主張したかったことは、特徴量が機械学習プロダクト・プロジェクトの成否を左右する中心資産であるということです。

### そして特徴量ストアは、プロダクション環境で特徴量を活用して価値を発揮する上で重要なコンポーネントだ!

さて前サブセクションで「特徴量は機械学習プロダクトの成否を左右する中心資産だ!」と述べましたが、“最初のPoC段階” では特徴量の運用はそこまで難しくありません。
主にDWHやdatalakeからデータを直接引っこ抜いて、 CSVやparquetファイルをこねくり回して、「学習用の特徴量できた！モデルも学習できた！性能評価もできた！Yes！」 という世界では、特徴量は全て開発者の手元にあり、再現性も整合性もほぼ問題になりません。
さらにPoCでは、特徴量の生成に何秒かかろうが、学習用に集計に数時間かかろうが全く困らないので、レイテンシ要件やスループット要件の懸念もありません。

![PoC時での特徴量生成 -> 学習 -> 推論の流れのイメージ図]()

またPoCを超えて本番プロダクトにMLを組み込む段階でも、例えば日次や週次バッチで特徴量生成・学習・推論を一括で行えばOKなユースケースの場合は、この設計・運用でも十分に運用可能だと思います。

しかし一方で、**プロダクション環境にMLを組み込んだ瞬間、特徴量運用の難易度は一気に跳ね上がります。**
実運用では、例えば次のような課題が出てきます。

- あれ、新規ユーザや新規アイテムを扱いたいからモデルの推論にリアルタイム性が求められるんだけど...
  - 特徴量ってレイテンシー要件を満たせる範囲でリアルタイムに作成できるんだっけ? :thinking:
  - モデルの学習時と推論時で、特徴量の生成ロジックって一貫してるっけ?? 一貫性を保証できるっけ?? :thinking:
  - 特徴量は事前計算しておくとしたら保存場所は?? datalakeやDWHだと低レイテンシでアクセスできないよね...でも学習とかの際はむしろ高スループットでアクセスしたいし...! :thinking:
  - リアルタイムアクセス用にキーバリューストア、バッチアクセス用にDWHとかdatalakeとか複数の保存場所を用意するとして、両者の一貫性の保証はどうやろう...!:thinking:
- 自社プロダクト内で機械学習やアルゴリズムを扱うユースケースもチームも増えてきたんだけど...
  - 同じような特徴量をユースケース毎に別々の生成ロジックで作って試行錯誤しちゃってない?? いい感じに共有できた方が改善のiteration早く回せそう...!:thinking:
  - リアルタイム推論のユースケース達がそれぞれ特徴量を事前計算してキャッシュする仕組みを持っちゃってるな、毎回キャッシュの仕組みを追加するのも開発コスト高いし、運用コスト・認知負荷も高くなってきた...!:thinking:
- 過去のユーザ行動などの歴史的特徴量が、推薦タスクなどでは効果的だから使いたいんだけど...
  - 学習時に未来の情報が漏洩(future data leak)しないように、歴史的特徴量についてある1時点の値を正しく再現できるようにしたいんだけど、どう管理したらいいんだっけ...!:thinking:

![PoC時のまま、本番プロダクトの機械学習モデルの運用を組み込んだイメージ図]()

上記のような特徴量周りの実運用のあれこれの課題解決の責務を担う役割として導入されるのが **特徴量ストア(Feature Store)** というコンポーネントです。
特徴量ストアは、例えば以下のような機能を提供することで上記の課題の解消を図ります。

- 特徴量生成と学習 & 推論を分離したアーキテクチャの提供
  - 特徴量生成ロジックを独立させることで、学習時と推論時で一貫性のある特徴量を提供できる。
  - 事前計算したリッチな特徴量をリアルタイム推論で活用できる。
- 低レイテンシー & 高スループットな特徴量アクセス基盤(オンラインストア & オフラインストア)の提供
  - リアルタイム推論に必要な特徴量を低レイテンシーで提供できる。
  - バッチ学習に必要な特徴量を高スループットで提供できる。
  - 両者の整合性の保証は特徴量ストアが担保する。
- 様々な種類の特徴量を一元管理
  - 特徴量の再利用がしやすくなる。
  - オフライン&オンラインストアを内包してる事で、高スループットのオフラインアクセス、低レイテンシーのオンラインアクセス両方に対応できる。
- 歴史的特徴量はtimestamp付きで管理
  - 過去のある1時点の特徴量を正しく再現し、学習時のデータリーク問題を防止できる。

![特徴量ストアありver.のアーキテクチャ(FTI Pipelines Architecture)]()

このサブセクションで伝えたかったメッセージは、**PoC は簡単。でも本番運用では特徴量が一気に“技術負債の塊”になる。その負債を抜本的に解消するための仕組みが Feature Store なんだ！**ということでした。

<!-- ### そしてNewsPicksでも特徴量ストアの必要性が高まってきた感がある!

ここまで一般的な課題を述べてきましたが、NewsPicksでもFeature Storeの必要性は明確に高まってきています。  
その主な理由は **2つ** です。

---

#### 1. 推薦まわりの高度化（context-aware化）が進んだため

これまでは協調フィルタリング → 内容ベースが中心で、特徴量の種類もそこまで多くありませんでした。
しかし最近は、よりユーザの文脈（context）を理解した推薦が求められています。

- 直近の閲覧履歴  
- 時間帯・デバイス情報  
- Pick傾向  
- 30日集計などの歴史的特徴量  
- リアルタイム行動の反映  

こうした **多種多様な特徴量** を扱う必要が出てきたことで、  
オフライン・オンライン双方で整合性を保ちながら管理する難度が一気に上がりました。

また、複雑な context-aware 推薦の運用ノウハウが社内に十分蓄積されていなかったため、  
まずは **マネージドなFeature Storeを実際に使って運用感覚を掴む** 必要もありました。

---

#### 2. ML活用者の増加で、特徴量の共有・再利用が重要になったため

ここ1年で、事業部向かいの **ストリームアラインドチーム** が  
MLによる機能改善や分析に積極的に取り組むようになりました。  
Claude Codeなどの登場で、ML活用のハードルが下がったことも大きいです。

その結果、

- チームごとに似た特徴量が量産される  
- 特徴量の意味・定義・責任者が分からない  
- どの特徴量を使えばいいか判断しづらい  

といった **再利用性・発見性（discoverability）の問題** が顕在化してきました。

---

このように、

- 推薦手法の高度化（＝特徴量の多様化・複雑化）  
- ML活用者の増加（＝特徴量の共有・再利用ニーズの増加）  

この2つが重なった結果、  
NewsPicksでも **Feature Storeという“特徴量運用の基盤”が必要なフェーズに入った** と感じています。

この前提があった上で、私たちは **SageMaker Feature Storeを4ヶ月試験運用** し、  
「NewsPicksにとって本当に必要なFeature Storeの観点」を整理しました。 
次の章でその4つの観点を紹介します。 -->

## 本論: NewsPicksで真に価値を発揮する特徴量ストアに重要そうな観点たち

ここからは、SageMaker Feature Store を約4ヶ月試験運用してみた経験をもとに、NewsPicksプロダクトの特徴量ストアが真に価値を発揮するために重要だと感じた観点を紹介します。

自社の特徴量ストアが満たすべき要件として、特に重要だと感じた観点は次の4つです。

1. リアルタイム推論に必要な特徴量を低レイテンシーで提供できること
2. ストリーミング/マイクロバッチ更新へのコスト効率と耐性があること
3. 歴史的特徴量の backfill が容易であること
4. ML利用者がアクセスしやすく、特徴量が発見しやすいこと

以下で順に紹介していきます。

### その1: リアルタイム推論時に必要な特徴量を低レイテンシーで提供できること

<!-- - 書きたいこと
  - この観点は既知。試験運用の前から明らかではあった。
  - NewsPicksにおけるMLの主要なユースケースの1つが、推薦や検索などのコンテンツ編成・配信の最適化タスクであり、リアルタイム性が求められる場合が多い。
    - 理由は以下:
      - 1つ目: ニュースコンテンツのlifetimeが短いため、新着ニュースをなるべく興味がありそうなユーザに届けたい。
      - 2つ目: ユーザのあるニュースに対するポジティブなリアクションを、なるべく早く次の推薦に反映したい。
  - その点で、リアルタイム推論のユースケースが多いNewsPicksでは、特徴量ストアにオンラインストア機能が求められる。
  - 当たり前?って思われるかもだが、全てのプロダクトでオンラインストア機能が必要なわけでもないと思う。
    - 例えば映画などのlifetimeが長いアイテムを扱うプロダクトでは、新しいアイテムを即時に推薦する必要性が低く、日次バッチで推論を回すだけで十分かもしれない。Netflixのおすすめ機能では日次バッチで推論してると書いてあった。この場合、高スループットなアクセスができるオフラインストア機能だけで問題なさそう。
      - ただちなみに、アイテム側のlifetimeが長くても、ユーザ側の行動履歴などの特徴量をなるべく迅速に反映したい場合はバッチではなくリアルタイム推論が必要かも。その場合はオンラインストア機能が必要になることも全然ありそう。
    - また実際、現在の特徴量ストアのマネージドサービス達の全てがオンラインストア機能を備えているわけでもない。 -->

<!-- 以下、本文 -->

この観点については SageMaker Feature Store の試験運用を始める前から「必須だよね」という認識はありました (でも重要観点として一応挙げさせてください)。
というのも、NewsPicksにおける機械学習の主要なユースケースの1つが、**ニュース推薦や検索といったコンテンツの編成・配信を最適化するタスクであり、ここではリアルタイム性が重視される場面が多いため**です。
ニュースはlifetimeが短く、新着ニュースを適切なユーザーに素早く届けられるかが体験の質を左右します。また、ユーザの行動も高速に変化するため、その反応を即座に次の推薦へ反映できることが重要です。

こうした背景から、リアルタイム推論のユースケースが多いNewsPicksでは、低レイテンシで特徴量を取得できるオンラインストア機能が、特徴量ストアに強く求められます。
一見すると当たり前の要件に見えるかもしれませんが、**すべてのプロダクトにとってオンラインストア機能が必須というわけではない**、という点は意識しておく必要があります。
実際、現在ベンダー各社から提供されているフルマネージドな特徴量ストアの中にも、オンラインストア機能を前提としていない、あるいはオフライン中心の設計を採用しているものも存在します。

例えば、映画やドラマのようにアイテムのlifetimeが比較的長いプロダクトでは、新しいアイテムを即時に推薦に反映する必要性はそこまで高くありません。実際、Netflixの推薦システムでは日次バッチで推論を行っているという話もあり、このようなケースでは高スループットなオフラインストア機能だけで十分に成立することもあります。
ただちなみに、アイテムのlifetimeが長い場合でも、ユーザの行動履歴や嗜好の変化を素早く反映したい場合には、リアルタイム推論が求められることもあります。その場合は、やはりオンラインストア機能が必要になる可能性は高いでしょう。

というわけで、リアルタイム推論への対応はプロダクト特性に依存する要件ですが、少なくともNewsPicksの文脈においては、オンラインで低レイテンシーに特徴量を提供できることは、特徴量ストアが価値を発揮するための前提条件の1つだと感じています。

### 2. 歴史的特徴量の　backfill が容易で現実的なコストで耐えられること

<!-- - ざっくり書きたいこと
  - NewsPicksでは推薦や検索などのコンテンツ編成・配信の最適化タスクが多い。
  - こういったタスクでは、ユーザの過去のリアクション履歴などの**歴史的特徴量(historical feature)の活用**が高い価値を発揮する。
  - なので特徴量ストアの要件として、歴史的特徴量をいい感じに管理・運用できることは重要。
    - 学習時のデータリーク(future data leak)を防ぐために、過去のある時点(tの時点)における特徴量の値を正しく再現できること、これはまあ当然必須。
  - そして歴史的特徴量をいい感じに活用する上で、試験運用を通して特に重要だと感じたのが backfill の容易さ だった。
    - backfill = ある時点 t における特徴量値を一括で再計算して保存すること。
    - モデルの性能を改善するために、新しい歴史的特徴量を追加したり、既存の歴史的特徴量の生成ロジックを変更したりする。
    - この際、学習データ期間の各時点 t における特徴量値を一括で再計算して保存する必要がある。
    - なので、特徴量生成パイプラインは状態を持たずに冪等性を持つべきだし、**特徴量ストアは backfill 時に大量の書き込みを効率的に行えることが重要**。
  - そしてこの観点が、Sagemaker Feature Storeを試験運用した際に、課題だった。
    - なぜなら、SageMaker Feature Storeにはオフラインストア限定の書き込みAPIが存在せずに、必ずオンライン/オフラインストア両方に書き込み処理が発生するため、backfill時に大量の書き込みを行う場合に高コストになりがちだった。
      - 歴史的特徴量のbackfillは、主に過去の古い期間の特徴量の値を再計算して保存する。一方でオンラインストアはリアルタイム推論用なので、過去の古い期間の特徴量値をオンラインストアに書き込む必要は基本的にない。
      - しかしSageMaker Feature Storeでは、backfill時にオンラインストアへの不要な書き込みが大量に発生(実際にはtimestampを見て現存レコードより新しいか判定され、古ければ更新はされない)し、高コストになりがちだった。(DynamoDBと同じくらいの書き込み料金がかかるイメージ)
      - この課題は、他ブログ記事でも言及されていた。
        - [Ingesting Historical Feature Data into SageMaker Feature Store](https://towardsdatascience.com/ingesting-historical-feature-data-into-sagemaker-feature-store-5618e41a11e6/)
      - この課題を回避するために、Sagemaker Feature Storeの公式の書き込みAPIを使わずに、オフラインストアのみに直接書き込みを行う処理を自前で実装する必要があった。
      - ただもちろんこの仕様自体のお気持ちは理解できる。この仕様にすることで、オンラインストアとオフラインストアの整合性・一貫性を強力に保証できるから。ただ歴史的特徴量を多用する我々の場合は、backfill時のコストが無視できないレベルで大きくなる可能性があった。
  - 歴史的特徴量の backfill は、MLモデルの性能改善のiterationを回す上で非常に重要な作業。
    - なのでもしbackfillが重い・高い・遅い特徴量ストアだと、気軽に特徴量の追加・ロジック変更ができず、試行錯誤のコストが高いため億劫になり、改善のiterationが滞るリスク。
    - 逆に、もしbackfillを迂闊にできない状況だと何が起こる?
      - 新しい歴史的特徴量を追加したり既存の歴史的特徴量のロジックを変更した時に、本番システムをリリースして特徴量ログを集め始めて学習データが十分に集まるのを待つ必要が出てきてしまう。
  - なので、特に歴史的特徴量を活用するMLユースケースが多いNewsPicksでは、backfillのしやすい特徴量ストアである事が重要な要件。 -->

<!-- 以下、本文 -->

「その1」で述べた通り、NewsPicksでは推薦や検索といったコンテンツ編成・配信の最適化タスクが多く、こうしたユースケースでは**ユーザの過去のリアクション履歴などの歴史的特徴量（historical feature）**が非常に高い価値を発揮します。そのため、特徴量ストアがこれらの歴史的特徴量を適切に管理・運用できることは、重要な要件の1つです。

もちろん、学習時の future data leak を防ぐために、過去のある時点 $t$ における特徴量の値を正しく再現できることは前提条件です。しかし、試験運用を通してそれ以上に重要だと感じたのが、**歴史的特徴量の backfill をどれだけ容易に行えるか**という点でした。

ここでいう 「歴史的特徴量のbackfill」とは、過去のある時点 $t$ における特徴量値を、特定の期間全体にわたって再計算し、保存し直す作業を指します。モデル性能を改善する過程では、**新しい歴史的特徴量を追加したり、既存の特徴量の生成ロジックを変更したりすること**が頻繁に発生します。そのたびに、過去の各時点における特徴量値を再計算して学習データを作り直す必要があります。

このため、特徴量生成パイプラインは状態を持たず、冪等性を保った設計であることが望ましく、同時に特徴量ストア側も backfill 時に大量の書き込みを効率よく処理できることが求められます。

![]()

一方で、この観点は SageMaker Feature Store を試験運用する中で、明確な課題として浮き彫りになりました。
SageMaker Feature Store には、オフラインストアのみに書き込む公式な API が存在せず、書き込み時には必ずオンライン・オフライン両方への処理が発生します。そのため、過去の古い期間を対象とする歴史的特徴量の backfill であっても、**リアルタイム推論用に最新の特徴量を保持するためのオンラインストアに対して書き込みリクエストが発生**してしまいます。
しかし、これらのデータは学習用途でのみ利用されるものであり、オンラインストアに保存する必要は本来ありません。
実際には、タイムスタンプを見て現存レコードより古い場合は更新されないものの、書き込みリクエスト自体は発生するため、結果として DynamoDB 相当の不要な書き込みコストが積み重なりやすい構造になっていました。

この課題は既存のブログ記事でも指摘されており、この課題を回避するためには、公式の書き込み API を使わず、オフラインストアに直接書き込む処理を自前で実装する必要がありました。
もちろん、この仕様によってオンラインストアとオフラインストアの整合性・一貫性が強く保証されている点は非常に理解できます。ただ、歴史的特徴量を多用するNewsPicksのユースケースでは、backfill 時のコストが無視できないレベルになる可能性がありました。

歴史的特徴量の backfill は、MLモデルの性能改善におけるイテレーションを回す上で欠かせない作業です。もし backfill が重く、高コストで、時間もかかる仕組みだと、特徴量の追加やロジック変更を気軽に試せなくなり、結果として改善のスピードが落ちてしまいます。
仮にbackfillができない場合どうなるかというと、新しい特徴量を導入するたびに本番リリース後のログ蓄積を待つ必要があり、学習データが揃うまで何週間も改善を止めざるを得ない、という状況にもなりかねません。

こうした理由から、特に歴史的特徴量を活用するMLユースケースが多いNewsPicksにおいては、**backfill が容易で、かつ現実的なコストで耐えられる特徴量ストアであること**が、非常に重要な要件だと感じています。

### 3. ストリーミング / マイクロバッチでの高頻度の読み書きに現実的なコストで耐えられること

<!-- - 書きたいこと
  - NewsPicksはニュース記事を扱うので、新規ニュースが常に入ってくる。
    - よって、新規ニュースが入ってきた時になるべく早く特徴量生成して、興味のあるユーザに届けたい。
    - また、ユーザのリアクション関連の特徴量も、なるべく少ないラグで更新して、パーソナライズフィード内に反映できるようにしたい意図もある。
  - 上記の経緯から、特徴量生成パイプラインをストリーミングやマイクロバッチで稼働させたいことも多い。
  - そのために、特徴量ストアが持つ特性として、高頻度の読み書きに対応できることが望ましい。
    - 例えば、並列での書き込みなどが苦手だったりすると困る。
    - また、ストリーミングで読み書きするとめっちゃ高額なコストがかかる...みたいな状況は避けたい。
  - ちなみにこの観点は、Sagemaker Feature Storeは要件を満たしていた。
    - オンラインストアはDynamoDBベースなので、高頻度の読み書きに強い。
    - オフラインストアはS3+Icebergベースなので、マイクロバッチでの書き込みも比較的安価にできる。
  - よって、常に新しいニュース記事が入ってくるNewsPicksにおいて、
    ストリーミング/マイクロバッチでの高頻度の読み書きに現実的なコストで耐えられることは重要な要件。 -->

<!-- 以下、本文 -->

NewsPicksはニュース記事を扱うプロダクトであるため、新しいコンテンツが継続的に流入します。そのため、新規ニュースが公開されたタイミングでできるだけ早く特徴量を生成し、興味を持ちそうなユーザに届けたいという要求が自然に生まれます。加えて、クリックや閲覧といったユーザのリアクションに基づく特徴量も、なるべく小さなラグで更新し、パーソナライズされたフィードに反映したいという意図があります。

こうした背景から、**特徴量生成パイプラインは日次バッチだけでなく、ストリーミングやマイクロバッチで稼働させたいケース**が多くなります。その結果、**特徴量ストア側にも高頻度な読み書きに耐えられる特性**が求められます。
具体的には、並列書き込みに弱かったり、アクセスが集中した際にレイテンシが大きく悪化したりする仕組みでは運用が難しくなります。また、ストリーミング処理を行うだけでコストが急激に膨らんでしまうような設計も厳しいです。

この観点においては、SageMaker Feature Store は要件を比較的よく満たしていました。オンラインストアは DynamoDB をベースとしており、高頻度な読み書きや並列アクセスに強い設計になっています。また、オフラインストアは S3 + Iceberg をベースとしてるためコストを抑えつつ柔軟に運用することが可能でした。

常に新しいニュース記事が流入し、ユーザの行動も継続的に発生するNewsPicksのようなプロダクトにおいては、**ストリーミング / マイクロバッチでの高頻度な読み書きを、現実的なコストで継続できること**が、特徴量ストアが本番で価値を発揮するための重要な要件だと感じています。

### 4. 開発組織内の機械学習やアルゴリズムを作る人たちが発見しやすく、アクセスしやすいこと

<!-- - ざっくり書きたいこと
  - 特徴量は、それを必要とする任意のチームがアクセスできる必要がある。
    - 既存文献でも、価値を発揮する特徴量ストアの重要な要件の1つとして、共有可能性が挙げられていた。
      - 参考: [5 Minimum Requirements of an Operational Feature Store](https://medium.com/data-for-ai/5-minimum-requirements-of-an-operational-feature-store-ab1436ca1a2c)
      - >Having a single repository of features that data scientists can search and reuse to help solve their problems is crucial to their productivity. (データサイエンティストが自分の問題を解決するために検索・再利用できる単一の特徴量リポジトリを持つことは、生産性にとって非常に重要です。)
      - >Easily searching through those features, whether that be through SQL or a dataframe-like API, is a must-have for data scientists to be successful. (SQLやデータフレームのようなAPIを通じて、それらの特徴量を簡単に検索できることは、データサイエンティストが成功するために必須です。)
  - Sagemaker Feature Storeを試験運用してどうだったか?
    - オフラインストアがS3+Icebergベースで AWS公式のSagemaker Python SDKではAthena経由でSQLクエリを投げられるようになってた。
    - しかしNewsPicksではDWH/BIツールとして主にmetabaseやsnowsight (Snowflake のweb UI) を使っているため、Athena経由でのアクセスはあまり親和性が高くなかった。
      - パッと、「このユーザってどんな特徴量持ってるんだっけ?」とか「この記事の特徴量ってどういう値になってるんだっけ?」とかを調べたい場合に、Athena経由でS3上のIcebergテーブルにアクセスするのはNewsPicksの開発メンバーにとってはあまり馴染みがなく、ハードルが高かった。Snowflake経由でクエリを投げてパッと確認できたらかなり嬉しい。
      - また、分析目的でsnowsight上のnotebookでTree系モデルを使って特徴量の重要度分析をしたい用途もあり、その点でもAthenaではなくSnowflake経由で特徴量にアクセスできることが望ましかった。
    - そのため、Sagemaker Feature Storeが作ったS3上のIcebergテーブルをSnowflakeの外部テーブルとしてマウントを試みたが連携に苦戦。
      - ちなみに具体的に苦戦した理由: Sagemaker側固有の仕様?が理由なのか、Icebergテーブルの初期化時に 0 byteのdata fileが生成されており。それがSnowflake側では0 byte fileの読み込みエラーを引き起こし、外部テーブルとして取り込めず。良い解消方法があるかもしれないがパッとわからず断念。
  - よって、NewsPicksで活用されてるDWH/BIツールから特徴量ストアにアクセスしやすいことは重要な要件だった (具体的にはSnowflake) -->

<!-- 以下、本文 -->

特徴量は、それを必要とする任意のチームが容易にアクセスできる必要があります。
既存の文献でも、**価値を発揮する特徴量ストアの重要な要件の1つとして、共有可能性（discoverability）**が挙げられています。

> Having a single repository of features that data scientists can search and reuse to help solve their problems is crucial to their productivity.  
> (データサイエンティストが自分の問題を解決するために検索・再利用できる単一の特徴量リポジトリを持つことは、生産性にとって非常に重要です。)
> Easily searching through those features, whether that be through SQL or a dataframe-like API, is a must-have for data scientists to be successful.
> (SQLやデータフレームのようなAPIを通じて、それらの特徴量を簡単に検索できることは、データサイエンティストが成功するために必須です。)
> ([5 Minimum Requirements of an Operational Feature Store](https://medium.com/data-for-ai/5-minimum-requirements-of-an-operational-feature-store-ab1436ca1a2c) より引用)

この観点で SageMaker Feature Store を試験運用してみると、NewsPicksの開発組織のワークフローとは必ずしも噛み合っていない部分が見えてきました。
SageMaker Feature Store のオフラインストアは S3 + Iceberg をベースとしており、AWS公式の SageMaker Python SDK を使えば、Athena 経由で SQL クエリを投げて特徴量にアクセスできます。

しかし、NewsPicksでは日常的なデータ分析や調査に、Metabase や Snowflake（Snowsight）といった DWH / BI ツールを主に利用しています。そのため、ちょっとした確認のために Athena を経由して S3 上の Iceberg テーブルにクエリを投げる、という体験は、開発メンバーにとってあまり馴染みがあるものではありませんでした。
例えば、「このユーザはどんな特徴量を持っているんだっけ?」とか「この記事の特徴量はどういう値になってるんだっけ?」といった疑問をパッと調べたい場合に、Snowflake 経由でクエリを投げて確認できれば非常に楽なのですが、Athena経由だとハードルがかなり高い訳です。

また、分析用途として Snowsight 上の notebook で Tree 系モデルを使い、特徴量の重要度分析を行いたい、といったユースケースもありました。この点でも、Athena ではなく Snowflake 経由で特徴量にアクセスできることが望ましい状況でした。

そこで、SageMaker Feature Store が生成する S3 上の Iceberg テーブルを、Snowflake の外部テーブルとしてマウントすることも試みましたが、連携には苦戦しました。
具体的には、Sagemaker側でのIceberg テーブルの初期化時に生成される 0 byte の data file が Snowflake 側で読み込みエラーを引き起こし、外部テーブルとして取り込めないという問題に直面しました。当時は明確な解決策が見つからず連携を断念したのでした。

こうした経験から、**NewsPicksで日常的に使われている DWH / BI ツールから、特徴量ストアに自然にアクセスできること**は、想像以上に重要な要件だと感じています。
技術的に正しく設計されていても、特徴量が「見つけにくい」「触りにくい」状態では再利用は進まず、結果として特徴量ストアの価値も十分に引き出せません。NewsPicksの文脈では、特に Snowflake を中心とした分析体験と親和性の高い形で特徴量にアクセスできることが、重要なポイントでした。

## 学びを踏まえて、今後の改善の話:
<!-- 
- フルマネージドサービスではなく、AWSのメジャーなサービス(S3, DynamoDB等)を組み合わせた自前Feature Storeに移行を考えている。
- 理由: フルマネージドサービスを採用するメリットよりも、自前の方が自社プロダクトの要件に柔軟に最適化できる & 学習コストが低いメリットの方が大きいと判断したため。
  - SageMaker Feature Storeでは、前述の要件を満たすのが難しい点がいくつかあった。
    - 課題1: backfillしやすさ -> 大量の読み書きが高コスト(なぜならオフラインストア限定の書き込みAPIが存在しないから)。回避策としてオフラインストアのみに直接書き込む自前実装が必要になり、フルマネージドサービスの恩恵が薄れる。
    - 課題2: 発見しやすさ! アクセスしやすさ!
        - DWHやBIツールとの連携 -> AWS公式のSagemaker Python SDKはAthena経由APIを提供してるが、NPではあまりAthenaを使ってないので親和性が低め。
        - NPのDWHはSnowflakeでBIツールもsnowsightなどを使ってるため、開発者たちがSnowflake経由でパッと特徴量を参照したり分析したりできる仕組みが望ましい。しかし、Sagemaker Feature StoreはSnowflakeとの連携しづらさがあった。
          - Icebergテーブルの連携に苦戦、ここを解決しようと思うと、結局内部実装を細かく理解する必要が出てきて、フルマネージドサービスの恩恵が薄れる。
  - 一方で、フルマネージドサービスゆえの学習コストの高さもあった。
    - SageMaker Feature Storeはどうしてもまだマイナーサービスなので、仕様や挙動の理解に時間がかかる。
    - 自社用途に合わせたコスト最適化・高速化のためには、結局“内部構造を深く理解してカスタム”する必要があり...。
  - これらを踏まえて、S3 × Iceberg（オフラインストア） + DynamoDB（オンラインストア）を中心にした自前Feature Storeの構築を段階的に検討している。
    - データストアの実体は、S3テーブルバケット上のIcebergテーブル, DynamoDBというAWSのメジャーなサービスを使うので、開発メンバーの学習コストも低めに抑えられる。
    - また、前述の要件も満たしやすい。
  - もちろん、フルマネージドサービスがダメという話ではなくて、自社のユースケース・ワークロード・コスト構造を踏まえると自前で実装した方がメリットが大きそう、という話。
    - 最初にSageMaker Feature Storeを試験運用したのは良い判断だった。
      - NPの多くのサービスはAWS上で稼働してるので親和性高い。少ない開発コストで高速に導入できる。
      - 抽象化された特徴量管理基盤として学びも多く、運用の勘所を掴む上でかなり有益だった。
      - 実際、自前Feature Storeの設計は、かなりSageMaker Feature Storeの理解を踏まえている (S3のIcebergテーブルベースのオフラインストア, DynamoDBベースのオンラインストア, timestampカラムを用いた歴史的特徴量の管理, etc.) -->

<!-- 以下、本文 -->

これまでの試験運用を踏まえ、現在はフルマネージドな特徴量ストアをそのまま使い続けるのではなく、**AWSのメジャーなサービスを組み合わせた自前の Feature Store へ段階的に移行することを検討しています。**
具体的には、オフラインストアとして S3テーブルバケット × Icebergテーブル形式、オンラインストアとして DynamoDB を中心に据えた構成です。

この判断に至った背景には、フルマネージドサービスを採用するメリットと、自前で構築するメリットを比較した結果、**今のNewsPicksの文脈では後者の方が柔軟性と学習コストの面で有利だと判断したため**です。

Sagemaker Feature Store を試験運用する中で、前述したいくつかの重要要件を満たすのが難しい場面がありました。
特に、歴史的特徴量の backfill に関しては、オフラインストアのみに書き込む公式 API が存在しないため、大量の読み書きが発生する backfill 処理が高コストになりがちでした。これを回避するには、結局オフラインストアへ直接書き込む処理を自前で実装する必要があり、フルマネージドサービスとしての恩恵が薄れてしまいます。

また、特徴量の発見しやすさ・アクセスしやすさという観点でも課題がありました。
AWS公式の SageMaker Python SDK は Athena 経由でのアクセスを前提としていましたが、NewsPicksでは Snowflake を中心に DWH / BI ツールを構成しており、日常的な分析フローとの親和性は高くありませんでした。S3 上の Iceberg テーブルを Snowflake から直接参照することも試みましたが、Iceberg テーブルの内部仕様に起因する問題に直面し、スムーズな連携には至りませんでした。こうした点を解消しようとすると、結果的に内部実装を深く理解し、細かくカスタマイズする必要が出てきます。この点でもフルマネージドサービスの恩恵が薄れる感がありました。

さらに、**フルマネージドサービスゆえの学習コスト**の高さも無視できませんでした。
SageMaker Feature Store は比較的新しいサービスであり、仕様や挙動を正しく理解するまでに一定の時間がかかります。加えて、自社のワークロードに合わせたコスト最適化やパフォーマンス改善を行おうとすると、抽象化の内側を理解する必要があり、その点でも自前実装との差が縮まっていく印象を受けました。

こうした学びを踏まえ、S3 × Iceberg と DynamoDB といった、**NewsPicks開発組織にとって馴染みのある AWS の基盤サービスを組み合わせた Feature Store** を構築することで、学習コストを抑えつつ、これまで挙げてきた要件をより素直に満たせるのではないかと考えています。データストアの実体が明確である分、コスト構造や挙動も把握しやすく、プロダクト要件に応じた調整もしやすくなります。

もちろん、これは「フルマネージドサービスを使うべきではない」という話ではありません。
実際、最初に SageMaker Feature Store を試験運用した判断は非常に良かったと感じています。AWS 上で稼働する NewsPicks のシステムと親和性が高く、少ない開発コストで特徴量ストアを素早く立ち上げることができましたし、抽象化された特徴量管理基盤として、多くの学びを得ることができました。
現在検討している自前 Feature Store の設計も、SageMaker Feature Store を通じて得た理解を強く反映しています。S3 上の Iceberg テーブルを用いたオフラインストア、DynamoDB を用いたオンラインストア、timestamp カラムを活用した歴史的特徴量の管理など、その多くは試験運用の経験があったからこそ自然に導かれた選択です。

## おわりに

- ざっくり書きたいこと
  - 本記事の内容の振り返り:
    - SageMaker Feature Store を4ヶ月間試験運用した経験をもとに、NewsPicksで真に価値を発揮する特徴量ストアに重要だと感じた観点を整理しました。
    - 重要な観点は次の4点:
      - リアルタイム推論に対応できること
      - 歴史的特徴量の backfill が容易で現実的なコストで耐えられること
      - ストリーミング / マイクロバッチでの高頻度の読み書きに現実的なコストで耐えられること
      - NewsPicksで日常的に使われている DWH / BI ツールからアクセスしやすいこと
    - これらの観点は、NewsPicksで特徴量ストアが真に価値を発揮するための前提条件であり、今後の自前Feature Store構築の指針にもなっている。
  - 改めて...
    - 特徴量は、機械学習プロダクト・プロジェクトの成否を左右する重要な中心資産である。
    - 特徴量ストアは、プロダクション環境で特徴量運用の課題を解決し、特徴量の価値を最大化するための重要なコンポーネントである。
  - MLシステムのプラットフォーム基盤への投資について個人的な見解
    - [既存文献](https://multithreaded.stitchfix.com/blog/2019/03/11/FullStackDS-Generalists/) では、データサイエンスプロジェクトの成功にはフルスタックなデータサイエンスゼネラリストが自律的に改善のiterationを回せる環境が重要と主張されてる。そして同時にこれらの人材の活躍は、作業するための堅牢で適度に抽象化されたデータプラットフォームの前提に大きく依存してる。
    - 特にNewsPicksでは、近年事業部向かいの開発メンバーもデータサイエンスゼネラリスト的にMLの活用に取り組むケースが増えてきている。
    - Rules of Machine Learningでも、MLプロジェクトで直面する問題の多くはエンジニアリングの問題であり、優れた特徴量の重要性や堅牢なデータパイプラインの優先度の高さが強調されている。
    - なので、MLシステムのプラットフォーム基盤への投資は価値貢献のために重要であり、一定のリソースを割いて取り組むべきだと考えている。
      - もちろん自分も、MLプラットフォームの改善だけじゃなくて、一部でフルスタックデータサイエンティスト的な役割を発揮することも。バランスとりながら貢献できるように頑張りたい。

