# NewsPicksで真に価値を発揮する特徴量ストアに重要そうな観点たち ~SageMaker Feature Storeを4ヶ月試験運用した学びから見えてきたこと~

皆さんこんにちは! ソーシャル経済メディア「NewsPicks」プロダクトエンジニアの森田( [@moritama7431](https://twitter.com/moritama7431) )です:)
この記事は [NewsPicks アドベントカレンダー 2025](https://qiita.com/advent-calendar/2024/newspicks) の16日目の記事です。

---

さて本日の記事は、ざっくり機械学習のプロダクトへの実応用やMLOpsに関する内容です。

## TL;DR

- hoge

## はじめに

## 背景: NewsPicksで機械学習の成果をスケールさせるために特徴量ストアが必要になってきた感がある

### まず特徴量は、機械学習プロダクトの成否を左右する中心資産だ!

まず「特徴量(Feature)」とは、ある対象(entity, ex. ユーザ, 記事, etc.)の属性(property)を数値化したもので、機械学習モデルの入力情報として予測や意思決定に役立つデータのことを指します。
例えばNewsPicksプロダクト内での特徴量の例としては、以下のようなものがあります。

- ユーザの特徴量: 年齢、性別、過去のニュース閲覧履歴, アクセス頻度, etc.
- 記事の特徴量: 記事のカテゴリ, 公開日時, 著者情報, 閲読数, etc.

機械学習モデルの性能は入力する特徴量に大きく依存します。
既存文献では以下のように機械学習プロダクト・プロジェクトにおける特徴量の重要性が強調されています。

> Most of the problems you will face are, in fact, engineering problems. Even with all the resources of a great machine learning expert, most of the gains come from great features, not great machine learning algorithms.
> (あなたが直面するほとんどの問題は、実際にはエンジニアリングの問題です。優れた機械学習の専門家のすべてのリソースを持っていても、ほとんどの利益は優れた特徴量から得られ、優れた機械学習アルゴリズムからは得られません。)
> (ブログ記事「Rules of Machine Learning: Best Practices for ML Engineering」より引用)

また、Facebookの広告CTR予測に関する論文でも以下のように述べられています。

> Not surprisingly, the most important thing is to have the right features.
> (驚くべきことではないが、最も重要なことは適切な特徴量を持つことです。)
> (論文「Facebook広告のCTR予測からの実践的な教訓」より引用)

このサブセクションでとにかく主張したかったことは、特徴量が機械学習プロダクト・プロジェクトの成否を左右する中心資産であるということです。

### そして特徴量ストアは、プロダクション環境で特徴量を扱う上で重要な役割のコンポーネントだ!

さて前サブセクションで「特徴量は機械学習プロダクトの成否を左右する中心資産だ!」と述べましたが、“最初のPoC段階” では特徴量の運用はそこまで難しくありません。
主にDWHやdatalakeからデータを直接引っこ抜いて、  CSVをこねくり回して、「学習用の特徴量できた〜！モデルも学習できた〜！やった〜！」 という世界では、特徴量は全て開発者の手元にあり、再現性も整合性もほぼ問題になりません。
さらにPoCでは、特徴量の生成に何秒かかろうが、学習用に集計に数時間かかろうが全く困らないので、**レイテンシー要件も存在しません。**

![PoC時での特徴量生成 -> 学習 -> 推論の流れのイメージ図]()

しかし一方で、**プロダクション環境にMLを組み込んだ瞬間、特徴量運用の難易度は一気に跳ね上がります。**
実運用では、例えば次のような問題が出てきます。

- 学習時と推論時で特徴量の作り方がズレる（training–serving skew）
- 過去時点の特徴量の値を再現できず、誤って未来情報を学習に使ってしまう(future data leak)
- リアルタイム推論時に、特徴量生成・取得にかかる時間が長すぎてレイテンシー要件を満たせない。
- プロジェクトやユースケースごとに特徴量が乱立し、定義がサイロ化したり重複する
- 特徴量の意味・型・責任者・更新ロジックが分からず、誰も再利用できない

![PoC時のまま、本番プロダクトの機械学習モデルの運用を組み込んだイメージ図]()

こういった“特徴量まわりの開発・運用コスト”が積み重なると、MLプロダクトはなかなかスケールしません。
こういった特徴量周りの実運用の課題を解決する役割を担うのが「特徴量ストア(Feature Store)」というコンポーネントです。
特徴量ストアは、以下のような機能を提供することで、上記の課題の解消を図ります。

- 特徴量生成と学習&推論を分離したアーキテクチャの提供
  - 学習時と推論時は共に特徴量ストアから特徴量を取得するため一貫性を保てる。
  - リアルタイム推論時に、事前計算した特徴量を低レイテンシー提供できる。
- 様々な種類の特徴量を一元管理
  - 特徴量の再利用がしやすくなる。
  - オフライン&オンラインストアを内包してる事で、高スループットのオフラインアクセス、低レイテンシーのオンラインアクセス両方に対応できる。
- timestamp付きで特徴量の履歴を管理する。
  - 過去時点の特徴量を再現でき、未来情報の漏洩を防止できる。

このサブセクションで伝えたかったメッセージは、**PoC は簡単。でも本番運用では特徴量が一気に“技術負債の塊”になる。その負債を抜本的に解消するための仕組みが Feature Store なんだ！**ということでした。

### そしてNewsPicksでも特徴量ストアの必要性が高まってきた感がある!

ここまで一般的な課題を述べてきましたが、NewsPicksでもFeature Storeの必要性は明確に高まってきています。  
その主な理由は **2つ** です。

---

#### 1. 推薦まわりの高度化（context-aware化）が進んだため

これまでは協調フィルタリング → 内容ベースが中心で、特徴量の種類もそこまで多くありませんでした。  
しかし最近は、よりユーザの文脈（context）を理解した推薦が求められています。

- 直近の閲覧履歴  
- 時間帯・デバイス情報  
- Pick傾向  
- 30日集計などの歴史的特徴量  
- リアルタイム行動の反映  

こうした **多種多様な特徴量** を扱う必要が出てきたことで、  
オフライン・オンライン双方で整合性を保ちながら管理する難度が一気に上がりました。

また、複雑な context-aware 推薦の運用ノウハウが社内に十分蓄積されていなかったため、  
まずは **マネージドなFeature Storeを実際に使って運用感覚を掴む** 必要もありました。

---

#### 2. ML活用者の増加で、特徴量の共有・再利用が重要になったため

ここ1年で、事業部向かいの **ストリームアラインドチーム** が  
MLによる機能改善や分析に積極的に取り組むようになりました。  
Claude Codeなどの登場で、ML活用のハードルが下がったことも大きいです。

その結果、

- チームごとに似た特徴量が量産される  
- 特徴量の意味・定義・責任者が分からない  
- どの特徴量を使えばいいか判断しづらい  

といった **再利用性・発見性（discoverability）の問題** が顕在化してきました。

---

このように、

- 推薦手法の高度化（＝特徴量の多様化・複雑化）  
- ML活用者の増加（＝特徴量の共有・再利用ニーズの増加）  

この2つが重なった結果、  
NewsPicksでも **Feature Storeという“特徴量運用の基盤”が必要なフェーズに入った** と感じています。

この前提があった上で、私たちは **SageMaker Feature Storeを4ヶ月試験運用** し、  
「NewsPicksにとって本当に必要なFeature Storeの観点」を整理しました。 
次の章でその4つの観点を紹介します。

## 本論: NewsPicksで真に価値を発揮するFeature Storeに重要そうな観点たち

ここからは、SageMaker Feature Store を約4ヶ月試験運用してみた経験をもとに  
「NewsPicksで本当に価値を発揮するFeature Storeとは何か？」  
という問いに対する、現時点の4つの結論を最初に共有しておきます。

**NewsPicksで価値を発揮するFeature Storeにとって特に重要だと感じた観点は次の4つです。**

1. **歴史的特徴量の管理 & backfill が容易であること**  
2. **ストリーミング/マイクロバッチ更新へのコスト効率と耐性があること**  
3. **新しい特徴量の試行錯誤を高速・低コストで回せること**  
4. **ML利用者がアクセスしやすく、特徴量が発見しやすいこと**

以下では、この4観点それぞれについて、  
実際の運用で感じた背景・理由・課題・学びを深掘りしていきます。

---

### 1. 歴史的特徴量の管理や backfill が容易であること

NewsPicksでは、推薦や配信最適化などのユースケースで  
**過去のある時点の特徴量（historical features）** を頻繁に扱います。

- 例: 「過去30日の閲読数」「直近のPick傾向」「カテゴリ別行動量」
- 過去値を正しく管理しないと **future data leak** が起きる

そのため Feature Store には、

- 特徴量を timestamp 付きで管理できる  
- “時点 t の特徴量” を正しく再現できる  
- 特徴量の追加・ロジック変更時に **大量の backfill を安全・高速に実行できる**

といった要件が必須でした。

backfill が重い・高い・遅い Feature Store は、長期運用でほぼ詰みます。

---

### 2. ストリーミング / マイクロバッチで高頻度の読み書きに現実的なコストで耐えられること

NewsPicksはニュースアプリなので、

- 常に新しい記事が入ってくる  
- ユーザ行動（閲覧・Pick・コメント）がリアルタイムで発生する  

この特性上、特徴量パイプラインは **ストリーミング or マイクロバッチ（1〜5分）** が基本になります。

そこで重要なのが、

- Feature Storeが高頻度の書き込みを処理できる
- コストが爆増しない
- オンライン推論に必要な値を低レイテンシで返せる

という“実運用で耐えられる性能”です。

ストリーミング読み書きが高額になったり、  
スループットが詰まる設計だと、サービス特性上かなり厳しいです。

---

### 3. 新しい特徴量の試行錯誤を安く・高速に回せること

MLシステム開発では、  
**新しい特徴量を作って試す → モデル性能を検証する**  
という探索サイクルが本当に大事です。

そのため Feature Store は、

- オフラインでの特徴量読み書きが高速・低コスト
- backfill が簡単（＝特徴量ロジックを気軽に変えられる）
- 「まずはオフラインだけで使う → 性能が良ければオンライン化」
  といった柔軟なワークフローを許容する

といった “試行錯誤のしやすさ” が重要でした。

探索・改善を高速で回せることが、  
結局モデル性能の向上に直結します。

---

### 4. MLを使う人たちからアクセスしやすく、発見しやすいこと（Discoverability）

ここ1年で ML 活用者が増えたことで、  
**“特徴量を組織的に管理する必要性”** が一気に高まりました。

- 特徴量の意味・型・責任者が分からない  
- 似た特徴量が別チームで量産される  
- 特徴量は存在するのに誰も気づかない  
- DWH/BIツールからアクセスしづらい

こういった課題を解消するため、Feature Storeには

- 特徴量のカタログ機能（説明・schema・責任者）  
- 再利用性の高い構造  
- DWH/BIツールとの親和性  
- オフラインは高スループット、オンラインは低レイテンシ

など、**“MLを使う人たちが気持ちよくアクセスできる仕組み”** が必要でした。

---

### まとめ

4ヶ月の試験運用を経て、

1. **歴史的特徴量の管理 & backfill の容易さ**  
2. **ストリーミング/マイクロバッチ更新へのコスト効率と耐性**  
3. **新しい特徴量の試行錯誤を高速・低コストで回せること**  
4. **ML利用者がアクセスしやすく、発見しやすいこと**

この4点こそ、NewsPicksで Feature Store が“真に価値を発揮するための核心”だと感じています。

## 今後の取り組み: 自前Feature Storeへの移行を検討している理由

4ヶ月間の試験運用で、SageMaker Feature Store は「抽象化された特徴量管理基盤」として学びも多く、  
運用の勘所を掴む上ではとても有益でした。

一方で、NewsPicksのユースケースに照らしてみると  
**今回整理した4つの重要観点を“すべて”満たすのは難しい部分がある** ことも分かってきました。

特に以下の点は、自前で設計したほうが柔軟に最適化できると判断しています。

- **歴史的特徴量のbackfillが高コストになりがち**
  - オフラインストアへの大量書き込みに専用APIが無く、Icebergを直接操作する必要があった  
  - 「特徴量を増やすほど backfill コストが指数的に増える」構造は避けたい

- **ストリーミング/マイクロバッチでの高頻度書き込みが高コスト化しやすい**
  - サービス特性上 “書き込み回数が多い” ため、料金モデルとの相性がシビア

- **学習コストの高さ**
  - マイナーサービスゆえに仕様や挙動の理解に時間がかかる  
  - コスト最適化・高速化のためには結局“内部構造を深く理解してカスタム”する必要があった

こういった背景から、  
今後は **S3 × Iceberg（オフラインストア） + DynamoDB（オンラインストア）** を中心にした  
“自前 Feature Store” の構築を段階的に検討しています。

もちろん、フルマネージドがダメという話ではなくて、  
**「自社のユースケース・ワークロード・コスト構造を踏まえると、自前のほうがフィットする部分が大きく見えてきた」**  
というのが率直な結論です。

## おわりに

本記事では、  
4ヶ月間のSageMaker Feature Store試験運用で得られた知見をもとに、  
「NewsPicksで本当に価値を発揮するFeature Storeの条件とは？」  
というテーマで考察してきました。

まとめると、重要なのは次の4点でした。

1. **歴史的特徴量の管理 & backfill が容易であること**  
2. **ストリーミング/マイクロバッチ更新へのコスト効率と耐性**  
3. **新しい特徴量の試行錯誤を高速・低コストで回せること**  
4. **ML利用者がアクセスしやすく、特徴量が発見しやすいこと**

これらは単なる“機能要件”ではなく、  
**NewsPicksがMLプロダクトの価値を継続的に高めていくために欠かせない土台**  
だと強く感じています。

Feature Store の設計は、  
「単にデータを保存して返す」技術ではなく、  
**組織全体の ML 開発体験（DX）を底上げする基盤づくり** そのものだと思っています。

今後は自前 Feature Store 構築に向けて、  
実験・検証・プロトタイピングを繰り返しながら、  
さらに良い形を探っていこうと思います。

もし同じような課題に取り組んでいる方がいれば、  
ぜひ気軽にコメント・議論してもらえると嬉しいです！



