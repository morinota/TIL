# NewsPicksで真に価値を発揮する特徴量ストアに重要そうな観点たち ~SageMaker Feature Storeを4ヶ月試験運用した学びから見えてきたこと~

皆さんこんにちは! ソーシャル経済メディア「NewsPicks」プロダクトエンジニアの森田( [@moritama7431](https://twitter.com/moritama7431) )です:)
この記事は [NewsPicks アドベントカレンダー 2025](https://qiita.com/advent-calendar/2024/newspicks) の16日目の記事です。

---

さて本日の記事は、ざっくり機械学習のプロダクトへの実応用やMLOpsに関する内容です。

## TL;DR

- hoge

## はじめに

## 背景: NewsPicksで機械学習の成果をスケールさせるために特徴量ストアが必要になってきた感がある

### まず特徴量は、機械学習プロダクトの成否を左右する中心資産だ!

まず「特徴量(Feature)」とは、ある対象(entity, ex. ユーザ, 記事, etc.)の属性(property)を数値化したもので、機械学習モデルの入力情報として予測や意思決定に役立つデータのことを指します。
例えばNewsPicksプロダクト内での特徴量の例としては、以下のようなものがあります。

- ユーザの特徴量: 年齢、性別、過去のニュース閲覧履歴, アクセス頻度, etc.
- 記事の特徴量: 記事のカテゴリ, 公開日時, 著者情報, 閲読数, etc.

機械学習モデルの性能は入力する特徴量に大きく依存します。
既存文献では以下のように機械学習プロダクト・プロジェクトにおける特徴量の重要性が強調されています。

> Most of the problems you will face are, in fact, engineering problems. Even with all the resources of a great machine learning expert, most of the gains come from great features, not great machine learning algorithms.
> (あなたが直面するほとんどの問題は、実際にはエンジニアリングの問題です。優れた機械学習の専門家のすべてのリソースを持っていても、ほとんどの利益は優れた特徴量から得られ、優れた機械学習アルゴリズムからは得られません。)
> (ブログ記事「Rules of Machine Learning: Best Practices for ML Engineering」より引用)

また、Facebookの広告CTR予測に関する論文でも以下のように述べられています。

> Not surprisingly, the most important thing is to have the right features.
> (驚くべきことではないが、最も重要なことは適切な特徴量を持つことです。)
> (論文「Facebook広告のCTR予測からの実践的な教訓」より引用)

このサブセクションでとにかく主張したかったことは、特徴量が機械学習プロダクト・プロジェクトの成否を左右する中心資産であるということです。

### そして特徴量ストアは、プロダクション環境で特徴量を扱う上で重要な役割のコンポーネントだ!

さて前サブセクションで「特徴量は機械学習プロダクトの成否を左右する中心資産だ!」と述べましたが、“最初のPoC段階” では特徴量の運用はそこまで難しくありません。
主にDWHやdatalakeからデータを直接引っこ抜いて、  CSVをこねくり回して、「学習用の特徴量できた〜！モデルも学習できた〜！やった〜！」 という世界では、特徴量は全て開発者の手元にあり、再現性も整合性もほぼ問題になりません。
さらにPoCでは、特徴量の生成に何秒かかろうが、学習用に集計に数時間かかろうが全く困らないので、**レイテンシー要件も存在しません。**

![PoC時での特徴量生成 -> 学習 -> 推論の流れのイメージ図]()

しかし一方で、**プロダクション環境にMLを組み込んだ瞬間、特徴量運用の難易度は一気に跳ね上がります。**
実運用では、例えば次のような問題が出てきます。

- 学習時と推論時で特徴量の作り方がズレる（training–serving skew）
- 過去時点の特徴量の値を再現できず、誤って未来情報を学習に使ってしまう(future data leak)
- リアルタイム推論時に、特徴量生成・取得にかかる時間が長すぎてレイテンシー要件を満たせない。
- プロジェクトやユースケースごとに特徴量が乱立し、定義がサイロ化したり重複する
- 特徴量の意味・型・責任者・更新ロジックが分からず、誰も再利用できない

![PoC時のまま、本番プロダクトの機械学習モデルの運用を組み込んだイメージ図]()

こういった“特徴量まわりの開発・運用コスト”が積み重なると、MLプロダクトはなかなかスケールしません。
こういった特徴量周りの実運用の課題を解決する役割を担うのが「特徴量ストア(Feature Store)」というコンポーネントです。
特徴量ストアは、以下のような機能を提供することで、上記の課題の解消を図ります。

- 特徴量生成と学習&推論を分離したアーキテクチャの提供
  - 学習時と推論時は共に特徴量ストアから特徴量を取得するため一貫性を保てる。
  - リアルタイム推論時に、事前計算した特徴量を低レイテンシー提供できる。
- 様々な種類の特徴量を一元管理
  - 特徴量の再利用がしやすくなる。
  - オフライン&オンラインストアを内包してる事で、高スループットのオフラインアクセス、低レイテンシーのオンラインアクセス両方に対応できる。
- timestamp付きで特徴量の履歴を管理する。
  - 過去時点の特徴量を再現でき、未来情報の漏洩を防止できる。

このサブセクションで伝えたかったメッセージは、**PoC は簡単。でも本番運用では特徴量が一気に“技術負債の塊”になる。その負債を抜本的に解消するための仕組みが Feature Store なんだ！**ということでした。

### そしてNewsPicksでも特徴量ストアの必要性が高まってきた感がある!




## 本論: NewsPicksで真に価値を発揮するFeature Storeに重要そうな観点たち

## おわりに: 今後の展望とまとめ
