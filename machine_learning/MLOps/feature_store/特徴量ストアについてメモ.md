## これは何?

- 特徴量ストア(feature store) について調査したものです。

## refs:

- 自前でfeature storeを実装した事例: [WantedlyでFeature Storeを導入する際に考えたこと](https://speakerdeck.com/zerebom/wantedlydefeature-storewodao-ru-suruji-nikao-etakoto?slide=42)
- neptuneの特徴量ストアのブログ:
- [5 Minimum Requirements of an Operational Feature Store](https://medium.com/data-for-ai/5-minimum-requirements-of-an-operational-feature-store-ab1436ca1a2c)
- [Feature Store: The Definitive Guide 2025年ver.](https://www.hopsworks.ai/dictionary/feature-store)

# メモ

- Feature Storeとは？
  - MLモデルのライフサイクル全体にわたり特徴量を管理するデータプラットフォーム
- 構成要素：
  - `Feature repository`：バージョン管理された特徴量を保存
  - `Feature serving layer`：学習・推論時にリアルタイムで特徴を提供
  - `Metadata store`：特徴量の由来・変換履歴などのメタ情報を保持
- Feature Storeを使う利点
  - モデルのトレーニング・推論で**同じ特徴を再利用可能**
  - 過去時点の特徴値を再現できる（Point-in-time consistency）
  - リアルタイム/バッチ/ストリーム処理のMLすべてに対応可能
  - オンライン推論で使う特徴が、学習時と一致する保証ができる

## OperationalなFeature Storeに必要な5つの最低条件

### Shareableであること

- フィーチャーは**チーム間・プロジェクト間で再利用可能**であるべき
- データサイエンティストが新しいプロジェクトのたびに同じ特徴量を再構築する必要がなくなる
- 例：ユーザーの過去7日間のクリック数をカウントする特徴量を何度も定義し直すのは非効率
- 「Feature repo + documentation + discoverability」が大事


# Feature Store決定版ガイド2025年ver.を読んだメモ

## 特徴量とは? なんで専用の保存場所が必要?

- 特徴量(feature)とは
  - ある対象(entity)の属性(property)を数値化したもので、かつ機械学習モデルの予測に役立つもの。
  - 特徴量は、MLモデルの学習や、バッチMLシステムおよびオンラインMLシステムでの推論に使用される。
  - 特徴量は、必要なときにその場で計算することも、事前に計算して後で学習や推論に使用することもできる。
- なんで専用のストアが必要なの?
  - 特徴量を保存することの利点の一部は、それらが簡単に発見され、異なるモデルで再利用しやすい状況を作れること。
    - それにより、新しいMLシステムを構築するために必要なコストと時間を削減できること。
  - リアルタイム推論の場合に、事前に計算しておいたリッチな特徴量を提供できること。
    - オンラインモデルはlocal stateを持たない傾向があるらしい。
      - (これってどういう意味だろう。local stateを持たない傾向、って部分。perplexityに聞いてみた感じ、各ユーザやリクエストの履歴・状態をモデル本体やサーバーのメモリ内に溜め込まず、**「今来たリクエスト」に含まれる情報だけをそのまま使う傾向がある**、みたいな意味合いっぽい...!:thinking:)

## 特徴量ストアとMLOps、MLシステムとの関連

- MLOpsプラットフォームにおける特徴量ストアは、**異なるMLパイプラインを結びつけて完全なMLシステムを作る接着剤の役割**を持つ
  - Feature Pipelineは、特徴量を計算し、特徴量(およびlabel/target)を特徴量ストアに書き込む。
  - Training Pipelineは、特徴量ストアから特徴量(およびlabel/target)を読み込み、MLモデルを学習する(学習されたモデルはmodel registryに書き込まれる)。
  - Inference Pipelineは、特徴量ストアから事前計算された特徴量を読み込み、推論を行う。
  - (メモ: 上記の内容って、思いっきりFTI Pipelines architectureの思想! 特徴量ストアを採用すること = FTI Pipelines Architectureを採用すること、と言って良さそう...!:thinking:)
- MLOpsの主な目標 = モデル試行錯誤のiteractionを短縮し、モデルのパフォーマンスを向上させ、ML資産（特徴、モデル）のガバナンスを確保し、コラボレーションを改善すること。
  - (ちなみに「MLOps処方箋本」のMLOpsの定義は「MLの成果をスケールさせるための取り組み」な訳だけど、上記を改善することがMLの成果のスケールに繋がるから、って解釈できそう...!:thinking:)
  - 特徴量ストアを採用すること(i.e. FTI Pipelines Architectureを採用すること)によって、この目標の達成につながるよ〜みたいな話。

## 特徴量ストアはどのような問題を解決するのか??

- 特徴量ストアはざっくり、どんな時の課題を解決する?
  - (1) モデルを本番環境にデプロイする際の課題
  - (2) デプロイするモデルの数をスケールする際の課題
  - (3) MLチームの規模を拡大する際の課題

特徴量ストアが解決する課題10個:

- 解決1: MLシステムのcollaborativeな開発!
- 解決2: 特徴量データのincrementalな管理(本番MLシステムにおける特徴量は、一回作って終わりじゃなくて、incrementalに変化していくものなので...!)
- 解決3: 特徴量のbackfillingと学習データのbackfilling (これは、特徴量ストアは特徴量をevent_timeと一緒に管理するから実現できるよね、って話かな...?:thinking:)
- 解決4: リアルタイム推論サービスに、「今来たリクエスト」に含まれる情報以外に、事前計算した特徴量を提供できる! (これは前述してたlocal stateを持たない傾向、みたいな話!)
- 解決5: 特徴量の再利用がしやすくなる! (これは一元管理してるから??:thinking:)
- 解決6: バッチ/ストリーミング/リクエスト時計算など、特徴量に求められる鮮度に基づくいろんな計算パターンに対応させやすい(全て特徴量ストアを経由するようになるから?? :thinking:)
- 解決7: 特徴量データのvalidationやドリフト監視がしやすくなる! (これも一元管理してるから??:thinking:)
- 解決8: 学習時と推論時の特徴量の計算方法のズレ(data skew)を防げる!
- 解決9: point-in-time consistency (時点整合性) を持つ学習データを作りやすくなる! (これは特徴量ストアがevent_timeを元に特徴量を管理するから!:thinking:)
- 解決10: リアルタイム推論時に、事前計算した特徴量を低レイテンシーで提供できる。(これはオンラインストアを含む特徴量ストアの話! 非対応のものもある印象...! :thinking:)
- 解決11: 埋め込みベクトルを使用して、similarity searchを行うこともできる! (これは特徴量ストアがベクトルデータをサポートしてる場合! similarity search機能はサポートしてない場合も全然ありそう! :thinking:)

状況別の特徴量ストアの役立ちポイントまとめ:

- バッチMLシステムの本番稼働シナリオ
  - incrementalな特徴量の管理
  - 特徴量のvalidation
  - 学習時と推論時のdata skewの防止
  - point-in-time consistencyを持つ学習データの作成
- リアルタイムMLシステムの本番稼働シナリオ
  - (上記に加えて...)
  - リアルタム推論サービスに、事前計算した特徴量を提供
  - オンラインストアによる低レイテンシーな特徴量の提供
  - 埋め込みベクトルを使用したsimilarity search
  - 特徴量のストリーミング計算やオンデマンド計算への対応
    - (オンデマンド計算した特徴量は、リアルタイム推論の後で特徴量ストアに書き込むのかな...!:thinking:)
- 大規模なML展開シナリオ:
  - (上記に加えて...)
  - チーム間コラボの促進
  - 特徴量の再利用の促進

### 解決ポイント1: Collaborative Development (MLシステムのcollaborativeな開発!)

- 特徴量ストアがcollaborativeな開発をどう支えるか??
  - 1点目: チームごと・開発者ごとの役割分担を可能にする。
    - Feature Storeがあることで(i.e. FTI Pipelines Architectureであることで)、MLシステムの構築・運用をパイプライン単位に分解できるようになる。
    - ex.)
      - Feature Pipeline: データエンジニア・データサイエンティスト
      - Training Pipeline: データサイエンティスト
      - Inference Pipeline: ソフトウェアエンジニア、MLOpsエンジニア
    - これによって、
      - 各種パイプラインでやるべきことが明確化される
      - Feature Storeをハブにして各パイプラインが独立して開発・運用できる
    - したがって、特徴量ストアが整っていれば、チーム間・チーム内でスムーズに役割分担・連携しやすい！ 
      - (メモ: **特徴量 x ルールベースによる推論だったら、Inference Pipelineを非MLチームのソフトウェアエンジニアが担当することも全然あり得る**...!:thinking:)
  - 2点目: 共通言語が生まれる
    - Feature Storeを中心に据えることで、チーム間で「Feature Pipeline」「Training Pipeline」「Inference Pipeline」っていう共通の言葉・設計思想を持てる！
    - ex.) チームが構築しているのがバッチMLだろうとリアルタイムMLだろうと、開発者たちが「どうやって特徴量を管理してるか」を共通理解できるようになる! だから、**チーム内・チーム間のコミュニケーションコストが下がる!**
      - (hogeパイプラインの入り口or出口は、まあ特徴量ストアだよね〜みたいな共通認識を持ちやすい、みたいな??::thinking:)
    - **ML資産の共有とチーム内およびチーム間のコミュニケーションの改善が可能になる!**

ちなみに...特徴量ストアの各種データの保存場所について:

- historicalな特徴量データ(i.e. event_timeを持つバージョニングされた特徴量データ??)は、オフラインストア(通常は列指向データストア)に保存される。
- リアルタイム推論で使用される最新バージョンの特徴量データは、オンラインストア(通常は行指向データストア or key-valueストア)に保存される。
- (個人的気づき: **あ、オンラインストアに全ての特徴量を保存する必要はなくて、リアルタイム推論で使うもの、かつ最新のversionの特徴量レコードのみで良さそう...!! :thinking:**)
  - 最初オンラインストアのコストめっちゃ高くなりそうだと思ってた。でもオフラインストアの全てをオンラインに同期する必要はなくて、リアルタイム推論で使う特徴量、かつ最新のversionの特徴量レコードのみで良いんだよな...!:thinking:

ちなみに...データストアの選択について:

- 一部のフィーチャーストアは、プラットフォームの一部としてストレージ層を提供し、一部は部分的または完全にpluggableなストレージ層を持つ。
  - 前者の例: Sagemaker Feature Store, Google Cloud Vertex AI Feature Store, Snowflake Feature Storeなど
    - Sagemaker Feature Storeは、オフラインストアはS3のParquet、オンラインストアはAWS Aurora(MySQL)で多分固定。
  - 後者の例: FeastなどOSS系。
    - Feastは、オフラインストアとしてBigQueryやSnowflake、オンラインストアとしてRedisやDynamoDBをpluggableに取り替えできる感じ。

ちなみに、予測ログも特徴量ストアに保存するといいよ的なことも書いてあった!(特徴量/モデルの監視とデバッグしやすさの観点で!)


### 解決ポイント2: Incremental Feature Management (特徴量データのincrementalな管理)

### 解決ポイント3: Backfilling feature data and Training Data(特徴量のbackfillingと学習データのbackfilling)

### 解決ポイント9: Point-in-time correct Training Data (時点正確な学習データ)

### 解決ポイント4: History and Context for Online Models (リアルタイム推論時に、事前計算した特徴量を提供)

### 解決ポイント5: Feature Reuse (特徴量の再利用)

### 解決ポイント6: Multiple Feature Computation Models (複数の特徴量計算パターンへの対応)

### 解決ポイント7: Validate Feature Data and Monitor for Drift (特徴量データのvalidationやドリフト監視)

### 解決ポイント8: Taxonomy of Data Transformations (学習時と推論時の特徴量の計算方法のズレ(data skew)を防げる)

# Sagemaker Feature Storeのメモ

## Feature Groupの分け方Tips

- tip1: 特徴量数の管理: 1グループ50特徴量以下を推奨。
- tip2: 命名規則: `{ドメイン}-{データソース}-v{バージョン}`
- tip3: バージョン管理: スキーマ変更時(ex. 特徴量追加/削除)は新Feature Groupを作成
  - **あれ、でも公式ドキュメントを見ると、作成後にスキーマの変更が可能**って書いてあるな...!!:thinking:
    - refs: https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store.html#create-feature-groups
- tip4: データソースと、更新頻度、アクセスパターンによる分割

### Feature Groupの更新方法

- refs:
  - [Add features and records to a feature group](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-update-feature-group.html)
  - [SageMaker Python SDK FeatureGroup.update() APIリファレンス](https://sagemaker.readthedocs.io/en/stable/api/prep_data/feature_store.html)

- 注意点: 
  - **追加できるのは新しい特徴量のみです。既存の特徴量の削除や型変更はできない。**。
    - 削除できるのはFeature Group単位のみ。
  - **オンラインストアを有効化できるのはFeature Group単位だし、既存のFeature Groupを途中からオンラインストア有効化もできない!**
  - 追加した特徴量は、以降の put_record() や ingest() で値を入れることができる。
- Sagemaker Python SDKで使えるメソッド:
  - `FeatureGroup.update()`メソッド
    - AWS公式ドキュメントでは、**update()で変更可能な項目として「特徴量の追加」「オンラインストアのTTL設定」「スループットモード変更」のみが明記されてるらしい**。
    - 引数:
      - `feature_additions`: 追加したい特徴量定義のsequence。
      - `online_store_config`: オンラインストアのTTL設定を変更したい場合に指定できる。
      - `throughput_config`: スループットの設定(on-demand/provisioned)を変更したい場合に指定する。
  - `FeatureGroup.update_feature_metadata()`メソッド
    - 既存の特徴量のメタデータ更新に利用できる。
    - 引数は以下:
      - `feature_name`: 更新したい既存の特徴量名
      - `description`: 新しい説明文。
      - `parameter_additions`: 追加したい特徴量メタデータ(key-valueペア)のlist。
      - `parameter_removals`: 削除したい特徴量メタデータのkeyのlist。

## Feature Groupの概念って、Feature Store共通??

- Feature Groupの概念:
  - 「特徴量の集合・テーブル」のようなもので、**ひとまとまりの特徴量（カラム）と、その主キー（Identifier）やイベント時刻（EventTime）を持つデータ構造**。
    - 「ユーザー属性特徴量グループ」「商品特徴量グループ」など、用途やドメインごとに分けて管理されるのが一般的。
  - 特徴量の論理的なグループとして、割と共通の概念っぽい！
- 各Feature Storeソフトウェアごとの「Feature Group」的な概念の位置付け:
  - Sagemaker Feature Store
    - 呼称「Feature Group」
  - Feastでの位置付け
    - 呼称「Feature View」
  - Hopsworksでの位置付け
    - 呼称「Feature Group」
  - Databricks Feature Storeでの位置付け
    - 呼称「Feature Table」
  - Vertex AI Feature Storeでの位置付け
    - 呼称「Feature Group」(旧バージョンでは「Entity Type」だったらしい)
  - Snowflake Feature Storeでの位置付け
    - 呼称「Feature View」
  - (いずれも、役割は似たような感じ！:thinking:)

## どう実装する感じになるんだろ??

Feature Storeとのput/getのやりとりは、FeatureStoreRepositoryクラスにwrapして、インターフェースと実装を追加するイメージで良さそう。
でもFeature Groupの作成や定義の更新は、Repositoryクラスに含めるべきでない気がする。
 
- 理由:
  - 理由1: **関心の分離(Separation of concerns)の観点**から分けたい
    - FeatureStoreRepositoryは、Feature Storeとのやりとりを担うクラスであるべき。
    - Feature Groupの作成・削除・管理は、**「データスキーマをどう設計するか」というライフサイクル管理**の話...!!
    - よって、Repositoryクラスはデータの読み書き係にして、Feature Store Manager的なデータスキーマや構造の設計・管理係を別で用意すると良さそう!:thinking:
  - 理由2: 運用フェーズが違うから! 
    - Feature Groupの作成・更新って、基本的に開発初期やスキーマ変更時だけやるオペレーションのはず。
    - 一方で、データのput/getは、本番システムの運用中に頻繁に行われるオペレーション。
    - だから、ランタイム中に無駄に「create_or_update」みたいな処理を含めない方が良い。システムの使い方（ライフサイクル）が自然になる
    - これもまあ「関心の分離」の観点の一種と言えるみたい...!
      - 「運用フェーズごとの責務分離」とか呼ばれる??
      - 「CQRS（Command Query Responsibility Segregation）」的な考え方とも類似しているかも。スキーマ管理（構造変更）」と「データ操作（put/get）」の責務を明確に分離することで、運用ミスや設計の複雑化を防ぐという点で。
