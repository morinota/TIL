## これは何?

- 特徴量ストア(feature store) について調査したものです。

## refs:

- 自前でfeature storeを実装した事例: [WantedlyでFeature Storeを導入する際に考えたこと](https://speakerdeck.com/zerebom/wantedlydefeature-storewodao-ru-suruji-nikao-etakoto?slide=42)
- neptuneの特徴量ストアのブログ:
- [5 Minimum Requirements of an Operational Feature Store](https://medium.com/data-for-ai/5-minimum-requirements-of-an-operational-feature-store-ab1436ca1a2c)
- [Feature Store: The Definitive Guide 2025年ver.](https://www.hopsworks.ai/dictionary/feature-store)

# Operational(=本番システム上で実際に価値を発揮する?)なFeature Storeに必要な5つの最低条件を読んで思ったことメモ

(ブログタイトル: 5 Minimum Requirements of an Operational Feature Store)

- ここで"Operational"ってどう言う意味合いだろ??
  - 直訳すると"運用可能な"だと思うけど、ブログの文脈的に"本番システム上に組み込んで実際に価値を発揮する"みたいなニュアンスと解釈してみてる...!:thinking:

## refs

- [5 Minimum Requirements of an Operational Feature Store](https://medium.com/data-for-ai/5-minimum-requirements-of-an-operational-feature-store-ab1436ca1a2c)

## 条件1: Shareableであること

- feature storeの基本的な前提は、それが組織全体で共有可能でなければならないこと。**特徴量は、それを必要とする任意のチームがアクセスできる必要がある。**
  - これにより、開発工数が一定かかるような複雑な特徴量も再利用可能になる (埋め込みベクトルとか...!:thinking:)
- 特徴量の共有に関するアイデアは、すでに普及してる。
  - Twitterは「[Sharing Adoption](https://twitter.com/jim_dowling/status/1257588702156591104)」というmetricを用意して監視してるみたい。
    - link元をたどって読んでいってみると...
      - **自社のFeature Storeの価値や効果を評価するための方法**として、Twitterのエンジニアリングチームは、"Sharing Adaption"という指標を採用して監視してるっぽい。(なるほど...! Feature StoreのShareable度合いを測るためのmetricか...!!:thinking:)
      - Sharing Adaption指標の定義: The number of teams who use another teams' features in production. (他のチームの特徴量を本番環境で使用しているチームの数)
    
- **データサイエンティストが検索して再利用できる特徴量達の単一のリポジトリを持つことは、DSの生産性にとって重要**である。
  - SQLやデータフレームのようなAPIを通じて、様々な特徴量を簡単に検索できることは、DSの成功に重要。

## 条件2: Transparent (透明性) が高いこと

- feature storeが信頼されるためには、**各特徴量のorigin(=元のデータソース?:thinking:)と実装が調査可能である必要**がある。
  - そのためには、特徴量の生成プロセスが十分に文書化され(=まあコードが追えればいい気がする...!:thinking:)、全ての人がそのプロセスを辿れるようにすべき。

## 条件3: Versioned (バージョン管理) されてること

- feature storeの中心的なテーマの一つは、collaborativeな開発を促進すること。
  - そのためには、前述のshareable & 高いtransparentさに加えて、**versionedであることも重要**
- versionedであることは、以下の2つの形で提供される:
  - 1. 特徴量生成 (特徴量がどのように計算されるか) のバージョン管理 (つまりfeature pipelineのプロダクションコードか...!:thinking:)
  - 2. 特徴量そのもの (特徴量が更新された日時) のバージョン管理 (つまり特徴量のevent_timeか...!:thinking:)
    - 特徴量ユーザが、推論時に誤って古いデータを使ってしまうことを防ぐ。
    - 特徴量がいつ更新されたかを追跡するだけじゃなく、その変更の履歴を保持することが重要。
      - (うんうん、学習時のデータリークを防ぐpoint-in-time correct joinのために、過去のバージョンの特徴量も欲しいので...!:thinking:)

## 条件4: Governed & Access Controlled (管理・アクセス制御されてること)

- **誰が特徴量ストアをクエリできるか、また歴史的に誰がクエリしてきたかに対する強力な管理・アクセス制御**が重要。
  - feature storeの管理者は、各特徴量へのアクセスを簡単に制限できるべきだし、組織内の誰が特定の特徴量をいつクエリしたかを確認できるべき。
- 同様に、特徴量のinsert/update/deleteも厳密に制御されるべき。
- (この条件のモチベーションは、MLOps技術的負債論文で言及されてた「データ依存関係のスパゲティ化を防ごう」みたいな話かな...!:thinking:)

## 条件5: 

- feature storeは通常、オフラインとオンラインの2つの異なるワークロードに分けられる:
  - オフラインワークロード(offline workload):
    - 定期的なバッチでの特徴量作成時に、feature storeに書き込むプロセス
    - MLモデルのオフライン学習時に、feature storeから大規模に特徴量を取得するプロセス
    - MLモデルのバッチ推論時に、feature storeから大規模に特徴量を取得するプロセス
  - オンラインワークロード(online workload):
    - streamlingな特徴量作成時に、feature storeに書き込むプロセス
    - MLモデルのリアルタイム推論時に、feature storeから特徴量を取得するプロセス
- 上記2つのワークロードは、**しばしばそれぞれ専用のコンピューティングエンジンを持つ2つの別々のフィーチャーストアによって処理され、必要に応じて相互に通信する**。(ex. DWHとRedisなど! :thinking:)
  - そしてこれが問題である!
    - データ不整合のリスク(学習時と推論時の特徴量がズレる...! data skew...!:thinking:)
    - 同期用のETLパイプラインの必要性、運用コスト増。
    - アーキテクチャの複雑性を増加させる!
  - 上記の理由から、劣悪なモデルや悪いビジネス結果につながり得る...! 
    - (MLOps処方箋本におけるMLOpsの定義を参考に言い換えると、MLの成果をスケールできない要因となり得る、みたいな...!:thinking:)
      - ちなみに...MLOps処方箋本のMLOpsの定義は「機械学習の成果をスケールさせるためのさまざまな取り組み」
- 理想のアーキテクチャ: 単一エンジンで両方の用途をカバーしていること!
  - **単一のFeature Storeがバッチも、分析クエリも、低レイテンシーのlookupも対応しているべき**。
    - (うんうん、裏側ではオンライン&オフラインに分かれてるとは思うけどけど、少なくとも特徴量を取得するユーザ側にはオンライン&オフラインの境界が情報隠蔽されてるべきかも...!:thinking:)
  - メリット:
    - オフライン・オンラインのdata skewを防止。
    - 運用がシンプル(同期用のETLパイプラインが不要)
    - Single source of Truth (真実の単一の起源?)が得られる。
- よりシンプルなパラダイム(見方、考え方??): 特徴量計算の概念を、特徴量利用から分離すること。
  - (これはあんまり説明がなくてよく意味がわかってないけど、要するにfeature storeとfeature pipelineは分離して考えようね、って話かな...!:thinking:)
  - **特徴量計算は、frequency(頻度)とComplexity(複雑さ)の2つの軸で考えると良いらしい**。(feature pipelineを設定するときの観点かな...!:thinking:)
    - Frequency(頻度): バッチ(定期実行) or リアルタイム(イベント駆動、ストリーミング)
    - Complexity(複雑さ): 算術程度の軽い計算 ~ 埋め込みなどの重めな計算
  - 一方で特徴量利用時には、**特徴量計算のFrequencyやComplexityによらず、ビジネスロジックやMLモデルのリアルタイム推論時には低レイテンシーで容易に取得できる必要がある...!**
    - (まあビジネスロジックや推論が全てバッチで行われる場合は、この要件は不要のはず...!:thinking:) 
  
# Feature Store決定版ガイド2025年ver.を読んだメモ

## そもそも特徴量とは? なんで専用の保存場所が必要?

- そもそも特徴量(feature)とは??
  - **特徴量 = エンティティの数値的な属性で、学習/推論の入力として使うやつ**。
    - ある対象(entity)の属性(property)を数値化したもので、かつ機械学習モデルの予測に役立つもの。
    - 特徴量は、MLモデルの学習や、バッチMLシステムおよびオンラインMLシステムでの推論に使用される。
    - 特徴量は、必要なときにその場で計算することも、事前に計算して後で学習や推論に使用することもできる。
- **特徴量を保存する場所が必要なのは...**
  - **「再利用」や「発見しやすさ」が重要だから（= 開発効率UP）**
    - 特徴量を保存することの利点の一部は、それらが簡単に発見され、異なるモデルで再利用しやすい状況を作れること。
    - それにより、新しいMLシステムを構築するために必要なコストと時間を削減できること。
  - **「リアルタイム推論」時に、今来たリクエストだけじゃなく事前計算したリッチな情報が必要だから（= モデル精度UP）**
    - リアルタイム推論の場合に、事前に計算しておいたリッチな特徴量を提供できること。
      - オンラインモデルはlocal stateを持たない傾向があるらしい。
        - (これってどういう意味だろう。local stateを持たない傾向、って部分。perplexityに聞いてみた感じ、各ユーザやリクエストの履歴・状態をモデル本体やサーバーのメモリ内に溜め込まず、**「今来たリクエスト」に含まれる情報だけをそのまま使う傾向がある**、みたいな意味合いっぽい...!:thinking:)

## 特徴量ストアとMLOps、MLシステムとの関連

- MLOpsプラットフォームにおける特徴量ストアは、**異なるMLパイプラインを結びつけて完全なMLシステムを作る接着剤の役割**を持つ (FTI Pipelines Architectureの発想そのもの...!:thinking:)
  - Feature Pipelineは、特徴量を計算し、特徴量(およびlabel/target)を特徴量ストアに書き込む。
  - Training Pipelineは、特徴量ストアから特徴量(およびlabel/target)を読み込み、MLモデルを学習する(学習されたモデルはmodel registryに書き込まれる)。
  - Inference Pipelineは、特徴量ストアから事前計算された特徴量を読み込み、推論を行う。
  - (メモ: 上記の内容って、思いっきりFTI Pipelines architectureの思想! 特徴量ストアを採用すること = FTI Pipelines Architectureを採用すること、と言って良さそう...!:thinking:)
- MLOpsの主な目標 = モデル試行錯誤のiteractionを短縮し、モデルのパフォーマンスを向上させ、ML資産（特徴、モデル）のガバナンスを確保し、コラボレーションを改善すること。
  - (ちなみに「MLOps処方箋本」のMLOpsの定義は「MLの成果をスケールさせるための取り組み」な訳だけど、上記を改善することがMLの成果のスケールに繋がるから、って解釈できそう...!:thinking:)
  - 特徴量ストアを採用すること(i.e. FTI Pipelines Architectureを採用すること)によって、この目標の達成につながるよ〜みたいな話。

## 特徴量ストアはどのような問題を解決するのか??

- 特徴量ストアはざっくり、どんな時の課題を解決する?
  - (1) モデルを本番環境にデプロイする際の課題
  - (2) デプロイするモデルの数をスケールする際の課題
  - (3) MLチームの規模を拡大する際の課題

特徴量ストアが解決する課題11個:

1. MLシステムのcollaborativeな開発の促進
2. 特徴量データのincrementalな管理
  (本番MLシステムにおける特徴量は、一回作って終わりじゃなくて、incrementalに変化していくものなので...!:thinking:)
3. 特徴量のbackfillingと学習データのbackfilling 
  (これは、特徴量ストアは特徴量をevent_timeと一緒に管理するから実現できるよね、って話かな...?:thinking:)
4. ステートレスなリアルタイム推論モデルにリッチな特徴量を供給
5. 特徴量の再利用 (DRY化, 複数モデルで使い回し)
6. 特徴量の様々な計算パターンへの対応
7. バリデーションやドリフト監視の容易化
8. 学習/推論時のdata skewの防止
9. point-in-time consistency (時点整合性) を持つ学習データの担保
10. リアルタイム推論時に、事前計算した特徴量を低レイテンシー提供
11. 埋め込みベクトルを使用したsimilarity search

シナリオ別の特徴量ストアの役立ちポイントまとめ:

- バッチMLシステムの本番稼働シナリオ(2, 3, 7, 8, 9)
- リアルタイムMLシステムの本番稼働シナリオ(上記に加えて、4, 6, 10, 11)
- 大規模なML展開シナリオ(上記に加えて、1, 5)

<!-- - 解決1: MLシステムのcollaborativeな開発!
- 解決2: 特徴量データのincrementalな管理(本番MLシステムにおける特徴量は、一回作って終わりじゃなくて、incrementalに変化していくものなので...!)
- 解決3: 特徴量のbackfillingと学習データのbackfilling (これは、特徴量ストアは特徴量をevent_timeと一緒に管理するから実現できるよね、って話かな...?:thinking:)
- 解決4: リアルタイム推論サービスに、「今来たリクエスト」に含まれる情報以外に、事前計算した特徴量を提供できる! (これは前述してたlocal stateを持たない傾向、みたいな話!)
- 解決5: 特徴量の再利用がしやすくなる! (これは一元管理してるから??:thinking:)
- 解決6: バッチ/ストリーミング/リクエスト時計算など、特徴量に求められる鮮度に基づくいろんな計算パターンに対応させやすい(全て特徴量ストアを経由するようになるから?? :thinking:)
- 解決7: 特徴量データのvalidationやドリフト監視がしやすくなる! (これも一元管理してるから??:thinking:)
- 解決8: 学習時と推論時の特徴量の計算方法のズレ(data skew)を防げる!
- 解決9: point-in-time consistency (時点整合性) を持つ学習データを作りやすくなる! (これは特徴量ストアがevent_timeを元に特徴量を管理するから!:thinking:)
- 解決10: リアルタイム推論時に、事前計算した特徴量を低レイテンシーで提供できる。(これはオンラインストアを含む特徴量ストアの話! 非対応のものもある印象...! :thinking:)
- 解決11: 埋め込みベクトルを使用して、similarity searchを行うこともできる! (これは特徴量ストアがベクトルデータをサポートしてる場合! similarity search機能はサポートしてない場合も全然ありそう! :thinking:) -->

### 解決ポイント1: Collaborative Development (MLシステムのcollaborativeな開発!)

- 特徴量ストアがcollaborativeな開発をどう支えるか??
  - 1点目: チームごと・開発者ごとの役割分担を可能にする。
    - Feature Storeがあることで(i.e. FTI Pipelines Architectureであることで)、MLシステムの構築・運用をパイプライン単位に分解できるようになる。
    - ex.)
      - Feature Pipeline: データエンジニア・データサイエンティスト
      - Training Pipeline: データサイエンティスト
      - Inference Pipeline: ソフトウェアエンジニア、MLOpsエンジニア
    - これによって、
      - 各種パイプラインでやるべきことが明確化される
      - Feature Storeをハブにして各パイプラインが独立して開発・運用できる
    - したがって、特徴量ストアが整っていれば、チーム間・チーム内でスムーズに役割分担・連携しやすい！ 
      - (メモ: **特徴量 x ルールベースによる推論だったら、Inference Pipelineを非MLチームのソフトウェアエンジニアが担当することも全然あり得る**...!:thinking:)
  - 2点目: 共通言語が生まれる
    - Feature Storeを中心に据えることで、チーム間で「Feature Pipeline」「Training Pipeline」「Inference Pipeline」っていう共通の言葉・設計思想を持てる！
    - ex.) チームが構築しているのがバッチMLだろうとリアルタイムMLだろうと、開発者たちが「どうやって特徴量を管理してるか」を共通理解できるようになる! だから、**チーム内・チーム間のコミュニケーションコストが下がる!**
      - (hogeパイプラインの入り口or出口は、まあ特徴量ストアだよね〜みたいな共通認識を持ちやすい、みたいな??::thinking:)
    - **ML資産の共有とチーム内およびチーム間のコミュニケーションの改善が可能になる!**

ちなみに...特徴量ストアの各種データの保存場所について:

- historicalな特徴量データ(i.e. event_timeを持つバージョニングされた特徴量データ??)は、オフラインストア(通常は列指向データストア)に保存される。
- リアルタイム推論で使用される最新バージョンの特徴量データは、オンラインストア(通常は行指向データストア or key-valueストア)に保存される。
- (個人的気づき: **あ、オンラインストアに全ての特徴量を保存する必要はなくて、リアルタイム推論で使うもの、かつ最新のversionの特徴量レコードのみで良さそう...!! :thinking:**)
  - 最初オンラインストアのコストめっちゃ高くなりそうだと思ってた。でもオフラインストアの全てをオンラインに同期する必要はなくて、リアルタイム推論で使う特徴量、かつ最新のversionの特徴量レコードのみで良いんだよな...!:thinking:

ちなみに...データストアの選択について:

- 一部のフィーチャーストアは、プラットフォームの一部としてストレージ層を提供し、一部は部分的または完全にpluggableなストレージ層を持つ。
  - 前者の例: Sagemaker Feature Store, Google Cloud Vertex AI Feature Store, Snowflake Feature Storeなど
    - Sagemaker Feature Storeは、オフラインストアはS3のParquet、オンラインストアはAWS Aurora(MySQL)で多分固定。
  - 後者の例: FeastなどOSS系。
    - Feastは、オフラインストアとしてBigQueryやSnowflake、オンラインストアとしてRedisやDynamoDBをpluggableに取り替えできる感じ。

ちなみに、予測ログも特徴量ストアに保存するといいよ的なことも書いてあった!(特徴量/モデルの監視とデバッグしやすさの観点で!)

### 解決ポイント2: Incremental Feature Management (特徴量データのincrementalな管理)

- feature pipelineは、MLシステムが稼働してる限り、特徴量を追加・更新し続ける (incremental dataset)
- Feature Storeがなければ、複数ストアへの整合性管理が大変になる。
  - オフライン・オンライン・ベクトルDBが別々に存在してる場合、それぞれ認証・接続方法などが異なり、それぞれのデータ同期を保つのは大変。
- Feature Storeはこれらをwrapして、統一的なCRUD(create/read/update/delete)インターフェースを提供してくれるので、可変な特徴量データセットの管理を容易にする役割を果たす。
  - 特徴量データの更新は、ストア（オフライン/オンライン/ベクトルDBストア）間で透過的に同期される。
  - (たぶん、オフラインストアにだけあればOKなデータは最初のcreateフェーズで定義しておくんだろうな...! そしてオンラインストアには最新ver.の特徴量のみが存在してる状況:thinking:)
- 同じfeature groupをストリーム処理クライアント(streaming feature pipeline)を使用して更新することもできる。(同じ特徴量グループを、バッチでもストリームでも更新できるよ、って話か。まあそりゃそうな気がする...!:thinking:)

### 解決ポイント3: Backfilling feature data and Training Data(特徴量のbackfillingと学習データのbackfilling)

- feature pipelineはbackfillできる必要がある。そのためには無状態 & 冪等性を持つパイプラインを意識すべき、という話...!! :thinking:
  - backfillingは、生の履歴データからデータセットを再計算するプロセス。
  - これには、**ユーザがbackfillするデータの範囲のためにstart_timeとend_timeを提供する必要がある**。(feature pipelineを作るときは、無状態 & 冪等なデータパイプラインを意識すべき...!:thinking:)
  - 思ったことメモ:
    - 毎回全ユーザ分の特徴量を作る系のfeature pipelineだったら、backfillはあくまで学習用データセットを作るため、という用途になりそう...!:thinking:
    - 特定期間内に追加・更新されたアイテムだけの特徴量を作る系のfeature pipelineだったら、学習用だけじゃなくて推論用のデータを作る目的でもbackfillしそう。
    - まあすでに既存の特徴量パイプライン達が運用されてる状況だったらbackfillってのはあんまりする必要はなくて、**どちらにせよ、特徴量グループに新しい特徴量を追加したり既存特徴量の作り方を変更した場合などにbackfillすることになるはず**:thinking:
    - **backfill可能なデータパイプラインである為には、やはり無状態 & 冪等性を持つパイプラインを意識**する必要がありそう...!:thinking:

- 同じ特徴量を作るfeature pipelineの実装が別々にならないようにしようね！という話...! :thinking:
  - ある特徴量のbackfillに使用されるfeature pipelineは、"live"データも処理できる必要がある。
    - (うんうん、リアルタイムで現在収集してるデータも同じパイプラインで処理させようね、という話。ここで実装が別々になってしまってるとバグの温床なんだよな...!:thinking:)
    - そのための方法はシンプルで、単にfeature pipelineを、データソースとデータの範囲を指定できるようにすればOK。
      - (要するに、**わざわざ「backfill用の特別なパイプライン」を別で作るのはやめようね**、って話だと思ってる! backfill時は、対象データ期間を「過去データの範囲に切り替えて」動かすだけ! :thinking:)
  - バッチとストリーミングのfeature pipelineの両方が、特徴量をbackfillできる必要がある。
    - (**ストリーミングパイプラインもbackfillできるようにしておこうね**、という話か...!ストリームのreplay設計っていうらしい...!:thinking:) 
    - (でも結局、大量の期間のデータをbackifillする際には、バッチというかバルクで一気に処理できる設計になってた方がいいよな...**単一のパイプラインをバッチでもストリームでも実行できるようにしておくのが運用上最強ってことでは**...!:thinking:)

- 特に学習データを作るという観点で、特徴量をbackfillできることは重要である、という話:
  - 逆に、もし特徴量をbackfillできないと、既存特徴量の定義を変更したり新しい特徴量を追加した場合に、本番システムリリース後に特徴量ログを集め始めて学習データが十分に集まるのを待つ必要が出てきてしまう。

### 解決ポイント9: Point-in-time correct Training Data (時点正確な学習データ)

- ざっくり、特に推薦などのタスクではpoint-in-time joinが重要だよね、という話...!
  - 時系列の特徴量データから未来のデータリークなしに学習データを作りたい場合、**時点正確な結合（point-in-time correct join）**と呼ばれる結合を行う必要がある。
  - 時点正確なトレーニングデータを作成しないと、モデルのパフォーマンスが悪化し、その悪化の根本原因を特定することが非常に難しくなる。
  - ちなみにブログ内では、以下の2種類をデータリークと呼んでた。
    - 予測したい教師ラベルや報酬ログのtimestampよりも、未来のtimestampを持つ特徴量を使ってしまうこと。(こっちは一般的な気がする...!:thinking:)
    - 予測したい教師ラベルや報酬ログのtimestampよりも、古すぎる特徴量を使ってしまうこと (これもデータリークって言うんだ...! 結局これって、推論時はもっと新しい特徴量を使うのに学習時はそれよりも古い特徴量を使ってしまってて、そこに差分というかdata skewが発生してしまってるのが問題、って感じなのかな...!!:thinking:)
- 多くのフィーチャーストアは、特徴量をevent_timeと一緒に保存することで、時点正確なトレーニングデータを作成できるようにしてる認識...!:thinking:
- バッチ推論時は、一律で現在時刻を指定してpoint-in-time joinして、特徴量データを取得すれば良さそう!

### 解決ポイント4: History and Context for Online Models (リアルタイム推論時に、事前計算した特徴量を提供)

- リアルタイム推論は「ステートレス」のケースも多い。
  - モデルはユーザーリクエストだけを受け取り、その情報のみを元に、即時に推論を返す（状態は持たない）(まあ推薦タスクだと、ユーザの過去の履歴情報などを使いまくって推論することが多いから、あんまりステートレスなモデルはない気がするけど...!:thinking:)
  - しかし、ユーザーのリクエストは「情報が乏しい」＝単体では弱い特徴しか取れない。
- ユーザーIDなどをキーにして「過去の履歴」をオンラインストアから取得する。
  - 事前に計算されたユーザ履歴や文脈情報（トレンド、過去の閲覧など）を活用
  - リアルタイム推論の特徴を豊かに拡張することができる
- オンラインストアがリアルタイム意思決定を支える
  - 例: Tiktokでは、最近見た10本の動画に関する特徴（カテゴリ、視聴時間、友達の行動など）をオンラインストアに保持
  - これを即時に取得して、深いユーザー理解をベースにした推論が可能になる
- エンティティが単純とは限らない（複合キーのサポートも重要）
  - 多くのケースでは単一のエンティティ（user_idやitem_id）で十分。
  - より高度な推薦やランキングでは、(user_id, item_id) のような**複数カラムの主キー（複合キー）**が必要になる場合もある
  - Uberなどの事例ではこの点が非常に重要になっている.
  - ちなみに、触ってみた感じ、SageMaker Feature Storeは現時点では複合キー非対応っぽい...!:thinking:
    - 主キーは1カラムに限られる。
    - なので複合キーが必要なときは、`user_id|item_id` のように文字列結合で擬似複合キーを作る工夫が必要になりそう...??
      - まあこれはどこもそうなのかも? perplexityに聞いてみたらUberもTikTokもそうしてるって言われた。

### 解決ポイント5: Feature Reuse (特徴量の再利用)

- 1. 最初のMLモデル構築では、特徴量パイプラインが「場当たり的」になりがち。
  - 学習用にCSVやDB直クエリなど、特注のスクリプトやETLで特徴量を作ることが多い。
  - そのあと本番運用に入ると「推論のためにリアルタイムで同じ特徴量作る必要あるじゃん…」となって、別のパイプラインが作られがち。
  - 例:
    - 最初にMLモデルを作るとき...
      - 「アプリケーションDBやDWHから直接データ引っこ抜いて…」
      - 「CSVこねくり回して…」
      - 「学習用の特徴量作った〜！やった〜！」
    - そので、モデルを本番運用するときに、
      - 「あ、リアルタイムでこの特徴量作らないとダメじゃん」
      - 「本番用に別パイプライン作るか〜」
    - みたいな感じで、トレーニング用・本番用で別々にデータ準備しちゃうことが多い!
- 2. モデルが増えると「同じ特徴量を何度も再計算」するようになる。
  - 複数モデルが、別々のパイプラインで同じ特徴量をそれぞれ作る
  - → 計算リソース・ストレージがムダ
  - → コードが重複して**非DRY（Don't Repeat Yourself）**になる
  - → 保守が地獄になる
- 3. Feature Storeがあると「特徴量の再利用」が簡単になる!
  - 一度作った特徴量はFeature Groupとして保存 → 他モデルでもすぐ使える！
  - Metaの事例: 「**最も人気な100特徴量が100以上のモデルで再利用されてる**」
    - よって、特徴量を使い回す前提で設計した方が良い...!!:thinking:
- 4. 特徴量の再利用によって得られる効果
  - 特徴量の品質が向上：多くのモデルで使われることで、レビューや改善が進む
  - ストレージと計算コストの削減
  - パイプラインの数が減る → メンテしやすい
  - 結果：**特徴量ストアは、本番環境で実行するモデルの数と、維持しなければならないfeature pipelineの数を切り離す**。(この観点大事だ...! 言い換えるとFTI Pipelines Architectureの利点でもある!)
- 5. 特徴ストアが十分に整備されていれば、必要な特徴量がすでにFeature Storeにあるなら、新しいモデルのためにfeature pipelineを書く必要はなくなる。
  - 新規ユースケースの開発工数が大幅に削減される。

### 解決ポイント6: Multiple Feature Computation Models (複数の特徴量計算パターンへの対応)

- 特徴量ストアの採用により、言い換えるとFTI Pipelines Architectureの採用により、MLの各データパイプラインの特性に応じた計算パターンに対応できる。
  - feature pipelineの特性:
    - 基本的にはGPU不要。
    - 実装スタイルは様々
      - pandas, polars, spark, SQL, etc.
    - 実行形式: バッチ or ストリーム
  - training pipelineの特性:
    - GPUが必要になることも多い。
    - 実装スタイルはほぼ確実にPython
    - 実行形式: バッチ .
      - (bandit的なオンライン学習だとしても、実務上はバッチになりがちなので...!:thinking:)
  - inference pipelineの特性:
    - 実装スタイルは様々
      - Python, バックエンドサーバーの言語だったり。
    - 実行形式: バッチ or リアルタイム (or ストリームもありそう?:thinking:)
- 特徴量生成・学習・推論の3つのパイプラインは、それぞれ異なる技術・スケーリング要件・実行スタイルを持っている。
  - これらを役割分担して設計することで、MLシステムは柔軟かつ運用しやすくなる！

### 解決ポイント7: Validate Feature Data and Monitor for Drift (特徴量データのvalidationやドリフト監視)

- 1. 「Garbage In, Garbage Out」はMLにも完全に当てはまる。
  - モデルの性能は入力データの品質に大きく依存する
  - → 特徴量の品質チェックは必須！
- 2. 特徴量バリデーション（Validation）＝Feature Storeに書き込む前のチェック
  - バリデーションは 特徴量パイプラインの出口 or Feature Storeへの書き込み時に実行
  - (まあfeature pipelineの最後のstepでvalidationを実行すれば良さそう...!:thinking:)
- 3. 特徴量モニタリング（Monitoring）＝保存後の変化・異常の検知
  - Feature monitoringは、多くのフィーチャーストアが提供するもう一つの便利な機能。
    - (あ、これはvalidationというよりはdrift監視みたいな話か...!前者は特徴量ストアに保存するときに実行されて、後者は特徴量ストアの中で定期的もしくはon-demandで実行されるイメージかな...!:thinking:)
  - バッチMLシステムを構築する場合でもオンラインMLシステムを構築する場合でも、システムのモデルに対する**推論データを監視し、それがモデルのトレーニングデータ（データドリフト）と統計的に有意に異なるかどうかを確認できる必要がある**。
  - もし異なる場合は、ユーザ(=開発者)にアラートを通知し、**理想的にはより最近のトレーニングデータを使用してモデルの再トレーニングを開始するべき**。
  - Hopsworksの例では、ドリフト検知のバッチが1日一回実行されるようになってるみたい。
    - 推論時の特徴量の統計量が、学習時の同じ値から50%以上逸脱してた場合に、データドリフトが発生したとみなし、アラートをtriggerするような仕組みになってるみたい。
    - (この場合のデータdriftの監視は、バッチで行われるイメージなんだ。理想的にはこれもストリーミング的に実行される方が良い、というブログを見たな...!:thinking:)


### 解決ポイント8: Taxonomy of Data Transformations (学習時と推論時の特徴量の計算方法のズレ(data skew)を防げる)

- 特徴量に関するデータ変換(data transformation)の分類(Taxonomy)は**3種類**ある。
  - 1. model-independent transformation(モデル非依存変換)
    - どのモデルでも再利用可能な、汎用的な特徴量を作る処理。
    - 実行場所: feature pipeline (batch / streaming)
      - モデル非依存変換は、feature pipelineの中でのみ実行されるべき(i.e. つまり学習 & 推論パイプラインには含まれるべきではない...!)
  - 2. model-dependent transformation(モデル依存変換)
    - 各モデルの最適化に調整するような、モデル固有の前処理(ex. one-hot encoding, 欠損値補完, 0~1スケーリングなど)。
      - (カテゴリ変数をone-hot encodingしたり、数値特徴量を標準化したり、欠損値を埋めたり...は、各モデルの精度を上げるために個別に細かくチューニングするもの...!:thinking:)
    - 実行場所: training pipeline / inference pipeline 
  - 3. on-demand transformation(オンデマンド変換)
    - リアルタイム推論時、リクエスト中の情報から特徴量を計算する処理。
    - 実行場所: (real-time) inference pipeline / feature pipeline
    - 過去のデータから特徴量をbackfillする場合は、feature pipelineで実行できる必要がある。
      - (学習時にon-demand変換による特徴量も用意する必要があるからか。特徴量定義が変わらない限りは、on-demand変換したタイミングでfeature storeに保存しておけばそれで良いが、特徴量定義を変えたい場合はbackfillする必要がある、って話か...!:thinking:)
- 3種類全てのデータ変換について、異なるpipelineで同等の変換が実行できる必要があったりする。
  - 具体的には...
    - モデル非依存変換の場合は、batch/streamingのfeature pipeline。
    - モデル依存変換の場合は、training/inference pipeline。
    - オンデマンド変換の場合は、feature pipelineとreal-time inference pipeline。
  - **複数のpipelineで同等の変換が実行されることを保証する必要がある**。
    - 変換方法に違いがある場合、モデルの性能バグが発生し、特定やデバッグも非常に困難になる。
  - つまり...この辺りが整理して運用できてないと...
    - モデル依存変換の場合は学習パイプラインと推論パイプラインで、on-demand変換の場合は推論パイプラインとfeature pipelineで、特徴量作成ロジックにズレが生じうる...!
    - -> 学習時と推論時で data skew問題が発生する...!
    - **モデル依存変換やオンデマンド変換の場合は、まあ特徴量生成処理をモジュール化して同じ関数を呼び出せるようにする**んだろうな...:thinking:
    - 例えばHopsworksだと、この辺りをサポートする機能があるみたい。

## 特徴量ストアは必要か??

- 過去の特徴量ストアは...
  - Uberの Michelangelo のような **ビッグデータMLプラットフォームの一部**
  - 特徴ロジックの指定からパイプライン構築・運用までを含む、**フルMLワークフロー管理ツール** 
- 最近の特徴量ストアは...
  - オープンソース化が進み、Python / Spark / Flink / SQL など 既存のMLパイプラインとの統合が容易
  - Serverless feature stores も登場し、小規模なチームでも採用しやすくなっている。
- ほとんどのチームが必要とする主要な機能：
  - Point-in-time correct feature data の一貫した読み書きAPI
  - Feature monitoring
  - Feature discovery and reuse
  - Feature dataの versioning / tracking over time

## 特徴量ストアとベクトルDBの違いは何??

- 両者の共通点:
  - どちらもMLシステムで使われるデータ基盤
  - ともに特徴量ベクトルを扱うが、目的や構造が異なる。
- Feature Storeの役割と構成
  - 目的:
    - 特徴量データの保存・再利用・取得（トレーニング・推論の両方）
  - 主な機能：
    - Point-in-timeな特徴量のクエリ
    - オフライン＆オンラインストアの分離
    - モニタリング・バリデーション・バージョニング
  - ストレージ構成：
    - オフラインストア（列指向）
    - オンラインストア（行指向, key-value store）
- Vector DBの役割と構成
  - 目的:
    - 類似ベクトル検索 (ANN)
  - 主な機能：
    - 類似アイテム・ユーザの検索
    - 高次元空間における距離ベースの探索
  - ストレージ構成：
    - ベクトルインデックス（FAISS, ScaNNなど）
    - → 高速なANN探索のために最適化された専用データ構造を使用
- 両者を統合したプラットフォームの例: Hopsworks
  - Feature Store + Vector DB を統合的に提供
  - Feature Groupにembedding列を含めて、ベクトルインデックスとして登録可能
  - フィルタ付きのANN検索もサポート

# Sagemaker Feature Storeを使ってみたメモ。

## Feature Groupの分け方Tips

- tip1: 特徴量数の管理: 1グループ50特徴量以下を推奨。
- tip2: 命名規則: `{ドメイン}-{データソース}-v{バージョン}`
- tip3: バージョン管理: スキーマ変更時(ex. 特徴量追加/削除)は新Feature Groupを作成
  - **あれ、でも公式ドキュメントを見ると、作成後にスキーマの変更が可能**って書いてあるな...!!:thinking:
    - refs: https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store.html#create-feature-groups
- tip4: データソースと、更新頻度、アクセスパターンによる分割

### Feature Groupの更新方法

- refs:
  - [Add features and records to a feature group](https://docs.aws.amazon.com/sagemaker/latest/dg/feature-store-update-feature-group.html)
  - [SageMaker Python SDK FeatureGroup.update() APIリファレンス](https://sagemaker.readthedocs.io/en/stable/api/prep_data/feature_store.html)

- 注意点: 
  - **追加できるのは新しい特徴量のみです。既存の特徴量の削除や型変更はできない。**。
    - 削除できるのはFeature Group単位のみ。
  - **オンラインストアを有効化できるのはFeature Group単位だし、既存のFeature Groupを途中からオンラインストア有効化もできない!**
  - 追加した特徴量は、以降の put_record() や ingest() で値を入れることができる。
- Sagemaker Python SDKで使えるメソッド:
  - `FeatureGroup.update()`メソッド
    - AWS公式ドキュメントでは、**update()で変更可能な項目として「特徴量の追加」「オンラインストアのTTL設定」「スループットモード変更」のみが明記されてるらしい**。
    - 引数:
      - `feature_additions`: 追加したい特徴量定義のsequence。
      - `online_store_config`: オンラインストアのTTL設定を変更したい場合に指定できる。
      - `throughput_config`: スループットの設定(on-demand/provisioned)を変更したい場合に指定する。
  - `FeatureGroup.update_feature_metadata()`メソッド
    - 既存の特徴量のメタデータ更新に利用できる。
    - 引数は以下:
      - `feature_name`: 更新したい既存の特徴量名
      - `description`: 新しい説明文。
      - `parameter_additions`: 追加したい特徴量メタデータ(key-valueペア)のlist。
      - `parameter_removals`: 削除したい特徴量メタデータのkeyのlist。

## 特徴量レコード削除について

- 前提
  - 特にオフラインストアの場合、Feature Storeのデータは基本append-only (オンラインストアの場合は物理削除できるけど、オフラインストアはできない)
  - よって「削除」という動作は、`is_deleted`フラグを立てる(論理削除)という動作になる!
    - レコードを消すのではなく「無効です!」とマークすることになる。
    - **なので、オフラインストアにあるデータを物理削除するには、S3側の機能を使う必要があるみたい...! ライフサイクルルールとか!**
- 唯一提供されてる削除API: `FeatureGroup.delete_record()`メソッド
  - 引数は2つ (=削除したいレコードを一意に識別するための情報のみ...!シンプル!:thinking:)
    - `record_identifier_value_as_string`: 削除したいレコードのentity id
    - `event_time`: 削除したいレコードのevent time (i.e. レコードのversion)
- tips:
  - 公式には「一括の論理削除」のAPIは存在しない。forループで順番にdeleteするしかない。
  - Athenaクエリでレコードを取得するときは、is_deletedを考慮すべき。`where is_deleted = 0`みたいな条件を追加する必要がある!

## Feature Groupの概念って、Feature Store共通??

- Feature Groupの概念:
  - 「特徴量の集合・テーブル」のようなもので、**ひとまとまりの特徴量（カラム）と、その主キー（Identifier）やイベント時刻（EventTime）を持つデータ構造**。
    - 「ユーザー属性特徴量グループ」「商品特徴量グループ」など、用途やドメインごとに分けて管理されるのが一般的。
  - 特徴量の論理的なグループとして、割と共通の概念っぽい！
- 各Feature Storeソフトウェアごとの「Feature Group」的な概念の位置付け:
  - Sagemaker Feature Store
    - 呼称「Feature Group」
  - Feastでの位置付け
    - 呼称「Feature View」
  - Hopsworksでの位置付け
    - 呼称「Feature Group」
  - Databricks Feature Storeでの位置付け
    - 呼称「Feature Table」
  - Vertex AI Feature Storeでの位置付け
    - 呼称「Feature Group」(旧バージョンでは「Entity Type」だったらしい)
  - Snowflake Feature Storeでの位置付け
    - 呼称「Feature View」
  - (いずれも、役割は似たような感じ！:thinking:)



## どう実装する感じになるんだろ??

Feature Storeとのput/getのやりとりは、FeatureStoreRepositoryクラスにwrapして、インターフェースと実装を追加するイメージで良さそう。
でもFeature Groupの作成や定義の更新は、Repositoryクラスに含めるべきでない気がする。
 
- 理由:
  - 理由1: **関心の分離(Separation of concerns)の観点**から分けたい
    - FeatureStoreRepositoryは、Feature Storeとのやりとりを担うクラスであるべき。
    - Feature Groupの作成・削除・管理は、**「データスキーマをどう設計するか」というライフサイクル管理**の話...!!
    - よって、Repositoryクラスはデータの読み書き係にして、Feature Store Manager的なデータスキーマや構造の設計・管理係を別で用意すると良さそう!:thinking:
  - 理由2: 運用フェーズが違うから! 
    - Feature Groupの作成・更新って、基本的に開発初期やスキーマ変更時だけやるオペレーションのはず。
    - 一方で、データのput/getは、本番システムの運用中に頻繁に行われるオペレーション。
    - だから、ランタイム中に無駄に「create_or_update」みたいな処理を含めない方が良い。システムの使い方（ライフサイクル）が自然になる
    - これもまあ「関心の分離」の観点の一種と言えるみたい...!
      - 「運用フェーズごとの責務分離」とか呼ばれる??
      - 「CQRS（Command Query Responsibility Segregation）」的な考え方とも類似しているかも。スキーマ管理（構造変更）」と「データ操作（put/get）」の責務を明確に分離することで、運用ミスや設計の複雑化を防ぐという点で。
