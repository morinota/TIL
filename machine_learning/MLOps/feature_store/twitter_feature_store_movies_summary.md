
## 1. TwitterにおけるMLの活用

- 発表者はウルフ・アーノルドさん。Twitter Cortexのエンジニアリングマネージャーとして、Feature managementチームを率いる。
- Twitterでは、ユーザを「今、世界で何が怒っているか」に繋ぐために、いろんなプロダクトサービスでコンテンツ推薦を行ってる。ex. タイムライン上のツイートのリスト。Webページの広告。トレンドのリスト。フォローすべきおすすめユーザ, ツイートの返信を表示すべきか否か、etc.
- 上記全てのサービスはMLによって動かされており、**多くのMLアプリケーションは推薦システムとして機能する**。
- アーノルドさん「Now, the fuel for all of machine learning, as you've been hearing all day, is data, specifically features. **MLの燃料はデータ、特に特徴量である!**」

## 2. 特徴量と特徴量エンジニアリング

- 「特徴量(feature)」とは、**未加工のデータソース(ex. ユーザのプラットフォーム上での行動ログ)から派生した、処理済みのデータ片やシグナルのこと**。
  - これらは、MLアルゴリズムを訓練するために使用され、特定の目的（例：ユーザーがツイートをリツイート、いいね、または広告をクリックする可能性を予測する）に役立つ。
- **未加工データから特徴量を生成するプロセスは「特徴量エンジニアリング(feature engineering)」**と呼ばれ、これは**MLモデルの構築や改善において最も時間がかかる側面の一つ**。
  - (なるほど、未加工のデータが、特徴量エンジニアリングを経て、特徴量になるのか:thinking:)
  - データの分析、サンプリング、変換、フィルタリング、異なるデータソースとの結合などが含まれる。
  - ちなみに、Twitterのランキングモデルで一般的に使用される特徴量の例は以下。
    - ソーシャルグラフシグナル: ユーザのフォロー状況やフォロワーに関する情報。
    - ツイートの人気度シグナル: いいねやリツイートの数など。
    - コンテンツシグナル:
      - ツイートのテキストや添付メディアに関する情報。

## 3. サイロ化された特徴量エンジニアリングの問題

- 特徴量の生成・取得プロセスが、Twitter内の様々なランキングシステムで発生するが、チームやシステムが「サイロ化(siloed)」されていた。
  - データソースが類似してるのに別々の特徴量を作ってたり。個別の技術スタックに依存してたり。組織的な境界が原因だったり...で特徴量の共有が阻害されてた。
  - これにより、**特徴量エンジニアリングの価値が各サイロに閉じ込められていた**。
  - 特に、グラフ特徴量、エンゲージメント特徴量、コンテンツ特徴量などの洗練された特徴量でこのサイロ化の問題が顕著だった。

## 4. TwitterのFeature Storeによる解決策

- アーノルドさんのチームは、このサイロを打破することを目指した。
  - チームミッション: **会社全体の全てのMLモデルが特徴量を効率的に共有・整理・発見・アクセスできる最先端のシステム**を構築すること。**中央インフラ**チーム。
  - 各MLチームには1人から5人のエンジニアがフィーチャーエンジニアリングに専念してた。多数のチームが存在するため、この労力の再利用は非常に重要。
- 新しい特徴量を使いたい時...
  - MLエンジニアには2つの選択肢がある。
    - 1. 大規模なデータセットを精査し、試行錯誤を繰り返して新しいフィーチャーを考案すること。
    - 2. 他チームが既に苦労して作成したフィーチャーを利用すること。
  - Feature Storeの導入により、後者の選択肢が遥かに容易になる。

## 5. Feature Storeの「共有と需要(supply and demand)」モデル

- Feature Storeは、**特徴量の供給と需要を仲介する役割**を果たす。
  - feature producer(特徴量の供給者)
  - feature consumer(特徴量の需要者)

## 6. 「共有の悲劇(Tragedy of the Commons)」への対処とFeature Storeの成功

- Feature store導入当初、「共有の悲劇(Tragedy of the Commons)」という問題に直面した。
  - 誰もがフィーチャーを消費したがる一方で、フィーチャーを登録することに積極的なチームが少なかった。
  - フィーチャー登録には、新しい標準やAPIへの適合、学習といった多少の労力が必要だった。
- この問題に対処するため、アーノルドさんのチームは3つの戦略を実行した。
  - 1. **一部の重労働を自ら行う**: チームが自らフィーチャー登録作業の一部を引き受けた。これにより、ライブラリの改善点も発見できた。
  - 2. **目標の再調整**: 顧客(MLチーム)がフィーチャー消費のためにフィーチャーストアとの統合を求めていた時期に、彼らのフィーチャー登録への協力を求めた。
  - 3. チームの成功指標の変更: **チーム自身の成功指標を「他のチームのフィーチャーを本番環境で利用しているチームの数」に設定した("Sharing Adoptation Metric"と呼ばれる指標)**。


## 7. 特徴量エンジニアリングの加速

## 8. Feature Storeのマーケットプレイス機能

- Feature Storeは、特徴量のマーケットプレイスとして機能する。
  - カタログ機能:
    - 検索可能で閲覧可能なUIがあり、特徴量を検索できる。
    - feature family、feature group、entity typeなどで整理されており、詳細ページではデータソース、オンライン/オフラインの可用性、派生フィーチャー、そして重要な「プライバシーデータ保護ラベル」が確認できる。
  - ニュースレター機能:
    - 定期的に発行されるニュースレターは、ステークホルダーやユーザーに特徴量を宣伝し、フィーチャーエンジニアリングの成果を紹介するチャンネル。
    - 供給側と生産側を結びつけ、**特定のフィーチャーがモデルの改善にどれだけ貢献したか（例：ランキングモデルがX%改善した）といった成功事例を共有**することで、チーム間のコミュニケーションを活性化させている。
  - 特徴量ブローカーとしての役割:
    - チームはマーケットプレイスの運営者として、自然な仲介役（フィーチャーブローカー）となった。
    - フィーチャーコンシューマーはカタログのナビゲートや適切なフィーチャーの発見について相談し、フィーチャープロデューサーは新しいフィーチャーの配布を依頼する。
    - これにより、メディア理解や自然言語処理に基づく汎用シグナルを生成するSignalsグループのような新しい組織の流通チャネルとしても機能している。

## 9. 成果と今後の展望

- Feature Storeの取り組みは2年間で、1000以上のフィーチャーが登録され（複雑なものを含めると10,000近くになる可能性もある）、Twitterの主要なMLチームすべてと連携してきた。
  - **特に、最も要求の厳しいMLアプリケーションのニーズを満たすことに注力し、「大物(the whales)」をターゲットにすることで、フィーチャーアクセスの民主化と統一というビジョンを実現しようとした**。
- 最終的な成功の指標は、顧客(=特徴量を使うMLエンジニア達のチーム)にとってのKPI指標の改善。
  - feature storeの新しい特徴量がモデルの改善につながり、それが会社のKPI指標（例：デイリーアクティブユーザー（DAU）、ユーザーアクティブ時間、健康指標、動画視聴時間、収益）の向上に貢献していることが示されている。
  - これらの改善は、年に1、2度しか起こらないような重要な成果であり、フィーチャーストアの価値を示している。
- 今後解決したい課題
  - 組織全体で特徴量の価値を体系的に追跡し、モデルの改善を特定の特徴量に因果的に帰属させる方法。(各特徴量の効果検証的なアプローチ)
  - メタデータを使って特徴量のレコメンデーションを行う方法。

## 10. まとめと提言

- アーノルドさんは、聴衆に向けて以下の問いかけで講演を締めくくっている。
  - あなたの組織では、誰が特徴量エンジニアリングを行っていますか？
  - その特徴量エンジニアリングから恩恵を受けているのは、1つのチームだけですか、それとも多くのチームですか？
  - あなたのMLチームは互いに特徴量を共有していますか？彼らは互いに会話していますか？お互いの存在を知っていますか？
  - 特徴量を共有したり、互いの存在を知ったり、会話したりすることはどれくらい簡単ですか？
  - そうしないことによる機会損失は何ですか？
