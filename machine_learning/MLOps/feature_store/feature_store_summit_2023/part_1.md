Feature Store Summit 2023 - YouTube
https://www.youtube.com/watch?v=nIOZqtg4atI

Transcript:
(00:00) compared to what maybe it's it's it's training or or production right so you have you know different teams kind of making taking care of different different stages of the let's say um you know mlops uh um mlops process and um then you know there are walls and you know um there are situations where you throw the your work over the wall to the next team or the next person responsible for it and they obviously creates um frictions and creates um you know points of failures and and and and things like
(00:29) this um one other um thing that we we see often is that there are often times custom like oneof basb pipelines to do different things right so um a team might build a pipeline to train a model that's taking data from data warehouse do and Transformations and and train a model but then the same model needs to be served in in production real time behind the rest CPI and the team goes off or some other team goes off and and build totally different pipeline that maybe relies on a CFA stream or maybe reliz on on other on other like
(01:03) Technologies underneath and then it's a nightmare to keep those things and things right um so these are kind of the um the kind of the eye level the eye level challenges um and and feature stor to a large degree try to address those challenges um but what we found is that um tools only you get you so far right so um the challenges um you know you can't just you know magically drop in the future store um and all the challenges go away um you need um you need proper process in place so um we work with users um and we work with
(01:33) customers um to um you know try to identify some of the patterns and things that we over see and make for a successful implementation uh of of a feature store right so the goal for us is to go to a complex system like this um to a more well-defined system a more simple system to understand and and and reason about um which is the FTI pipelines uh we call it FTI pipelines FTI stands for feature training inference p pipeline um and the goal is essentially to um you know split the process of De developing a model and
(02:06) deploying a model into production into three independent um logical components uh which are responsible for different part of this of this process right so um we have feature pipelines that are responsible for you know reading the data and and Computing the features and and and um um you know um producing the features training pipelines are responsible for actually building the models and that includes everything from you know experimentation and actually training the model the final model um and finally we have the infer pipeline
(02:36) which is responsible for um uh you know taking the model um and making inference um both real time uh or also in batches um these are independent components um the the the nice aspect about this is that you can reason you can reason about every single component um individually um you can have for instance different teams working on different components you can have different uh you can use different Frameworks um you can orchestrate for instance the different component different pipelines independently so you might have a
(03:06) feature pipeline runs in a streaming our way you might have a feature pipeline that runs in a in a in in a batch fashion every day you might have a training pipeline runs once a once a um once a month or something like this right so the the idea is not to have a single um UniFi pipeline but you have actually split them up one thing that is missing here from the picture is all the three different pipelines work together to you know build this ml systems right um and that's where where obso comes into the picture right so obso as a FID
(03:36) store provide new things provides the um capabilities to to manage the artifacts to manage the features um to store them and serve them and so on but it also provides um an open API um which are in Python mainly but also available in Scala and Java to be able to actually interact for for this pipelines to actually interact with with the feature store right so if you're writing a feature pipeline um then you will call the API to register the um the uh the features with the feature store and if you are writing a new trending pipeline
(04:08) you will need API to retrieve the features from the feature store um and also for the inference Pipeline and so on right so OBS provides the capabilities for these three pipelines to um you know share the outputs and build on top with each other um while keep while keeping them um you know separated and independent now if if we look a little bit more in detail about the different step so if you start from from the feature pipeline right the feature pipeline as you said is responsible for um you know Computing the features um
(04:37) and and um you know producing the features and you potentially also the the labels if necessary right um the the expectation is that you have a really clean system uh where basically uh you get a bunch of data and you do Transformations and then there you go you you basically have your features as we said earlier like one of the challenges that you have when you're building machine Learning Systems is that you're dealing with um a bunch of different data sources um with different time with different like timelines in
(05:06) terms of ingestions so you might have set a streaming pipeline com again that needs to be processed in real time you might have a data warehouse you know that is loaded once a day once a month you might have you know existing pipelines that you need to combine um so there's a lot of complexity and and a lot of like different tools and and different processes that are that are required um one of the challenge is that um you don't have one to Ru them all so you don't have one single framework to do everything right so you have
(05:34) different Frameworks and different things actually you know prefer different um different different Frameworks right so if for instance if you're doing um if you're working with small data sets um you can probably get away with pandas and paas maybe you're dealing with like um streaming API with streaming data um you might be dealing you might want to look at you know stuff like either beam flank or spark streaming um you might have data data warehouse so you might be looking at you know um big qu is not flake and
(06:00) leveraging the their their execution engine and and so on right so there's different tools um and different pipelines are written different tools and they need to com be combined with each other right the the idea and the the benefits of of the of the feature pipeline is that all this complexity is actually um hidden and and and taken away from the rest of the training pipel inference pipeline is all combined into the the fature pipel um OB has always adopt a philosophy of being an open platform um also being and the fet
(06:31) pipeline kind of adopts that philosophy as well um to basically allow different Frameworks to be used um not only the Frameworks exist today but also future proofing your infrastructure and the infrastructure of our user and customers um so that if let's say in two years from now the next activ comes out or the next forus comes out um we can plug it in and you can leverage it to compute features right you don't have to wait for um a specific um you know tool toward supporting the DSL use it and and call the API um to to register what we
(07:04) call in OB register data frame um data frame are common concept across um all the data processing tools out there um so um that's essentially that's essentially what we what we provide in ter of platform um to implement um the feature pipeline um API um Oneal thing that I something that that it's new in obso that um we have released as a preview right now um it's it's feature monitoring right so the goal is that when features leave the feature pipeline everybody can trust it right so if I'm a data scientist
(07:38) building a training pipeline or if I'm building like an inference pipeline I know that the data can get in the the data is available in the feature store is actually high quality and correct right obso has had support uh for great expectation for many many releases now um that's mostly covering bad data so for instance I have ning my data or have you know negative values when supposed to be only positive um these new capabilities feature monitoring um actually looks at more um statistical data statistics properties of the data
(08:11) and making sure if the data is shift drifting um the you can basically you can basically get an alert and you know um you know you either retrain your model or or adapt your model essentially and we have again open python API to do that um it's the same API for for bch and the same API to um real time uh real time pipelines and you can basically you can basically have a look at documentation is going to be available soon as well to to look at this um at this API the next step is um you know once the features being producers is actually
(08:47) um it's time to actually train um a specific um a specific model um training a specific model again the the the underlying concept is the platform needs to be able to support um you know all the different Frameworks that you that you might the scientist might want to use right so everything from Deep learning Frameworks like Pythor and so on but all the way to let's say if you're doing working with TBL data and so on H you might want to look at I don't know ex boost or something like this um so for for upor and for for
(09:17) fidget Stores um the the key concept here is to provide an API to give back um Panda sta frame right um AB supports that all the F out there they support the same API um one important aspect I will say that you really want to be careful about is the way you're retrieving data right so um if you look at FID out there um and you know to a large degree OB back in the days um they either built on two underly technologies right either built on spark or they are built on data warehouse right um then you know they ship the data to the
(09:52) clients um using gtpc protocol essentially right um the the challenges of the texture is that for inance spark has a really um like a long ccept like if you want to start a spark application it takes a couple of seconds um to get up to do anything useful um to even like start retrieving the data um and that has an impact on the user experience right so one of the things we see often times when we work with the scientist um using obser and using fidget stores is that what they want is um they want to be able to have the same let's say
(10:27) laptop experience um that they would have if they were to train on CSV file right obviously if you are a large Enterprise or if you're you know you care about data governance and you know you have working with sensitive data you can't just have a bunch of CSV file flying around on the laptops of people because there a recipe for disaster so you want to adopt a centralized architecture but at the same time you don't want to take away um the flexibility in the user experience that you know people are used to right so
(10:54) that's what we actually try to address um in the summer with ob 3.3 um which essentially allow replacing the the spark spark qu engine with a combination of dub and autoflight right um the basic idea here is TB has really good performance especially for Point time correct joints and there a typical work use case that you see when you're dealing with feature data um and outut oflight is a protocol to be able to um ship data between client and server in a way so that you don't have to uh you know you don't have do a bunch of
(11:30) distalization you don't have to move go from col format which is the typical the typical way the data is store in in a fe store to row format which isbc to back into a columnal format which is a data frame in pandas right so we FL you can do end to end without um the serialization serialization so right so um there something that as J was mentioning earlier uh we have benchmarked uh we U you know worked with kth and uh Institute you look at you know typical use cases as I said typical use case would be sending data to a
(12:05) pandas um application for for for train your model um so we had done actually two um main experiments one is as I said um this one which is basically sending data itself using using dctb and AR flight uh you know for ups and you know use all the Technologies for the other um for the other vendors um you can see that like performance are extremely well compared to tools out there um similar thing um you know often times you don't want to um just get P the data frame often times you want to you know get a
(12:39) materialized version of the drain data set maybe you're doing a parameter tuning you want to have a fixed Target that you're training on um so in this case you can potentially say obso offers the API and the old tools as well um to be able to say okay collect all these features um in a in a CSV file or a TF records file um and you know you know we we we Benchmark it as well um again for obss using the combination of dctb and and and and nof flight um and you can see that you know again the performance
(13:09) are significantly higher both because of this um timization of Point time joint DB but also because of the um you know outof FL protocol um so yeah finally um we're looking at the inference pipeline so the last part of the of of the mop SL cycle um totically it um the the INF pipeline is responsible for outputting predictions um whether you are predicting on a single vector or you are predicting on uh you know like a 500 500 um uh Vector input or you know a million rolls or something doesn't matter um one
(13:48) of the benefit of the FTI Pipeline and you can you can really see it here in the inference pipeline part is the unified architecture between um you know batch and train right so you know the the the feature pipelines and the training pipelines don't really need to know whether or not you you're going to be um you're going to be um you know doing real- time inference or you're going to be doing best inference right so um the inference takes care of that complexity all the complexity for for that is included and and limited to the
(14:18) um to the inference P itself um the inference pance does essentially two things right so um and this is really important in terms of real time um use cases the inference pipul retri is responsible for retrieving data from the from the fature store um in upso if you're retrieving a small set of data because you are doing real time inference we go to the online fidget store um if you're retrieving data for like a large patches uh we go to the offline part and the the other aspect it does the fut the future pipel sorry the
(14:49) in PIP plan is responsible for is actually um doing on demand Transformations right so there is a you know cost of use cases iue the majority of the use cases for which um the some of the features data is not going to be you're not going to be able to precompute it right it's going to come in using the request data from the request data and what we do in OBS works is we actually um do that from we use something called like pandas udfs right pandas GFS are um really powerful because you can run them on top of you
(15:20) know Panda series and so you can get you know if you are in the inference pipeline you have you are in a pure python environment um you can basically just the computer features on top of the panda series um but you can actually apply them if you if if you're doing for instance um large feature engineering or your backfilling large amount of datas you can take the same feature um you can take the same feature functions um as P UDF and give them to spark spark is optimized for that is going to push them down to the executors um and it's going
(15:50) to use Arrow to communicate between the executor and the the pandf make it extremely fast and extremely performant um again the feature pipeline the inference pipeline again it merges to merges to combines the data coming from the feature store combines the data from the request data and the on demand informations and provide it to the model for making predictions right and um OBS is a platform um provides the API to combine these two and to you know retrieve the data and so on and all the metadata about which features are needed
(16:22) and from where they needed whether they need to be computed on demand or they can be retrieved immediately it's all managed by opso and it's all of the offs metadata layer and Tim you can make predictions um we've done a bunch of benchmarks as well um for um for the real time aspect as well um we'll be looking at um retrieving data from the from from the feature store U we've done it for two um well we've done it for more than two you can you can actually look at the um feature store do/
(16:50) benchmarks URL that you have here um and um with I'm going to show you like two examples one for batch size one um and the other one for bch size 500 uh 500 being a good number that's usually use case where you're doing for instance recommendation systems um that's you know you have a like a large P of candidates um to be able to rank you want to rank to be able to you know recommend to the user and you know the larger the candidate poll then you know potentially um you going to get better better results in terms of uh you know
(17:22) more diversity of candid to to to give back to the users um you can see the difference between um couple different vendors out uh obser and a couple different vendors um and again you can find the code of the benchmarks to be if you want to reproduce them if you want to add your own system um you can find the code in the in the in the URL um itself and um yeah and some of the other benchmarks that that that we have done now if you go back and we take a a step back look at the full pictures of what are the you know the benefits of
(17:53) this new architecture and this new FDI pattern um and and we We compare against the data challenges that we had at the beginning um the first one being variety of data sources um the feature pipelines is the one responsible for dealing with all the this data sources all the um all the uh you know complexity of changing dealing with different data is all is all combined and and constrained into the feature pipelines um in OBS the feature pipeline can be expressed with any different any framework and so um we
(18:25) going to solve also the Second Challenge which is basically say okay I have you know B different pipelines running bunch of different Frameworks Ops can take care of all of them um again we provide an openingi to be able to actually um you know provide the feature store and later on retrieve features um the other challenge is disconnection between experimentation and training and production um you know the new uh the new setup and the new pipelines actually allow you to you know register features for for for experimentation and whether
(18:56) or not you're going to train model whether you're not you productionize the model um it's the same pattern the same API and it's it's it's one tool um to to kind of go through all all the steps um this one pattern for them and it's also one pattern for doing both pch in real time as I said earlier um the only really component that needs to be aware of whether or not it's retrieving features for a real time request and for which he has a bunch of slas against or as more like relax as today because it's
(19:24) it's a bad job running every night for instance um it's actually only inference pipeline right training Pipeline and and fature pipelines are not going to be responsible for uh for for for that and they not need to be aware about the um about the implication where the when the data is going to be needed now um if you want to try out this pipeline uh if you want to try out you know this pent um we actually have as obso available um a s platform right it's it's a free sandbox um that you can register um we launch it over um over a
(20:00) year ago and we have reached over 3,500 users right now on the platform um some like the platform is the same as if were on OBS customer and deploy it in your own VPC on the cloud or on Prem um the same API the same user experience as the same components for feature store so feature management um but also model registry and model service you can also you can also go and and serve your model um directly into into upso I said the same user experience same API that you will use um if you were upsource customer Enterprise customer um you
(20:35) don't have any infrastructure to manage um so everything is managed by us it's free um and you can just register and there is no there is no um time limit um we build a community around it um there's if you go on the csl.org website you can find a bunch of different examples that you can take inspiration from um all of them follow this FDI P pattern and so you can get a feeling of what the AP what what this ptn looks like in practice and we also have two amazing indicators Paul and po um they've been building a lot of tutorials
(21:07) and a lot of the um you know a lot of uh examples uh for the community um and you know they're really active in the community um and on upss now the Sal platform is is great uh but it's not meant for Enterprises is meant for as a as a Sandbox for you to build your you know examples or to build your own um you know site project and so on uh we don't provide any strict SLA it's a sh infrastructure for everybody and you have limited quots um that we also you know one of the things we actually get
(21:41) once we launch this um we got a bunch of people asking for okay can do I get can I get more ports can I actually deploy my own um my own you know Enterprise applications on top of obso right so that's why today I'm super excited to announce that we are actually releasing um the same user experience of servers as obso um so it's the same user experience you find today in serverless but targeting Enterprises with you know both Enterprise slas and manage platform as a fully managed platform um it has the same set of
(22:11) functionalities uh b f store model registry and mod survey it's currently being used by a couple different small set of users uh but you can register and you can join the waiting list uh right now by SC the QR code um and we open up a bunch of different um slots every every couple every couple of weeks and so we're going to reach out to you uh once new slot get available um you get a bunch of quots in terms of both online offline and number of model you can actually serve uh with again Enterprise slas and support from
(22:44) um the OBS team one of the things that really excited that we worked on really hard throughout summer um we actually made OBS available um across multiple regions um this was one of requirements that we work with um a Fortune 500 company um and um this is targeting Fortune 500 companies essentially right so um if you are for instance on Prem and or El on the cloud and you want to be able to um uh you know be available if one of your region goes down now you can deploy UPS so that um the data and metadata gets
(23:19) replicated uh between different regions so that if your region goes down um you can still um you can still be able to serve your uh applications and serve your business processes um through from from from essentially the um the other region um we have again this is mostly to um you know help Fortune 5and companies I said we we build it with a fortune for company um we're going to run webinars we're going to run a bunch of different events um going in details about um about these capabilities and what it means and how to deploy and so
(23:52) on um so you can you know feel free to um like join us um we have um a bunch of different events coming up uh we're going to talk about it we are going to be um in several US cities um over the course next next couple of weeks you can find all the events in this QR code um and that's everything for me um yeah I don't know if there are any questions I think I don't have too much time but yeah let's see if we can take them thanks Fabio very exciting very interesting and great to see the the the
(24:23) featur store platforms being pushed forward with with features like multi Region High availability and and serverless we have a couple of minutes for questions so I'm going to move over to the Q&A button thanks for people who ask questions using the Q&A button because often people use chat and that's really great uh I'll start with Joe Joe Schmidt asks um how does hopworks deal with time series data does it help to split the data by time to avoid leaking future data um and what's your answer on
(24:53) that Fab yeah I mean that's that's that's a that's a that's a really good answer like I think the I think the challenge when you're doing with with with the with the biggest CH when you're doing with the um time Ser data is making sure that if I go back one second if I go back all the way here if I'm dealing with M Ser data I I want to be able to or have different Transformations um um you know have different Transformations um you know join them together and making sure that
(25:21) they are I'm not licking um information from the Futures right so there are two aspects right um when you're dealing with time series data first of all is you end up with um you know bunch of different events um obss when you register a feature you need to tag um what is the primary key but you also need to tell what is the time of that features valed for right so let's say someone goes on the website makes makes an order that becomes your um your event time for that specific feature and when you do and join things together um then
(25:49) you know obss make sure and that's one of the pattern that you can see here in the poting time join um H make sure that the you can basically um you're not leaking data from from from the future so you're not joining the transaction done today with the profiles of the user done done tomorrow that's taken care by offs um behind the API so user don't have to kind of deal with that um the other aspect is one of the other things one of the typical um operation you do when you're dealing with time Ser data also it's it's
(26:17) lugging and and obviously um you know looking at you know what's the event in the past and stuff like this you know this is U something that uh we defer to the framework itself that you use in future engineering so you know obviously um pandas and and and Spark and all the like this have good support for doing okay what is the you know last what's the average order of the use in last seven days and stuff like this all this can be done by by the uh by the feature uh by the Frameworks that you're using
(26:43) for doing feature in genuity and then you register that um event with with obso as set of features essentially great thanks Fe there are some more questions but we won't have time to answer them live um I think Chris asks about duck DB uh just a clarification that duct DB is not the feat store and hops works it's just used as a query engine Fab can clarify that I think in the slack Channel if you go there and then there's questions on should you store label columns in a feature store I think it's a great
(27:09) question again go to the slack to to continue that discussion and Integrations with hws particularly with Vector databases we see that a lot for um personalized recommendations so I'm going to move on we're going to move on thanks Fabio um so we now have Uber I'm delighted to announce so we have Nicholas who's here not for the first time so Nicholas Brett markot he's a staff software engineer and Technical lead manager on Uber's AI feature store team in San Francisco Bay area and he specializes in serving data for ML
(27:38) models at high scale and he previously worked on performance of Sira at Apple and we also have parth chatani and he's a staff software engineer on Uber's AI feature store team again in the Bay Area he specializes in large scale distributed systems for ML infrastructure and previously he's worked at Microsoft teams amazon.
(27:56) com and ads chatbot thank thanks guys looking forward to this uh the floor is yours hey thanks I was going to int introduce myself but thanks for that great introduction so I guess we can just uh hop right in so first I'd like to give everyone a brief introduction of what capabilities and features Michelangelo's uh pallet feature store provides our feature store serves as the backbone for dealing with data in ml one of the first steps when you're dealing with data ml is feature preparation Pala AIDS users here by
(28:31) autogenerating batch pipelines and setting up streaming ingestion Services if the necessary features are already available in our common store Pala can help discover and analyze them this beats manual selection or Brute four ceration over many feature types and here in the center and at the heart of any feature store is the actual suring of features pet provides apis to consistently serve the same features from both an online database and offline batch systems low latency High availability and low cost are the name
(29:02) of the game here Pala also provides automated monitoring systems to notify users as early as possible of any failures or issues with data quality bad data is just as detrimental to prediction performance as a bad model lastly depicted here is the Michelangelo Transformer the convenience API provided to join and transform features consistently online and offline for a model so next I'd like to go over just a brief history of pallets Evolution to help understand how we got to where we are now back in 2016 2017 we launched and
(29:39) made public the industry's first feature store this had the core components that allowed for storing Uber's ml data in one repository and serving it online and offline at this time the focus was on batch features next then as Uber and its own as its use of ml continued to scale pallet needed to go through its own growing pains and meet the strong demand this meant optimizing for latency and high scale of millions of QPS at the same time more support for streaming features was built into the platform after data could be served at
(30:14) scale a couple of years ago the focus shifted back to the data itself where teams ensuring that they're using the best features and ensuring they remain high quality we added automatic feature selection and tools to ensure High data quality to address these concerns and that brings us to today where we have focused on feature apis embeddings and reliability today's talk focuses primarily on the feature apis and its related metadata which have helped ensure seamless operation and better modeling of complex
(30:46) systems so what level of scale are we looking at in Pallet our online serving systems serve a wide array of use cases across all major Uber products such as eats rides safety all summing up to over tens of millions of requests per second and with p99s under the 10 millisecond range offline serving is also no small task with some single training jobs reading up to hundreds of terabytes of data per training run along with so many models comes thousands of feature pipelines with so many touch points it is key to have a
(31:20) highly available and reliable system with minimal user involvement lastly in the topic of today are metadata changes which are in the thousands per week with many moving Parts feature deploys and code deploys it is essential to avoid metadata changes negatively affecting Production Services as a platform at this scale any small cracks in the system can have an outsized effect so what high level problems can a subpar metadata system cause first off is unreliability when bad metadata changes are deployed across the system it can
(31:57) negatively affects any number of services and products second is slow developer velocity without clean apis and tooling the system can be difficult to operate and debug and lastly is customer dissatisfaction so we want to feature store users and our team alike find the debris to work with anytime working with data for ML so now I'll provide a couple of problematic examples to illustrate all these potential gaps the first is the system misbehavior so first off we have an example of a bad config being deployed online this could be a change
(32:34) such as adding a new feature group incorrectly or maybe a change which routes requests to an online database cluster which hasn't even been created if this change gets rolled out it causes serious effects for Downstream services such as causing bad recommendations in the Uber Eats home feed or any other product so if these changes are rolled out quickly and with no Auto rollback mechanisms this could spell dis second we can have inconsistent metadata in the system depicted here on the slide we have user order features writing to
(33:08) one online database but the recommender service is trying to read the data from another reader and writers of the feature data are not in agreement of where the data is even residing this can be caused by multiple sources of Truth such as configs living and separate repos another cause can be incorrect coordination coordination of metadata rollouts um such as the metadata change being landed but not yet taking effect in the live system without tools to fully understand and strictly control the state of the system services are
(33:38) unnecessarily exposed to risk and our last example here is high operational complexity so in the image here you'll see a complex web of where Services fetch their features many use cases across Uber require isolated environment to avoid Noisy Neighbor effects we don't want one high spike in QPS from an experiment or relatively unimportant use case Bringing Down the most important models this results in a in unique setups per isolated environment also many of these cases are such high scale to require multiple database clusters as
(34:15) well as caches this adds even more complexity to the web if all these cross dependencies need to be constructed and maintained through manual metadata changes there many touch points for failure so our new API and metadata design are targeted to solve exactly these problems we've introduced much better validation we now maintain a strict schema design with added semantic checks to ensure cross en entity consistency and this helps catch bad configs as early as possible we have further unified the metadata instead of configs living in
(34:52) multiple systems we've centralized them all under one roof this simplifies everything and allows for better cross entity validations third we have made the system easier to operate by being more Dynamic and automated time to deploy and validate changes has been significantly reduced and finally we have added new abstractions to simplify the complex web of configs providing for better modeling of the problem space so now I'd like to hand it off to par who's going to dive a bit deeper into each of these
(35:22) Solutions awesome thank you Nicholas um for the wonderful Journey so far so as Nicholas was just starting to talk about the solution aspect of what how we solve these problems these are some of the principles that we wanted to keep in mind as we were building the solution out so first is we wanted to have like uh apis for all our first class entities that we you know Define in the system and we want uh to clearly identify and then we wanted a a solution which could work well when if you build a u on top of like our whole metadata system as
(36:00) well as we support like code driven interactions for for interacting with the metadata thirdly we wanted consistency making sure like all the metadata pieces live together they they we we have a clear uh way where metadata entities can interact with each other and there's no fragmentation at all in how metadata is is structured and where it's placed and then uh lastly we wanted to uh make sure our solution is such that it we can extend it for very future use cases that we haven't even anticipated completely
(36:35) yet yeah so next slide please so um uh looking at our Uber experience of how you know we built uh the pallet feature store and pallet being the first feature store we have like uh you know uh tried to scale pallet to millions of QPS and and with that experience that we have across like managing this complex millions of QPS across Uber we we we had the we took those insights and we came up with this unique uh you know schema and you can say object model here uh specifically you know features is obviously the heart
(37:15) of the ml system here and and feature group when we say here feature group it means it's it's collection it basically can you know have collection of features which are correlated under under the umbrella of a feature group right now we introduced a concept which is pretty unique and not unheard not heard of anywhere else it's called online feature serving group now this concept comes from our years of experience of how we managed the infrastructure underneath to support this much scale uh so online
(37:48) feature serving group what we mean here is a collection of all the various uh storage entities that basically uh come together when we need to serve a particular infant server for example and we'll go into examples of how we have structured this for various use cases but it's the abstraction that helps us cleanly bring all the storage entities together and then from an inference server perspective we don't need to leak any of the storage details to how what in the the infant server level uh the infant server just knows
(38:24) that yes I need to talk to this entity called online featur serving group and the rest of the details of what storage exactly we need to fetch features from where do we need to cash these features all of that is abstracted away so so it's a very clean abstraction similarly is the case for a feature group where feature group uh let's say is is dispersed to various online storage systems for online serving but we don't want to leak these details uh completely uh in a place where the infant server now needs to care about this so so
(38:59) feature group also has a wonderful abstraction and Link with the online feature serving group and that way we bring all of these Hardware you know storage abstractions very very underneath in one umbrella and all of the other entities don't need to care about it anymore which which makes it very easy for us to navigate the system and uh for customers for the pallet pallet basically on calls and and my engineers in general to interact with the pet ecosystem yeah all right so we can go to next slide yeah so here is an
(39:34) example basically you know of one of the tenets that we were talking about right and Nicholas started going into that which was cross entity validation so so imagine we have a bad configuration you know and and as Nicholas was mentioning when the bad configuration lands into a production system uh it leads to actually you know surfacing either error messages to the user or a poor experience where the recommendations are of not good quality because we had a bad configuration which leads to bad predictions so to prevent
(40:09) that whole chain of bad predictions what we have done is we introduced this feature validation service which can basically um given a metadata configuration it can validate across the all the entities that we've mentioned in the previous diagram and it can validate and make sure the the Whole Health of that entity ecosystem is maintained before the configuration is deployed to production in that way we catch any metadata problems right at the code review time itself we don't let it go beyond code reviews so that's something
(40:47) we uh introduced here to make sure like no bad configurations can be deployed ever to production from now on yes yeah yes next slide please the other problem that we uh had was like our configuration was fragmented in many many different systems to give an example uh we had like a cache configuration uh which was living in one particular metad data system there was datab database related configurations of which feature groups connect with which databases uh and all of that abstract all of those Storage level details that
(41:27) was living in another ecosystem and then we had streaming features related configuration which was living in third system and then we we have the metadata repository which we which is like the central place where our customers interact with pallet uh that was living in another system and basically we were in such a mess where all of our configurations were in these different systems and and U imagine a new engineer coming to our team and then like uh the the complexity in which they are interacting right now and like the
(42:02) confusion uh in which like they have to navigate to make make sense of the metadata you know is very very complex so so we we we took that feedback from our new Engineers on the team we took feedback from our customers and we we started rethinking we were like this is not the way we want to design a new system so so we wanted to unify all of these different metadata systems in one place uh so the what we did here was we we eliminated all of these different various metadata systems U and instead unified all of that in our metadata
(42:40) repository backed by a schema that we talked about in the previous diagram the object model right that way all of our metadata now is in only one place customers and palet on calls everybody has only one place to go one one single structure to interact with there is a solid schema now and and there is only one system which pushes this whole metadata to to the online serving as as well as offline serving so which makes life very very simple for our customers when they want to track a metadata change and also for our on calls when
(43:14) they want to interact with the metadata and want to track and see where the metadata changes are for for a given um particular change so so we unified everything in under one umbrella now we eliminated everything all the other configurations and now life is very simple uh to interact with as as everything lives in one ecosystem now yeah all right next Slide the other other other major change we did was um previously our metor but the way we were interacting with it and way we were actually trying to you know
(43:47) push some of the changes to our offline and online serving systems uh anytime a user or a pallet onon makes a metadata change we would iterate through literally and you can imagine in the previous slides Nicholas was mentioning there are thousands of these metadata changes happening on a regular Cadence and imagine having to iterate through all of them every time every time even a one change is happening we're iterating through all of them which is there in the metadata repository and then trying to push each one of them again back to
(44:18) offline and online serving and imagine as as as the metadata as the number of features feature groups grow the the the scale at which the push is happening is super slow and and when you make one small mistake in the system the roll back is also extremely slow now which makes the whole system extremely slow to interact with very fragile and and leads to a lot of online serving issues offline serving issues and and uh the speed at at which we can react to a problem is very very slow so which means we hurt the business a lot in this case
(44:54) so we wanted to re redo this whole push system because uh we have we felt we had opportunities to to enhance the system so instead of making it a full push system where we go through all changes or all particular metadata at once for any small change we came up with this incremental update system where whenever a metadata is changed we look at what particular metadata has changed we only pick those changes and push them to offline and online serving systems uh in an increment manner that way the speed at which the push is happening is coming
(45:30) from hours to minutes and also um we are able to react much faster when there is a problem we're able to link all the alerting with this incremental changes and we able to roll back automatically when there is a problem now so and the roll back is speed is also super fast because the we are only pushing what we have changed so so the the roll back also means we can react much faster now yeah all right next slide yeah so the other part to our pain of the old metad system was we because we had this many many configurations living
(46:06) in many many different places um that was one part of the problem and another part of the problem was our online serving system it was basically linking with the whole metadata uh as a code and you know generally there's a principle about uh making sure that your config lives in a different place your code lives in a different place in our case we were mixing up the code and the config right excuse me so because the code in the config was mixed up completely um every time we had to make a config change we
(46:42) had to deploy the config as part of the online serving code and and the rigor obviously is much High when you have to deploy a code change which meant that we always lost one to two weeks for any small change and this is fr frustrating for our on calls frustrating for our users having to wait for any small change to be deployed you're waiting now two weeks and you lose such such velocity which means that you know you could iterate on things much faster but now you're losing time just just for the deployment sake so we we we as we were
(47:17) unifying the whole configuration system we also wanted to make sure we stick to the principle where no config lives with the code any any more and we eliminate all the configurations that are living in the in the same place as where our code lives so we we we read it we as we were revamping this we brought the all the configurations inside the metadata repository and now it's you can see the number of steps is also reduced and also we no longer need the deployment to happen with the code now which means
(47:48) configuration changes they get deployed in order of minutes and we' have eliminated the whole cycle time for waiting week to to interact and really use pallet yeah so that that's how we've automated uh the whole on the onboarding system to pallet and we also reduced the number of places uh where configuration is living going forward yeah next yeah so coming back to online featur serving group um I want to go slightly more deeper into that concept because it's a unique thing that we have introduced here and and this diagram
(48:24) depicts the problem that we had before where we have a recommended service we have a pricing service all of these Services need to know which particular databases uh they need to interact with to get the features right and and on the right side we have these various feature groups uh like restaurant ratings user orders demand and supply and and all of them also need to interact and say yes I you know these feature groups need to be dispersed to database 2 database 3 database 1 database 4 right and and and you can just imagine the
(48:59) complexity when you are interacting with let's say hundreds of features and and just visualize the messy graph you would land into right where and this was exactly where we were anytime we had to even change let's say we have to make a hardware upgrade now we want to move from database 2 to database 5 now we need to know we have to build this we have to build this graph ourselves to even visualize okay which particular feature group which particular service is interacting with which database and which databases we need to update to
(49:31) even migrate right so so that was the complexity we were dealing with and any database change we would be you know any database upgrade we would be looking at months generally to make sure we don't cause any outage anywhere so that's the mess we were in before now with online feature serving group in the next slide yeah so with the abstraction that we have created it's such such simp simplified system system where all the recommended Service pricing service all the feature groups they only need to
(50:01) care about Which online feature serving group they talk to right and which they link to and that's the bridge between your online services or your feature groups uh that's the abstraction we created underneath if you want to swap out a database let's say two with database five there's only one place we need to update now pretty much and other places don't need to worry about those aspects which means it's a clean abstraction and and only one place that the on call needs to care about in that way the
(50:32) whole migration of particular database is so simple now and also easy to visualize as you as you can see the graph is very simple to visualize here yeah so the online feature serving group has simplified our interaction with the storage uh entities and we have simplified our on call lives thanks to that yeah yeah next slide please yeah yeah so with migrating to the new system we did encounter a lot of challenges now as we know pallet is at scale running at millions of CPS any small metadata mistake is is is a is a recipe for an
(51:10) outage right so we had to make sure first we do our due diligence comparing the metadata between old and new systems so that we have parity in the metadata right and then um for for which we used a thorough between old and new metadata system uh and we also made sure that the data Integrity is preserved between the old old and new system that way um there is no mistake whatsoever as we are migrating right with this for our offline ecosystems also we did something similar where we we did thorough testing we did thorough metadata comparisons to
(51:49) make sure everything lines up as we are moving the offline ecosystem which which where are training and other ecosystems use this metadata uh to make sure the training happens in the right way right we had a solid roll back plan uh with where we had a kill switch uh which could flip the which system we read the metadata from in matter of like minutes basically so so any mistake uh would would would we would want to make sure like we we could come back to the old healthy system and quickly right uh to make sure our customer lives were easy
(52:22) as we were migrating because we changed the underlying structure of the new metod it was backed by a new schema the old metadata did not have any schema we did automated back fills from old to new metadata and then our customers when we were onboarding them to the new system we had clear onboarding docks and we made sure that um because we had the automated back fills customers didn't have to worry about creating those new metadata files and new metadata you know entities we did everything for them and they they just had to use the new
(52:54) onboarding Docs and and that that was it to interact with the new metadata system um I'll hand it over to Nicholas to conclude here yeah thanks par so to wrap things up we'd like to re reiterate some of the benefits we've seen from improving our apis in metadata ecosystem first off is ease of use so with these new abstractions and more automation we are no longer hitting a lot of the misconfigurations that used to occur What Might Have Been multiple code changes before is just a single one second is reduced mainten and operation
(53:26) cost we reduced the number of moving Parts in the system making for easier Updates this improves the process for adding new capabilities into our system as well as performing tasks such as migrating from one online database to another next we have reduced deployment time in customer onboarding Times by clearly separating out config from code from config changes now we can have a simpler roll out flow that is independent of the code changes cicd so changing the metadata backbone of a system such as feature store which has
(53:59) so many moving Parts was no easy task and we are happy to now be seeing these benefits of our hard work at the end of this year so shout out to all the members on the team listed here on the slide who also helped make this happen and we'll soon be publishing a Blog with more details on our journey and hope for all you to tune in so I think we might have a couple minutes for questions now thanks everyone brilliant thanks Nicholas thanks par fascinating talk it's like it's like a a look into the future I think for many many of us here
(54:28) to see you know the challenges you have at scale uh one of the kind of cliches you get is that that every time you 10x the size of your platform you have to do a rewrite I don't know if you've heard that cliche before um but you mentioned there were two main areas here one was the metadata rewrite was fascinating and then you had the online feature serving rewrite so if we start with the metadata um you know what lessons do you think we have for for the community in general in terms of the importance of metadata and
(54:56) uh I guess some of the techniques you you worked on because um you know you present a bunch of them here yeah I think you know it's about modeling the problem space correctly having simple flows a lot of validation kind of all the points we talked on in this yeah and let me be technical now I mean you you're talking about you know the the way you did the incremental updates to the metadata often I think and if we look at many other feature stores they tend to use row oriented databases so transactional uh relational
(55:24) databases for metadata but you seem to have a a cumner store behind this and you're pushing incremental changes is there um a motivation for that no it's not a cmer store it's just a matter of changing how all the code changes we do have a centralized database as well as different like a different repository for Distributing in on the online services so just making sure that entire pipeline in end to end is is served in an incremental manner was what what brought a lot of the benefits into our system um so we have a question from
(55:57) from Ben online is how big is the metadata schema now that there's one unified metadata service can filling out many metadata Fields get burdensome for a user I mean yeah the schema in terms of schema we do have um many fields but but we have simplified the number of fields that user needs to interact with so we we divided what users interact with versus what palleton calls interact with so we have actually reduced the number of things users need to fill in now so which which makes it less for the US user the burden is less on the user
(56:27) going forward plus there is a schema now so users also have a easier time interacting with the system given that they know uh what field means what uh in the new system here I'm sure that makes for happier users um I have one more question on the online part so you know your your online feature um serving group it's it's backed sometimes by multiple different databases is that for multi-tenancy or per different performance characteristics of the databases or is it because teams are organized around that way or what's the
(56:59) main motivation for that yeah part you want to take that one yeah sure it's it's it's a matter of like basically you know us uh having to work with the scale at which we which we work with right like so Uber scale given the millions of QPS it's just uh hard for us to scale like let's say and have just one centralized database which can just serve everything uh it's also a matter of just sharding and you know our high tier use cases we want to make sure that we give them like really good
(57:29) experience with slas and all of that and we have very very extremely low latencies in terms of millisecond so so we can't afford to make sure we can't afford to have low tier use cases mixed with high tier use cases and you know disrupt the customer experience here brilliant and and those numbers tens of millions of QPS at P99 of under 10 milliseconds is really incredible thanks guys um brilliant fascinating as as always um we'll move on so I'm delighted that we have one of the Chinese uh hyperscalers the AI
(58:03) hyperscalers so we have WeChat we have yinhang here yinhang is a software engineer in wechat's ml platform team where he maintains the feature computer engine for their in-house feature platform he holds a master's degree in computer science from CMU and he previously worked with Google Cloud vertex AI feature store team and he's also an active contributor to the Apache art project that we heard about earlier H the floor is yours Jan yeah thank you Jim uh let me show my screen he how does oh here
(58:40) okay right we're good yeah okay cool um all right thank you everybody for attending my session uh my name is Jean I'm a software engineer at tenson wead and today I'm going to talk about our future compute engine for real time recomend commended systems so a little bit about about myself uh I'm currently a software engineer at W has ml platform team I'm the lead developer of our vectorized feature compute engine and uh I'm also a active Community contributor of Pachi Arrow because our engine use is
(59:11) a Apachi arrow and we actually uh contributed a lot of functions to uh back to apachi Arrow after our our engine is deployed and previously I was a software engineer intern with Google uh I worked on the Google Cloud vertex a feature store another feature store uh before I join vad and uh I got my masters in computer science uh from carik M University so some background um so wead is the biggest app here in China and um it offers a lot of functionalities you can think of it as uh the combination of Facebook and
(59:46) Twitter and Tik Tok maybe Amazon and wuber so basically we offer a lot of things to our users and we also use machine learning in a lot lot of scenarios uh so the mo the most prevalent usage of machine learning is for recommended systems we uh recommend a lot of stuff to our users such as advertisements articles uh videos live streams feeds like okay we seem to be having technical difficulties here folks um so Yin the speaker mood yeah as people can see we do have a connection problem Yin we're going to try and
(1:00:41) connect to him in the background and we'll see if we can get him back as soon as possible Yin you're back can you hear me yeah yeah I can hear you okay we lost you for for about 30 seconds there H sorry about that yeah because I'm in China so maybe the network between China and us is a little bit unstable sorry this the the the VPN okay I mean just continue your floor is your again and uh um I we we we'll let you know if there's an issue again thanks okay okay thank you thank so sorry about that okay uh let me here
(1:01:18) yeah so basically what I wanted to say is we use machine learning for a lot of stuff and uh the the future engine I'm going to talk about today is used on our recommendation systems uh so basically today's topic is going to be future engineering for recommendation and in our scenario feature engineering is divided into two stages so uh the first of which is offline feature generation so basically um we generate features from locks um I think this is kind of like a there's already like an industry standard so
(1:01:51) people use apachi spark for batd drops and Flink for streaming jobs this is also what we use for offline feature generation and the second stage is online feature extraction so basically extraction is to transform data in your database into features for the models and um these are olap like operations on small batches so basically uh for us every request is typically a few hundreds of items uh uh feeded to the model and also requirs low latency because it's online request and users are waiting for the request to complete
(1:02:25) so uh typically it requires very very few uh milliseconds for requests for us the requirement was about uh 50 milliseconds but typically the average time for online f exraction for us is about 10 to 20 milliseconds and typical examples of feature extraction Frameworks are Facebook F3 and open ldb online engine uh I think open LLB was here last year and uh uh Facebook uh publicized their F3 engine like three years AG [Music] ago um so what are the operations that we do online so operations uh typically online operations are more expensive than
(1:03:05) offline operations so the principle is to do uh everything offline unless there's a necessary uh condition that we have to do it online so here are a few examples of operations that we have to do it online so the first one is filtering so basically uh when doing things offline we're doing things with distributed uh machine for example we use spark is a distributed cluster and we typically use a distributed database and when things are distributed they are always Corruptions because you have to send data across different servers and
(1:03:37) uh the first thing in online extraction is to filter out the corrupted data so when there's so basically we use a filter operator to eliminate the invalid and abnormal values and uh the second one is joining so in recommendation systems uh we use a lot of cross cross features basically we need to combine user and item features into a new cross feature and fed it to the to the model and if we do this dra offline it will be too expensive and Bas I in my opinion it's basically impossible for large scale recommendation systems uh for
(1:04:10) example for us there's uh over a billion users and uh the item space is in the in the form of uh millions or even billions uh if we have to cross it offline that means we have to cross it for each user and each item then the keyspace will become millions of trillions which is impossible store in any distributed KV store uh so we have to do this drawing online and sorting and aggregation are typically performed on user sequences user action sequences and uh it is actually cheaper to do the sorting and aggregation online for us because uh if
(1:04:45) we do it online we'll have to do it for each request and if we do it offline we'll have to do it for each action because whenever user has an action you will have to update the uh s list or the aggregated result and uh typically in a recommendation scenario if we have uh so for every request user send us we'll have we'll give back a few hundred items or like tens of items at least and then the user may have very different a lot of actions on this request for example user may watch a video user may uh tag
(1:05:15) the video as favorite user may like a video user may uh follow the author uh and they may have a lot of actions on each of the items that means for each request there will be hundreds of actions so it's actually cheaper to do the Sorting aggregation online because there are very few requests compared to the actions and the last one is numerical Transformations uh examples are discretization and hashing and uh because typically different models have different parameters or different algorithms for doing these numerical
(1:05:45) Transformations if you do it offline we'll have to do it for all the models that we have but if you do it online because in the online stage we already know which model we're going to use for for this request we only have to do it for the model we choose so it actually saves a lot of competition uh engineering resources if we do it online um and next uh there's a few observations on the online extraction workload so first each request will contain a single user and multiple items and for each item we will compute the
(1:06:17) same set of features and the features will have fixed competion logic once they're deployed online because uh you know because once you started training the model with with the certain features you choose you cannot change the features anymore because that way there will be data leaks or inconsistencies between training and inference so you have to fix the computation logic once model is deployed online and that basically means the same computation tasks are repeated over and over again uh during online trans uh online
(1:06:45) extraction uh so with these observations it leads to a conclusion that it's actually the online extraction state is actually the perfect scenario for vector ization compilation uh it's perfect for vectorization because we will uh we have to do the computation for each item and uh and they are the same computations and compilation uh is good because we know the logic beforehand and we're going to repeat it for each request so we can just compile the logic into some uh fixed code a compiled code and then
(1:07:14) we just call it uh during the online extraction stage and that is our uh that is what our feature engine uses uh vectorization comp compilation proved very very efficient uh in our in our future engine so next I'm going to talk about uh the technical details or implementations of our engine and how we use vectorization and compilation to accelerate our feature computations so first uh as I said our feature engine is based on a Pache Arrow uh so uh what is a Pache Arrow Pache arrow is a standard for in memory colum
(1:07:48) or vector data layout uh it's actually I believe the most widely used vector formatting data analysis world uh for example for ad hoc analysis there's Pi Arrow the official python package for Arrow and there's pandas and there's polers uh both data frame analysis Frameworks and they both depend on Arrow and uh also some famous olap engines use arrow for example docb and matad valock engine and data Fusion is a query engine provided by the rust version of par arrow and also people use arrow for ml
(1:08:24) data for example huging face data set uses arrow for file IO and rate data set uses Arrow as a as a their internal file format no internal memory format sorry and uh apart from being a standard they also Arrow also comes with a complete toolbox for Vector data uh so the first thing is it's it's actually very expressive so other than the primitive data so people think of array as like just a flat array that's a primitive array for Arrow there's also list array map array struct Union and even extensions if you if none of the the
(1:09:00) previous ones satisfy your need and also there's uh IO utilities so basically Arrow provide utilities to convert to and from major file formats such as uh CSV Json uh Parkway orc and AO and also Arrow provide a uh zero copy serialization scheme for uh IPC so basically inter interprocess communication you don't have to copy you don't have to serialize anything you just you just copy the data to and from processes and uh also Arrow comes with a lot of compute functions so basically they are native functions that you can
(1:09:36) call to operate on Arrow data and uh apart from that Arrow also provides interoperability between languages basically it provides uh a package for all the major languages listic here and also I think C Swift and Ruby and a lot more so how do we use the patchy Arrow to represent features um in our scenario each feature value is represented as an arrow array or scalar so for user features uh it's quite simple because there's only one user for for recommendation uh so scalar feature is just a narrow scalar and sequence
(1:10:12) features are just primitive arrays so just simple array for for sequence and for itom is it's a little bit more complicated because there are a lot of items so we can't use a scalar to represent scalar features if you want to do vectorization we have to use a vector so which is a primitive array in Arrow to represent the scalar features so for example here we have this uh this array here to represent item ratings for example and suppose we have five items we'll have an array of L five and each single value in this array is just the
(1:10:44) score of the rating for for each corresponding item so the first one the first item will have rating nine the last one will have rating seven and you can see here there's a null value um so Arrow arrays natively support null value uh in this case null value just represent uh the features missing the features missing for for particular atom and uh for sequence features uh we use list arrays to represent uh to represent the feature uh for example here uh let's say for example movie tax uh the first one the first item will have action
(1:11:17) horror a list as its feature and also for five items it's a list array of L five and each of the AR elements is a list and uh there's also a Nuance difference to note between the amp list and the null list so here this is the third atom will have a ANM list empty list and the fourth atom has a null list uh so for the Nuance difference comes from for example if you want to get the size of the number of TXS the user uh item he in the end uh the third one will have have zero as a feature value and the fourth one will have null so the
(1:11:54) third one will have a value but the fourth one will have no values and uh next is how do we do computation with the paty arrow arrays so our framework our compute engine provide common operators such as join sort uh or mathematical Expressions to users and user Define a feature by combining these operators so for example here if we want to do a cross feature here is the definition of that feature so it takes user a user sequence and item id as input uh it first does um aggregation on the user sequence for example we take
(1:12:33) the the sum for each item and uh we perhaps want to do a sword on the on the sequence and after processing the user sequence we do a join with the with the item IDs to get the features for each item and uh once we have the feature for each item we do a hashing to Hash it into a value used by the uh by the model so basically user doesn't have to write any code or uh doesn't have to write any complex logic to in order to define a feature it's just uh the user just have to uh has to uh write down a couple of
(1:13:05) combinations of operators and that's it that's the feature definition and uh so how do we do Sy vectorization on AR Ras there are four major ways we do it so the first one is with lvm Git engine uh so the lvm GT engine is basically uh we compile our logic we compile The Operators into lvm ir and the lvm g engine will execute these IRS uh and the second one is Arrow native compute functions so Apachi Arrow officially supports a lot of compute functions to operate with arrow data and we sometimes our operator uh just call these computer
(1:13:44) functions to to operate on the data and the third one is compiler of factorization so if H for very simple simple operations uh if it meets uh certain standards the compiler will just automatically vectorize will automatically generate seed instructions for these operations and the last one is handw Rd sy intrinsics so in certain scenarios the compiler is not smart enough we'll have to call uh manually the simed functions in order to generate Sim Sim instructions so let me go over these four approaches one by one so the first
(1:14:22) one's lvm um we do this with gandiva gandiva expression compiler so gandiva expression compiler is a sub project of Arrow so it's originally developed by Dro uh and it was donated to Arrow I think in 2018 and it's currently maintained by the arot team I'm actually one of the engineers myself um so uh gandiva provides arithmetic functions pre-compiled to lvm so basically you can see here you can write your original function is z C++ or rust or even you can just hardcode it in lvm and the compiler will just compile
(1:15:00) into lvm I here means inter U intermediate representation so it's like a middle level U representation between uh user code and uh assembly code so it's like an intermediate one and uh gandiva would combine these functions into Expressions uh at the IR level so basically once you have the IR Ganda will uh combine these functions into a module and then it will leverage lvm for various optimizations so lvm provide a lot of optimization passes and um for example here we use Loop vectorization path for vectorization and there's also
(1:15:37) function inlining instruction combination and a lot of other stuff and uh we use gandiva expression uh for projection and filtering so basically we deal with mathematical expressions with gandiva so here's an example uh for example a simple feature is defined as a plus b time C and here is the gandiva expression uh in the IR form uh so you can see here at the very beginning of the vector body uh we do a lot of bit cust from double pointer into two times double pointer so double pointer is basically the input the input array is a
(1:16:13) double pointer it's it's just an a pointer is the same as arrays and um here it will be casted into a two times double array which means uh the elements of the ray becomes two * double which is the vector form in lvm IR since uh it is compiled on my Mac M1 machine uh which comes with rv8 neon instruction set where the maximum bit width is 128 bits so that's exactly two double because each double is 64 and two double is 128 and you can see here uh the the addition a plus b and the multiplication time C here are operated on the two
(1:16:50) times double so on the vector rather than on the double scalars so this is how IR lvm IR represents uh vector vector operations and here's uh how we we're able to do this with gandiva and uh well gandiva is actually very very fast it's it's I think one of the fastest uh possible ways to do compiled Expressions but it's kind of hard to develop and maintain because you know we have to first compile our code into into lvm ir and then we have to operate on IR level to com to combine them into expressions and it's actually
(1:17:26) also very hard to debug because we're essentially running a virtual machine and uh GDB doesn't really give us a lot of helpful information when we want to debug uh our code so um that's why we use scanda only for simple operations such as ma maic pressions and arrow also comes with uh this official compute functions that are natively written in C++ and uh these functions are are uh actually much easier to write and then therefore they support much complex operations so they are dynamically dispatched at run time so when you call
(1:18:02) a function uh it will go through a function dispatcher first and then it will it will match a C++ kernel depending on your input type and input size and uh then it just calls the kernel uh for for a data you just call the the kernel on data and then you get the output it's very easy and arrow provides a vectorized kernel for many functions and because it's easier to write it's just native C+ Plus Code uh it supports various complex operations for example source and aggregation all support it and uh another benefits of
(1:18:33) Arrow compute is all functions are exported to python so it's much easier to experiment experiment with compared to just C++ so for example here um so here I have a bunch of uh examples uh to to show you the benefits of uh show you the power of of compute functions so here uh the code is in Python just for demonstration purposes because uh uh python is easier to experiment with uh but the actual code we use is actually in C C++ uh so here for example sorting if we have an array here and we just call the compute sort
(1:19:12) indices function and we return the values sorted represented by their indexes and we call take on these indexes we'll get a sorted so take is basically materializing the array and uh we'll get the sorest array and here is the aggregation sum so if you call sum on the array we just get back the sum of the whole array and on the right right hand side the this is example of uh joining so basically we use this indexing function uh so we call indexing we we want to find the index of requested items in user history ID so
(1:19:48) here this triple 9 trip 7 triple 5 Are all uh item IDs and we want to find here the these are the candidate items and we want to find their index u in the user history and once we have the index with index in function we just call take again uh we'll get the respective watch time of each uh candidate candidate item so here in the end we have uh 50 for the third one which is Triple 7 and you can see here for user is 50 for Triple 7 and 30 for triple for triple9 here we have 30 for triple9 So This Is How We Do
(1:20:25) joints and uh well since since we started using Arrow we noticed that even though the computer the compute functions are very powerful it still lack a lot of feature operations so we actually write those feature operations by ourselves and contribute these functions back to Arrow so for example uh cumulative functions uh rolling functions are basically rolling Statistics over a fix Lance sliding window and a joyance list is basically if we have have a couple features we want to combine them uh into a list feature we use a join as list to combine
(1:20:59) them and parway difference is um to compute the difference between two consecutive elements so we use this for computing the difference between user user action timestamp so like how often user perform actions on our our atoms and integr run functions basically Runing functions into powers of 10 or powers of hundreds this is used for uh discretization and also Arrow supports uh temporal times temporal types such as time stamps and durations and it didn't support arithmatic arithmatic operations on them and we added this uh support and
(1:21:35) on the right hand side it's actually my GitHub handle and you can see here I was actually among top 20 contributors uh in the past in the past year for Pari arrow and uh the third approach we use is with compiler Auto vectorization so because Arrow arrays always stored in contiguous memory um for some lightweight operations it's actually too heavy to use gandiva or Arrow compute so we just rely on compilers to automatically vectorize these operations for GCC we just pass in the Tre vectorized optimization uh option and
(1:22:10) for Kang is enabled by default so for example when we are dealing with uh multiple arrays we'll have to do a bitwise uh end on their no bit map because as I said uh Arrow natively support now values so it uses a bit map to store their validity status and sometimes we use bit bitwise end we just do a simple code it like this and compilers are smart enough to uh compile into these vectorized operations such as like V move V insert and VPN are just the vectorized form of move and end and this insert is just to uh Pat the the
(1:22:48) memory and uh for simple operations we can just rely on the compiler but for complex operations they are not smart enough uh so sometimes we have to manually call the Sy functions provided by Intel and AMD uh to to convert them into Sy instructions so for example here our hashing functions we use a very complex hashing algorithm to Hash our values hash our feature values into tensors and um the compiler doesn't automatically uh compile them into Sy instructions so we have to so on the left side here you can see this is the
(1:23:25) the code we used to have uh which is which is to shift a 64-bit value uh to the right by by some bits and uh this code doesn't compile to S instructions so we have to call this see mm2 56 shift right and here's the shift left and here's or so they are basically the same version of of C++ operations we can call and uh these are the avx2 instruction sets so um with all four approaches we perform very efficiently the engine perform very efficiently on on vectorized data however uh not every uh request come with a large batch size so
(1:24:07) not every request come with a vectorized backr data so in some scenarios uh there are only a few candid items or even one cand item for example sometimes we do online training with just one sample and we have to get the features for that one uh item and also sometimes there's push notifications so we basically use an algorithm to decide whether we want to push a certain item to a user so there's only one kind item we just need to decide whether we want it or not and in these scenarios there's only one item so
(1:24:35) it's not NE it's technically not a vector if you if you use a vector of L one you can still use a vector of of size one to store it but uh The vectorized Operators will perform very badly if the b b size is very small so there are three overheads so first one's array overhead head uh Apache Arrow arrays need to store array metadata for example the type of the array uh the length of the array and uh the the bit map and also uh Arrow arrays always aligned at 64 bytes because it's it's better for vectorization if you are
(1:25:09) lined at a certain 64 128 bytes uh but if you only have one data which is like for example in it's only four byes so we're basically storing 16 more data than I need and uh there's also a vectorization overhead uh for example if you call a seed instruction it will perform the the instruction a whole 128 bit or 26 bit data but if you only have a 32bit integer that will be extra uh extra cost on on computation and also there's a compute function overhead because compute functions are uh there's a
(1:25:43) dispatcher so you have to go through a dispatcher on every function call and this overhead is actually very small but if you want to have one data it can't be amortized over the the vect over the vectorized data so uh the overhead will become significant if you have only small small batch size so how do we solve the the performance issue for small batch sides um the answer is native operators so basically for all operators we provide to users we also provide a native implementation native meaning non vectorized and in this native engine
(1:26:16) every atom feature is stored separately as a single value and uh we dynamically dispatch to Native and vectorize when the feature request comes so basically uh in our Benchmark the the threshold is eight so if there are fewer than eight items we use a native engine and if there's larger than or equal to eight items we use a vectorized engine and uh another problem is how do we guarantee the consistency or the equal equalness equality between these these two engines uh well we have a full test coverage we have unit test on the
(1:26:49) operator level and then we have endtoend test on the engine level to guarantee the the equality between these two engines and um we also have a daily pipeline to examine this from feature locks so basically every day we have certain requests that go through both engines so we we send this request to both the native engine and the vectorized engine and we lock the result and we have a daily pipeline to examine if there are any diffs uh so with these two approaches we can guarantee that this 100% equal and another performance
(1:27:21) optimization we use is operator Fusion so basically there's an overhead for each operator call uh there's virtual dispatch there's we have to validate the input and copy it into the function and we have to allocate memory for the output and um these calls these these overheads can be uh uh can be saved with operator Fusion so basically most operators can be fused with projection and filtering uh normally these operations for example if we do a projector with a sword with with a filter normally they will have to go
(1:27:54) through three different function calls but with operator Fusion they can be combined into one operation uh into one operator in location and these overheads can be saved so the last uh part is the performance benchmarks uh so here we can see a difference between the vectorized approach and the native approach uh you can see as the number of items increases uh here the the the black line is native approach you can see it's it's a very sharp linear well it's linear because uh here the the x-axis is not is
(1:28:25) logarithmic is expon exponential sorry so you can see exponential curve but the the actual curve is linear and you can see the blue curve which is a vector wise one uh grows much slower than the black one and the threshold as I said is eight it itom num is less than eight native is better when it's larger than eight vectorize is much better and uh s64 vectorize is six times faster and 128 vectorize 10 times faster and uh that's because the overhead is amortized for a larger batch and also actual deployment statistics uh once we
(1:29:00) deployed it online uh we see a 50% uh down in CPU usage uh on deployment uh we can see this right line here is the CPU usage we can see it dropped from uh 40% to 20% uh so this 50% drop actually saved us millions of CPU course uh over the last year okay this is uh all that I have to present uh are there any questions fantastic Ian this is a a great set of um feature engineering uh tips for for high performance online feature computation uh we're out of time unfortunately with we had our little Network disruption there we're going to
(1:29:40) keep schedule we're going to keep schedule today we are supposed to have a two-minute break so we're going to start again in two minutes time you can ask Yin questions on the slack Channel I have a couple questions I'd like to ask pop over there and ask them Jen Yen if you could join the slack channel that would be great and and we can get take them in there so I'm going to take our other people take a quick break we'll be back in two minutes all right that was a quick
(1:32:07) break uh we'll get cracking again so I'm delighted to have uh Alexander Christof here from wafer Alexander is a staff ml scientist on wafer's marketing science team previously he led development of the Merc feature platform as well as several initiatives improving marketing personalization which is a a really hot topic and area where people are applying feature stores uh at scale Alexander great to have you thank you uh let me just see if I can share my screen here um yeah let it's gone well so far let's not jinx
(1:32:43) it you able to see it yes we're we're alive thank you great all right thank you very much um so yeah I'm excited to talk to you today about um this Mercury project which is a one of a few feature processing tools we have at wafer um it was built with a specific set of use cases in Mind by um you know a number of folks pitched in but it was kind of on average about a two to three person kind of project that found a lot of success um it does some unusual things that I want to tell you about today um so the
(1:33:13) core idea behind Mercury is it's a very opinionated future processing platform specifically designed around lowering the effort to Define features similar features and to lower the compute necess uh compute resources necessary to calculate them in the long run the goal of this project is to improve ml performance because small teams can effectively manage more ml signals um and therefore have uh their models have access to uh more features to learn from this is achieved because at its core Mercury assumes you aren't writing a
(1:33:42) single feature at a time rather what you're doing is writing building and consuming features as a group together um features can be as few as say six or they can be significantly more over a thousand so maybe it's helpful to illustrate this with an example let's say you're trying to figure out how popular product is going to be with customers if you're working in such a problem space it's not uncommon to have similar features like the two that I'm showing you here you can count the
(1:34:08) number of times the product has been ordered on let's say different browser experiences and over different time windows and Mercury treats this not as just some accident um rather it's a core design concept for us Mercury kind of nudges you to Define and build these features together and I'll describe this how later but before I do that what I actually want to discuss is a general framework for uh framework for trade-offs in machine learning systems that will help you both understand the decisions we made with Mercury and um I
(1:34:38) think it'll be hopefully applicable to some of the ml applications you may work with um so at its core this is a conversation around tradeoffs so if you take any production Enterprise ml system you can collect it characteristics into like three main groups here in generally we face trade-offs between these three axes so the first of these is predictive performance at some business critical task many widely used statistical metrics for this F1 ndcg um but also many business metrics can also be thought of as falling under this
(1:35:10) category then you have resource efficiency that's the number of CPUs gpus Cloud costs or maybe it's hitting your latency budget and lastly there's the human effort needed to maintain and evolve this system you can measure that things like headcount hours uh spent velocity things like that so A Core theme of this talk is that we should be deliberate about the path we want to take through this three-dimensional space so in that vein um I'd like you to think about the following example um here I'm showing you two models one's in
(1:35:41) red one's in purple the red one's more predictive but it's also more computationally expensive it's more operationally complex to maintain so which one of these would you deploy which one of when faced with this trade-off the last time you had this at your company which one did you favor so in general you know there's no single answer to this question it depends on all kinds of things it depends on can your team handle the supporting the more complex system do you need something simpler um can you move your resource
(1:36:11) budget or is it fixed you know maybe you don't have a way to get more vram or you can't move your latency budget and I think another question is how valuable is this business problem um to your company what I want to emphasize is that a big driver in all of this is opportunity cost you know what else could a team be working on here it's helpful to introduce this framework of like tall and wide teams tall teams kind of tend to iterate in the same problem space over time and incrementally improve a core function wi teams tend to
(1:36:43) kind of build something good enough and then move on to a net new problem that maybe hasn't been covered by ml before and you know it's not all always clear that the needs of those two team types are going to be exactly the same what I want to emphasize here is that company context can determine where we prefer our ml systems to be in this three-dimensional space it's not often about making a single model maximally predictive rather than it is about optimizing the portfolio of ml systems a team can effectively um support whether
(1:37:15) that's a few or many um now within this concept of tradeoffs I think it's important that we talk about the flexibility of our feature platform so um specifically I want to talk about how much flexibility users should have in defining the features that they use should they be able to build anything in any way or should there be strict guidelines for how features are produced and consumed at first it's very tempting to think everything should be permitted how can we know ahead of time what some ml practitioner might need to do to
(1:37:45) deliver business value um but at the same time if everything is permitted it's harder to provide provide operational guarantees at platform level for the features and the ml systems um a more restrictive approach is often easier to maintain and better out of the box so both of these approaches have merits but I personally strongly suspect that on average like across our industry we probably overvalue flexibility a little bit because it's easier to kind of Envision this hypothetical best case performance we can get through
(1:38:19) flexibility but we have a harder time thinking about the like longer term maintenance and overhead and opportunity cost that we get from increased flexibility so the reason I think flexibility comes at a high cost is that every ml practitioner you know is always short on time there are too many experiments to run there's too many features to write there's too many projects you could be working on and you don't ever get to put into practice all of the flexibility you might be given to you so another way to
(1:38:49) say this is that teams have bounded time they're not always trying to perfect a single model they're looking to maximize the total value of a portfolio of projects and we can think of this in terms of a team having like a caring capacity a total amount of things that they can support rather than just focusing on the velocity to ship one thing so down at the bottom I want to show you the approach we've taken which is to First make features more efficient and maintainable to produce get a lot of them and then over time as you have
(1:39:15) access to more and more signals models can become more predictive out of the box so um the way Mercury makes features more maintainable is to reuse the recipe and pipeline for similar features and the key idea here is that related features can be thought of as you know kind of filling in the blanks on a common pattern um I've shown two examples of this in these gray boxes you can quickly see from the one in the top that yeah you can be filtering by different browsers or aggregating over different time windows and and through
(1:39:45) those combinations you quickly get a lot of Leverage it's easy to imagine being able to get dozens more from the from the pattern I've shown you and for completeness you know there's another example uh below that so in preparing this talk and as you've kind of heard from others you've heard multiple people use the term future group I think it's a widely appealing phrase but is one that's a little bit overloaded so I want to be uh follow suit here and be very specific about my definition that I'm
(1:40:12) using here um when Mercury talks about a future group we're thinking about two core things one is um you're sharing the same template pattern here the second is that you're sharing the same uh Source event so there's um that allows you to basically build the features together all at once effectively um now within that I also want to take out take a bigger picture view and and kind of introduce this notion that like mercury has a full hierarchy um at the bottom you have individually programmatically generated
(1:40:46) features that get all built together through this next level in the hierarchy which is feature groups and then we have an additional notion which is something we call a feature family um which is this idea that if you're counting let's say the add to carts across different geographies well you probably want the orders to and maybe the times of product has been favor um so that um higher level in the hierarchy is a tool that helps with Discovery and also helps with um um yeah users basically being able to
(1:41:19) understand what features they want to use so with that I want to Briefly summarize where this approach has taken us um the emphasis is on helping users Define and uh maintain thousands of features um and to do scoring for millions of uh entities every day this enables us to run hundreds of models on Mercury um in production the real Focus however is kind of these user experience um improvements so some numbers rough numbers to share uh a few systems migrated over from previous pipelines onto Mercury uh when they did so um they
(1:41:51) observed let's say a few perc Improvement uh in their target predictive metrics for net new development when team started working on completely new projects they reported sometimes reductions of two to five times in terms of um time it takes to develop a new model and one team reported um saving up to four hours a week on the pipelines that they got to deprecate as a result of switching over to a centralized uh product so um with that kind of um out of the way I want to talk about focus in further detail on some of the
(1:42:26) key architectural enablers behind Mercury um I won't go into everything but rather I want to focus on um the kind of key enablers of this mission to Define and produce many features efficiently I'll focus on what I call the paved path it's shown here with these kind of purple boxes so raw events get pre-aggregated uh from those pre aggregations features are built as grouped uh and consumed across scoring most often through sparkml libraries and there going to be four key lessons I want to share from that pave path which
(1:43:02) I want to highlight because I think they're generally applicable regardless of whether your future processing system is going to look like Mercury or potentially look quite different so they're about the importance of pre-aggregation about the ability to package features together as vectors um an emphasis on reproducibility and uh different ways we can drive future reuse so first of all I want to talk about pre-processing so you probably know that if you want to compute an average over some set of uh events or
(1:43:32) some set of um facts in your data store you don't need every single event every single row of some table um you just need kind of sums and totals so you can pre-aggregate data and kind of boil it down into just what needs to get used later so here's a madeup example we have some madeup products and the price of those products products in various orders and across various geographies so rather than Computing averages by directly scanning through all of this um what we do is store sums and totals and when it comes time to Computing features
(1:44:04) from this we have a lot less work to do um similarly the process is also helpful if you want to enrich data say if you want to rather than grouping by Geo you want to group by let's say style um and maybe count the style of uh products that a customer is buying well if the style the product isn't in the event itself you can just join ahead of time to save yourself having to do it later but still create essentially the same core data structure and we found significant savings by having systems pushing compute earlier into the
(1:44:33) pre-processing to make future uh Downstream compute run faster um so despite being very opinionated about this data format the approach actually supports many different types of features averages extremas sums counts so forth right uh probably more that I haven't listed here it doesn't support everything you can't easily count distinct values and there are some complex sequence processing things that obviously are a little bit harder to do but nonetheless like some of those calculations can be approximated pretty well through these
(1:45:08) approaches and um furthermore you can choose to aggregate over different types of Windows um I know lots of feature processing systems do this um but here I'll just say we kind of have um two two things are enough for us we have uh for features that have up to a one-year look back window uh we use daily biding um or or things smaller than that and for things beyond that um we can combine uh both daily and monthly aggregations okay so now given those Aggregates I've shown you uh I want to talk about how Mercury builds features
(1:45:44) and from those Aggregates in groups and packages them as a vector so um busy slide I'll walk you through it but the goal is to have a quick picture of what this looks like and we're going to make a group of features that all at once um for both average price and total orders per A supplier and we get that across various geographies and across various time windows so at the very top on the left a user provides a list of entities for which they want to calculate the features so this is in this case suppliers dates um from that user
(1:46:16) provided list Mercury actually Builds an entity mapping layer um so map suppliers to products because the data that we need to build this feature is aggregated at the product level and then the mapping data is joined to pre-aggregated data uh that's this top table on the right um along the way you Group by on you group on things or aggregate on things like the time window the geography the supplier and then you do the aggregation that allows you to compute values now once all of that's done all of your
(1:46:52) features um are each feature is basically a different Row for let's say a fixed supplier here um what we do is we pivot back uh into a single Vector um for the entity and this actually deploys all the features and produces them all at once while actually needing to do only a single scan of the large underlying data okay so these large vectors may seem like they're kind of bulky and difficult to use but we've actually found they can be used quite flexibly and and easily particularly in sparkml so I want to just give an example of
(1:47:28) this so here we have two of these feature groups we can uh one of them has the numbers you can see in red one has them in blue what you can do is concatenate them together so this builds you a single vector and then you can have multiple models who um are packaged together with uh what is in sparkml something called a vector slicer this allows them to essentially pick out from this Vector only the features that a model needs and this packaging actually um makes it possible for lots of models to reshare to share the same vectors
(1:48:01) while not having to actually use all of those features and it simplifies the operational process so that you can run you know many many models that are all sharing the same data set um so the next lesson of these uh four this is now number three uh that I want to share is about how the choice of Upstream data sources influences the requirements of feature processing to explain this point I have to introduce a tiny bit of terminology and the reason is I think feature store can sometimes be a little overloaded um I think it
(1:48:32) helps to break down the functionality into four key parts so there's a library that's the collection of recipes by which you make features that could be SQL could be a yaml file could be a collection of python functions then you have an engine which is how those recipes get materialized into values that could be streaming could be batch could be some combination thereof you have archival which is the ability to store outputs of feature computation for further use and of course you can also cach for low latency
(1:48:58) retrieval sometimes when you're building features from data sources where you can't reproduce past state in those cases the information might be getting uh overwritten or you don't know when it got written into the source at all in these cases you can turn to feature archival to give you a measure of online offline consistency but um this still has some drawbacks right you might need months of historical data to train a model particularly if the events you're trying to study or trying to model are rare
(1:49:29) events you might need to look back for a very long time those also when you cold start and build a new feature you have some period where you need to accumulate new features for training now on the other hand if the data source you started with um has an easily reproducible historical state so like maybe it's an appendonly log that replicates the data that was being streamed in real time and all of the timestamps are properly you know provided then you can design a feature engine and feature Library around that
(1:50:00) fact um and produce and reproduce features quite reliably in practice excuse me and this actually diminishes the need for uh feature value archival and helps you save uh quite a bit of money on storage costs in our case so um so the fourth lesson I want to talk about is different mechanisms that we found from this architecture on driving feature use so we spend a lot of human and machine time writing calculating features we should want to make sure that those features get used um earlier I mentioned how feature
(1:50:36) vectors can be sliced and consumed by multiple models um particularly in sparkml I've also talked about how Mercury reuses pipelines to build features together um now I want to talk about a different kind of reuse which is the ReUse of a feature definition across multiple entities when building features let's start with another example so on the left you have data that is pre-aggregated at this product date level in a previous example I showed you you can group these products by supplier um and use that to compute future values
(1:51:07) however it turns out if you hadn't you know grouped on supplier and instead you were grouping on product class well all of the subsequent recipes Downstream uh all of the subsequent steps in the recipe Downstream would have been exactly the same uh similarly if you had kept the data at product level you could also do all of the subsequent um after grouping a product level all of the downstream steps for calculating the features would be exactly the same so um this is a remarkably powerful idea it means you
(1:51:39) could write a hundred features at for one entity so let's say you could write features at the option combination level um that would be something like how often has this particular red king-sized bed frame bin purchased and then you could actually reuse that feature at the next level in the hierarchy which is how often has this bed been purchased for all different colors and all different sizes you might even be able to reuse the feature at category level so like how many beds have been purchased right this values that you're Computing are
(1:52:14) different but the single recipe can actually be reused and this pattern can actually be reused in many places because there are many places where you have hierarchies of entities like the ones I'm showing you here um whether that's in ad campaign management um whether that's user accounts um belonging to different businesses so forth um so that's an often kind of unusual form of of reuse um I think there are other drivers of reuse I I want to kind of highlight quickly um so first I think it's important or or I think it's
(1:52:50) helpful that we have leverage from being able to produce many features with fewer lines of code you can read all the feature definitions your model uses and um this actually reduces the need for some forms of metadata management second I want to highlight that discovering features by metadata alone such as who uses them who owns them when were they created is often secondary to just being able to um know whether the feature will improve the model performance for the problem that you're working on and for
(1:53:18) this reason um just as the earlier speakers from Uber alluded we've invested in automated and scalable feature selection methods so that you can Traverse these large feature libraries to find features that are helpful to your problem not just on metadata alone and last I want to point out that our that in my experience you know the single most effective way to actually get ml teams to reuse each other's features is about having clear expectations around what happens in the event of changes to Upstream data um
(1:53:48) who's going to be making changes to to to the to the definitions um who's going to be having to retrain and so forth and combined I just want to share all of these because I think all of these are incremental Parts in scaling reuse and therefore scaling the number of features that each team can effectively use because they don't have to keep their own copies so with that um I just want to provide a little bit of intuition um for why mercury has been effective in making models performant um making lots of
(1:54:17) features like this um is not doesn't seem at first like it's guaranteed to work well um but I want to put the the results in the context of um some previous theoretical results about something called random kitchen syns this isn't a proof but it's a helpful vehicle to build intuition so um to do this um the intuition depends on the following analogy think of your Enterprise data Lake as a kind of neural network right let's think so on the left we have a neural network it takes inputs on the left i1 I2 through through linear
(1:54:50) algebra and some nonlinear functions you get the numbers in the middle H1 to H5 those then get consumed um to build the output a one a common way that we build intuition about the functioning of this network is to think about the middle layer H1 to H5 as kind of building features um from the raw data right um and because the model trains over time um and learns better weights um you can think of the the network actually iterates to build better features okay so then now on the left let's look at the data ecosystem a very simplified
(1:55:24) picture is you have raw data um perhaps in the form of some event logs you write features to transform the raw data via some functions and then you combine those into a model over time your uh data Engineers ml Engineers data scientists tune the feature definitions to make the features better um now that brings me to this paper by Ali rahimi and benr um in the interest of time I'm going to try to distill the paper through these two pictures on the left if you visualize what's happening in the training process of a neural network you
(1:55:59) have these um hidden this hidden layer um these values H1 to H5 they depend on i1 and I2 and in the plot what we're basically showing through these colored marks is how much each one depends on i1 and I2 now let's say there is a best case performance where these five um hidden units these things their uh dependence on i1 and I2 is represented by the black stars so the goal of training the network is so that over time these um colored marks move around to be on top of those uh black stars and that's what happens when you train a
(1:56:36) conventional neural network now what this paper shows you is that instead of doing that on the left what you can do is on the right um rather than trying to tune the featurization process you just initialize many many features at random and and apply a simple learning procedure to figure out how much to weight them in fact by using an L1 penalty you can use sparsity to basically throw some of them away and what this paper does is it shows functional uses functional analysis um to basically prove the models you get
(1:57:05) are very similar with high probability but there's this further benefit that they train up to 10 times faster so to further distill this down the the key idea here is you want to replace a slow endtoend learning process with a fast high-dimensional Kickstart and then you want to quickly learn how to do waiting so if we translate that to the Enterprise data warehouse what I'm saying is you can take two approaches right you can iterate to build five perfect features um or you can make many features and learn to weight them well
(1:57:43) essentially what I want to suggest is that programmatic fature generation gives you this on the right of this inset it's a Not So Random kitchen sink uh it's a large basis of features in a complex functional space that's hopefully very close to the best case you would have if you tuned your features by hand and in practice because we have finite time to train models the models you get out of this are actually quite performant now I want to be clear I'm not saying feature quality doesn't matter features should all be of a high
(1:58:11) standard but what my message is is that you want to maximize the value delivered by a portfolio of all features and over all of the models that consume that it's hard to know in advance which ones are important so it helps to have a large library of high quality features to draw so lastly I just want to situate this in what I think is a growing Trend over the last decade there's been a considerable investment in so-called automl Frameworks that take a given data set optimize training over that data by
(1:58:38) handling things like hyperparameter search and missing data imputation the methods are very powerful they've saved a lot of human effort they become the basis of offerings at many Cloud providers um but these methods only work work with the data that's been given to them and where I think there are still opportunities is about extracting more data from the warehouse from what's available and making it easily consumable the area is much less mature but I'm happy to share some of our first 4as into this problem space um and I'm
(1:59:07) excited about what future changes are going to look like so thanks and with that um happy to take any questions Max Million Alexander that was a that was a tour to force I think you know we went from a great templates on on how to create features in in marketing domain um you know to counts and frequencies and really intuitive I think for people and then feature reuse uh you went into great detail about some of the great things you've done there and then you finish off with this Vision I mean it's a great vision for data
(1:59:37) Centric AI really um you know the data Lake as a function approximator a neural network um what like what would the loss function be for these features and you know we have gradient descent to update the weight so what would be that I mean where does domain knowledge come into feature engineering is domain knowledge part of our future or what what are your takes on all of these kind of in questions ringing around in my head at the moment yeah I I want to be clear this is a vehicle for building intuition not a formal proof um but I think the
(2:00:08) the if you kind of think about this maybe to continue the analogy with this kitchen sinks paper one of the things that's important is that your randomization over feature space um at least in in that paper it should be saturating you you should kind of cover everything I think the place that domain knowledge you can very easily see it still applying is the notion that you have to have coverage over relevant Fields right so it's much more about getting access to data so um maybe you have information about product reviews
(2:00:40) maybe you don't have information about um incidents how often do things break and need to be returned so the domain knowledge is going and saying okay that's the missing Source we have to think about how do we pull that into our system and get better coverage of the basis and I think there's less of like aggregate over s days versus aggregate over 10 days um kind of questions which are very incremental I think the other thing is there's still a lot of domain knowledge in label engineering um and
(2:01:07) and a lot of data Centric work there obviously you know don't have time to go into all of that but I think there are still places um where um it's it's just really about shifting prioritization and where we invest heavily and what are the things that we think are maybe like lower return because as I've alluded to multiple times we're all uh very strap for time and so we have to prioritize I definitely agree that automation is coming Aro strev has a has a question a more praic question what does mercury
(2:01:37) look like in practice is it a domain specific language templates yamama files um um so it's a combination of um the SQL and and yaml files um there are uh and it's I kind of showed this it's a it's built on a combination of big query and Spark um for the the core processing cool that's brilliant thanks a Millian if you have more questions for Alexander please hit them in take them in the slack uh we're gonna move on again and um I'm really delighted to have George O Callen here from Gartner
(2:02:14) George is a a Gartner analyst on the analytics and AI for technical professionals team um and she covers feature stores data literacy analytics business intelligence tooling analytics governance and previously she had been a cognitive neuroscientist specializing in the anal analysis of FM fmri scans of the brain to understand development and most recently she completed postdoctoral research fellowship at um the NIH in the US studying neural correlat of depression and adolesence fascinating stuff and I think we're also both um uh
(2:02:47) graduates of Trinity College Dublin which is great to know too over to you Georgia great thank you so much for the introduction um I am really really thrilled to be here I'm going to try and share my screen so you can see I haven't used uh we're yeah we're not there yet now we're going yeah we're great how are we doing yes perfect always have to go between so many different modalities great well thank you so much um really interesting talks so far this going to be a little bit more higher level because I have a
(2:03:24) an interesting perspective or at least I get to speak to lots of different organizations who are at various stages of trying to build this out themselves or um or wondering you know what products in this space could potentially help them uh but and I know this isn't an interactive session but what I want to start with is a question just you know if you can think to yourselves how good do you you think organizations are really at getting their machine learning models into production so I'm talking about a reliable pathway they've got a
(2:03:58) great success rate they're very confident in their process and in in our research we've actually found that it's just 10% of organizations can get at least three quarters of their model into production so that means that 90% of organizations are still struggling to create that reliable pathway so that they can be really you know good at this and one aspect that organizations are still struggling with is how to get B better at managing their data for machine learning so that they can create that reusability reliability
(2:04:35) and reproducibility of features so what I'm going to cover is a little bit about the problem I won't dwell there I know we're all very familiar and then to go a little bit more into some trends that we see in terms of what people are interested in um you know what's happening in the market and then what these conversations usually boil down to is that question of build versus buy you know what capabilities do we need is this something that we can do ourself and and you know what might that look like so
(2:05:07) what would some sample architectures be so talking about the problem you know in our data that we found it takes on average about seven months for people to develop a model put it into production and that's only if you're staff correctly so if you have some Talent short FS that average Rises to 10 months and we've all heard those numbers you know data scientists spend between 60 to 80% of their time just finding data and preparing it doing feature engineering before they even get to building the
(2:05:43) model and since data scien to skills are so coveted so valuable at the moment we really don't want them to be spending so much time especially when often it's the case that they're just duplicating the work that has already been done by other people so we want to shift this so they can spend less time on that feature engineering component more time developing models productionizing them optimizing them so to do this we've got to tackle some of the main data related challenges that you face during that
(2:06:18) machine learning model development life cycle and the first is a lack of reusability it's been mentioned already you don't want a lot of siloed work that isn't reusable uh particularly if people then end up having to resolve the same problems over and over again another issue is reliability because after you put in so much effort into developing a model and getting it into production you want to make sure that it's durable and provides value for a really long time but then training servings you is such a
(2:06:49) big problem and it can arise for a variety of reasons and then the third problem is reproducibility so you know it's really difficult for a lot of people to recreate the exact data set that was used to train a model and you know even if people have retained their code you need a lot more information about where the data came from how was sampled time Windows to establish point in time correctness um and you know there are increasing the you know really valued cases where this is necessary so if you you know need to um you know buide by
(2:07:27) some model audit regulations if you need to do explainable AI or even just for model retraining and some of our data shows that people do this at least once a quarter for any given model and so if you're talking about doing this manually for one model yeah I'm sure you'd be fine or maybe even tens of models although you'd find this extremely difficult but people are trying to break that barrier how do they scale and get into hundreds or thousands of models and so the challenge of trying to manually
(2:08:02) manage features and other artifacts for machine learning just you know becomes more pronounced when you're trying to scale up so you know what many organizations want to know and and what they come to us for is this something that they can solve them eles or do they need a product for this and then you know if not if they're looking to build their own solution what would that implementation look like and across the last two years if we break down the types of requests that we get for information about half generally fall
(2:08:37) into that theme of still even just understanding what a feature store is then you know wanting to know what's the state of the market how mature is it best practices for implementing feature stores pitfalls to avoid and also real interest in case studies people want to know success stories how much value are these really providing to organizations then 26% are specifically interested in vendors so they want to know who's out there how does one compare to another and and even um how they compare to other platforms that
(2:09:16) they may already have like DSM platforms mlops platforms sometimes even certain you know data management platforms like semantic layers um but then we still have a good portion 21% who want to build a feature management solution themselves they want to understand more about the essential capabilities or how to evolve their existing implementation so if we focus on those first two cash atories so the inquiries that we get from clients so we see that despite the idea of a feature store being around for a few years there are
(2:09:57) still a lot of people who are confused confused about what capabilities really constitute a feature store and what the underlying architecture should be and one reason for this is because you know if we look across the market not all feature stores are created equal so if you break really down into some buckets there are still some out there that just serve as a repository for holding or training and test data sets and then many more that also add on that serving component so for batch or online serving and some vendors are better than others
(2:10:35) and then while many clients that I speak to take this for granted actually not all products out there can orchestrate the data pipelines to keep features up to dat and this is definitely not a trivial thing because if we know uh and we've seen already depending on the requirements of your models um you may need you know data to be refreshed at really high rates um you may need on demand uh feature transformation pipelines so this is this is not an a um a trivial thing um there are also some vendors that jump straight from you know
(2:11:12) the creating pipelines to the serving so not having a storage aspect and they're o others that uh their product is more following a virtualized approach um so you know more flexibility in terms of what underlying storage modalities could be used in compute rather than having a unified storage uh of features and then finally not all uh contain monitoring out of the box so if you can see from this people are understandably quite confused when they're trying to compare their options and then this is made to
(2:11:48) kind of further Complicated by a high degree of overlap in places with data science machine learning platforms ml Ops tooling some even monitoring tools or even things like data versioning tools or semantic layers and when we specifically look at dsml and mlops tools a few have Incorporated what we'd consider to be a feature store into their product there's been a few more over the years an initial kind of Burst when when came up in this area but really it is still a small proportion of these platforms
(2:12:24) overall and those that don't have kind of an explicit feature store still have some feature management capabilities often so they can in often cases orchestrate your data pipelines at least for batch updates um some you know they often offer model monitoring and production some offer data monitoring um some can provide some uh feature reuse capabilities so you know reusing engineering code in different workflows so again people come to us and they say well we have a particular product you know what um you know what
(2:13:02) feature management capabilities do we have do we need something that's going to plug in this Gap basically if they identify one um and on the other hand we have a whole kind of group of clients who would completely deliberately avoid a platform like this because uh you can see that they just um they don't want to be locked into a particular vendor that their preferred strategy across the board for machine learning is that they have a composable platform so it's made up of components some open source some V
(2:13:36) to breed some custom Solutions and that's uh you know the the Strategic direction that they have taken so so when people come to me and they ask ask you know the question do they need a vendor could they build this themselves um I like to pose back the question that it shouldn't necessarily be can you but should you particularly if something that already meets your needs is available off the shelf um and the opposite can also be true sometimes you know when when people come first with the the you know wanting to know
(2:14:12) about the feature store this can just lead to a product Centric discussion when they haven't even considered what their own requirements are yet so we want to take it back a little bit start with um you know more of the idea of feature management um so what we have is you know the concept of The Logical feature store so it's it's a bit more flexible because it lets organizations Define and implement the capabilities that are proportionate to the requirements of their machine learning portfolio because because you know the
(2:14:49) answer to this question of build versus buy and what your architecture should look like will depend on the scale of machine learning operations within your organization and the requirements of those use cases the types of capabilities that you need and it very much also depends on you know what in-house skills you have um and you know things like resources like money uh you know and time that you would have to undertake this project because it's not trivial obviously the more complex your requirements and your use cases the
(2:15:21) harder it's going to be to build out and maintain this solution yourself and then on the other side like much more simple requirements don't often necessitate necessitate a full-blown you know feature store product in the in the kind of traditional sense so whether you know anyone here is just starting to think about feature management or you're already more mature in your implementation uh I want to just walk through uh the feature management capabilities that make up the logical feature store solution in more of a an implementation
(2:15:59) technology agnostic way and then based on these capabilities we can go over H different implementation options so the first key thing to this is to have some ability for for storage of pre-computed features um in an ideal scenario data scientists would be able to commit features to this store themselves um then within this repository you need to have features that are accessible so that they can be reused so here we're talking about some kind of UI or catalog um where people can search for features find what they need you need to be able
(2:16:37) to tag to that certain policies and processes so you can govern access um in a way that balances democratizing that data and also securing it then within this catalog you need metadata to make features understandable so things like feature um descriptions definitions transformation code when they were last updated how often are they updated lineage basically the kinds of of uh metadata that help to promote trust in your data which will facilitate reuse then you know you want to accelerate the development of new models
(2:17:15) um so you want a way to be able to pull data sets for training and testing but you also want to facilitate that faster time to production so you need a way to serve these features directly to models and without needing to replicate code build you know new pipelines so this serving it could be batch or on demand it kind of really depends on your specific requirements and then to establish reliability you want to make sure features are constantly validated and monitored can prevent poor data quality or Drift from disrupting the performance
(2:17:53) of your models in production and then finally Version Control features it's really important so you want to be able to allow a feature definitions to change over time but still be able to serve the right version of the right feature to the right model in production so if we look at all of this together we know that many organizations have built out all or some of these capabilities to varying degrees and that there are several product offerings on the market we've already seen some examples and I know that we'll see many
(2:18:28) more across the course of today and they're largely referred to as feature stores or sometimes feature platforms so there's some variability there um but as I alluded to earlier not all of these Solutions will have exactly the same set of capabilities so what we really need to be asking first is not what product you should select but what are your requirements and then what architecture can support that and this is overall The Logical feature store approach so we try kind of Coach clients through this thought process um
(2:19:08) so that um you know basically they're getting something that's aligned to their specific needs um so for example let's say you just have Fe features and models that are updated in batch you know what might a feature a logical feature store look like in that context so you know at a very basic basic level you can store pre-computed features in some dedicated tables in an existing relational database in your organization so they can be retrieved for offline and training and offline model scoring it's
(2:19:41) really not groundbreaking um some people are exploring the capabilities of some Modern cloud databases for doing indb analytics you know so for some organizations that work might work really well you know gives data scientists the ability to create feature tables themselves the danger here is that and maybe some of you have come across this you can really really quickly rack up some huge costs um if you materialize a bunch of features that you don't need or if you're iterating through feature definitions that's not
(2:20:16) ideal um and uh you know so for that reason and and others you know particularly governance reasons uh organizations that have these capabilities don't really want them necessarily to be used in this way um so if that is the case in your organization you're kind of back to that problem of trying to figure out well then who's responsible for actually taking my code and translating that into materialized features in the store so it's it's not an ideal scenario um but if we are going back to
(2:20:52) the um you know uh logical feature store kind of capabilities that I mentioned before uh it's not just about being able to transform and persist features keep them up to date but we also need to be able to find and understand those so you're talking about adding to this then some kind of feature registry and catalog and this can be very homegrown here we're talking about a very you know like a simplistic implementation so it could just be something like your future registry could be well organized git
(2:21:25) repository um and then the catalog could be something Standalone you're managing yourself there's some open- Source tools that can do this set of more basic level um or if you have a an Enterprise data catalog that's available and you are allowed to use it um because that's not always a given um then that could be something that you use to basically catalog your features and add that metadata uh and basically encapsulating then all these capabilities uh is is The Logical feature store in its basic
(2:22:00) implementation um but if we consider this obviously it doesn't include all of the use cases that you may potentially want so for a lot of people who might just explore this as an initial scenario often need to graduate off this H pretty quick because as soon as you you know talk about scaling up the number of models you have in production or you know if you've got um lots of features if you need both batch and streaming and you've got both batch model scoring and online model scoring then that previous
(2:22:32) approach isn't going to cut it um and we all you know know having um you know attended some of the kind of early uh um really interesting webinars on building a feature store that when people have approached this problem they usually then end end up looking at two separate databases um to handle this these kind of diverse use cases one optimized for you know um scalable storage and the other optimized for low latency of retrieval and um you know the The Logical feature store it's not uh something brand new that you're int
(2:23:10) introducing it's often recruiting existing technology that you have in your stack so when we look across um the various Solutions um that have been previously you know captured on on our featur store.org website very common options for offline include things like snowflake or big query and online feature stores are most often key value stores like redis or Dynamo DV um but in this scenario you do have to think about uh how you know what are your data pipelines uh that are feeding features into these Stores um they're
(2:23:49) typically seen as separate um and again you can be using existing uh technology spark EMR other for ETL and orchestrating things with with airflow but you do have to think about in this kind of scenario if you're doing this yourself you now have two databases that you've got to manage maintain and have consistency across them and you need orchestration to push features from your offline store into your online store so that you're only retaining the latest version of of every uh feature and this is even before we have touched on demand
(2:24:28) so I think what I'm trying to illustrate here is that you're ending up with now you've got to um be able to have um you know a much more comprehensive solution additional catalog capabilities you've got many more features at play and it it you know a lot of people who attempt to build a solution like this some are more successful than others um others are kind of starting out on this journey and they're wondering like should we commit to this should we keep going um you know and others that have built this um and
(2:25:04) they found that it was fine for a while now they're looking at the next evolution of this they want to be able to um manage this complexity um a lot better it's getting kind of too much for them uh so you know when we talk about when we talk about the more um you know comprehensive you know logical feature store approach that we um that we see and when people are trying to emulate something like this you know people often start out building something before uh fully realizing how complicated it's going to get so if we
(2:25:44) think about that Evolution you know people people tend to start off with something small that they've built-in house and then they might graduate to some components that are open source or some similar light solution that they're customizing and incorporating um some uh kind of piece together components but when it grows to the point where they're finding it difficult to maintain then they start to really examine the market to think about you know is there a vendor solution out there that can really simplify this for me because it's
(2:26:19) getting too much of a beast um they want to you know set up poc's with vendors um uh but there are still plenty of customers that we speak to who are fully confident in this um who have achieved something similar um and you can see even from the speakers today that this is definitely done um but you know in the majority of cases though uh particularly when we're talking about um size of the Enterprise the number of people that they have in on staff it really you know and even the existing Tech you know technology components they
(2:26:57) have in their you know in their Tech stack I think the real question isn't you know could we do this but the question should always be should should we do this um it's not something to take lightly and from experience um we've seen that you know only a smaller percentage of of organizations can actually get to something like this so to bring that all together um you know organizations want to put as much care into managing their features uh as they do with their machine learning models the aim overall is to create that
(2:27:34) reusability reliability and reproducibility um you know they feature Management systems that I've seen they vary across organizations even within organizations and they evolve over time so with the logical feature store approach we've kind of outlined this flow to help people to make a decision so the very first thing that they have to do is understand the current state of feature engineering the requirements of their machine learning portfolio um you know the kind of data types they're working with serving
(2:28:08) requirements you know the scale of operations and also what inefficiencies they currently have and then based on that to determine the kinds of you know feature management capabilities that they need and you know thinking about something that's going to satisfy their requirements it's you know that balance between something that's not overly complex and you know has too many capabilities that you don't need versus what's going to kind of future proof you and allow you to grow and scale over
(2:28:38) time and then part of this is to review the uh existing tools that you have as I mentioned in many cases people people already have a data science machine learning platform or an mlop solution so there can be a lot of overlap uh and then you know if the decision is made that you have this Gap and you need to fill and you're thinking of build versus buy so thinking of whether this is something that you can build yourself or do you want to use an off-the-shelf product and then you know for your logical feature store whatever
(2:29:13) your implementation looks like my advice would be to appoint an owner early on so maybe the lead data scientist or a senior data engineer somebody has to manage and maintain the system you want to make sure you establish and reinforce best practices for its use like making sure everybody adds relevant metadata when you know tagging new features to the store or that there isn't duplicated features there uh because the last thing you want to do is for all of your hard work all of your efforts um to turn into
(2:29:50) something like what we see happen to dat Lakes all of the time turn into to a swamp um so yeah thank you so much this is this has been um a pleasure H to and and so happy to be invited to speak at this thank you to hopworks for hosting and for all of your attention thanks Georgia fascinating and and you did a better job I can say than any vendor I've ever heard of peeling back the layers of complexity of an ENT featur store and I think those really really fantastic stuff I'm going to ask you a quick question about um the interesting
(2:30:23) statistic at the start and you may not know the answer but you said 10% of companies get 75% of their models of production do you have any stats on how many of them are running future stores no h no This research was done and that was a b before um we didn't include uh the presence or or you know absence of feature stores one the question questions I think that that would be very interesting for the community um and of course Gartner are very famous for the hype cycle and I don't remember seeing featur STS the
(2:30:55) hype cycle where would we be where would you think we are as a community right now yeah um well actually I have I've um championed the the feature store and it is on the hype cycle for machine learning um so it's been this is the third year that it's been there yet now the first year it was just feature store and in the last two years it's been logical feature store um um so to have more of that kind of flexible term okay I I haven't I actually missed that so where are we on the hype citec
(2:31:24) are we at the top or are we coming up or down I'm I don't I'm coming up coming up to the top um so it's it's something that really still not everybody knows about as I said like there's still significant proportion um of my calls where I'm still just really helping to ground people in what it is and what it isn't um um so I think like you know over over the next few years hopefully we'll see the adoption catch up to the interest I think so so if you have questions for Georgia um you can put
(2:31:59) them on the slack um we'll be around for hopefully you can have time to drop in there Georgia and and we can uh continue okay brilliant um so we're going to move on we're going to talk uh G to have a talk now from delivery hero we have breno Costa breno is a seasoned ml engineer with many years of experience in ml driven software development Over The Last 5 Years within ml platform teams his mission has centered on delivering solutions to empower data scientists and ml Engineers within application teams he developed and
(2:32:27) delivered two feature stores running and production as well as other platform components to streamlined uh different staff to the ml life cycle such as model development deployment and monitoring processes we're glad to have you bro um how are things go and let's try and let's try and get over the the hurdle of sharing your screen okay uh thank you thank you for the introduction I think you can see my screen uh yes we're good I think that's you so okay stage nice yeah hi everyone uh so in this session I will present
(2:32:59) this uh future s solution that we have um in the future store I think the focus here would be uh will be on the um the how the feature store is driving the efficience and quality for uh some feature Engineering Process in some teams at deliv here and I'll will talk about our compx workflow and some parts of the architecture and before jumping uh jumping into the presentation itself I just want to talk briefly about the deliver hero uh if you don't know um and where my team fits in the organization and delivery hero is a food delivery
(2:33:45) company uh founded in Berlin um that became a global company uh delivery hero is a holding of different brains and we are present in over 70 countries across the world you might have used some of these apps um of some of these Brands here like fodora in Europe or food panda in Southeast Asia Glo in Spain pidia in South America and all of these brands are part of the part of the age and uh we have a internal platform called Pandora Pandora is an internal name that poers some of these brains of delivery hero and uh I am from the ml platform
(2:34:32) team uh within Pandora and we have some cross functional squads in Pandora uh these squads work on different aspects of the product and I think the our our mission as a team is to standardize some um the DML life cycle we try to provide some platform companies to cover the different uh parts of this uh life cycle that's our mission um we have some other different platforms within deliver hero that use different solutions but just to uh show to you how how this an platform team fits in the organization um back
(2:35:17) some one or two years ago uh we were evaluating the our context um in our tribe and we have the this kind of context um the data science and Engineers they create their mod implementations in different GitHub repos and we provide some model interface and they have to implement the training and the inference parts and they use it to create a features for ML models inside this model reples but this became inefficient for the company as the number of people teams and projects scale up and we saw that features are
(2:36:02) not easily reused across different projects um similar features were created over and over again and there are some lack of standardization for the the process um like the feature um feature generation and feature quality process and we decided to um move forward with the feature store idea and we decide to implement this uh feature store um as a way of mitigating part of those issues and the future store acts as a central component that allows the people to create serve monitor features uh this is not only the store part let's
(2:36:49) say but I will show some other parts of the architecture and we we've seen that this uh has been increasing the future visability and the most of the future generation monitoring process are standardized and as a consequence we've seen increased consistence um and quality and reduceed effort to create new models and in our case we have some different kinds of features for example we have some features which are calculated by in real time let's say because um they depend on the input of user um for example location is one
(2:37:33) input provided by the uh by user to use the deliver app and we have some features calculated based on their location we also have some features calculated every minutes but the the most of features are calculated in batch I will focus more on this batch part in this presentation because I think this we have more platform components um provided for this use case um let's talk about workflow um in the in our case we decide to create one feature rep uh all the features are the same repo and we maintain this feature repo as a platform
(2:38:22) team but the users can contribute to this repo to create features to make configurations and the same repo is shared with different teams um they have permissions to create brand open requests and so on um and within this repo they just need to clone this repo in their local machines and they can create and test features using their development tools let's say they have vs code or Pam this development environments and everything they they need for development purpose is out there they just need to um just need to
(2:39:02) create the feature transformation codes they have a CLI to run uh these features they can create some configuration to monitor the features they have a CLI to run the monitoring modules and they have access to some reports and so on and when the development is finished um they open for request uh request reviews from their peers and to this this is also part of the uh the process to gra to guarantee the code quality and consistence I think this is very important and the C pipelines are triggered as soon as the pr is merged
(2:39:42) into main branch and those pipelines updated update some remote configuration files uh some f flow dags they don't need to interact with the orchestrator with the a flow uh to uh to run the features uh this we have some pipelines that um make this um in automated way and just to to show some highly architecture uh we have some components here the feature Transformations components uh allows the users to create features using SQL or python uh they can choose according to the use case um a feature monitoring component uh we have
(2:40:29) two kinds of U monitoring One is using rate expectations to set to run some ass assertions on on the data and also a component to uh detect drift drift detection and this uh these are pipelines managed by the F flow and the future Transformations the pipelines ingested data to offline in online store and as offline store we are using bqu um to to run the SQL Transformations and to store the data the historical data and we also use the Reds as a online store to provide the low Laten database for model apis and fist we are
(2:41:18) using to provide registry layer um some materialization uh jobs and also to provide the SDK to get historical features and uh online features uh this is the high architecture um let me talk about the components feature transformations in Python this mostly using when they need to write some features and that need some more complex Transformations that cannot be managed in SQL uh or when they need to use some python package to apply some transformation function and that is not available in SQL they can use this um these we rely
(2:42:07) on kubernets to run the transformations in Python and this is orchestrated by the F flow um and we also have this module to create the feuture transformations in SQL data scientist can write their features using a SQL uh and this is definitely the most used one I think the the combination of DBT and big quy uh gives us um many benefits um both both tools are extensively used at V hero um but I think they are mostly us it on the data engineering side um but we decide to use the especially DBT um because it provides some benefits
(2:43:01) for us U let's say big quy is a tool um that makes it easier to manage the the pipelines uh your SQL scripts for example if you have uh complex transformation pipeline uh you can decompose your pipeline in different steps and DBT provide some functionalities for that it has a good usability uh it's flexible for different data sources and it has a simil integration with big quid and big quid is good for also for main reasons because it it is seress and provides a high processing power to bring scalability to our workloads
(2:43:51) and regarding the cost in live project we have used the flat rate compute pricing to manage cost and in staging for development we have used some recent feature uh reled by byid which is the alt scale um to out to scale the slots the processing slots and theity um just to provide one example of feature Transformations um uh in the feature repo they have a this kind of folder structure for example there is a folder called features and this folder contains a sub folder DBT and there are some features grouped by entities um some
(2:44:38) examples of entities are vendors products and customers and but for this example I just create one um project called called sandbox uh I cannot just close some details on the feature Transformations but just to give you you an idea of this just create one vop popularity features. SQL file and this is and the content of this file is show at the right uh in the file you can see at the the top of the the file we have some configurations is a mix of DBT configuration and B qu configuration and with this configuration uh we can def find some uh
(2:45:25) configuration for the tables for example the partitioning and the clustering and we can also make some configurations on DBT uh how DBT will materialize the data uh what will be the uh incremental strategy for DBT and other aspects of DBT can be defined here here and the data scientist can write a SQL file and this is an example if you look at the line 15 there is a brackets this is part of the DBT syntax um with DBT you can call some functions or macros from DBT and this helps to create the the scripts and just to give another example at line
(2:46:15) 25 five there is a a function called ra and in DBT you can use this uh ra function to uh use the results of a table uh that will be produced by another script in your project for example order with Matrix is another script called orders with matrix. SQL and when you do that when you create your SQL in this way DBT will automatically generate the dependance graph for you uh you don't need to um to do no yeah uh ndbt also offers uh CLI with the CLI you can run uh the the SQL scrips you can uh run the all the scripts you can run a subset
(2:47:13) of them you can also run some tests you can create tests for your SQL uh and you can manage the dependence graph as I mention for example this is a a a screenshot of a documentation page from DBT and in this documentation page you can see the lineage graph generated by the DBT the vendor popularity features at the right of this um lineage is the actual feature table let's say uh and this these scripted use order with Matrix as a dependence and other RI matrics use another ones as dependence and DBT provides this uh this kind of management
(2:48:04) for us I think one benefit of U another benefit of the BT is with this pipeline DEC composition we can also reuse intermediate Transformations for example the orderest past um 60 days is a SQL scrip it um that can also be re reused because this will produce a table that can be reused this another benefit of DBT you cannot reuse only the features you can also reuse other parts of the Transformations and other component of the our feature store is the feature monitoring part we have two components as I said the first one is quality
(2:48:53) checks uh this component is built on top of Great Expectations uh Great Expectations is uh also extensively us it at delivery hero um but for our use case we decided to create one wrapper on top of Great Expectations to make it easy for data scientists and Engineers to create this and for example the the folder structure is quite similar than the Transformations one they just need to write one um module for example ven features is a monitoring modu in this context they need to write a function to Fat quality checks and they need to
(2:49:41) write these expectations um for the data and this this is a syntax from the Great Expectations and they also have a CI to run these monitoring models and have access to the reports and these reports on the right side is generated by great expectations and they can see the number of of evaluated expectations uh how many expectations have failed and they have details about the failure they can use this report to uh to debug the uh the issues and to fix the the the problem this the the first one uh the second one is for drift
(2:50:25) detection um the folder structure the the ideas is the same they have this folder structure they can be use the same python module to define the monitoring module vendor popularity features but for a drift detection they need to write uh uh this function f drift config and they just need to return this drift config and this drift config contain some um some information about The Columns that will be uh analyzed The Matrix that will be used to uh calculate the drift the distributions and the threshold for each column and
(2:51:10) this component is built on top of evidently AI when the pipeline runs it cause evident C to runs this drift detection and they also have a c to run this monitoring module and have access to the reports they can run this in their local environment and have access to this reports this is an example of a report generated by this drift configuration it has uh six stest and when one one test fails you can see that it was failed and uh you can see some chart and this is also automated I will show later how this is automated but
(2:51:59) they have access to these reports on uh the live environment and we uh as per our experience we have detected a lot of issues with these two components uh for example unexpected duplication of keys in some dat Source tables because of many reasons because someone changed the um the application that produce the data for example this one reason and there are other um detected ISS uh for example some events that happen in some countries that that was triggered by some event that we don't have much control uh on um this uh has happened some some
(2:52:51) time or the classical error let's say some data production pipeline has changed it has changed the ETL scripts or uh has dicated some table field and so on and that produce Inc incorrect data and all of these issues can be detected uh by these monitoring components and this brings some uh quality and reliability for the future data which is produced in the future store uh in terms of Feature Feature registry um we are using the Feist as I mentioned and the Feist you can Define the data source that you want to use and
(2:53:42) you can Define the feature View and the feature service for that example I just Define here one feature view with the schema with a data source from bqu and with the schema you have to define the name and types and for feature service I Define this feature Service uh with only one feature view but you can combine some feature views uh to create one feature service um and feast provides this uh user interface with the entities with the feature views feature Services uh created in your uh registry you you have access to this uh
(2:54:27) feature view they can um ver on the features and using this uh using Fe they can also create a feature views using different data sources for example they can create using stream data sources or some files as a their sourcing and so on but in the future St for bat features we use um the B CR as I mentioned and and the feuture serving part uh we have to uh create some setup to deploy the these different R instance in different geographical regions because we have uh some con strs about the Laten some requirements type requirements
(2:55:18) about the Laten for model VPI and we have this multi Regional setup uh just put two regions here to give an example uh Asia East one and Europe West three um but the idea here is we have the the Reds in different regions and we have the M of VPI deployed in different regions as well and we can have the model Ser API the same region than Reds and this to reduce the the total latens and with this atap and with some optimizations on fish SDK I think it's important something important to say um we have to make some customizations on
(2:56:05) on the feast to materialize data in different regions because it's not kind of supported on feast and we have this atop in we have a good numbers of latens um we are able to um for some use case we are able to fetch uh data with less than uh 5 milliseconds or P99 and this are a good a good number for our use case and for pipelines uh we use the F flow to orchestrate the future Pipelines for example this would be like the uh the dag for the this example proposed uh by me this presentation we have the we can reproduce the same dependence graph
(2:56:59) that is generated by DBT we use the DBT manifest file to generate this dependence graph on the F FL and we can re reproduce the same if some task fails we just need to resume from that task and to save resources computational resource and they can also Back Field tables there is a configuration uh that can be used to back field tables and these dags are generated dynamically programmatically they don't need to um interact with a flow at all and these dags run on live environment and if some issue happen for
(2:57:43) example uh future transformation is failed or the data quality issue is found is raised they they receive like notifications they can have access they can click on on the issue and have access to the reports uh for these we have the reports stored in our metadata tracking server U both data quality and brief reports and they can be verified by users and just to finish my presentation uh some takeaways from our side I think having this Str component actually promotes the uh reability of features I think at the beginning this might be
(2:58:30) hard to get adoption from all data scientists because um we have to on board them in into a new to and but little by little they are sort of convincing when they see that they can reu some features uh from the the repo um when they contribute to their features to this repo and this will be reused in different models and this is very important for the long-term objectives long-term goals the of the company because the data scienes can leverage existing features and this reduce the creation of redundant features and also to reduce
(2:59:18) the engineering efforts on squats since big part of the job is provided as a service and I just put one some articles here in presentation when you have access to the presentation can go to our Tech blood to have more details we have two um blog post on the feature store and one for feature store one for feature monitoring and another about the personalization strategy at delivery hero yeah thank you so much brilant thank you bro great to see see the great work you're doing in bring machine learning to production at Li hero uh I I
(2:59:59) have a question I'm going to start with a question about um Georgia's statistic you remember in the previous talk artner she said that only 10% of companies at 10% of companies 75% of their models make it to production are you in the 10% I delivery hero in that 10% no no I I think we have many models going to production using store yeah but do you think like I mean just to go on on that do you think the future store is helped increase the percentage of models that make a production and you know do you have any estimate of
(3:00:37) that yeah I think the future story is um is helping the the the data science to create more models to reduce the time to create new features and yeah I think this has some impact on on this right and and it was really fascinating I think this is the first talk we've had where um you've talked about using DBT for feature engineering we at hoper we wrote about this actually in the summer I think it's going to be a growing uh area of use for uh feature stores so feature Engineering in DBT and SQL but have you seen um many
(3:01:14) many limitations in in engineering features of DBT because you know not all the libraries are there that you might want to have in spark or python or or even flank yeah I think uh the this SQL features cover um prob a big part but this is only a part of the um total uh amount of features for example if they need to generate some um vector Bings for example this sorine they cannot use uh DBT and SQL but I think this SQL is a big part of is still a big part of the the feuture engineer and I think it covers most most of our use C right and
(3:02:00) then just one quick question from Alexi on on on the chat um how good is Feast deployed on top of Google big query and RIS in terms of performance can you do all the things like materialization feature retrieval on demand I know you talked about support for multiple regions what's your experience yeah um I can say for example uh for these multiple Regional deployment uh fist has not uh doesn't have this configuration uh to materialize a subset of data in each region we have to create a a customization on top of the Fist
(3:02:38) configuration file that's one limitation uh we also uh had another limitation in terms of performance on the uh the F SDK uh to get line features from radis we we were able to optimize some parts of the code that fast metadata um but yeah we don't use the on demand features but I think for this uh for this use case that I've presented it is good so far so good let's see really thanks very much brano okay um it's time for a break everyone um we're going to start again it's slightly less than 10
(3:03:22) minutes now 8 minutes time um I'm going to spin off and maybe get something to eat or something to drink but uh I'll see you all at 5 to the hour unless you're in India then it'll be 5 to the half hour okay thanks okay welcome
