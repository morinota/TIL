## refs:

- [Icebergテーブルの内部構造について](https://yassan.hatenablog.jp/entry/advent-calendar-2023-1201)

## Icebergテーブル形式の内部構造について

- Icebergテーブルのアーキテクチャは、**大きく3種のコンポーネント**で構成される。
  - カタログ
  - メタデータ層
  - データ層

下流側からデータ層 → メタデータ層 → カタログの順にまとめる。
  
### コンポーネント1: データ層:

- 実際のデータを格納する層。
  - 主にデータファイル自体で構成され、**クエリしたユーザに結果を返すために必要なデータを提供**する。
  - ただし、**後述のメタデータ層の構造体が結果を返す例外もある(ex. ある列の最大値など)**。
- データ層は分散ファイルシステム(HDFS)やオブジェクトストレージ(Amazon S3など)に対応。実際には、以下の**3つ**で構成される。
  - データファイル
  - 削除ファイル
  - Puffinファイル

- データファイル:
  - データそのものを格納。
  - ファイル形式にとらわれず、列指向に適したParquetやORC、行指向でストリーミングなどの書き込み性能重視のAvroに対応。
    - **なので、テーブルのワークロードに合わせたファイル形式を選択できる!**
      - (まあSagemaker Feature Storeのオフラインストア機能ではparquet固定...!:pray:)
    - 注意点: この特性はHiveテーブル形式(=Glueテーブル形式)と同じ。しかし**Icebergの場合は単一のテーブル中に複数のファイル形式を持つことも可能**!
      - なので、**SparkなどストリーミングでデータレイクにSinkする際はWrite重視のAvroを用い、テーブルをクエリする際にパフォーマンス出るようにRead重視のParquetに「後から」変換する**、と言った戦略を取ることが可能...!!
- 削除ファイル:
  - **テーブル内のどのレコードが削除されたかを追跡**する際に利用する。
    - (Feature Storeのオフラインストアで運用する場合は、基本的にはappend-onlyなのであまり意識しないかも...!!:thinking:)
  - 削除や更新の際は、Copy-On-Write（CoW）と、Merge-On-Read（MoR）の**2種類の戦略**がある。
    - Copy-On-Write（CoW）:
      - 削除・更新操作の際、古いファイルをコピーして、変更を反映した新しいファイルを用意する。
      - **この場合、読込み時は速いが、書き込みに時間がかかる**。
    - Merge-On-Read（MoR）:
      - 新しいファイルに削除・更新といった変更点だけを書き込んだ削除ファイルを用意する。そして読み込む際に、削除ファイルとデータファイルをマージして結果を返す。
      - これは書き込みは速いが、読み込みが遅くなる。
      - 注意点: **Merge-On-Read（MoR）戦略をとったとしても、後から、削除ファイルをマージして新しいデータファイルを作成することも可能**!
  - 削除ファイルの戦略にも「位置削除」と「均等削除」の2種類があるらしい。
- Puffinファイル:
  - データファイルやメタデータファイルに格納される統計情報よりも更に幅広い、**クエリのパフォーマンスを向上させるデータテーブル内のデータに関する統計情報とインデックスを格納**してる。

### コンポーネント2: メタデータ層

- Icebergテーブルの全てのメタデータファイルを含む層。
  - ツリー構造になっていて、全ての操作がメタデータとデータファイルで追跡されてる。
- **メタデータ層のツリーは以下の3つで構成**される。
  - メタデータファイル
  - マニフェストリスト
  - マニフェストファイル
  - (これらはIcebergテーブルの特徴的な機能である、Time Travel・Rollback、Hidden Partitioning、Full Schema Evolutionを実現するために不可欠らしい...!!:thinking:)

これも下から順にまとめる。

- マニフェストファイル:
  - ファイル名は`*****.avro`の形式。
  - データ層内のファイル（データファイル、削除ファイル、Puffinファイル）の追跡と、各ファイルに関する追加の詳細や統計情報を保持してる。
  - **Hiveテーブルと決定的な違いとして、Icebergテーブルはファイルレベルでテーブルにどのようなデータがあるかを追跡してる。**
    - (なるほど、だからただS3の指定の場所にparquetファイルを追加しただけではIcebergテーブルにデータが追加されないのか...!!:thinking:)
  - 各マニフェストファイルには、パーティションのどこに紐づいているか、レコード数、カラムの上限と下限値などの情報が含まれてる。
    - その結果として、**データファイルを開く操作を減らせるのでクエリパフォーマンスの向上が見込める。**
- マニフェストリスト:
  - ファイル名は`snap-*****.avro`の形式。
  - その名の通り、**マニフェストファイル達のリスト(集合)**を意味している。
  - マニフェストリストは「**スナップショットのリスト**」と考えるとイメージしやすい。
    - マニフェストリストには、スナップショット（Icebergテーブルのある時点でのテーブルの状態）を構成する各マニフェストファイルに関する情報がある。
  - マニフェストリストが持っている各マニフェストファイルに関する情報は以下:
    - マニフェストファイルの場所。
    - 追跡するデータファイルのパーティション列の下限および上限。
  - ↑は、**テーブル・スキャンを計画する際にスナップショット内のすべてのマニフェストのスキャンを回避するために使用**できる要約メタデータが含まれる。
  - マニフェストのリストは常に新しいスナップショットを生成するために変更されるため、スナップショットをコミットしようとするたびに新しいマニフェストリストが書き込まれます。
- メタデータファイル:
  - ファイル名は `v{数字}.metadata.json` もしくは `{数字}-{ランダムuuid}.metadata.json` の形式。
    - どちらの形式かはカタログの実装により決まる。
  - **メタデータファイルは、テーブルに関するメタデータを格納**する。
    - 以下の情報が含まれる。
      - テーブルのスキーマ情報。
      - パーティションに関する情報。
      - パーティション情報や履歴
      - テーブルのプロパティ（例えば、オーナーは誰かとか）

### コンポーネント3: カタログ

- **最新のメタデータ(=メタデータファイル?)がどこにあるか**が保持される。
  - その為、カタログの主な要件は、現在のメタデータのポインタを更新するためのアトミックな操作をサポートすることにある。
- カタログの代表的な実装。
  - S3上に、メタデータファイルのバージョン番号を格納したversion-hint.textを作成して管理する「Hadoopカタログ」方式。
  - AWSのサービスとして提供されている「**AWS Glueデータカタログ**」
    - これはIceberg以外のApache HudiやDelta Lakeもサポートしてる。(Hiveテーブル形式もだよね...!:thinking:)

